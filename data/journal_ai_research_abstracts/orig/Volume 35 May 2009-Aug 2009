<cite>Y.  Chali, S.  R. Joty and S.  A. Hasan (2009) "Complex Question Answering: Unsupervised Learning Approaches and Experiments", Volume 35, pages 1-47</cite>
<p class="media"><a href="/media/2784/live-2784-4446-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2784/live-2784-4447-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2784'>doi:10.1613/jair.2784</a></p>
<p>Complex questions that require inferencing and synthesizing information from multiple documents can be seen as a kind of topic-oriented, informative multi-document summarization where the goal is to produce a single text as a compressed version of a set of documents with a minimum loss of relevant information. In this paper, we experiment with one empirical method and two unsupervised statistical machine learning techniques: K-means and Expectation Maximization (EM), for computing relative importance of the sentences. We compare the results of these approaches. Our experiments show that the empirical approach outperforms the other two techniques and EM performs better than K-means. However, the performance of these approaches depends entirely on the feature set used and the weighting of these features. In order to measure the importance and relevance to the user query we extract different kinds of features (i.e. lexical, lexical semantic, cosine similarity, basic element, tree kernel based syntactic and shallow-semantic) for each of the document sentences. We use a local search technique to learn the weights of the features. To the best of our knowledge, no study has used tree kernel functions to encode syntactic/semantic information for more complex tasks such as computing the relatedness between the query sentences and the document sentences in order to generate query-focused summaries (or answers to complex questions). For each of our methods of generating summaries (i.e. empirical, K-means and EM) we show the effects of syntactic and shallow-semantic features over the bag-of-words (BOW) features.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Complex Question Answering: Unsupervised Learning Approaches and Experiments">
<meta name="citation_author" content="Chali, Y.">
<meta name="citation_author" content="Joty, S. R.">
<meta name="citation_author" content="Hasan, S. A.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="47">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2784/live-2784-4446-jair.pdf">

<cite>J.  Hoffmann, P.  Bertoli, M.  Helmert and M.  Pistore (2009) "Message-Based Web Service Composition, Integrity Constraints, and Planning under Uncertainty: A New Connection", Volume 35, pages 49-117</cite>
<p class="media"><a href="/media/2716/live-2716-4457-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2716/live-2716-4456-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2716'>doi:10.1613/jair.2716</a></p>
<p>Thanks to recent advances, AI Planning has become the underlying technique for several applications. Figuring prominently among these is automated Web Service Composition (WSC) at the "capability" level, where services are described in terms of preconditions and effects over ontological concepts. A key issue in addressing WSC as planning is that ontologies are not only formal vocabularies; they also axiomatize the possible relationships between concepts. Such axioms correspond to what has been termed "integrity constraints" in the actions and change literature, and applying a web service is essentially a belief update operation. The reasoning required for belief update is known to be harder than reasoning in the ontology itself. The support for belief update is severely limited in current planning tools.<br />
<br />
Our first contribution consists in identifying an interesting special case of WSC which is both significant and more tractable. The special case, which we term "forward effects", is characterized by the fact that every ramification of a web service application involves at least one new constant generated as output by the web service. We show that, in this setting, the reasoning required for belief update simplifies to standard reasoning in the ontology itself. This relates to, and extends, current notions of "message-based" WSC, where the need for belief update is removed by a strong (often implicit or informal) assumption of "locality" of the individual messages. We clarify the computational properties of the forward effects case, and point out a strong relation to standard notions of planning under uncertainty, suggesting that effective tools for the latter can be successfully adapted to address the former.<br />
<br />
Furthermore, we identify a significant sub-case, named "strictly forward effects", where an actual compilation into planning under uncertainty exists. This enables us to exploit off-the-shelf planning tools to solve message-based WSC in a general form that involves powerful ontologies, and requires reasoning about partial matches between concepts. We provide empirical evidence that this approach may be quite effective, using Conformant-FF as the underlying planner.<br />
</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Message-Based Web Service Composition, Integrity Constraints, and Planning under Uncertainty: A New Connection">
<meta name="citation_author" content="Hoffmann, J.">
<meta name="citation_author" content="Bertoli, P.">
<meta name="citation_author" content="Helmert, M.">
<meta name="citation_author" content="Pistore, M.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="49">
<meta name="citation_lastpage" content="117">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2716/live-2716-4457-jair.pdf">

<cite>S.  D. Ramchurn, C.  Mezzetti, A.  Giovannucci, J.  A. Rodriguez-Aguilar, R.  K. Dash and N.  R. Jennings (2009) "Trust-Based Mechanisms for Robust and Efficient Task Allocation in the Presence of Execution Uncertainty", Volume 35, pages 119-159</cite>
<p class="media"><a href="/media/2751/live-2751-4470-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2751/live-2751-4469-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2751'>doi:10.1613/jair.2751</a></p>
<p>Vickrey-Clarke-Groves (VCG) mechanisms are often used to allocate tasks to selfish and rational agents. VCG mechanisms are  incentive compatible, direct mechanisms that are efficient (i.e., maximise social utility) and individually rational (i.e., agents prefer to join rather than opt out). However, an important assumption of these mechanisms is that the agents will "always" successfully complete their allocated tasks. Clearly, this assumption is unrealistic in many real-world applications, where agents can, and  often do, fail in their endeavours. Moreover, whether an agent is deemed to have failed may be perceived differently by different agents. Such subjective perceptions about an agent's probability of succeeding at a given task are often captured and reasoned about using the notion of "trust". Given this background, in this paper we investigate the design of novel mechanisms that take into account the  trust between agents when allocating tasks.  <br />
<br />
Specifically, we develop a new class of mechanisms, called "trust-based mechanisms", that can take into account multiple subjective measures of the probability of an agent succeeding at a given task and produce allocations  that maximise social utility, whilst ensuring that no agent obtains a negative utility. We then show that such mechanisms pose a challenging new combinatorial optimisation problem (that is  NP-complete),  devise a novel representation for solving the problem, and develop an effective integer programming solution (that can solve instances with about 2x10^5 possible allocations in 40 seconds). <br />
</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Trust-Based Mechanisms for Robust and Efficient Task Allocation in the Presence of Execution Uncertainty">
<meta name="citation_author" content="Ramchurn, S. D.">
<meta name="citation_author" content="Mezzetti, C.">
<meta name="citation_author" content="Giovannucci, A.">
<meta name="citation_author" content="Rodriguez-Aguilar, J. A.">
<meta name="citation_author" content="Dash, R. K.">
<meta name="citation_author" content="Jennings, N. R.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="119">
<meta name="citation_lastpage" content="159">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2751/live-2751-4470-jair.pdf">

<cite>V.  Conitzer (2009) "Eliciting Single-Peaked Preferences Using Comparison Queries", Volume 35, pages 161-191</cite>
<p class="media"><a href="/media/2606/live-2606-4473-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2606/live-2606-4474-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2606'>doi:10.1613/jair.2606</a></p>
<p>Voting is a general method for aggregating the preferences of multiple agents.  Each agent ranks all the possible alternatives, and based on this, an aggregate ranking of the alternatives (or at least a winning alternative) is produced.  However, when there are many alternatives, it is impractical to simply ask agents to report their complete preferences. Rather, the agents' preferences, or at least the relevant parts thereof, need to be elicited.  This is done by asking the agents a (hopefully small) number of simple queries about their preferences, such as comparison queries, which ask an agent to compare two of the alternatives.  Prior work on preference elicitation in voting has focused on the case of unrestricted preferences.  It has been shown that in this setting, it is sometimes necessary to ask each agent (almost) as many queries as would be required to determine an arbitrary ranking of the alternatives.  In contrast, in this paper, we focus on single-peaked preferences.  We show that such preferences can be elicited using only a linear number of comparison queries, if either the order with respect to which preferences are single-peaked is known, or at least one other agent's complete preferences are known.  We show that using a sublinear number of queries does not suffice.  We also consider the case of cardinally single-peaked preferences.  For this case, we show that if the alternatives' cardinal positions are known, then an agent's preferences can be elicited using only a logarithmic number of queries; however, we also show that if the cardinal positions are not known, then a sublinear number of queries does not suffice.  We present experimental results for all elicitation algorithms.  We also consider the problem of only eliciting enough information to determine the aggregate ranking, and show that even for this more modest objective, a sublinear number of queries per agent does not suffice for known ordinal or unknown cardinal positions.  Finally, we discuss whether and how these techniques can be applied when preferences are almost single-peaked.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Eliciting Single-Peaked Preferences Using Comparison Queries">
<meta name="citation_author" content="Conitzer, V.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="161">
<meta name="citation_lastpage" content="191">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2606/live-2606-4473-jair.pdf">

<cite>R.  El-Yaniv and D.  Pechyony (2009) "Transductive Rademacher Complexity and its Applications", Volume 35, pages 193-234</cite>
<p class="media"><a href="/media/2587/live-2587-4482-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2587/live-2587-4486-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2587'>doi:10.1613/jair.2587</a></p>
<p>We develop a technique for deriving data-dependent error bounds for transductive learning algorithms based on transductive Rademacher complexity. Our technique is based on a novel general error bound for transduction in terms of transductive Rademacher complexity, together with a novel bounding technique for Rademacher averages for particular algorithms, in terms of their "unlabeled-labeled" representation. This technique is relevant to many advanced graph-based transductive algorithms and we demonstrate its effectiveness by deriving error bounds to three well known algorithms. Finally, we present a new PAC-Bayesian bound for mixtures of transductive algorithms based on our Rademacher bounds.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Transductive Rademacher Complexity and its Applications">
<meta name="citation_author" content="El-Yaniv, R.">
<meta name="citation_author" content="Pechyony, D.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="193">
<meta name="citation_lastpage" content="234">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2587/live-2587-4482-jair.pdf">

<cite>M.  Petrik and S.  Zilberstein (2009) "A Bilinear Programming Approach for Multiagent Planning", Volume 35, pages 235-274</cite>
<p class="media"><a href="/media/2673/live-2673-4491-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2673/live-2673-4490-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2673'>doi:10.1613/jair.2673</a></p>
<p>Multiagent planning and coordination problems are common and known to be computationally hard.  We show that a wide range of two-agent problems can be formulated as bilinear programs.  We present a successive approximation algorithm that significantly outperforms the coverage set algorithm, which is the state-of-the-art method for this class of multiagent problems. Because the algorithm is formulated for bilinear programs, it is more general and simpler to implement. The new algorithm can be terminated at any time and-unlike the coverage set algorithm-it facilitates the derivation of a useful online performance bound. It is also much more efficient, on average reducing the computation time of the optimal solution by about four orders of magnitude.  Finally, we introduce an automatic dimensionality reduction method that improves the effectiveness of the algorithm, extending its applicability to new domains and providing a new way to analyze a subclass of bilinear programs.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="A Bilinear Programming Approach for Multiagent Planning">
<meta name="citation_author" content="Petrik, M.">
<meta name="citation_author" content="Zilberstein, S.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="235">
<meta name="citation_lastpage" content="274">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2673/live-2673-4491-jair.pdf">

<cite>P.  Faliszewski, E.  Hemaspaandra, L.  A. Hemaspaandra and J.  Rothe (2009) "Llull and Copeland Voting Computationally Resist Bribery and Constructive Control", Volume 35, pages 275-341</cite>
<p class="media"><a href="/media/2697/live-2697-4493-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2697/live-2697-4492-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2697'>doi:10.1613/jair.2697</a></p>
<p>Control and bribery are settings in which an external agent seeks to influence the outcome of an election.  Constructive control of elections refers to attempts by an agent to, via such actions as addition/deletion/partition of candidates or voters, ensure that a given candidate wins.  Destructive control refers to attempts by an agent to, via the same actions, preclude a given candidate's victory. An election system in which an agent can sometimes affect the result and it can be determined in polynomial time on which inputs the agent can succeed is said to be vulnerable to the given type of control.  An election system in which an agent can sometimes affect the result, yet in which it is NP-hard to recognize the inputs on which the agent can succeed, is said to be resistant to the given type of control.<br />
<br />
Aside from election systems with an NP-hard winner problem, the only systems previously known to be resistant to all the standard control types were highly artificial election systems created by hybridization.  This paper studies a parameterized version of Copeland voting, denoted by Copeland^\alpha, where the parameter \alpha is a rational number between 0 and 1 that specifies how ties are valued in the pairwise comparisons of candidates.  In every previously studied constructive or destructive control scenario, we determine which of resistance or vulnerability holds for Copeland^\alpha for each rational \alpha, 0 \leq \alpha \leq 1.  In particular, we prove that Copeland^{0.5}, the system commonly referred to as ``Copeland voting,'' provides full resistance to constructive control, and we prove the same for Copeland^\alpha, for all rational \alpha, 0 < \alpha < 1.  Among systems with a polynomial-time winner problem, Copeland voting is the first natural election system proven to have  full resistance to constructive control.  In addition, we prove that both Copeland^0 and Copeland^1 (interestingly, Copeland^1 is an election system developed by the thirteenth-century mystic Llull) are resistant to all standard types of constructive control other than one variant of addition of candidates.  Moreover, we show that for each rational \alpha, 0 \leq \alpha \leq 1, Copeland^\alpha voting is fully resistant to bribery attacks, and we establish fixed-parameter tractability of bounded-case control for Copeland^\alpha.<br />
<br />
We also study Copeland^\alpha elections under more flexible models such as microbribery and extended control, we integrate the potential irrationality of voter preferences into many of our results, and we prove our results in both the unique-winner model and the nonunique-winner model.  Our vulnerability results for microbribery are proven via a novel technique involving min-cost network flow.<br />
</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Llull and Copeland Voting Computationally Resist Bribery and Constructive Control">
<meta name="citation_author" content="Faliszewski, P.">
<meta name="citation_author" content="Hemaspaandra, E.">
<meta name="citation_author" content="Hemaspaandra, L. A.">
<meta name="citation_author" content="Rothe, J.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="275">
<meta name="citation_lastpage" content="341">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2697/live-2697-4493-jair.pdf">

<cite>R.  Sebastiani and M.  Vescovi (2009) "Automated Reasoning in Modal and Description Logics via SAT Encoding: the Case Study of K(m)/ALC-Satisfiability", Volume 35, pages 343-389</cite>
<p class="media"><a href="/media/2675/live-2675-4501-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2675/live-2675-4502-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2675'>doi:10.1613/jair.2675</a></p>
<p>In the last two decades, modal and description logics have been applied to numerous areas of computer science, including knowledge representation, formal verification, database theory, distributed computing and, more recently, semantic web and ontologies. For this reason, the problem of automated reasoning in modal and description logics has been thoroughly investigated. In particular, many approaches have been proposed for efficiently handling the satisfiability of the core normal modal logic K(m), and of its notational variant, the description logic ALC. Although simple in structure, K(m)/ALC is computationally very hard to reason on, its satisfiability being PSPACE-complete.  <br />
<br />
In this paper we start exploring the idea of performing automated reasoning tasks in modal and description logics by encoding them into SAT, so that to be handled by state-of-the-art SAT tools; as with most previous approaches, we begin our investigation from the satisfiability in K(m). We propose an efficient encoding, and we test it on an extensive set of benchmarks, comparing the approach with the main state-of-the-art tools available. Although the encoding is necessarily worst-case exponential, from our experiments we notice that, in practice, this approach can handle most or all the problems which are at the reach of  the other approaches, with performances which are comparable with, or even better than, those of the current state-of-the-art tools.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Automated Reasoning in Modal and Description Logics via SAT Encoding: the Case Study of K(m)/ALC-Satisfiability">
<meta name="citation_author" content="Sebastiani, R.">
<meta name="citation_author" content="Vescovi, M.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="343">
<meta name="citation_lastpage" content="389">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2675/live-2675-4501-jair.pdf">

<cite>R.  Daly and Q.  Shen (2009) "Learning Bayesian Network Equivalence Classes with Ant Colony Optimization", Volume 35, pages 391-447</cite>
<p class="media"><a href="/media/2681/live-2681-4509-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2681/live-2681-4508-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2681'>doi:10.1613/jair.2681</a></p>
<p>Bayesian networks are a useful tool in the representation of uncertain knowledge. This paper proposes a new algorithm called ACO-E, to learn the structure of a Bayesian network. It does this by conducting a search through the space of equivalence classes of Bayesian networks using Ant Colony Optimization (ACO). To this end, two novel extensions of traditional ACO techniques are proposed and implemented. Firstly, multiple types of moves are allowed. Secondly, moves can be given in terms of indices that are not based on construction graph nodes. The results of testing show that ACO-E performs better than a greedy search and other state-of-the-art and metaheuristic algorithms whilst searching in the space of equivalence classes.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Learning Bayesian Network Equivalence Classes with Ant Colony Optimization">
<meta name="citation_author" content="Daly, R.">
<meta name="citation_author" content="Shen, Q.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="391">
<meta name="citation_lastpage" content="447">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2681/live-2681-4509-jair.pdf">

<cite>F.  Bromberg, D.  Margaritis and V.  Honavar (2009) "Efficient Markov Network Structure Discovery Using Independence Tests", Volume 35, pages 449-484</cite>
<p class="media"><a href="/media/2773/live-2773-4549-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2773/live-2773-4550-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2773'>doi:10.1613/jair.2773</a></p>
<p>  We present two algorithms for learning the structure of a Markov network from data:  GSMN* and GSIMN.  Both algorithms use statistical independence tests to infer the structure by successively constraining the set of structures consistent with the results of these tests.  Until very recently, algorithms for structure learning were based on maximum likelihood estimation, which has been proved to be NP-hard for Markov networks due to the difficulty of estimating the parameters of the network, needed for the computation of the data likelihood.  The independence-based approach does not require the computation of the likelihood, and thus both GSMN* and GSIMN can compute the structure efficiently (as shown in our experiments).  GSMN* is an adaptation of the Grow-Shrink algorithm of Margaritis and Thrun for learning the structure of Bayesian networks.  GSIMN extends GSMN* by additionally exploiting Pearl's well-known properties of the conditional independence relation to infer novel independences from known ones, thus avoiding the performance of statistical tests to estimate them.  To accomplish this efficiently GSIMN uses the Triangle theorem, also introduced in this work, which is a simplified version of the set of Markov axioms.  Experimental comparisons on artificial and real-world data sets show GSIMN can yield significant savings with respect to GSMN*, while generating a Markov network with comparable or in some cases improved quality.  We also compare GSIMN to a forward-chaining implementation, called GSIMN-FCH, that produces all possible conditional independences resulting from repeatedly applying  Pearl's theorems on the known conditional independence tests.   The results of this comparison show that GSIMN, by the sole use of the Triangle theorem, is nearly optimal in terms of the set of independences tests that it infers.<br />
</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Efficient Markov Network Structure Discovery Using Independence Tests">
<meta name="citation_author" content="Bromberg, F.">
<meta name="citation_author" content="Margaritis, D.">
<meta name="citation_author" content="Honavar, V.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="449">
<meta name="citation_lastpage" content="484">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2773/live-2773-4549-jair.pdf">

<cite>P.  Faliszewski, E.  Hemaspaandra and L.  A. Hemaspaandra (2009) "How Hard Is Bribery in Elections?", Volume 35, pages 485-532</cite>
<p class="media"><a href="/media/2676/live-2676-4535-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2676/live-2676-4536-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2676'>doi:10.1613/jair.2676</a></p>
<p>We study the complexity of influencing elections through bribery: How computationally complex is it for an external actor to determine whether by paying certain voters to change their preferences a specified candidate can be made the election’s winner?  We study this problem for election systems as varied as scoring protocols and Dodgson voting, and in a variety of settings regarding homogeneous-vs.-nonhomogeneous electorate bribability, bounded-size-vs.-arbitrary-sized candidate sets, weighted-vs.-unweighted voters, and succinct-vs.-nonsuccinct input specification.  We obtain both polynomial-time bribery algorithms and proofs of the intractability of bribery, and indeed our results show that the complexity of bribery is extremely sensitive to the setting.  For example, we find settings in which bribery is NP-complete but manipulation (by voters) is in P, and we find settings in which bribing weighted voters is NP-complete but bribing voters with individual bribe thresholds is in P.  For the broad class of elections (including plurality, Borda, k-approval, and veto) known as scoring protocols, we prove a dichotomy result for bribery of weighted voters: We find a simple-to-evaluate condition that classifies every case as either NP-complete or in P.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="How Hard Is Bribery in Elections?">
<meta name="citation_author" content="Faliszewski, P.">
<meta name="citation_author" content="Hemaspaandra, E.">
<meta name="citation_author" content="Hemaspaandra, L. A.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="485">
<meta name="citation_lastpage" content="532">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2676/live-2676-4535-jair.pdf">

<cite>J.  E. Gallardo, C.  Cotta and A.  J. Fern&#225;ndez (2009) "Solving Weighted Constraint Satisfaction Problems with Memetic/Exact Hybrid Algorithms", Volume 35, pages 533-555</cite>
<p class="media"><a href="/media/2770/live-2770-4543-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2770/live-2770-4544-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2770'>doi:10.1613/jair.2770</a></p>
<p>A weighted constraint satisfaction problem (WCSP) is a constraint satisfaction problem in which preferences among solutions can be expressed. Bucket elimination is a complete technique commonly used to solve this kind of constraint satisfaction problem. When the memory required to apply bucket elimination is too high, a heuristic method based on it (denominated mini-buckets) can be used to calculate bounds for the optimal solution. Nevertheless, the curse of dimensionality makes these techniques impractical on large scale problems. In response to this situation, we present a memetic algorithm for WCSPs in which bucket elimination is used as a mechanism for recombining solutions, providing the best possible child from the parental set. Subsequently, a multi-level model in which this exact/metaheuristic hybrid is further hybridized with branch-and-bound techniques and mini-buckets is studied. As a case study, we have applied these algorithms to the resolution of the maximum density still life problem, a hard constraint optimization problem based on Conway's game of life. The resulting algorithm consistently finds optimal patterns for up to date solved instances in less time than current approaches. Moreover, it is shown that this proposal provides new best known solutions for very large instances.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Solving Weighted Constraint Satisfaction Problems with Memetic/Exact Hybrid Algorithms">
<meta name="citation_author" content="Gallardo, J. E.">
<meta name="citation_author" content="Cotta, C.">
<meta name="citation_author" content="Fern&#225;ndez, A. J.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="533">
<meta name="citation_lastpage" content="555">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2770/live-2770-4543-jair.pdf">

<cite>A.  Krause and C.  Guestrin (2009) "Optimal Value of Information in Graphical Models", Volume 35, pages 557-591</cite>
<cite>Honorable Mention for the 2012 IJCAI-JAIR Best Paper Prize</cite><p class="media"><a href="/media/2737/live-2737-5812-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2737/live-2737-5813-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2737'>doi:10.1613/jair.2737</a>
<br/><a href="/media/2737/live-2737-5814-jair.txt">Appendix 1</a> - Erratum&nbsp;|&nbsp;<a href="/media/2737/live-2737-5815-jair.pdf">Appendix 2</a> - Original Version</p>
<p>Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. In medical decision making tasks, one needs to select which tests to administer before deciding on the most effective treatment. It has been general practice to use heuristic-guided procedures for selecting observations. In this paper, we present the first efficient optimal algorithms for selecting observations for a class of probabilistic graphical models. For example, our algorithms allow to optimally label hidden variables in Hidden Markov Models (HMMs). We provide results for both selecting the optimal subset of observations, and for obtaining an optimal conditional observation plan.<br />
<br />
Furthermore we prove a surprising result: In most graphical models tasks, if one designs an efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytree graphical models. We prove that the optimizing value of information is $NP^{PP}$-hard even for polytrees. It also follows from our results that just computing decision theoretic value of information objective functions, which are commonly used in practice, is a #P-complete problem even on Naive Bayes models (a simple special case of polytrees).<br />
<br />
In addition, we consider several extensions, such as using our algorithms for scheduling observation selection for multiple sensors. We demonstrate the effectiveness of our approach on several real-world datasets, including a prototype sensor network deployment for energy conservation in buildings.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Optimal Value of Information in Graphical Models">
<meta name="citation_author" content="Krause, A.">
<meta name="citation_author" content="Guestrin, C.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="557">
<meta name="citation_lastpage" content="591">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2737/live-2737-5815-jair.pdf">

<cite>M.  Zytnicki, C.  Gaspin, S.  de Givry and T.  Schiex (2009) "Bounds Arc Consistency for Weighted CSPs", Volume 35, pages 593-621</cite>
<p class="media"><a href="/media/2797/live-2797-4566-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2797/live-2797-4565-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2797'>doi:10.1613/jair.2797</a></p>
<p>  The Weighted Constraint Satisfaction Problem (WCSP) framework allows representing and solving problems involving both hard constraints and cost functions. It has been applied to various problems, including resource allocation, bioinformatics, scheduling, etc. To solve such problems, solvers usually rely on branch-and-bound algorithms equipped with local consistency filtering, mostly soft arc consistency.  However, these techniques are not well suited to solve problems with very large domains. Motivated by the resolution of an RNA gene localization problem inside large genomic sequences, and in the spirit of bounds consistency for large domains in crisp CSPs, we introduce soft bounds arc consistency, a new weighted local consistency specifically designed for WCSP with very large domains. Compared to  soft arc consistency, BAC provides significantly improved time and space asymptotic complexity. In this paper, we show how the semantics of cost functions can be exploited to further improve the time complexity of BAC. We also compare both in theory and in practice the efficiency of BAC on a WCSP  with bounds consistency enforced on a crisp CSP using cost variables. On two different real problems modeled as WCSP, including our RNA gene localization problem, we observe that maintaining bounds arc consistency outperforms arc consistency and also improves over bounds consistency enforced on a constraint model with cost variables.<br />
</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Bounds Arc Consistency for Weighted CSPs">
<meta name="citation_author" content="Zytnicki, M.">
<meta name="citation_author" content="Gaspin, C.">
<meta name="citation_author" content="de Givry, S.">
<meta name="citation_author" content="Schiex, T.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="593">
<meta name="citation_lastpage" content="621">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2797/live-2797-4566-jair.pdf">

<cite>H.  Palacios and H.  Geffner (2009) "Compiling Uncertainty Away in Conformant Planning Problems with Bounded Width", Volume 35, pages 623-675</cite>
<cite>2012 IJCAI-JAIR Best Paper Prize</cite><p class="media"><a href="/media/2708/live-2708-4594-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2708/live-2708-4595-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2708'>doi:10.1613/jair.2708</a></p>
<p>Conformant planning is the problem of finding a sequence of actions for achieving a goal in the presence of uncertainty in the initial state or action effects.  The problem has been approached as a path-finding problem in belief space where good belief representations and heuristics are critical for scaling up.  In this work, a different formulation is introduced for conformant problems with deterministic actions where they are automatically converted into classical ones and solved by an off-the-shelf classical planner.  The translation maps literals L and sets of assumptions t about the initial situation, into new literals KL/t that represent that L must be true if t is initially true.  We lay out a general translation scheme that is sound and establish the conditions under which the translation is also complete.  We show that the complexity of the complete translation is exponential in a parameter of the problem called the conformant width, which for most benchmarks is bounded. The planner based on this translation exhibits good performance in comparison with existing planners, and is the basis for T0, the best performing planner in the Conformant Track of the 2006 International Planning Competition.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Compiling Uncertainty Away in Conformant Planning Problems with Bounded Width">
<meta name="citation_author" content="Palacios, H.">
<meta name="citation_author" content="Geffner, H.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="623">
<meta name="citation_lastpage" content="675">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2708/live-2708-4594-jair.pdf">

<cite>K.  Su, A.  Sattar, G.  Lv and Y.  Zhang (2009) "Variable Forgetting in Reasoning about Knowledge", Volume 35, pages 677-716</cite>
<p class="media"><a href="/media/2750/live-2750-4602-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2750/live-2750-4601-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2750'>doi:10.1613/jair.2750</a></p>
<p>In this paper, we investigate knowledge reasoning within a simple framework called knowledge structure. We use variable forgetting as a basic operation for one agent to reason about its own or other agents\' knowledge. In our framework, two notions namely agents\' observable variables and the weakest sufficient condition play important roles in knowledge reasoning. Given a background knowledge base and a set of observable variables for each agent, we show that the notion of an agent knowing a formula can be defined as a weakest sufficient condition of the formula under background knowledge base. Moreover, we show how to capture the notion of common knowledge by using a generalized notion of weakest sufficient condition. Also, we show that public announcement operator can be conveniently dealt with via our notion of knowledge structure. Further, we explore the computational complexity of the problem whether an epistemic formula is realized in a knowledge structure. In the general case, this problem is PSPACE-hard; however, for some interesting subcases, it can be reduced to co-NP. Finally, we discuss possible applications of our framework in some interesting domains such as the automated analysis of the well-known muddy children puzzle and the verification of the revised Needham-Schroeder protocol. We believe that there are many scenarios where the natural presentation of the available information about knowledge is under the form of a knowledge structure. What makes it valuable compared with the corresponding multi-agent S5 Kripke structure is that it can be much more succinct.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Variable Forgetting in Reasoning about Knowledge">
<meta name="citation_author" content="Su, K.">
<meta name="citation_author" content="Sattar, A.">
<meta name="citation_author" content="Lv, G.">
<meta name="citation_author" content="Zhang, Y.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="677">
<meta name="citation_lastpage" content="716">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2750/live-2750-4602-jair.pdf">

<cite>P.  A. Bonatti, C.  Lutz and F.  Wolter (2009) "The Complexity of Circumscription in DLs", Volume 35, pages 717-773</cite>
<p class="media"><a href="/media/2763/live-2763-4607-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2763/live-2763-4606-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2763'>doi:10.1613/jair.2763</a></p>
<p>As fragments of first-order logic, Description logics (DLs) do not provide nonmonotonic features such as defeasible inheritance and default rules. Since many applications would benefit from the availability of such features, several families of nonmonotonic DLs have been developed that are mostly based on default logic and autoepistemic logic. In this paper, we consider circumscription as an interesting alternative approach to nonmonotonic DLs that, in particular, supports defeasible inheritance in a natural way. We study DLs extended with circumscription under different language restrictions and under different constraints on the sets of minimized, fixed, and varying predicates, and pinpoint the exact computational complexity of reasoning for DLs ranging from ALC to ALCIO and ALCQO.  When the minimized and fixed predicates include only concept names but no role names, then reasoning is complete for NExpTime^NP.  It becomes complete for NP^NExpTime when the number of minimized and fixed predicates is bounded by a constant.  If roles can be minimized or fixed, then complexity ranges from NExpTime^NP to undecidability.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="The Complexity of Circumscription in DLs">
<meta name="citation_author" content="Bonatti, P. A.">
<meta name="citation_author" content="Lutz, C.">
<meta name="citation_author" content="Wolter, F.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="717">
<meta name="citation_lastpage" content="773">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2763/live-2763-4607-jair.pdf">

<cite>E.  Saquete, J.  Luis Vicedo, P.  Mart&#237;nez-Barco, R.  Mu&#241;oz and H.  Llorens (2009) "Enhancing QA Systems with Complex Temporal Question Processing Capabilities", Volume 35, pages 775-811</cite>
<p class="media"><a href="/media/2805/live-2805-4611-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2805/live-2805-4610-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2805'>doi:10.1613/jair.2805</a></p>
<p>This paper presents a multilayered architecture that enhances the capabilities of current QA systems and allows different types of complex questions or queries to be processed. The answers to these questions need to be gathered from factual information scattered throughout different documents. Specifically, we designed a specialized layer to process the different types of temporal questions. Complex temporal questions are first decomposed into simple questions, according to the temporal relations expressed in the original question. In the same way, the answers to the resulting simple questions are recomposed, fulfilling the temporal restrictions of the original complex question. A novel aspect of this approach resides in the decomposition which uses a minimal quantity of resources, with the final aim of obtaining a portable platform that is easily extensible to other languages. In this paper we also present a methodology for evaluation of the decomposition of the questions as well as the ability of the implemented temporal layer to perform at a multilingual level. The temporal layer was first performed for English, then evaluated and compared with: a) a general purpose QA system (F-measure 65.47% for QA plus English temporal layer vs. 38.01% for the general QA system), and b) a well-known QA system. Much better results were obtained for temporal questions with the multilayered system. This system was therefore extended to Spanish and very good results were again obtained in the evaluation (F-measure 40.36% for QA plus Spanish temporal layer vs. 22.94% for the general QA system).</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Enhancing QA Systems with Complex Temporal Question Processing Capabilities">
<meta name="citation_author" content="Saquete, E.">
<meta name="citation_author" content="Vicedo, J. Luis">
<meta name="citation_author" content="Mart&#237;nez-Barco, P.">
<meta name="citation_author" content="Mu&#241;oz, R.">
<meta name="citation_author" content="Llorens, H.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="775">
<meta name="citation_lastpage" content="811">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2805/live-2805-4611-jair.pdf">

<cite>T.  Janhunen, E.  Oikarinen, H.  Tompits and S.  Woltran (2009) "Modularity Aspects of Disjunctive Stable Models", Volume 35, pages 813-857</cite>
<p class="media"><a href="/media/2810/live-2810-4615-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/2810/live-2810-4614-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.2810'>doi:10.1613/jair.2810</a></p>
<p>Practically all programming languages allow the programmer to split a program into several modules which brings along several advantages in software development. In this paper, we are interested in the area of answer-set programming where fully declarative and nonmonotonic languages are applied. In this context, obtaining a modular structure for programs is by no means straightforward since the output of an entire program cannot in general be composed from the output of its components. To better understand the effects of disjunctive information on modularity we restrict the scope of analysis to the case of disjunctive logic programs (DLPs) subject to stable-model semantics. We define the notion of a DLP-function, where a well-defined input/output interface is provided, and establish a novel module theorem which indicates the compositionality of stable-model semantics for DLP-functions. The module theorem extends the well-known splitting-set theorem and enables the decomposition of DLP-functions given their strongly connected components based on positive dependencies induced by rules. In this setting, it is also possible to split shared disjunctive rules among components using a generalized shifting technique. The concept of modular equivalence is introduced for the mutual comparison of DLP-functions using a generalization of a translation-based verification method.</p>
<a href="/vol/vol35.html">Click here to return to Volume 35 contents list</a>
<meta name="citation_title" content="Modularity Aspects of Disjunctive Stable Models">
<meta name="citation_author" content="Janhunen, T.">
<meta name="citation_author" content="Oikarinen, E.">
<meta name="citation_author" content="Tompits, H.">
<meta name="citation_author" content="Woltran, S.">
<meta name="citation_publication_date" content="2009">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="813">
<meta name="citation_lastpage" content="857">
<meta name="citation_volume" content="35">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/2810/live-2810-4615-jair.pdf">
