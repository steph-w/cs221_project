<cite>A.  J. Coles, A.  I. Coles, M.  Fox and D.  Long (2012) "COLIN: Planning with Continuous Linear Numeric Change", Volume 44, pages 1-96</cite>
<p class="media"><a href="/media/3608/live-3608-6277-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3608/live-3608-6276-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3608'>doi:10.1613/jair.3608</a>
<br/><a href="/media/3608/live-3608-6280-jair.tgz">Appendix </a> - Data Files</p>
<p>In this paper we describe COLIN, a forward-chaining heuristic search planner, capable of reasoning with COntinuous LINear numeric change, in addition to the full temporal semantics of PDDL.  Through this work we make two advances to the state-of-the-art in terms of expressive reasoning capabilities of planners: the handling of continuous linear change, and the handling of duration-dependent effects in combination with duration inequalities, both of which require tightly coupled temporal and numeric reasoning during planning.  COLIN combines FF-style forward chaining search, with the use of a Linear Program (LP) to check the consistency of the interacting temporal and numeric constraints at each state.  The LP is used to compute bounds on the values of variables in each state, reducing the range of actions that need to be considered for application.  In addition, we develop an extension of the Temporal Relaxed Planning Graph heuristic of CRIKEY3, to support reasoning directly with continuous change.  We extend the range of task variables considered to be suitable candidates for specifying the gradient of the continuous numeric change effected by an action.  Finally, we explore the potential for employing mixed integer programming as a tool for optimising the timestamps of the actions in the plan, once a solution has been found. To support this, we further contribute a selection of extended benchmark domains that include continuous numeric effects.  We present results for COLIN that demonstrate its scalability on a range of benchmarks, and compare to existing state-of-the-art planners. <br />
</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="COLIN: Planning with Continuous Linear Numeric Change">
<meta name="citation_author" content="Coles, A. J.">
<meta name="citation_author" content="Coles, A. I.">
<meta name="citation_author" content="Fox, M.">
<meta name="citation_author" content="Long, D.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="96">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3608/live-3608-6277-jair.pdf">

<cite>D.  D. Maua, C.  P. de Campos and M.  Zaffalon (2012) "Solving Limited Memory Influence Diagrams", Volume 44, pages 97-140</cite>
<p class="media"><a href="/media/3625/live-3625-6282-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3625/live-3625-6281-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3625'>doi:10.1613/jair.3625</a></p>
<p>We present a new algorithm for exactly solving decision making problems represented as influence diagrams. We do not require the usual assumptions of no forgetting and regularity; this allows us to solve problems with simultaneous decisions and limited information. The algorithm is empirically shown to outperform a state-of-the-art algorithm on randomly generated problems of up to 150 variables and 10^64 solutions. We show that these problems are NP-hard even if the underlying graph structure of the problem has low treewidth and the variables take on a bounded number of  states, and that they admit no provably good approximation if variables can take on an arbitrary number of states.<br />
</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Solving Limited Memory Influence Diagrams">
<meta name="citation_author" content="Maua, D. D.">
<meta name="citation_author" content="de Campos, C. P.">
<meta name="citation_author" content="Zaffalon, M.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="97">
<meta name="citation_lastpage" content="140">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3625/live-3625-6282-jair.pdf">

<cite>C.  B&#228;ckstr&#246;m and P.  Jonsson (2012) "Algorithms and Limits for Compact Plan Representations", Volume 44, pages 141-177</cite>
<p class="media"><a href="/media/3534/live-3534-6287-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3534/live-3534-6286-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3534'>doi:10.1613/jair.3534</a></p>
<p>Compact representations of objects is a common concept in  computer science.  Automated planning can be viewed as a case of this concept: a planning instance is a compact implicit representation of a graph and the problem is to find a path (a plan) in this graph.  While the graphs themselves are represented compactly as planning instances, the paths are usually represented explicitly as sequences of actions.  Some cases are known where the plans always have compact representations, for example, using macros.  We show that these results do not extend to the general case, by proving a number of bounds for compact representations of plans under various criteria, like efficient sequential or random access of actions.  In addition to this, we show that our results have consequences for what can be gained from reformulating planning into some other problem.  As a contrast to this we also prove a number of positive results, demonstrating restricted cases where plans do have useful compact representations, as well as proving that macro plans have favourable access properties.  Our results are finally discussed in relation to other relevant contexts.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Algorithms and Limits for Compact Plan Representations">
<meta name="citation_author" content="B&#228;ckstr&#246;m, C.">
<meta name="citation_author" content="Jonsson, P.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="141">
<meta name="citation_lastpage" content="177">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3534/live-3534-6287-jair.pdf">

<cite>P.  Nakov and H. T.  Ng (2012) "Improving Statistical Machine Translation for a Resource-Poor Language Using Related Resource-Rich Languages", Volume 44, pages 179-222</cite>
<p class="media"><a href="/media/3540/live-3540-6293-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3540/live-3540-6296-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3540'>doi:10.1613/jair.3540</a></p>
<p>We propose a novel language-independent approach for improving machine translation for resource-poor languages by exploiting their similarity to resource-rich ones. More precisely, we improve the translation from a resource-poor source language X_1 into a resource-rich language Y given a bi-text containing a limited number of parallel sentences for X_1-Y and a larger bi-text for X_2-Y for some resource-rich language X_2 that is closely related to X_1. This is achieved by taking advantage of the opportunities that vocabulary overlap and similarities between the languages X_1 and X_2 in spelling, word order, and syntax offer: (1) we improve the word alignments for the resource-poor language, (2) we further augment it with additional translation options, and (3) we take care of potential spelling differences through appropriate transliteration. The evaluation for Indonesian- >English using Malay and for Spanish -> English using Portuguese and pretending Spanish is resource-poor shows an absolute gain of up to 1.35 and 3.37 BLEU points, respectively, which is an improvement over the best rivaling approaches, while using much less additional data. Overall, our method cuts the amount of necessary "real'' training data by a factor of 2--5.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Improving Statistical Machine Translation for a Resource-Poor Language Using Related Resource-Rich Languages">
<meta name="citation_author" content="Nakov, P.">
<meta name="citation_author" content="Ng, H. T.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="179">
<meta name="citation_lastpage" content="222">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3540/live-3540-6293-jair.pdf">

<cite>W.  Mao and J.  Gratch (2012) "Modeling Social Causality and Responsibility Judgment in Multi-Agent Interactions", Volume 44, pages 223-273</cite>
<p class="media"><a href="/media/3526/live-3526-6298-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3526/live-3526-6297-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3526'>doi:10.1613/jair.3526</a></p>
<p>Social causality is the inference an entity makes about the social behavior of other entities and self. Besides physical cause and effect, social causality involves reasoning about epistemic states of agents and coercive circumstances. Based on such inference, responsibility judgment is the process whereby one singles out individuals to assign responsibility, credit or blame for multi-agent activities. Social causality and responsibility judgment are a key aspect of social intelligence, and a model for them facilitates the design and development of a variety of multi-agent interactive systems. Based on psychological attribution theory, this paper presents a domain-independent computational model to automate social inference and judgment process according to an agent’s causal knowledge and observations of interaction. We conduct experimental studies to empirically validate the computational model. The experimental results show that our model predicts human judgments of social attributions and makes inferences consistent with what most people do in their judgments. Therefore, the proposed model can be generically incorporated into an intelligent system to augment its social and cognitive functionality.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Modeling Social Causality and Responsibility Judgment in Multi-Agent Interactions">
<meta name="citation_author" content="Mao, W.">
<meta name="citation_author" content="Gratch, J.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="223">
<meta name="citation_lastpage" content="273">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3526/live-3526-6298-jair.pdf">

<cite>P.  Ghosh, A.  Sharma, P.P.  Chakrabarti and P.  Dasgupta (2012) "Algorithms for Generating Ordered Solutions for Explicit AND/OR Structures", Volume 44, pages 275-333</cite>
<p class="media"><a href="/media/3576/live-3576-6324-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3576/live-3576-6323-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3576'>doi:10.1613/jair.3576</a></p>
<p>We present algorithms for generating alternative solutions for explicit acyclic AND/OR structures in non-decreasing order of cost. The proposed algorithms use a best first search technique and report the solutions using an implicit representation ordered by cost. In this paper, we present two versions of the search algorithm -- (a) an initial version of the best first search algorithm, ASG, which may present one solution more than once while generating the ordered solutions, and (b) another version, LASG, which avoids the construction of the duplicate solutions. The actual solutions can be reconstructed quickly from the implicit compact representation used. We have applied the methods on a few test domains, some of them are synthetic while the others are based on well known problems including the search space of the 5-peg Tower of Hanoi problem, the matrix-chain multiplication problem and the problem of finding secondary structure of RNA. Experimental results show the efficacy of the proposed algorithms over the existing approach. Our proposed algorithms have potential use in various domains ranging from knowledge based frameworks to service composition, where the AND/OR structure is widely used for representing problems.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Algorithms for Generating Ordered Solutions for Explicit AND/OR Structures">
<meta name="citation_author" content="Ghosh, P.">
<meta name="citation_author" content="Sharma, A.">
<meta name="citation_author" content="Chakrabarti, P.P.">
<meta name="citation_author" content="Dasgupta, P.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="275">
<meta name="citation_lastpage" content="333">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3576/live-3576-6324-jair.pdf">

<cite>M.  Fox, D.  Long and D.  Magazzeni (2012) "Plan-based Policies for Efficient Multiple Battery Load Management", Volume 44, pages 335-382</cite>
<cite>ICAPS 2011 Best Paper Award</cite><p class="media"><a href="/media/3643/live-3643-6341-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3643/live-3643-6342-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3643'>doi:10.1613/jair.3643</a></p>
<p>Efficient use of multiple batteries is a practical problem with wide and growing application. The problem can be cast as a planning problem under uncertainty. We describe the approach we have adopted to modelling and solving this problem, seen as a Markov Decision Problem, building effective policies for battery switching in the face of stochastic load profiles. <br />
<br />
Our solution exploits and adapts several existing techniques: planning for deterministic mixed discrete-continuous problems and Monte Carlo sampling for policy learning. The paper describes the development of planning techniques to allow solution of the non-linear continuous dynamic models capturing the battery behaviours. This approach depends on carefully handled discretisation of the temporal dimension. The construction of policies is performed using a classification approach and this idea offers opportunities for wider exploitation in other problems. The approach and its generality are described in the paper.<br />
<br />
Application of the approach leads to construction of policies that, in simulation, significantly outperform those that are currently in use and the best published solutions to the battery management problem. We achieve solutions that achieve more than 99% efficiency in simulation compared with the theoretical limit and do so with far fewer battery switches than existing policies. Behaviour of physical batteries does not exactly match the simulated models for many reasons, so to confirm that our theoretical results can lead to real measured improvements in performance we also conduct and report experiments using a physical test system. These results demonstrate that we can obtain 5%-15% improvement in lifetimes in the case of a two battery system.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Plan-based Policies for Efficient Multiple Battery Load Management">
<meta name="citation_author" content="Fox, M.">
<meta name="citation_author" content="Long, D.">
<meta name="citation_author" content="Magazzeni, D.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="335">
<meta name="citation_lastpage" content="382">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3643/live-3643-6341-jair.pdf">

<cite>P.  Haslum (2012) "Narrative Planning: Compilations to Classical Planning", Volume 44, pages 383-395</cite>
<p class="media"><a href="/media/3602/live-3602-6347-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3602/live-3602-6346-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3602'>doi:10.1613/jair.3602</a>
<br/><a href="/media/3602/live-3602-6350-jair.tar.gz">Appendix </a> - Source coder and example problems</p>
<p>A model of story generation recently proposed by Riedl and Young<br />
casts it as planning, with the additional condition that story<br />
characters behave intentionally. This means that characters have<br />
perceivable motivation for the actions they take. I show that this<br />
condition can be compiled away (in more ways than one) to produce a<br />
classical planning problem that can be solved by an off-the-shelf<br />
classical planner, more efficiently than by Riedl and Young's<br />
specialised planner.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Narrative Planning: Compilations to Classical Planning">
<meta name="citation_author" content="Haslum, P.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="383">
<meta name="citation_lastpage" content="395">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3602/live-3602-6347-jair.pdf">

<cite>E.  Albacete, J.  Calle, E.  Castro and D.  Cuadra (2012) "Semantic Similarity Measures Applied to an Ontology for Human-Like Interaction", Volume 44, pages 397-421</cite>
<p class="media"><a href="/media/3612/live-3612-6352-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3612/live-3612-6351-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3612'>doi:10.1613/jair.3612</a></p>
<p>The focus of this paper is the calculation of similarity between two concepts from an ontology for a Human-Like Interaction system. In order to facilitate this calculation, a similarity function is proposed based on five dimensions (sort, compositional, essential, restrictive and descriptive) constituting the structure of ontological knowledge. The paper includes a proposal for computing a similarity function for each dimension of knowledge. Later on, the similarity values obtained are weighted and aggregated to obtain a global similarity measure. In order to calculate those weights associated to each dimension, four training methods have been proposed. The training methods differ in the element to fit: the user, concepts or pairs of concepts, and a hybrid approach. For evaluating the proposal, the knowledge base was fed from WordNet and extended by using a knowledge editing toolkit (Cognos). The evaluation of the proposal is carried out through the comparison of system responses with those given by human test subjects, both providing a measure of the soundness of the procedure and revealing ways in which the proposal may be improved.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Semantic Similarity Measures Applied to an Ontology for Human-Like Interaction">
<meta name="citation_author" content="Albacete, E.">
<meta name="citation_author" content="Calle, J.">
<meta name="citation_author" content="Castro, E.">
<meta name="citation_author" content="Cuadra, D.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="397">
<meta name="citation_lastpage" content="421">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3612/live-3612-6352-jair.pdf">

<cite>J.  Velez, G.  Hemann, A.  S. Huang, I.  Posner and N.  Roy (2012) "Modelling Observation Correlations for Active Exploration and Robust Object Detection ", Volume 44, pages 423-453</cite>
<cite>ICAPS 2011 Best Student Paper</cite><p class="media"><a href="/media/3516/live-3516-6375-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3516/live-3516-6374-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3516'>doi:10.1613/jair.3516</a></p>
<p>Today, mobile robots are expected to carry out increasingly complex tasks in multifarious, real-world environments. Often, the tasks require a certain semantic understanding of the workspace. Consider, for example, spoken instructions from a human collaborator referring to objects of interest; the robot must be able to accurately detect these objects to correctly understand the instructions. However, existing object detection, while competent, is not perfect. In particular, the performance of detection algorithms is commonly sensitive to the position of the sensor relative to the objects in the scene.<br />
<br />
This paper presents an online planning algorithm which learns an explicit model of the spatial dependence of object detection and generates plans which maximize the expected performance of the detection, and by extension the overall plan performance. Crucially, the learned sensor model incorporates spatial correlations between measurements, capturing the fact that successive measurements taken at the same or nearby locations are not independent. We show how this sensor model can be incorporated into an efficient forward search algorithm in the information space of detected objects, allowing the robot to generate motion plans efficiently.  We investigate the performance of our approach by addressing the tasks of door and text detection in indoor environments and demonstrate significant improvement in detection performance during task execution over alternative methods in simulated and real robot experiments.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Modelling Observation Correlations for Active Exploration and Robust Object Detection ">
<meta name="citation_author" content="Velez, J.">
<meta name="citation_author" content="Hemann, G.">
<meta name="citation_author" content="Huang, A. S.">
<meta name="citation_author" content="Posner, I.">
<meta name="citation_author" content="Roy, N.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="423">
<meta name="citation_lastpage" content="453">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3516/live-3516-6375-jair.pdf">

<cite>M.  C. Cooper and S.  Zivny (2012) "Tractable Triangles and Cross-Free Convexity in Discrete Optimisation", Volume 44, pages 455-490</cite>
<p class="media"><a href="/media/3598/live-3598-6399-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3598/live-3598-6398-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3598'>doi:10.1613/jair.3598</a></p>
<p>The minimisation problem of a sum of unary and pairwise functions of discrete variables is a general NP-hard problem with wide applications such as computing MAP configurations in Markov Random Fields (MRF), minimising Gibbs energy, or solving binary Valued Constraint Satisfaction Problems (VCSPs).<br />
<br />
We study the computational complexity of classes of discrete optimisation problems given by allowing only certain types of costs in every triangle of variable-value assignments to three distinct variables. We show that for several computational problems, the only non- trivial tractable classes are the well known maximum matching problem and the recently discovered joint-winner property. Our results, apart from giving complete classifications in the studied cases, provide guidance in the search for hybrid tractable classes; that is, classes of problems that are not captured by restrictions on the functions (such as submodularity) or the structure of the problem graph (such as bounded treewidth).<br />
<br />
Furthermore, we introduce a class of problems with convex cardinality functions on cross-free sets of assignments. We prove that while imposing only one of the two conditions renders the problem NP-hard, the conjunction of the two gives rise to a novel tractable class satisfying the cross-free convexity property, which generalises the joint-winner property to problems of unbounded arity.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Tractable Triangles and Cross-Free Convexity in Discrete Optimisation">
<meta name="citation_author" content="Cooper, M. C.">
<meta name="citation_author" content="Zivny, S.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="455">
<meta name="citation_lastpage" content="490">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3598/live-3598-6399-jair.pdf">

<cite>J.  Huang, A.  Kapoor and C.  Guestrin (2012) "Riffled Independence for Efficient Inference with Partial Rankings", Volume 44, pages 491-532</cite>
<p class="media"><a href="/media/3543/live-3543-6403-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3543/live-3543-6402-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3543'>doi:10.1613/jair.3543</a></p>
<p>Distributions over rankings are used to model data in a multitude of real world settings such as preference analysis and political elections. Modeling such distributions presents several computational challenges, however, due to the factorial size of the set of rankings over an item set. Some of these challenges are quite familiar to the artificial intelligence community, such as how to compactly represent a distribution over a combinatorially large space, and how to efficiently perform probabilistic inference with these representations. With respect to ranking, however, there is the additional challenge of what we refer to as human task complexity — users are rarely willing to provide a full ranking over a long list of candidates, instead often preferring to provide partial ranking information.<br />
<br />
Simultaneously addressing all of these challenges — i.e., designing a compactly representable model which is amenable to efficient inference and can be learned using partial ranking data — is a difficult task, but is necessary if we would like to scale to problems with nontrivial size. In this paper, we show that the recently proposed riffled independence assumptions cleanly and efficiently address each of the above challenges. In particular, we establish a tight mathematical connection between the concepts of riffled independence and of partial rankings. This correspondence not only allows us to then develop efficient and exact algorithms for performing inference tasks using riffled independence based represen- tations with partial rankings, but somewhat surprisingly, also shows that efficient inference is not possible for riffle independent models (in a certain sense) with observations which do not take the form of partial rankings. Finally, using our inference algorithm, we introduce the first method for learning riffled independence based models from partially ranked data.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Riffled Independence for Efficient Inference with Partial Rankings">
<meta name="citation_author" content="Huang, J.">
<meta name="citation_author" content="Kapoor, A.">
<meta name="citation_author" content="Guestrin, C.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="491">
<meta name="citation_lastpage" content="532">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3543/live-3543-6403-jair.pdf">

<cite>P.  D. Turney (2012) "Domain and Function: A Dual-Space Model of Semantic Relations and Compositions", Volume 44, pages 533-585</cite>
<p class="media"><a href="/media/3640/live-3640-6410-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3640/live-3640-6411-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3640'>doi:10.1613/jair.3640</a>
<br/><a href="/media/3640/live-3640-6413-jair.txt">Appendix </a> - Dataset containing 2,180 seven-choice questions. </p>
<p>Given appropriate representations of the semantic relations between carpenter and wood and between mason and stone (for example, vectors in a vector space model), a suitable algorithm should be able to recognize that these relations are highly similar (carpenter is to wood as mason is to stone; the relations are analogous). Likewise, with representations of dog, house, and kennel, an algorithm should be able to recognize that the semantic composition of dog and house, dog house, is highly similar to kennel (dog house and kennel are synonymous). It seems that these two tasks, recognizing relations and compositions, are closely connected. However, up to now, the best models for relations are significantly different from the best models for compositions. In this paper, we introduce a dual-space model that unifies these two tasks. This model matches the performance of the best previous models for relations and compositions. The dual-space model consists of a space for measuring domain similarity and a space for measuring function similarity. Carpenter and wood share the same domain, the domain of carpentry. Mason and stone share the same domain, the domain of masonry. Carpenter and mason share the same function, the function of artisans. Wood and stone share the same function, the function of materials. In the composition dog house, kennel has some domain overlap with both dog and house (the domains of pets and buildings). The function of kennel is similar to the function of house (the function of shelters). By combining domain and function similarities in various ways, we can model relations, compositions, and other aspects of semantics.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Domain and Function: A Dual-Space Model of Semantic Relations and Compositions">
<meta name="citation_author" content="Turney, P. D.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="533">
<meta name="citation_lastpage" content="585">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3640/live-3640-6410-jair.pdf">

<cite>J.  Hoffmann, I.  Weber and F.  M. Kraft (2012) "SAP Speaks PDDL: Exploiting a Software-Engineering Model for Planning in Business Process Management", Volume 44, pages 587-632</cite>
<p class="media"><a href="/media/3636/live-3636-6417-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3636/live-3636-6416-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3636'>doi:10.1613/jair.3636</a></p>
<p>Planning is concerned with the automated solution of action sequencing problems described in declarative languages giving the action preconditions and effects. One important application area for such technology is the creation of new processes in Business Process Management (BPM), which is essential in an ever more dynamic business environment. A major obstacle for the application of Planning in this area lies in the modeling. Obtaining a suitable model to plan with -- ideally a description in PDDL, the most commonly used planning language -- is often prohibitively complicated and/or costly. Our core observation in this work is that this problem can be ameliorated by leveraging synergies with model-based software development. Our application at SAP, one of the leading vendors of enterprise software, demonstrates that even one-to-one model re-use is possible.<br />
<br />
The model in question is called Status and Action Management (SAM). It describes the behavior of Business Objects (BO), i.e., large-scale data structures, at a level of abstraction  corresponding to the language of business experts. SAM covers more than 400 kinds of BOs, each of which is described in terms of a set of status variables and how their values are required for, and affected by, processing steps (actions) that are atomic from a business perspective. SAM was developed by SAP as part of a major model-based software engineering effort.  We show herein that one can use this same model for planning, thus obtaining a BPM planning application that incurs no modeling overhead at all.<br />
<br />
We compile SAM into a variant of PDDL, and adapt an off-the-shelf planner to solve this kind of problem. Thanks to the resulting technology, business experts may create new processes simply by specifying the desired behavior in terms of status variable value changes: effectively, by describing the process in their own language.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="SAP Speaks PDDL: Exploiting a Software-Engineering Model for Planning in Business Process Management">
<meta name="citation_author" content="Hoffmann, J.">
<meta name="citation_author" content="Weber, I.">
<meta name="citation_author" content="Kraft, F. M.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="587">
<meta name="citation_lastpage" content="632">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3636/live-3636-6417-jair.pdf">

<cite>B.  Konev, M.  Ludwig, D.  Walther and F.  Wolter (2012) "The Logical Difference for the Lightweight Description Logic EL", Volume 44, pages 633-708</cite>
<p class="media"><a href="/media/3552/live-3552-6439-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3552/live-3552-6440-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3552'>doi:10.1613/jair.3552</a></p>
<p>We study a logic-based approach to versioning of ontologies. Under this view, ontologies provide answers to queries about some vocabulary of interest. The difference between two versions of an ontology is given by the set of queries that receive different answers.<br />
We investigate this approach for terminologies given in the description logic EL extended with role inclusions and domain and range restrictions for three distinct types of queries: subsumption, instance, and conjunctive queries. In all three cases, we present polynomial-time algorithms that decide whether two terminologies give the same answers to queries over a given vocabulary and compute a succinct representation of the difference if it is non-<br />
empty. We present an implementation, CEX2, of the developed algorithms for subsumption and instance queries and apply it to distinct versions of Snomed CT and the NCI ontology.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="The Logical Difference for the Lightweight Description Logic EL">
<meta name="citation_author" content="Konev, B.">
<meta name="citation_author" content="Ludwig, M.">
<meta name="citation_author" content="Walther, D.">
<meta name="citation_author" content="Wolter, F.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="633">
<meta name="citation_lastpage" content="708">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3552/live-3552-6439-jair.pdf">

<cite>C.  Domshlak, E.  Karpas and S.  Markovitch (2012) "Online Speedup Learning for Optimal Planning", Volume 44, pages 709-755</cite>
<p class="media"><a href="/media/3676/live-3676-6458-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3676/live-3676-6457-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3676'>doi:10.1613/jair.3676</a></p>
<p>Domain-independent planning is one of the foundational areas in the field of Artificial Intelligence. A description of a planning task consists of an initial world state, a goal, and a set of actions for modifying the world state. The objective is to find a sequence of actions, that is, a plan, that transforms the initial world state into a goal state. In optimal planning, we are interested in finding not just a plan, but one of the cheapest plans. A prominent approach to optimal planning these days is heuristic<br />
state-space search, guided by admissible heuristic functions. Numerous admissible heuristics have been developed, each with its own strengths and weaknesses, and it is well known that there is no single "best'' heuristic for optimal planning in general.  Thus, which heuristic to choose for a given planning task is a difficult question. This difficulty can be avoided by combining several heuristics, but that requires computing numerous heuristic estimates at each state, and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high. We present a novel method that reduces the cost of combining admissible heuristics for optimal planning, while maintaining its benefits.  Using an idealized search space model, we formulate a decision rule for choosing the best heuristic to compute at each state. We then present an active online learning approach for learning a classifier with that decision rule as the target concept, and employ the learned classifier to decide  which heuristic to compute at each state. We evaluate this technique empirically, and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum.</p>
<a href="/vol/vol44.html">Click here to return to Volume 44 contents list</a>
<meta name="citation_title" content="Online Speedup Learning for Optimal Planning">
<meta name="citation_author" content="Domshlak, C.">
<meta name="citation_author" content="Karpas, E.">
<meta name="citation_author" content="Markovitch, S.">
<meta name="citation_publication_date" content="2012">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="709">
<meta name="citation_lastpage" content="755">
<meta name="citation_volume" content="44">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3676/live-3676-6458-jair.pdf">
