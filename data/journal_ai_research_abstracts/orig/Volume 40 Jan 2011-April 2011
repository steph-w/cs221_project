<cite>M.  Milani Fard and J.  Pineau (2011) "Non-Deterministic Policies in Markovian Decision Processes", Volume 40, pages 1-24</cite>
<p class="media"><a href="/media/3175/live-3175-5361-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3175/live-3175-5362-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3175'>doi:10.1613/jair.3175</a></p>
<p>Markovian processes have long been used to model stochastic environments. Reinforcement learning has emerged as a framework to solve sequential planning and decision-making problems in such environments. In recent years, attempts were made to apply methods from reinforcement learning to construct decision support systems for action selection in Markovian environments. Although conventional methods in reinforcement learning have proved to be useful in problems concerning sequential decision-making, they cannot be applied in their current form to decision support systems, such as those in medical domains, as they suggest policies that are often highly prescriptive and leave little room for the user's input. Without the ability to provide flexible guidelines, it is unlikely that these methods can gain ground with users of such systems.<br />
<br />
This paper introduces the new concept of non-deterministic policies to allow more flexibility in the user's decision-making process, while constraining decisions to remain near optimal solutions. We provide two algorithms to compute non-deterministic policies in discrete domains. We study the output and running time of these method on a set of synthetic and real-world problems. In an experiment with human subjects, we show that humans assisted by hints based on non-deterministic policies outperform both human-only and computer-only agents in a web navigation task.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Non-Deterministic Policies in Markovian Decision Processes">
<meta name="citation_author" content="Milani Fard, M.">
<meta name="citation_author" content="Pineau, J.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="1">
<meta name="citation_lastpage" content="24">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3175/live-3175-5361-jair.pdf">

<cite>Y.  Zhou and Y.  Zhang (2011) "A Logical Study of Partial Entailment", Volume 40, pages 25-56</cite>
<p class="media"><a href="/media/3117/live-3117-5382-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3117/live-3117-5386-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3117'>doi:10.1613/jair.3117</a></p>
<p>We introduce a novel logical notion--partial entailment--to propositional logic. In contrast with classical entailment, that a formula P partially entails another formula Q with respect to a background formula set \Gamma intuitively means that under the circumstance of \Gamma, if P is true then some "part" of Q will also be true. We distinguish three different kinds of partial entailments and formalize them by using an extended notion of prime implicant. We study their semantic properties, which show that, surprisingly, partial entailments fail for many simple inference rules. Then, we study the related computational properties, which indicate that partial entailments are relatively difficult to be computed. Finally, we consider a potential application of partial entailments in reasoning about rational agents.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="A Logical Study of Partial Entailment">
<meta name="citation_author" content="Zhou, Y.">
<meta name="citation_author" content="Zhang, Y.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="25">
<meta name="citation_lastpage" content="56">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3117/live-3117-5382-jair.pdf">

<cite>H.  Aziz, Y.  Bachrach, E.  Elkind and M.  Paterson (2011) "False-Name Manipulations in Weighted Voting Games", Volume 40, pages 57-93</cite>
<p class="media"><a href="/media/3166/live-3166-5389-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3166/live-3166-5390-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3166'>doi:10.1613/jair.3166</a></p>
<p>Weighted voting is a classic model of cooperation among agents in decision-making domains. In such games, each player has a weight, and a coalition of players wins the game if its total weight meets or exceeds a given quota. A player's power in such games is usually not directly proportional to his weight, and is measured by a power index, the most prominent among which are the Shapley-Shubik index and the Banzhaf index.In this paper, we investigate by how much a player can change his power, as measured by the Shapley-Shubik index or the Banzhaf index, by means of a false-name manipulation, i.e., splitting his weight among two or more identities. For both indices, we provide upper and lower bounds on the effect of weight-splitting. We then show that checking whether a beneficial split exists is NP-hard, and discuss efficient algorithms for restricted cases of this problem, as well as randomized algorithms for the general case. We also provide an experimental evaluation of these algorithms. Finally, we examine related forms of manipulative behavior, such as annexation, where a player subsumes other players, or merging, where several players unite into one. We characterize the computational complexity of such manipulations and provide limits on their effects. For the Banzhaf index, we describe a new paradox, which we term the Annexation Non-monotonicity Paradox.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="False-Name Manipulations in Weighted Voting Games">
<meta name="citation_author" content="Aziz, H.">
<meta name="citation_author" content="Bachrach, Y.">
<meta name="citation_author" content="Elkind, E.">
<meta name="citation_author" content="Paterson, M.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="57">
<meta name="citation_lastpage" content="93">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3166/live-3166-5389-jair.pdf">

<cite>J.  Veness, K.S.  Ng, M.  Hutter, W.  Uther and D.  Silver (2011) "A Monte-Carlo AIXI Approximation", Volume 40, pages 95-142</cite>
<cite>Honorable Mention for the 2014 IJCAI-JAIR Best Paper Prize</cite><p class="media"><a href="/media/3125/live-3125-5397-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3125/live-3125-5396-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3125'>doi:10.1613/jair.3125</a></p>
<p>This paper introduces a principled approach for the design of a scalable general reinforcement learning agent. Our approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general reinforcement learning agents. Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms. We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent. To develop our approximation, we introduce a new Monte-Carlo Tree Search algorithm along with an agent-specific extension to the Context Tree Weighting algorithm. Empirically, we present a set of encouraging results on a variety of stochastic and partially observable domains. We conclude by proposing a number of directions for future research.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="A Monte-Carlo AIXI Approximation">
<meta name="citation_author" content="Veness, J.">
<meta name="citation_author" content="Ng, K.S.">
<meta name="citation_author" content="Hutter, M.">
<meta name="citation_author" content="Uther, W.">
<meta name="citation_author" content="Silver, D.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="95">
<meta name="citation_lastpage" content="142">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3125/live-3125-5397-jair.pdf">

<cite>C.  Geist and U.  Endriss (2011) "Automated Search for Impossibility Theorems in Social Choice Theory: Ranking Sets of Objects", Volume 40, pages 143-174</cite>
<p class="media"><a href="/media/3126/live-3126-5401-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3126/live-3126-5400-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3126'>doi:10.1613/jair.3126</a></p>
<p>We present a method for using standard techniques from satisfiability checking to automatically verify and discover theorems in an area of economic theory known as ranking sets of objects. The key question in this area, which has important applications in social choice theory and decision making under uncertainty, is how to extend an agent's preferences over a number of objects to a preference relation over nonempty sets of such objects. Certain combinations of seemingly natural principles for this kind of preference extension can result in logical inconsistencies, which has led to a number of important impossibility theorems. We first prove a general result that shows that for a wide range of such principles, characterised by their syntactic form when expressed in a many-sorted first-order logic, any impossibility exhibited at a fixed (small) domain size will necessarily extend to the general case. We then show how to formulate candidates for impossibility theorems at a fixed domain size in propositional logic, which in turn enables us to automatically search for (general) impossibility theorems using a SAT solver. When applied to a space of 20 principles for preference extension familiar from the literature, this method yields a total of 84 impossibility theorems, including both known and nontrivial new results.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Automated Search for Impossibility Theorems in Social Choice Theory: Ranking Sets of Objects">
<meta name="citation_author" content="Geist, C.">
<meta name="citation_author" content="Endriss, U.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="143">
<meta name="citation_lastpage" content="174">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3126/live-3126-5401-jair.pdf">

<cite>C.  Lecoutre, S.  Cardon and J.  Vion (2011) "Second-Order Consistencies", Volume 40, pages 175-219</cite>
<p class="media"><a href="/media/3180/live-3180-5405-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3180/live-3180-5404-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3180'>doi:10.1613/jair.3180</a></p>
<p>In this paper, we propose a comprehensive study of second-order consistencies (i.e., consistencies identifying inconsistent pairs of values) for constraint satisfaction. We build a full picture of the relationships existing between four basic second-order consistencies, namely path consistency (PC), 3-consistency (3C), dual consistency (DC) and 2-singleton arc consistency (2SAC), as well as their conservative and strong variants. Interestingly, dual consistency is an original property that can be established by using the outcome of the enforcement of generalized arc consistency (GAC), which makes it rather easy to obtain since constraint solvers typically maintain GAC during search.  On binary constraint  networks, DC is equivalent to PC, but its restriction to existing constraints, called conservative dual consistency (CDC), is strictly stronger than  traditional conservative consistencies derived from path consistency, namely partial path consistency (PPC) and conservative path consistency (CPC).  After introducing a general algorithm to enforce strong (C)DC, we present the results of an experimentation over a wide range of benchmarks that demonstrate the interest of (conservative) dual consistency.  In particular, we show that enforcing (C)DC before search clearly improves the performance of MAC (the algorithm that maintains GAC during search) on several binary and non-binary structured problems.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Second-Order Consistencies">
<meta name="citation_author" content="Lecoutre, C.">
<meta name="citation_author" content="Cardon, S.">
<meta name="citation_author" content="Vion, J.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="175">
<meta name="citation_lastpage" content="219">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3180/live-3180-5405-jair.pdf">

<cite>Y.  Wang, C.  Hang and M.  P. Singh (2011) "A Probabilistic Approach for Maintaining Trust Based on Evidence", Volume 40, pages 221-267</cite>
<p class="media"><a href="/media/3108/live-3108-5411-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3108/live-3108-5410-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3108'>doi:10.1613/jair.3108</a></p>
<p>Leading agent-based trust models address two important needs.  First, they show how an agent may estimate the trustworthiness of another agent based on prior interactions.  Second, they show how agents may share their knowledge in order to cooperatively assess the trustworthiness of others.  However, in real-life settings, information relevant to trust is usually obtained piecemeal, not all at once.  Unfortunately, the problem of maintaining trust has drawn little attention.  Existing approaches handle trust updates in a heuristic, not a principled, manner.<br />
<br />
This paper builds on a formal model that considers probability and certainty as two dimensions of trust.  It proposes a mechanism using which an agent can update the amount of trust it places in other agents on an ongoing basis.  This paper shows via simulation that the proposed approach (a) provides accurate estimates of the trustworthiness of agents that change behavior frequently; and (b) captures the dynamic behavior of the agents.  This paper includes an evaluation based on a real dataset drawn from Amazon Marketplace, a leading e-commerce site.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="A Probabilistic Approach for Maintaining Trust Based on Evidence">
<meta name="citation_author" content="Wang, Y.">
<meta name="citation_author" content="Hang, C.">
<meta name="citation_author" content="Singh, M. P.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="221">
<meta name="citation_lastpage" content="267">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3108/live-3108-5411-jair.pdf">

<cite>A.  Hunter and J.  P. Delgrande (2011) "Iterated Belief Change Due to Actions and Observations", Volume 40, pages 269-304</cite>
<p class="media"><a href="/media/3132/live-3132-5417-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3132/live-3132-5416-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3132'>doi:10.1613/jair.3132</a></p>
<p>In action domains where agents may have erroneous beliefs, reasoning about the effects of actions involves reasoning about belief change.  In this paper, we use a transition system approach to reason about the evolution of an agent's beliefs as actions are executed.  Some  actions cause an agent to perform belief revision while others cause an agent to perform belief update, but the interaction between revision and update can be non-elementary.  We present a set of rationality properties describing the interaction between revision and update, and we introduce a new class of belief change operators for reasoning about alternating sequences of revisions and updates.  Our belief change operators can be characterized in terms of a natural shifting operation on total pre-orderings over interpretations.  We compare our approach with related work on iterated belief change due to action, and we conclude with some directions for future research.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Iterated Belief Change Due to Actions and Observations">
<meta name="citation_author" content="Hunter, A.">
<meta name="citation_author" content="Delgrande, J. P.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="269">
<meta name="citation_lastpage" content="304">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3132/live-3132-5417-jair.pdf">

<cite>P.  Faliszewski, E.  Hemaspaandra and L.  A. Hemaspaandra (2011) "Multimode Control Attacks on Elections", Volume 40, pages 305-351</cite>
<p class="media"><a href="/media/3136/live-3136-5421-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3136/live-3136-5420-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3136'>doi:10.1613/jair.3136</a></p>
<p>In 1992, Bartholdi, Tovey, and Trick opened the study of control attacks on elections---attempts to improve the election outcome by such actions as adding/deleting candidates or voters.  That work has led to many results on how algorithms can be used to find attacks on elections and how complexity-theoretic hardness results can be used as shields against attacks. However, all the work in this line has assumed that the attacker employs just a single type of attack.  In this paper, we model and study the case in which the attacker launches a multipronged (i.e., multimode) attack.  We do so to more realistically capture the richness of real-life settings. For example, an attacker might simultaneously try to suppress some voters, attract new voters into the election, and introduce a spoiler candidate. Our model provides a unified framework for such varied attacks.  By constructing polynomial-time multiprong attack algorithms we prove that for various election systems even such concerted, flexible attacks can be perfectly planned in deterministic polynomial time.<br />
</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Multimode Control Attacks on Elections">
<meta name="citation_author" content="Faliszewski, P.">
<meta name="citation_author" content="Hemaspaandra, E.">
<meta name="citation_author" content="Hemaspaandra, L. A.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="305">
<meta name="citation_lastpage" content="351">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3136/live-3136-5421-jair.pdf">

<cite>A.  Atserias, J.  K. Fichte and M.  Thurley (2011) "Clause-Learning Algorithms with Many Restarts and Bounded-Width Resolution", Volume 40, pages 353-373</cite>
<p class="media"><a href="/media/3152/live-3152-5425-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3152/live-3152-5426-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3152'>doi:10.1613/jair.3152</a></p>
<p> We offer a new understanding of some aspects of practical SAT-solvers that are based on DPLL with unit-clause propagation, clause-learning, and restarts. We do so by analyzing a concrete algorithm which we claim is faithful to what practical solvers do. In particular, before making any new decision or restart, the solver repeatedly applies the unit-resolution rule until saturation, and leaves no component to the mercy of non-determinism except for some internal randomness. We prove the perhaps surprising fact that, although the solver is not explicitly designed for it, with high probability it ends up behaving as width-k resolution after no more than O(n^{2k+2}) conflicts and restarts, where n is the number of variables. In other words, width-k resolution can be thought of as O(n^{2k+2}) restarts of the unit-resolution rule with learning.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Clause-Learning Algorithms with Many Restarts and Bounded-Width Resolution">
<meta name="citation_author" content="Atserias, A.">
<meta name="citation_author" content="Fichte, J. K.">
<meta name="citation_author" content="Thurley, M.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="353">
<meta name="citation_lastpage" content="373">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3152/live-3152-5425-jair.pdf">

<cite>X.  Tannier and P.  Muller (2011) "Evaluating Temporal Graphs Built from Texts via Transitive Reduction", Volume 40, pages 375-413</cite>
<p class="media"><a href="/media/3118/live-3118-5459-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3118/live-3118-5458-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3118'>doi:10.1613/jair.3118</a></p>
<p>Temporal information has been the focus of recent attention in information extraction, leading to some standardization effort, in particular for the task of relating events in a text. This task raises the problem of comparing two annotations of a given text, because relations between events in a story are intrinsically interdependent and cannot be evaluated separately.  A proper evaluation measure is also crucial in the context of a machine learning approach to the problem.  Finding a common comparison referent at the text level is not obvious, and we argue here in favor of a shift from event-based measures to measures on a unique textual object, a minimal underlying temporal graph, or more formally the transitive reduction of the graph of relations between event boundaries. We support it by an  investigation of its properties on synthetic data and on a well-know  temporal corpus.<br />
</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Evaluating Temporal Graphs Built from Texts via Transitive Reduction">
<meta name="citation_author" content="Tannier, X.">
<meta name="citation_author" content="Muller, P.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="375">
<meta name="citation_lastpage" content="413">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3118/live-3118-5459-jair.pdf">

<cite>W.  Ruml, M.  B. Do, R.  Zhou and M.  P.J. Fromherz (2011) "On-line Planning and Scheduling: An Application to Controlling Modular Printers", Volume 40, pages 415-468</cite>
<p class="media"><a href="/media/3184/live-3184-5462-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3184/live-3184-5470-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3184'>doi:10.1613/jair.3184</a>
<br/><a href="/media/3184/live-3184-5466-jair.mp4">Appendix 1</a> - video: nominal operation in simulation&nbsp;|&nbsp;<a href="/media/3184/live-3184-5467-jair.wmv">Appendix 2</a> - video: nominal operation on hardware&nbsp;|&nbsp;<a href="/media/3184/live-3184-5468-jair.mp4">Appendix 3</a> - video: replanning in simulation&nbsp;|&nbsp;<a href="/media/3184/live-3184-5469-jair.wmv">Appendix 4</a> - video: replanning on hardware</p>
<p>We present a case study of artificial intelligence techniques applied to the control of production printing equipment.  Like many other real-world applications, this complex domain requires high-speed autonomous decision-making and robust continual operation.  To our knowledge, this work represents the first successful industrial application of embedded domain-independent temporal planning.  Our system handles execution failures and multi-objective preferences.  At its heart is an on-line algorithm that combines techniques from state-space planning and partial-order scheduling.  We suggest that this general architecture may prove useful in other applications as more intelligent systems operate in continual, on-line settings.  Our system has been used to drive several commercial prototypes and has enabled a new product architecture for our industrial partner.  When compared with state-of-the-art off-line planners, our system is hundreds of times faster and often finds better plans.  Our experience demonstrates that domain-independent AI planning based on heuristic search can flexibly handle time, resources, replanning, and multiple objectives in a high-speed practical application without requiring hand-coded control knowledge.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="On-line Planning and Scheduling: An Application to Controlling Modular Printers">
<meta name="citation_author" content="Ruml, W.">
<meta name="citation_author" content="Do, M. B.">
<meta name="citation_author" content="Zhou, R.">
<meta name="citation_author" content="Fromherz, M. P.J.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="415">
<meta name="citation_lastpage" content="468">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3184/live-3184-5462-jair.pdf">

<cite>A.  Rahman and V.  Ng (2011) "Narrowing the Modeling Gap: A Cluster-Ranking Approach to Coreference Resolution", Volume 40, pages 469-521</cite>
<p class="media"><a href="/media/3120/live-3120-5478-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3120/live-3120-5477-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3120'>doi:10.1613/jair.3120</a></p>
<p>Traditional learning-based coreference resolvers operate by training the mention-pair model for determining whether two mentions are coreferent or not. Though conceptually simple and easy to understand, the mention-pair model is linguistically rather unappealing and lags far behind the heuristic-based coreference models proposed in the pre-statistical NLP era in terms of sophistication. Two independent lines of recent research have attempted to improve the mention-pair model, one by acquiring the mention-ranking model to rank preceding mentions for a given anaphor, and the other by training the entity-mention model to determine whether a preceding cluster is coreferent with a given mention. We propose a cluster-ranking approach to coreference resolution, which combines the strengths of the mention-ranking model and the entity-mention model, and is therefore theoretically more appealing than both of these models. In addition, we seek to improve cluster rankers via two extensions: (1) lexicalization and (2) incorporating knowledge of anaphoricity by jointly modeling anaphoricity determination and coreference resolution. Experimental results on the ACE data sets demonstrate the superior performance of cluster rankers to competing approaches as well as the effectiveness of our two extensions.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Narrowing the Modeling Gap: A Cluster-Ranking Approach to Coreference Resolution">
<meta name="citation_author" content="Rahman, A.">
<meta name="citation_author" content="Ng, V.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="469">
<meta name="citation_lastpage" content="521">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3120/live-3120-5478-jair.pdf">

<cite>R.  He, E.  Brunskill and N.  Roy (2011) "Efficient Planning under Uncertainty with Macro-actions", Volume 40, pages 523-570</cite>
<p class="media"><a href="/media/3171/live-3171-5491-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3171/live-3171-5492-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3171'>doi:10.1613/jair.3171</a></p>
<p>Deciding how to act in partially observable environments remains an active area of research. Identifying good sequences of decisions is particularly challenging when good control performance requires planning multiple steps into the future in domains with many states. Towards addressing this challenge, we present an online, forward-search algorithm called the Posterior Belief Distribution (PBD). PBD leverages a novel method for calculating the posterior distribution over beliefs that result after a sequence of actions is taken, given the set of observation sequences that could be received during this process. This method allows us to efficiently evaluate the expected reward of a sequence of primitive actions, which we refer to as macro-actions. We present a formal analysis of our approach, and examine its performance on two very large simulation experiments: scientific exploration and a target monitoring domain. We also demonstrate our algorithm being used to control a real robotic helicopter in a target monitoring experiment, which suggests that our approach has practical potential for planning in real-world, large partially observable domains where a multi-step lookahead is required to achieve good performance.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Efficient Planning under Uncertainty with Macro-actions">
<meta name="citation_author" content="He, R.">
<meta name="citation_author" content="Brunskill, E.">
<meta name="citation_author" content="Roy, N.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="523">
<meta name="citation_lastpage" content="570">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3171/live-3171-5491-jair.pdf">

<cite>I.  A. Kash, E.  J. Friedman and J.  Y. Halpern (2011) "Multiagent Learning in Large Anonymous Games", Volume 40, pages 571-598</cite>
<p class="media"><a href="/media/3213/live-3213-5538-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3213/live-3213-5537-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3213'>doi:10.1613/jair.3213</a></p>
<p>In large systems, it is important for agents to learn to act effectively, but sophisticated multi-agent learning algorithms generally do not scale.  An alternative approach is to find restricted classes of games where simple, efficient algorithms converge.  It is shown that stage learning efficiently converges to Nash equilibria in large anonymous games if best-reply dynamics converge.  Two features are identified that improve convergence. First, rather than making learning more difficult, more agents are actually beneficial in many settings.  Second, providing agents with statistical information about the behavior of others can significantly reduce the number of observations needed.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Multiagent Learning in Large Anonymous Games">
<meta name="citation_author" content="Kash, I. A.">
<meta name="citation_author" content="Friedman, E. J.">
<meta name="citation_author" content="Halpern, J. Y.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="571">
<meta name="citation_lastpage" content="598">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3213/live-3213-5538-jair.pdf">

<cite>V.  Aravantinos, R.  Caferra and N.  Peltier (2011) "Decidability and Undecidability Results for Propositional Schemata", Volume 40, pages 599-656</cite>
<p class="media"><a href="/media/3351/live-3351-5544-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3351/live-3351-5545-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3351'>doi:10.1613/jair.3351</a></p>
<p>We define a logic of propositional formula schemata adding to the syntax of propositional logic indexed propositions and iterated connectives ranging over intervals parameterized by arithmetic variables.  The satisfiability problem is shown to be undecidable for this new logic, but we introduce a very general class of schemata, called bound-linear, for which this problem becomes decidable.  This result is obtained by reduction to a particular class of schemata called regular, for which we provide a sound and complete terminating proof procedure.  This schemata calculus allows one to capture proof patterns corresponding to a large class of problems specified in propositional logic. We also show that the satisfiability problem becomes again undecidable for slight extensions of this class, thus demonstrating that bound-linear schemata represent a good compromise between expressivity and decidability.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Decidability and Undecidability Results for Propositional Schemata">
<meta name="citation_author" content="Aravantinos, V.">
<meta name="citation_author" content="Caferra, R.">
<meta name="citation_author" content="Peltier, N.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="599">
<meta name="citation_lastpage" content="656">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3351/live-3351-5544-jair.pdf">

<cite>L.  Bordeaux, G.  Katsirelos, N.  Narodytska and M.  Y. Vardi (2011) "The Complexity of Integer Bound Propagation", Volume 40, pages 657-676</cite>
<p class="media"><a href="/media/3248/live-3248-5557-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3248/live-3248-5559-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3248'>doi:10.1613/jair.3248</a></p>
<p>Bound propagation is an important Artificial Intelligence technique used in Constraint Programming tools to deal with numerical constraints. It is typically embedded within a search procedure (”branch and prune”) and used at every node of the search tree to narrow down the search space, so it is critical that it be fast. The procedure invokes constraint propagators until a common fixpoint is reached, but the known algorithms for this have a pseudo-polynomial worst-case time complexity: they are fast indeed when the variables have a small numerical range, but they have the well-known problem of being prohibitively slow when these ranges are large. An important question is therefore whether strongly-polynomial algorithms exist that compute the common bound consistent fixpoint of a set of constraints. This paper answers this question. In particular we show that this fixpoint computation is in fact NP-complete, even when restricted to binary linear constraints.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="The Complexity of Integer Bound Propagation">
<meta name="citation_author" content="Bordeaux, L.">
<meta name="citation_author" content="Katsirelos, G.">
<meta name="citation_author" content="Narodytska, N.">
<meta name="citation_author" content="Vardi, M. Y.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="657">
<meta name="citation_lastpage" content="676">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3248/live-3248-5557-jair.pdf">

<cite>F.  Wu, J.  Madhavan and A.  Halevy (2011) "Identifying Aspects for Web-Search Queries", Volume 40, pages 677-700</cite>
<p class="media"><a href="/media/3182/live-3182-5568-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3182/live-3182-5567-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3182'>doi:10.1613/jair.3182</a></p>
<p>Many web-search queries serve as the beginning of an exploration of an unknown space of information, rather than looking for a specific web page. To answer such queries effec- tively, the search engine should attempt to organize the space of relevant information in a way that facilitates exploration.<br />
<br />
We describe the Aspector system that computes aspects for a given query. Each aspect is a set of search queries that together represent a distinct information need relevant to the original search query. To serve as an effective means to explore the space, Aspector computes aspects that are orthogonal to each other and to have high combined coverage.<br />
<br />
Aspector combines two sources of information to compute aspects. We discover candidate aspects by analyzing query logs, and cluster them to eliminate redundancies. We then use a mass-collaboration knowledge base (e.g., Wikipedia) to compute candidate aspects for queries that occur less frequently and to group together aspects that are likely to be “semantically” related. We present a user study that indicates that the aspects we compute are rated favorably against three competing alternatives – related searches proposed by Google, cluster labels assigned by the Clusty search engine, and navigational searches proposed by Bing.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Identifying Aspects for Web-Search Queries">
<meta name="citation_author" content="Wu, F.">
<meta name="citation_author" content="Madhavan, J.">
<meta name="citation_author" content="Halevy, A.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="677">
<meta name="citation_lastpage" content="700">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3182/live-3182-5568-jair.pdf">

<cite>A.  Cimatti, A.  Griggio and R.  Sebastiani (2011) "Computing Small Unsatisfiable Cores in Satisfiability Modulo Theories", Volume 40, pages 701-728</cite>
<p class="media"><a href="/media/3196/live-3196-5582-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3196/live-3196-5581-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3196'>doi:10.1613/jair.3196</a></p>
<p>The problem of finding small unsatisfiable cores for SAT formulas has  recently received a lot of interest, mostly for its applications in formal verification.  However, propositional logic is often not expressive  enough for representing many interesting verification problems, which can be more naturally addressed in the framework of Satisfiability Modulo Theories, SMT.  Surprisingly, the problem of finding unsatisfiable cores in SMT has received very little attention in the literature.<br />
<br />
In this paper we present a novel approach to this problem, called the Lemma-Lifting approach. The main idea is to combine an SMT solver with an external propositional core extractor. The SMT solver produces the theory lemmas found during the search, dynamically lifting the suitable amount of theory information to the Boolean level. The core extractor is then called on the Boolean abstraction of the original SMT problem and of the theory lemmas. This results in an unsatisfiable core for the original SMT problem, once the remaining theory lemmas are removed.<br />
<br />
The approach is conceptually interesting, and has several advantages in practice. In fact, it is extremely simple to implement and to update, and it can be interfaced with every propositional core extractor in a plug-and-play manner, so as to benefit for free of all unsat-core reduction techniques which have been or will be made available.<br />
<br />
We have evaluated our algorithm with a very extensive empirical test on SMT-LIB benchmarks, which confirms the validity and potential of this approach. </p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Computing Small Unsatisfiable Cores in Satisfiability Modulo Theories">
<meta name="citation_author" content="Cimatti, A.">
<meta name="citation_author" content="Griggio, A.">
<meta name="citation_author" content="Sebastiani, R.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="701">
<meta name="citation_lastpage" content="728">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3196/live-3196-5582-jair.pdf">

<cite>W.  Li, P.  Poupart and P.  van Beek (2011) "Exploiting Structure in Weighted Model Counting Approaches to Probabilistic Inference", Volume 40, pages 729-765</cite>
<p class="media"><a href="/media/3232/live-3232-5589-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3232/live-3232-5588-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3232'>doi:10.1613/jair.3232</a></p>
<p>Previous studies have demonstrated that encoding a Bayesian network into a SAT formula and then performing weighted model counting using a backtracking search algorithm can be an effective method for exact inference.  In this paper, we present techniques for improving this approach for Bayesian networks with noisy-OR and noisy-MAX relations---two relations that are widely used in practice as they can dramatically reduce the number of probabilities one needs to specify. In particular, we present two SAT encodings for noisy-OR and two encodings for noisy-MAX that exploit the structure or semantics of the relations to improve both time and space efficiency, and we prove the correctness of the encodings. We experimentally evaluated our techniques on large-scale real and randomly generated Bayesian networks.  On these benchmarks, our techniques gave speedups of up to two orders of magnitude over the best previous approaches for networks with noisy-OR/MAX relations and scaled up to larger networks. As well, our techniques extend the weighted model counting approach for exact inference to networks that were previously intractable for the approach.<br />
</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Exploiting Structure in Weighted Model Counting Approaches to Probabilistic Inference">
<meta name="citation_author" content="Li, W.">
<meta name="citation_author" content="Poupart, P.">
<meta name="citation_author" content="van Beek, P.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="729">
<meta name="citation_lastpage" content="765">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3232/live-3232-5589-jair.pdf">

<cite>T.  De la Rosa, S.  Jimenez, R.  Fuentetaja and D.  Borrajo (2011) "Scaling up Heuristic Planning with Relational Decision Trees", Volume 40, pages 767-813</cite>
<p class="media"><a href="/media/3231/live-3231-5615-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3231/live-3231-5616-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3231'>doi:10.1613/jair.3231</a>
<br/><a href="/media/3231/live-3231-5600-jair.tar.gz">Appendix 1</a> - Domain control-knowledge learned with ROLLER (domains: blocksworld, gold-miner, matching-bw, parking and satellite)&nbsp;|&nbsp;<a href="/media/3231/live-3231-5601-jair.tar.gz">Appendix 2</a> - Domain control-knowledge learned with ROLLER (domains: depots, rovers, storage, thoughtful and TPP).
</p>
<p>Current evaluation functions for heuristic planning are expensive to compute. In numerous planning problems these functions provide good guidance to the solution, so they are worth the expense. However, when  evaluation functions are misguiding or when planning problems are large enough, lots of node evaluations must be computed, which severely limits the scalability of heuristic planners. In this paper, we present a novel solution for reducing node evaluations in heuristic planning based on machine learning. Particularly, we define the task of learning search control for heuristic planning as a relational classification task, and we use an off-the-shelf relational classification tool to address this learning task. Our relational classification task captures the preferred action to select in the different planning contexts of a specific planning domain. These planning contexts are defined by the set of helpful actions of the current state, the goals remaining to be achieved, and the static predicates of the planning task. This paper shows two methods for guiding the search of a heuristic planner with the learned classifiers. The first one consists of using the resulting classifier as an action policy. The second one consists of applying the classifier to generate lookahead states within a Best First Search algorithm. Experiments over a variety of domains reveal that our heuristic planner using the learned classifiers solves larger problems than state-of-the-art planners.<br />
</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Scaling up Heuristic Planning with Relational Decision Trees">
<meta name="citation_author" content="De la Rosa, T.">
<meta name="citation_author" content="Jimenez, S.">
<meta name="citation_author" content="Fuentetaja, R.">
<meta name="citation_author" content="Borrajo, D.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="767">
<meta name="citation_lastpage" content="813">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3231/live-3231-5615-jair.pdf">

<cite>H.  Papadopoulos, V.  Vovk and A.  Gammerman (2011) "Regression Conformal Prediction with Nearest Neighbours", Volume 40, pages 815-840</cite>
<p class="media"><a href="/media/3198/live-3198-5605-jair.pdf">PDF</a>&nbsp;|&nbsp;<a href="/media/3198/live-3198-5604-jair.ps">PostScript</a>&nbsp;|&nbsp;<a href='http://dx.doi.org/10.1613/jair.3198'>doi:10.1613/jair.3198</a></p>
<p>In this paper we apply Conformal Prediction (CP) to the k-Nearest Neighbours Regression (k-NNR) algorithm and propose ways of extending the typical nonconformity measure used for regression so far. Unlike traditional regression methods which produce point predictions, Conformal Predictors output predictive regions that satisfy a given confidence level. The regions produced by any Conformal Predictor are automatically valid, however their tightness and therefore usefulness depends on the nonconformity measure used by each CP. In effect a nonconformity measure evaluates how strange a given example is compared to a set of other examples based on some traditional machine learning algorithm. We define six novel nonconformity measures based on the k-Nearest Neighbours Regression algorithm and develop the corresponding CPs following both the original (transductive) and the inductive CP approaches. A comparison of the predictive regions produced by our measures with those of the typical regression measure suggests that a major improvement in terms of predictive region tightness is achieved by the new measures.</p>
<a href="/vol/vol40.html">Click here to return to Volume 40 contents list</a>
<meta name="citation_title" content="Regression Conformal Prediction with Nearest Neighbours">
<meta name="citation_author" content="Papadopoulos, H.">
<meta name="citation_author" content="Vovk, V.">
<meta name="citation_author" content="Gammerman, A.">
<meta name="citation_publication_date" content="2011">
<meta name="citation_journal_title" content="Journal of Artificial Intelligence Research">
<meta name="citation_firstpage" content="815">
<meta name="citation_lastpage" content="840">
<meta name="citation_volume" content="40">
<meta name="citation_issn" content="1076 - 9757">
<meta name="citation_pdf_url" content="http://www.jair.org/media/3198/live-3198-5605-jair.pdf">
