b  price and  c  boutilier 2003 accelerating reinforcement learning through implicit imitation volume 19 pages 569629

imitation can be viewed as a means of enhancing learning in multiagent environments  it augments an agents ability to learn useful behaviors by making intelligent use of the knowledge implicit in behaviors demonstrated by cooperative teachers or other more experienced agents  we propose and study a formal model of implicit imitation that can accelerate reinforcement learning dramatically in certain cases  roughly by observing a mentor a reinforcementlearning agent can extract information about its own capabilities in and the relative value of unvisited parts of the state space  we study two specific instantiations of this model one in which the learning agent and the mentor have identical abilities and one designed to deal with agents and mentors with different action sets  we illustrate the benefits of implicit imitation by integrating it with prioritized sweeping and demonstrating improved performance and convergence through observation of single and multiple mentors though we make some stringent assumptions regarding observability and possible interactions we briefly comment on extensions of the model that relax these restricitions

