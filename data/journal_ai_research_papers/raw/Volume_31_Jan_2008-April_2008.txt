Journal of Artiial Intelligene Researh 31 (2008) 473-495

Submitted 03/07; published 03/08

Axiomati Foundations for Ranking Systems
epsalonstanford.edu

Alon Altman

Department of Computer Siene
Stanford University
Stanford, CA 94305-9020 USA

moshetie.tehnion.a.il

Moshe Tennenholtz

Faulty of Industrial Engineering and Management
Tehnion  Israel Institute of Tehnology
Haifa 32000, Israel

Abstrat

Reasoning about agent preferenes on a set of alternatives, and the aggregation of suh
preferenes into some soial ranking is a fundamental issue in reasoning about multi-agent
systems. When the set of agents and the set of alternatives oinide, we get the ranking
systems setting. A famous type of ranking systems are page ranking systems in the ontext
of searh engines. In this paper we present an extensive axiomati study of ranking systems.
In partiular, we onsider two fundamental axioms: Transitivity, and Ranked Independene
of Irrelevant Alternatives. Surprisingly, we nd that there is no general soial ranking rule
that satises both requirements. Furthermore, we show that our impossibility result holds
under various restritions on the lass of ranking problems onsidered. However, when
transitivity is weakened, an interesting possibility result is obtained. In addition, we show
a omplete axiomatization of approval voting using ranked IIA.
1. Introdution
The ranking of agents based on other agents' input is fundamental to multi-agent systems
(see e.g. Resnik, Zekhauser, Friedman, & Kuwabara, 2000). Moreover, it has beome a
entral ingredient of a variety of Internet sites, where perhaps the most famous examples
are Google's PageRank algorithm (Page, Brin, Motwani, & Winograd, 1998) and eBay's
reputation system (Resnik & Zekhauser, 2001).
This basi problem introdues a new soial hoie model.

In the lassial theory of

soial hoie, as manifested by Arrow (1963), a set of agents/voters is alled to rank a set of
alternatives. Given the agents' input, i.e. the agents' individual rankings, a soial ranking
of the alternatives is generated.

The theory studies desired properties of the aggregation

of agents' rankings into a soial ranking.

In partiular, Arrow's elebrated impossibility

theorem (Arrow, 1963) shows that there is no aggregation rule that satises some minimal
requirements, while by relaxing any of these requirements appropriate soial aggregation
rules an be dened.

The novel feature of the ranking systems setting is that the set of

agents and the set of alternatives

oinide.

Therefore, in suh setting one may need to

onsider the transitive eets of voting. For example, if agent
of (i.e.

votes for) agent

importane of agent

c;

b

a

reports on the importane

then this may inuene the redibility of a report by

b

on the

these indiret eets should be onsidered when we wish to aggregate

the information provided by the agents into a soial ranking.

 2008 AI Aess Foundation. All rights reserved.


Altman & Tennenholtz
Notie that a natural interpretation/appliation of this setting is the ranking of Internet
pages. In this ase, the set of agents represents the set of Internet pages, and the links from
a page

p

Q an be viewed as a two-level ranking
p to the agents (pages) whih are not in Q.

to a set of pages

preferred by agent (page)

where agents in

Q

are

The problem of nding

an appropriate soial ranking in this ase is in fat the problem of (global) page ranking.
Partiular approahes for obtaining a useful page ranking have been implemented by searh
engines suh as Google (Page et al., 1998).
The theory of soial hoie onsists of two omplementary axiomati perspetives:

â€¢

The desriptive perspetive: given a partiular rule

r

for the aggregation of individual

rankings into a soial ranking, nd a set of axioms that are sound and omplete for
That is, nd a set of requirements that

r

satises; moreover, every soial aggregation

rule that satises these requirements should oinide with
axiomatization is termed a

r.

representation theorem

r.

A result showing suh an

and it aptures the exat essene

of (and assumptions behind) the use of the partiular rule.

â€¢

The normative perspetive: devise a set of requirements that a soial aggregation rule
should satisfy, and try to nd whether there is a soial aggregation rule that satises
these requirements.

Muh eort has been invested in the desriptive approah in the framework of the lassial
theory of soial hoie.

In that setting, representation theorems have been presented to

major voting rules suh as the majority rule (May, 1952; see Moulin, 1991 for an overview).
In the ranking systems setting, we have suessfully applied the desriptive perspetive
by providing a representation theorem (Altman & Tennenholtz, 2005b) for the well-known
PageRank algorithm (Page et al., 1998), whih is the basis of Google's searh tehnology
(Brin & Page, 1998).
An exellent example for the normative perspetive is Arrow's impossibility theorem
mentioned above. Tennenholtz (2004) has presented some preliminary results for ranking
systems where the set of voters and the set of alternatives oinide. However, the axioms
presented in that work onsist of several very strong requirements whih naturally lead to an
impossibility result. Still in the normative approah to ranking systems, we have takled the
issue of inentives (Altman & Tennenholtz, 2006b, 2006), with both positive and negative
results. Reently, we have onsidered a variation of ranking systems, where a personalized
ranking is generated for every partiipant in the system (Altman & Tennenholtz, 2006a),
with surprisingly dierent results.
In this paper we provide an extensive study of ranking systems.

We introdue two

fundamental axioms. One of these axioms aptures the transitive eets of voting in ranking systems, and the other adapts Arrow's well-known independene of irrelevant alternatives (IIA) axiom to the ontext of ranking systems. Surprisingly, we nd that no general
ranking system an simultaneously satisfy these two axioms! This result means that if we
would like to fully apture transitive eets, ranking deisions must be made globally, or be
based on numeri alulations. We further show that our impossibility result holds under
various restritions on the lass of ranking problems onsidered.
On the other hand, we show a positive result for the ase when the transitivity axiom is
relaxed. This new ranking system is pratial and useful and an algorithm is provided for

474

Axiomati Foundations for Ranking Systems
its omputation. Finally, we use our IIA axiom to present a positive result in the form of
a representation theorem for the well-known approval voting ranking system, whih ranks
the agents based on the number of votes reeived.

This axiomatization shows that when

ignoring transitive eets, there is only one ranking system that satises our IIA axiom.
This paper is strutured as follows: Setion 2 formally denes our setting and the notion
of ranking systems. Setions 3 and 4 introdue our axioms of Transitivity and Ranked Independene of Irrelevant Alternatives respetively. Our main impossibility result is presented
in Setion 5, and further strengthened in Setion 6. Our main positive result, in the form
of a ranking system satisfying a weaker version of transitivity is given in Setion 7, while an
axiomatization for the Approval Voting ranking system is presented in Setion 8. Finally,
some onluding remarks are given in Setion 9.

2. Ranking Systems
Before desribing our results regarding ranking systems, we must rst formally dene what
we mean by the words ranking system in terms of graphs and linear orderings:

Denition 2.1.

Let

A

be some set. A relation

is reexive, transitive, and omplete. Let

Notation

.

2.2

Let



ab

but not

R âŠ†AÃ—A

is alled an

ordering

denote the set of orderings on

be an ordering, then

â‰ƒ

. Formally, a â‰ƒ b
b  a.

if and only if

strit order indued by
only if

L(A)

is the equality prediate of

ab

and

b  a;

,

on

A

if it

A.
â‰º
aâ‰ºb

and

and

is the
if and

Given the above we an dene what a ranking system is:

Denition 2.3.

system F
ordering

Let

GV

FG âˆˆ L(V ).

otherwise it is alled a

If

F

V . A ranking
G âˆˆ GV to an

be the set of all direted graphs with vertex set

is a funtional that for every nite vertex set

V

maps graphs

is a partial funtion then it is alled a

general ranking system.

partial ranking system,

One an view this setting as a variation/extension of the lassial theory of soial hoie
as modeled by Arrow (1963). The ranking systems setting diers in two main properties.
First, in this setting we assume that the set of voters and the set of alternatives oinide,
and seond, we allow agents only two levels of preferene over the alternatives, as opposed
to Arrow's setting where agents ould rank alternatives arbitrarily.
The two-level limitation is important in order to avoid Arrow-style impossibility results.
Indeed, in the dihotomous (i.e. two level) setting suh results do not apply (Bogomolnaia,
Moulin, & Stong, 2005). Had we allowed general rankings as the input of the system, we
would have reahed impossibility results as a diret result of Arrow-style impossibility. By
adding the dihotomous limitation, we ensure that our results will be a onsequene of the
o-inidene of the voters and alternatives and the related transitive eets.

2.1 Examples of Ranking Systems
In order to make the abstrat denition of ranking systems above more onrete, we shall
now give some examples of several well-known ranking systems.

In order to dene these

systems, and throughout this paper, we shall use the following notation:

475

Altman & Tennenholtz

a

e
c

f
d

b

Figure 1: Example graph for ranking systems.

Notation

.

G = (V, E) be some graph and v âˆˆ V be some vertex. Let PG (v) ,
{u|(u, v) âˆˆ E} and SG (v) , {u|(v, u) âˆˆ E} denote the predeessor and suessor sets of v
in G respetively. When G is understood from ontext, we will sloppily use P (v) and S(v).
2.4

Let

Approval Voting is a very simple ranking system that ranks the agents aording to the
number of votes (i.e. inoming edges) they have. Formally,

Denition 2.5.

The

approval voting ranking system AV

is the ranking system dened by:

v1 AV
G v2 â‡” |PG (v1 )| â‰¤ |PG (v2 )|
Consider the graph in Figure 1. The

f â‰ºcâ‰ƒdâ‰ƒe

AV

ranking system would rank this graph

based on the fat that the verties in

{a, b}, {f },

and

{c, d, e}

aâ‰ƒbâ‰º

have 0, 1, and

2 predeessors respetively. A full axiomatization of the approval voting ranking system is
given in setion 8.
One major appliation of Ranking Systems is in the ontext of Internet pages. In that
ontext, we represent the Internet as a direted graph, where the verties are websites, and
the edges are links between these websites.

A prominent ranking system in this setting

is PageRank (Page et al., 1998), whih is based on a random walk of the Internet graph.
Namely, in this proess we start in a random page, and iteratively move to one of the pages
that are linked to by the urrent page, assigning equal probabilities to eah suh page. We
dene the PageRank matrix whih aptures the random walk reated by the PageRank
proedure:

Denition 2.6.
ank Matrix AG

Let

G = (V, E) be a graph, and assume V = {v1 , v2 , . . . , vn }.
n Ã— n) is dened as:

1/|SG (vj )| (vj , vi ) âˆˆ E
[AG ]i,j =
0
Otherwise.

The

PageR-

(of dimension

The PageRank proedure will rank pages aording to the stationary probability distribution obtained in the limit of the above random walk; this is formally dened as follows:

Denition 2.7.

Let G = (V, E) be some graph, and assume V = {v1 , v2 , . . . , vn }. Let
0 â‰¤ d < 1 be a damping fator. Let rPbe the unique solution of the system (1 âˆ’ d) Â· AG Â·
ri = n. If there is no unique solution, then the
r + d Â· ( 1 1 Â· Â· Â· 1 )T = r where
ranking is not dened. Otherwise, the PageRank P RG (vi ) of a vertex vi âˆˆ V is dened as
P RG (vi ) = ri . The PageRank ranking system is a ranking system that for the vertex set
V maps G to PGR , where PGR is dened as: for all vi , vj âˆˆ V : vi PGR vj if and only if
P RG (vi ) â‰¤ P RG (vj ).

476

Axiomati Foundations for Ranking Systems

b
d

a

c

Figure 2: Example of Transitivity

It an be shown that for

d > 0,

there is indeed a unique solution and thus the ranking

system is a general one. However, when

d = 0 this ranking system beomes a partial ranking

system, as it is not always well dened.

d = 0.2

In the graph in Figure 1, for

(0.2, 0.2, 0.52, 1.7, 1.77, 1.61)

the PageRank values assigned for

giving the ranking

a â‰ƒ b â‰º c â‰º f â‰º d â‰º e.

a...f

are

Note that this

ranking diers from the one assigned by approval voting, that neither of the rankings is
a renement of the other.

This example shows that PageRank and Approval Voting are

distint ranking systems, and that the two may disagree on the ranking of two verties. We
will soon see that these systems satisfy two mutually exlusive properties of ranking systems.

3. Transitivity
A basi property one would assume of ranking systems is that if an agent
ranked higher than those of agent

b,

then agent

a

a's

voters are

should be ranked higher than agent

b.

This notion is formally aptured below:

Denition 3.1.

F be a ranking system. We say that F satises strong transitivity if
for all graphs G = (V, E) and for all verties v1 , v2 âˆˆ V : Assume there is a 1-1 mapping (but
not neessarily onto) f : P (v1 ) 7â†’ P (v2 ) s.t. for all v âˆˆ P (v1 ): v  f (v). Then, v1  v2 .
Further assume that either f is not onto or for some v âˆˆ P (v1 ): v â‰º f (v). Then, v1 â‰º v2 .
Let

To explain how the formal denition aptures the intuition, onsider the simple graph

aâ†’bâ†’c
Our intuition tells us that

c

and thus ranked higher than
to

b

who is at the end of the vote hain should be more trusted,

b,

this is beause of the fat that

having a vote ompared to

denition above:

a must

a

b

is more trusted than

a,

due

having none. This intuition is orretly aptured by the

be ranked stritly below

b beause

any funtion mapping

P (a) = âˆ…

P (b) = {a} is not onto, and b must be ranked stritly below c beause the trivial mapping
P (b) = {a} to P (c) = {b} satises a â‰º b, and thus we get b â‰º c, as expeted.
For a more involved example, onsider the graph G in Figure 2 and any ranking system
F that satises strong transitivity. F must rank vertex d below all other verties, as it has no
F
predeessors, unlike all other verties. If we assume that a G b, then by strong transitivity
F
F
we must onlude that b G c as well. But then we must onlude that b â‰ºG a (as b's
predeessor a is ranked lower than a's predeessor c, and a has an additional predeessor d),
F
whih leads to a ontradition. Given b â‰ºG a, again by transitivity, we must onlude that
c â‰ºFG b, so the only ranking for the graph G that satises strong transitivity is d â‰ºFG c â‰ºFG
b â‰ºFG a.
to

from

477

Altman & Tennenholtz
Tennenholtz (2004) has suggested an algorithm that denes a ranking system that satises strong transitivity by iteratively rening an ordering of the verties starting from the
ranking suggested by approval voting.
Note that the PageRank ranking system does not satisfy strong transitivity. This is due
to the fat that PageRank redues the weight of links (or votes) from nodes whih have a
higher out-degree. Thus, assuming Yahoo! and Mirosoft are equally ranked, a link from
Yahoo! means less than a link from Mirosoft, beause Yahoo! links to more external pages
than does Mirosoft. Noting this fat, we an weaken the denition of transitivity to require
that the predeessors of the ompared agents have an equal out-degree:

Denition 3.2.

Let F be a ranking system. We say that F satises weak transitivity if
G = (V, E) and for all verties v1 , v2 âˆˆ V : Assume there is a 1-1 mapping
f : P (v1 ) 7â†’ P (v2 ) s.t. for all v âˆˆ P (v1 ): v  f (v) and |S(v)| = |S(f (v))|. Then, v1  v2 .
Further assume that either f is not onto or for some v âˆˆ P (v1 ): v â‰º f (v). Then, v1 â‰º v2 .

for all graphs

For an example of weak transitivity, one an reonsider the strong transitivity example
above, as it still applies to weak transitivity.
The PageRank ranking system satises this weakened version of transitivity. This is due
to the fat that:

P R(v1 ) =

X P R(v)
X P R(f (v))
â‰¤
â‰¤
|S(v)|
|S(f (v))|

vâˆˆP (v1 )
In the ase where

v â‰º f (v)

vâˆˆP (v1 )

for some

v âˆˆ P (v1 )

X P R(v)
= P R(v2 ).
|S(v)|

vâˆˆP (v2 )

the rst inequality is strit, and if

f

is not

onto the seond inequality is strit.

4. Ranked Independene of Irrelevant Alternatives
A standard assumption in soial hoie settings is that an agent's relative rank should only
depend on (some property of ) the agents who have voted for them. Suh axioms are usually
alled independene of irrelevant alternatives (IIA) axioms. In our setting, suh IIA axioms
mean that an agent's rank must only depend on a property of its immediate predeessors.
In our setting, we require the relative ranking of two agents must only depend on the
pairwise omparisons of the ranks of their predeessors, and not on their identity or ardinal
value. Our IIA axiom, alled

ranked

IIA, diers from the one suggested by Arrow (1963) in

the fat that we do not onsider the identity of the voters, but rather their relative rank.

F
a â‰ƒ b â‰º c â‰ƒ d â‰º e â‰ƒ f . Now look at
the omparison between c and d. c's predeessors, a and b, are both ranked equally, and
both ranked lower than d's predeessor f . This is also true when onsidering e and f  e's
predeessors c and d are both ranked equally, and both ranked lower than f 's predeessor
e. Therefore, if we agree with ranked IIA, the relation between c and d, and the relation
between e and f must be the same, whih indeed it is  both c â‰ƒ d and e â‰ƒ f . However,
this same situation also ours when omparing c and f (c's predeessors a and b are equally
ranked and ranked lower than f 's predeessor e), but in this ase c â‰º f . All three ases
For example, onsider the graph in Figure 3. Furthermore, assume a ranking system

has ranked the verties of this graph as following:

involve omparing two verties, one with two weaker predeessors and one with one stronger

478

Axiomati Foundations for Ranking Systems

a
c

e

b

f
d

Figure 3: An example of RIIA.

b

a

Figure 4: Graph for prole

h(1, 1), (2)i.

predeessor, but the outome of these omparisons in not onsistent.
onlude that the ranking system

F

Therefore, we an

whih produed these rankings does not satisfy ranked

IIA.
To formally dene this ondition, one must onsider all possibilities of omparing two
nodes in a graph based only on ordinal omparisons of their predeessors.

We all these

possibilities omparison proles:

Denition 4.1. A omparison prole is a pair ha, bi where a = (a1 , . . . , an ), b = (b1 , . . . , bm ),
a1 , . . . , an , b1 , . . . , bm âˆˆ N, a1 â‰¤ a2 â‰¤ Â· Â· Â· â‰¤ an , and b1 â‰¤ b2 â‰¤ Â· Â· Â· â‰¤ bm . Let P be the set of
all suh proles.
A ranking system

satisfy
and

F,

G = (V, E), and a pair of verties v1 , v2 âˆˆ V are said to
ha, bi if there exist 1-1 mappings f1 : P (v1 ) 7â†’ {1 . . . n}
that given f : ({1} Ã— P (v1 )) âˆª ({2} Ã— P (v2 )) 7â†’ N dened

a graph

suh a omparison prole

f2 : P (v2 ) 7â†’ {1 . . . m}

suh

as:

f (1, v) = af1 (v)
f (2, u) = bf2 (u) ,
f (i, x) â‰¤ f (j, y) â‡” x FG y
Consider the prole

for all

(i, x), (j, y) âˆˆ ({1} Ã— P (v1 )) âˆª ({2} Ã— P (v2 )).

h(1, 1), (2)i.

This omparison prole illustrates the basi question of

omparing an agent who got two low-rank votes with one who got one high-rank vote. This
question is undeided by transitivity alone, and if we do assume transitivity this omparison
prole is satised by the pair
maps the predeessors of

a

(a, b) in the graph in Figure
b to 1 and 2 respetively.

4. The

f

funtion above simply

and

We now require that for every suh prole the ranking system ranks the nodes onsistently:

479

Altman & Tennenholtz
Denition 4.2.

F satises ranked independene of
f : P 7â†’ {0, 1} suh that for every
graph G = (V, E) and for every pair of verties v1 , v2 âˆˆ V and for every omparison prole
p âˆˆ P that v1 and v2 satisfy, v1 FG v2 â‡” f (p) = 1.
Let

F

be a ranking system. We say that

irrelevant alternatives (RIIA)

Notation

.

4.3

When the funtion

ab
b  a.

we will use the notation
to mean

if there exists a mapping

ab

and

f

from the denition above is understood from ontext,

to mean

f ha, bi = 1, a â‰º b

to mean

f hb, ai = 0,

and

aâ‰ƒb

(c, d), (c, f ), and (e, f )
h(1, 1), (2)i. As we have seen above, the pairs (c, d) and (e, f )
(1, 1) â‰ƒ (2), while (c, f ) entails that (1, 1) â‰º (2). These results ontradit eah

For example, in the example onsidered above, all of the pairs
satisfy the omparison prole
entail that

other, and therefore we onlude that the ranking system that produed this ranking does
not satisfy RIIA.
The denition of RIIA formalizes the requirement of onsisteny in the omparisons
suh as the one we have seen above. It means that any ranking system satisfying RIIA must
deide on the relative ranking of

a

and

b

in Figure 4, and (assuming transitivity) rank the

same in all other ourrenes of two weak vs. one strong predeessor.
As RIIA is an independene property, the ranking system

F= ,

that ranks all agents

equally, satises RIIA.

AV also satises RIIA. This is due
h(a1 , . . . , an ), (b1 , . . . bm )i, the f funtion for AV

The approval voting ranking system
for any omparison prole

n â‰¤ m.

to the fat that
ranks

ab

i

We will use this fat in the axiomatization of approval voting we present in Setion

8.

5. Impossibility
Our main result illustrates the impossibility of satisfying (weak) transitivity and RIIA simultaneously.

Theorem 5.1. There is no general ranking system that satises weak transitivity and RIIA.
Proof.

Assume for ontradition that there exists a ranking system

transitivity and RIIA. Consider rst the graph

G1

in Figure 5(a).

F

that satises weak

Note that all verties

in this graph have an out-degree of 2 or 0, and thus the out-degree requirement of weak
Now note that a1 and a2 must satisfy some omparison
pa = ((x, y), (x, y)) beause they have idential predeessors. Thus, by RIIA, a1 FG1
a2 â‡” a2 FG1 a1 , and therefore a1 â‰ƒFG1 a2 . By weak transitivity, it is easy to see that
c â‰ºFG1 a1 and c â‰ºFG1 b. If we assume b FG1 a1 , then by weak transitivity, a1 â‰ºFG1 b whih
F
F
ontradits our assumption. So we onlude that c â‰ºG a1 â‰ºG b.
1
1
Now onsider the graph G2 in Figure 5(b). Again, the out-degree requirement of weak
F
transitivity is trivially satised, and again by RIIA, a1 â‰ƒG a2 . By weak transitivity, it is
2
F
F
F
easy to see that a1 â‰ºG c and b â‰ºG c. If we assume a1 G b, then by weak transitivity,
2
2
2
F
b â‰ºG2 a1 whih ontradits our assumption. So we onlude that b â‰ºFG2 a1 â‰ºFG2 c.
Consider the omparison prole p = ((1, 3), (2, 2)). Given F , a1 and b satisfy p in G1
F
F
F
F
F
F
(beause c â‰ºG a1 â‰ƒG a2 â‰ºG b) and in G2 (beause b â‰ºG a1 â‰ƒG a2 â‰ºG c). Thus,
1
1
1
2
2
2
transitivity is trivially fullled.

prole

480

Axiomati Foundations for Ranking Systems

d
b

a1

a2


(a) Graph G1
a1

d
b



a2

(b) Graph G2
Figure 5: Graphs for the proof of Theorem 5.1

by RIIA,

b

â‰ºFG2

a1 FG1 b â‡” a1 FG2 b,

whih is a ontradition to the fat that

a1 â‰ºFG1 b

but

a1 .

This result is quite a surprise.

Intuitively, we would like a ranking proedure to be

sensitive to the relative ranking of eah agent's voters (transitivity) and not to be inuened
by any other seemingly irrelevant information (RIIA). Although these requirements may
seem omplementary, this impossibility theorem shows that these requirements are in fat
ontraditory.
If we onsider transitivity as a basi requirement, we learn that any axiomatization of
a transitive ranking system annot be restrited to loal ordinal properties. That is, when
designing a ranking system where transitivity is required, one must hoose whether to base
the system on some numeri omputation, or on ordinal axioms that operate on a global
sale.
For example, the standard formalism for the PageRank ranking system in Denition 2.7
and an axiomatization of a similar system suggested by Palaios-Huerta and Volij (2004)
are based on numerial omputation, while our suggested axiomatization (Altman & Tennenholtz, 2005b) uses ordinal axioms on a global sale. These axioms refer to invariants in
relations between ranking of dierent graphs, rather than between pairs of verties in the
same graph.
The PageRank example demonstrates that some ranking systems may be dened using
either of these approahes. We feel that the numeri approah is more suitable for dening and exeuting ranking systems, while the global ordinal approah is more suitable for
axiomati lassiation.

6. Relaxing Generality
A hidden assumption in our impossibility result is the fat that we onsidered only general
ranking systems. In this setion we analyze several speial lasses of graphs that relate to
ommon ranking senarios.

481

Altman & Tennenholtz
6.1 Small Graphs
A natural limitation on a preferene graph is a ap on the number of verties (agents) that
partiipate in the ranking. Indeed, when there are three or less agents involved in the ranking, strong transitivity and RIIA an be simultaneously satised. An appropriate ranking
algorithm for this ase is the one we suggested by Tennenholtz (2004).

That algorithm

simply starts with ranking by in-degree and renes the ranking as required by strong transitivity until it is satised. It is easy to see that the deisions for omparison proles possible
in a 3-vertex graph are ditated by either in-degree or transitivity. Speially, the prole

h(1, 3), (2, 2)i

used in the proof above is impossible in suh graphs.

When there are four or more agents, strong transitivity and RIIA annot be simultaneously satised (the proof is similar to that of Theorem 5.1, but with vertex

d

removed

in both graphs). When ve or more agents are involved, even weak transitivity and RIIA
annot be simultaneously satised, as implied by the proof of Theorem 5.1.

6.2 Single Vote Setting
Another natural limitation on the domain of graphs that we might be interested in is the
restrition of eah agent (vertex) to exatly one vote (suessor). For example, in the voting
paradigm this ould be viewed as a setting where every agent votes for exatly one agent.
The following proposition shows that even in this simple setting weak transitivity and RIIA
annot be simultaneously satised.

Proposition 6.1. Let G1 be the set of all graphs G = (V, E) suh that |S(v)| = 1 for all
v âˆˆ V . There is no partial ranking system over G1 that satises weak transitivity and RIIA.
Proof.

Assume for ontradition that there is a partial ranking system

satises weak transitivity and RIIA. Let

F.
G1 âˆˆ G1

f : P 7â†’ {0, 1}

F

over

G1

that

be the mapping from the denition

of RIIA for

x1 â‰ƒFG1 x2 â‰ºFG1 b â‰ºFG1 a.
(a, b) satises the omparison prole h(1, 1, 2), (3)i, so we must have (3) â‰º (1, 1, 2). Now let
G2 âˆˆ G1 be the graph in Figure 6b. By weak transitivity x1 â‰ƒFG2 x2 â‰ºFG2 y â‰ºFG2 a â‰ºFG2 b.
(b, a) satises the omparison prole h(2, 3), (1, 4)i, so we must have (1, 4) â‰º (2, 3).
Let G3 âˆˆ G1 be the graph in Figure 6. By weak transitivity it is easy to see that
x1 â‰ƒFG3 Â· Â· Â· â‰ƒFG3 x7 â‰ºFG3 y1 â‰ƒFG3 y2 â‰ºFG3 c â‰ºFG3 d. Furthermore, by weak transitivity we
F
â€²
F
â€²
F
F
F
onlude that a â‰ºG b and a â‰ºG b from c â‰ºG d; and y1 â‰ºG b from x3 â‰ºG d. Now
3
3
3
3
3
â€²
F
F
F
â€²
onsider the vertex pair (c, b ). We have shown that x1 â‰ƒG x2 â‰ºG y1 â‰ºG b. So, (c, b )
3
3
3
â€²
F
satises the omparison prole h(1, 1, 2), (3)i, thus by RIIA b â‰ºG c. Now onsider the
3
â€²
F
â€²
F
F
vertex pair (b, a). We have already shown that a â‰ºG b â‰ºG c â‰ºG d. So, (a, b) satises the
3
3
3
F
omparison prole h(2, 3), (1, 4)i, thus by RIIA b â‰ºG a. However, we have already shown
3
F
that a â‰ºG b  a ontradition. Thus, the ranking system F annot exist.
3
Let

be the graph in Figure 6a. By weak transitivity,

6.3 Bipartite Setting
In the world of reputation systems (Resnik et al., 2000), we frequently observe a distintion
between two types of agents suh that eah type of agent only ranks agents of the other

482

Axiomati Foundations for Ranking Systems

x1

a

b

x2

x2

y

x1

a

(a) Graph G1
x4

b

(b) Graph G2

y2

x5

d

b

b'

x6

a'

x7

a
x1


x2

x3

y1

() Graph G3
Figure 6: Graphs from the proof of proposition 6.1

type. For example buyers only interat with sellers and vie versa. This type of limitation
is aptured by requiring the preferene graphs to be bipartite, as dened below.

Denition 6.2.
V = V 1 âˆª V2 ,

G = (V, E) is alled bipartite if there exist V1 , V2 suh that
V1 âˆ© V2 = âˆ…, and E âŠ† (V1 Ã— V2 ) âˆª (V2 Ã— V1 ). Let GB be the set of all bipartite
A graph

graphs.
Our impossibility result extends to the limited domain of bipartite graphs.

Proposition 6.3. There is no partial ranking system over
transitivity and RIIA.
Proof.

The proof is exatly the same as for

G1 ,

GB âˆ© G1 that satises weak

onsidering that all graphs in Figure 6 are

bipartite.

6.4 Strongly Conneted Graphs
The well-known PageRank ranking system is (ideally) dened on the set of strongly onneted graphs. That is, the set of graphs where there exists a direted path between any
two verties.
Let us denote the set of all strongly onneted graphs

GSC .

The following proposition

extends our impossibility result to strongly onneted graphs.

Proposition 6.4. There is no partial ranking system over

tivity and RIIA.

483

GSC that satises weak transi-

Altman & Tennenholtz
Proof.

The proof is similar to the proof of Theorem 5.1, but with an additional vertex

e

in

both graphs that has edges to and from all other verties.

7. Relaxing Transitivity
Our impossibility result beomes a possibility result when we relax the transitivity requirement. Instead of omparing only verties with similar out-degree as in the weak transitivity
axiom above, we weaken the requirement for strit preferene to hold only in the ase where
the mathing predeessors of one agent are preferred to the

all

predeessors of the other.

Denition 7.1.

Let F be a ranking system. We say that F satises strong quasi-transitivity
G = (V, E) and for all verties v1 , v2 âˆˆ V : Assume there is a 1-1 (but not
neessarily onto) mapping f : P (v1 ) 7â†’ P (v2 ) s.t. for all v âˆˆ P (v1 ): v  f (v). Then,
v1  v2 . And, if P (v1 ) 6= âˆ… and for all v âˆˆ P (v1 ): v â‰º f (v), then v1 â‰º v2 .
if for all graphs

Strong quasi transitivity a signiantly weaker property than strong transitivity, as it
allows for muh more indierene in the resulting ranking. Speially, the ranking system

F=

that always ranks all verties equally satises strong quasi transitivity. More generally,

any ranking system where the value of a vertex is proportional to a sum of the values of some
subset of its predeessors satises strong quasi transitivity. We shall see more examples of
quasi-transitive ranking systems below.
When we only require strong

quasi-transitivity and RIIA, we nd an interesting family of

ranking systems that rank the agents aording to their in-degree, breaking ties by omparing
the ranks of the strongest predeessors. These reursive in-degree systems work by assigning
a rational value for every vertex, that is based on the following idea: rank rst based on
the in-degree. If there is a tie, rank based on the strongest predeessor's value, and so on.
Loops are ranked as periodial rational numbers in base

(n + 1)

with a period the length of

the loop, in the ase that ontinuing on the loop is the maximally ranked option.
The reursive in-degree systems dier in the way dierent in-degrees are ompared. Any
monotone inreasing mapping of the in-degrees ould be used for the initial ranking.

To

show these systems are well-dened and that the values an be alulated we dene these
systems algorithmially as follows:

Denition 7.2.

r : N 7â†’ N be a monotone nondereasing funtion suh that r(i) â‰¤ i for
all i âˆˆ N. The reursive in-degree ranking system with rank funtion r is dened as follows:
Given a graph G = (V, E), let n = |V |. The relative ranking of two verties is based on a
Let

numeri alulation:
r
v2 â‡” valuer (v1 ) â‰¤ valuer (v2 ),
v1 RID
G

where valuer (v) is dened by maximizing a valuation funtion vpr (Â·) on all paths that lead
to

v:
valuer (v)

=

max

aâˆˆPath(v)

vpr (a)

(1)

To ensure the denition is sound, we eliminate loops, and dene the path in reverse order:
Path(v)

= { (v = a1 , a2 , . . . , am )|m âˆˆ N,
(am , . . . , a1 )

is a path in

484

G âˆ§ (amâˆ’1 , . . . , a1 )

is simple}

Axiomati Foundations for Ranking Systems

d

e

0.1232

0.2123

f


b

g

h

0.112123

0.3112123

0.12123

0.2321

0.1
i

0.3212
a
0

Figure 7: Values assigned by the reursive in-degree algorithm

The path valuation funtion vp

: V âˆ— 7â†’ Q

denes the value to onform to a lexiographi

order on in-degrees along the path:

ï£®

ï£¹
r(|P
(a
)|)+
1
ï£±
ï£º
1 ï£¯
m=1
ï£² 0
ï£¯
ï£º
vpr (a1 , a2 , . . . , am ) =
vpr (a2 , . . . , am , a2 ) a1 = am âˆ§ m > 1ï£»
n+1ï£°
ï£³
vpr (a2 , . . . , am )
Otherwise.

(2)

Note that vpr (a1 , a2 , . . . , am ) is innitely reursive in the ase when the path ontains a
loop (.f.

a1 = am âˆ§ m > 1).

For omputation sake we an redene this ase nitely as:

vpr (a1 , . . . , am , a1 )

=

âˆž
X
i=0

=

Example 7.3.

m
X
r(|P (aj )|)
1
=
mi
(n + 1)
(n + 1)j
j=1

(n + 1)m
vp (a1 , . . . , am ).
(n + 1)m âˆ’ 1 r

(3)

An example of the values assigned for a partiular graph when

identity funtion is given in Figure 7.
reursive division by

n = 9,

As

r

is the

and the denition in (2) is based on

n + 1, these values are simply deimals whih onsist of a onatenation

of in-degrees along the maximal path.
The value of zero is assigned to
onsists of

a

itself. The value for

b

a

via the rst ase in (2), as the only path leading to

is arises from the path

the reursive all gives the value of the path
added to

r(|P (b)|) = 1

(a)

(b, a)

a

and the third ase in (2),

whih we have seen to be equal 0. This is

and divided by 10, giving the result

0.1.

The values of

c, d, e,

and

i

arise from a loop onsisting of these verties. Applying the seond ase in (2), we have the
equations

1
[3 + vpr (e, d, c, i, e)]
10
1
[2 + vpr (d, c, i, e, d)]
valuer (e) = vpr (e, d, c, i, e) =
10
1
[1 + vpr (c, i, e, d, c)]
valuer (d) = vpr (d, c, i, e, d) =
10
1
valuer (c) = vpr (c, i, e, d, c) =
[2 + vpr (i, e, d, c, i)]
10
valuer (i)

=

vpr (i, e, d, c, i)

485

=

Altman & Tennenholtz
By using (3), we get the periodi deimals seen in Figure 7. The values for verties
and

h

f , g,

are again assigned using the third ase in (2). Note that the omplete maximal paths

(e, d, c, i, e)

to these verties ontain the loop

and thus all of these verties' values inlude a

periodi deimal part, as an be seen in Figure 7.
The reursive in-degree system satises an interesting xed point property that an be
used to failitate its eient omputation:

Proposition 7.4. Let r : N 7â†’ N be a monotone nondereasing funtion suh that r(i) â‰¤ i
for all i âˆˆ N and dene r(0) = 0. The value funtion for the reursive in-degree ranking
system satises:


valuer (v) =
Proof.

Denote Path

through

v

â€²

(p, v)

1
n+1

0



r(|P (v)|) + maxpâˆˆP (v) valuer (p) P (v) 6= âˆ…

as the set of almost-simple direted paths to

unless immediately looping bak to

Path

â€²

(4)

Otherwise
p

whih do not pass

p:

(p, v) = { (p = a1 , a2 , . . . , am )|
(am , . . . , a1 )

is a path in

G âˆ§ (amâˆ’1 , . . . , a1 )

is simple

âˆ§

âˆ€i âˆˆ {1, . . . , m âˆ’ 2, m} : ai 6= v âˆ§
amâˆ’1 = v â‡” am = p}.
Let

vâˆˆV

be some vertex. Then,

valuer (v)

=

=

=
=
=

max

aâˆˆPath(v)

vpr (a)

=

ï£¹
r(|P (v)|) + max(v=a1 ,...,am )âˆˆPath(v)
1 ï£° 
vpr (a2 , . . . , am , a2 ) a1 = am âˆ§ m > 1 ï£» =
n+1
vpr (a2 , . . . , am )
Otherwise.
"
#
1
vpr (a) =
r(|P (v)|) + max
max
n+1
pâˆˆP (v) aâˆˆPathâ€² (p,v)
"
#
1
r(|P (v)|) + max
max vpr (a) =
n+1
pâˆˆP (v) aâˆˆPath(p)


1
r(|P (v)|) + max valuer (p) .
n+1
pâˆˆP (v)
ï£®

Note that (5) is equal to zero

0

if

P (v) = âˆ…,

as required.

holds, assume for ontradition that there exists
vpr (a)

From
wlog
path

> max

p âˆˆ P (v)

max

pâ€² âˆˆP (v) aâ€² âˆˆPathâ€² (pâ€² ,v)

(5)

(6)

To show that the equality (6)

and

vpr (a

â€²

a âˆˆ Path(p)
).

suh that
(7)

\ Pathâ€² (p, v), we know that ai = v for some i âˆˆ {1, . . . , m}. Assume
that i is minimal. Let b denote the path (p = a1 , a2 , . . . , ai , p) and let c denote the
(pâ€² = ai+1 , . . . , am , aj+1 , . . . , ai+1 ) if am = aj for some j < i or (pâ€² = ai+1 , . . . , am )
a âˆˆ

Path(p)

486

Axiomati Foundations for Ranking Systems

pâ€™
v

a = (p, x, v, pâ€² , x)

x

b = (p, x, v, p)

p

c = (pâ€² , x, v, pâ€² )
Figure 8: Example of paths from the proof of Proposition 7.5.

otherwise. An example of suh paths is given in Figure 8. Note that

câˆˆ

â€²

â€²
Path (p , v), where

p, pâ€²

vpr (a)

âˆˆ P (v).
=

bâˆˆ

Path

â€²

(p, v)

and

Now, note that

(n + 1)j âˆ’ 1
1
vpr (b) +
vp (c),
(n + 1)j
(n + 1)j r

and thus vpr (a) must be between vpr (b) and vpr (c), in ontradition to assumption (7).
Note that although it might look ompelling to use this xed point property as a definition of reursive-indegree, it is not well dened, as loops indue in an innite series of
maximizations the we must prove onverges. This is the essene of the proof above. This
xed point property is the basis for the eient algorithm for reursive-indegree provided
below.
We shall now show this ranking system does in fat satisfy RIIA and our weakened
version of transitivity.

Proposition 7.5. Let r : N 7â†’ N be a monotone nondereasing funtion suh that r(i) â‰¤ i
for all i âˆˆ N and dene r(0) = 0. The reursive in-degree ranking system with rank funtion
r satises strong quasi-transitivity and RIIA.
Proof.

0 â‰¤ valuer (v) < 1, and thus
verties are ordered rst by r(|P (v)|) and then by maxpâˆˆP (v) valuer (p). Therefore, every
omparison prole ha, bi where a = (a1 , . . . , ak ), b = (b1 , . . . , bl ) is ranked as follows:
The xed point result in Proposition 7.4 further implies

f ha, bi = 1 â‡” (k = 0) âˆ¨ (r(k) < r(l)) âˆ¨ [(r(k) = r(l)) âˆ§ (ak â‰¤ bl )] .
This ranking of proles trivially yields strong quasi-transitivity as required.
We have previously presented a preliminary version of the personalized variant of reursive in-degree (Altman & Tennenholtz, 2006a). The algorithm presented there is based on
an equivalent reursive denition for value:
valuer (v)

=

vpr (pvr ((), v))

(8)

ï£±
ï£² (v)
 P (v) = âˆ…
/a
v, maxpâˆˆP (v) pvr (a, v, p) v âˆˆ
pvr (a, v) =
ï£³
(ak , . . . , am , v)
a = (a1 , . . . , ak = v, . . . , am ),

where the maximum on the paths is taken over vpr (pvr (a, v, p)).

487

(9)

Altman & Tennenholtz
Algorithm 1 Eient algorithm for reursive in-degree
1. Initialize valuer (v)
2. Let

Vâ€²

1
n+1 r(|P (v)|) for all

â†

where

r(0)

is assumed to be

0.

be the set of verties with inoming edges.

|V |

3. Iterate

times:

(a) For every vertex

v âˆˆ V â€²:

i. Update valuer (v)
4. Sort

v âˆˆV,

Vâ€²

1
n+1

â†

by valuer (Â·).

5. Output all verties in

V \ Vâ€²



r(|P (v)|) + maxpâˆˆP (v) valuer (p) .

as weakest, followed by the verties in

Vâ€²

sorted by

valuer (Â·) in asending order.

The xed point property in (4) satises the lassial Bellman priniple of optimality
(Stokey & Luas, 1989), that is

v(xt ) = max [F (xt , xt+1 ) + Î²v(xt+1 )] .
Thus, we an apply a dynami programming algorithm to eiently ompute these values,
as seen in Algorithm 1. Note that due to the limits of the size of the graph we an limit the
number of iterations and still ensure an exat result in

O(|V | Â· |E|)

time. A simple heuristi

for improving the eieny of the algorithm for pratial purposes is to redue the number
of iterations, like in other xed point algorithms suh as PageRank (Page et al., 1998). We
shall now prove the orretness and omplexity of this algorithm.

Proposition 7.6. Algorithm 1 outputs verties in

Denition 7.2 and works in O(|V | Â· |E|) time.
Proof.

V in the order of RID as dened in

Let us rst denote

1
[r(|P (a1 )| + vpâ€²r (a2 , . . . , am , . . .)]
n+1
â€²
vpr () = 0.

â€²

vpr (a1 , a2 , . . . , am , . . .)

=

a1 , . . . , am âˆˆ Path(v): If a1 , . . . , am is simple, vpâ€²r (a1 , . . . , am ) =
â€²
vpr (a1 , . . . , am ). Otherwise if an = ai , then vpr (a1 . . . , am ) = vpr (a1 , . . . am , ai+1 , . . . , am , . . .).
Let P(v) be the set of all reverse paths to v in G, simple or otherwise. We then have for all
v âˆˆV:
Note that for all

vâˆˆV

and for all

valuer (v)

beause the rst loop in

=

p âˆˆ P(v)

max

pâˆˆPath(v)

vpr (p)

= max

pâˆˆP(v)

â€²

vpr (p),

an be replaed with the one maximizing vpr (Â·), thus

inreasing value.

488

Axiomati Foundations for Ranking Systems
The iteration in step 3 of the algorithm alulates for all

"

"

v:

"

# ##
1
1
1
r0 + max Â· Â· Â·
r
+
max
Â·Â·Â· ,
r
n+1
n + 1 |V |âˆ’1 p|V | âˆˆP (p|V |âˆ’1 ) n + 1 |V |
p1 âˆˆP (v)
where

ri = r(|P (pi )|)

p0 = v .

and

This value is equal to

max Â· Â· Â·

max

p1 âˆˆP (v) p2 âˆˆP (p1 )

max

p|V | âˆˆP (p|V | âˆ’1)
|V |+1

=
=
where

Pm (v)

max

(p1 ,...,p|V |+1 )âˆˆP|V | (v)

max

pâˆˆP|V |+1 (v)

â€²

vpr (v),

X
i=1

|V |

i=0

ri
=
(n + 1)i+1

ri
=
(n + 1)i

is the set of all reverse paths of length

there are only

|V |
X

(10)

â‰¤ m

to

v,

simple or otherwise.As

verties, any two verties that dier in the value assigned by the value

funtion from (1) must also dier the value (10) alulated by the algorithm and in the same
diretion.
We shall now prove the time omplexity of the algorithm, by traing eah step. Steps 1

O(|V |) time. The iteration in step 3 is repeated |V | times, and for every vertex
O(|P (v)|) alulations, so eah iteration takes O(|E|) time and thus the total
â€²
â€²
time is O(|V | Â· |E|). Step 4 takes O(|V | log |V |) â‰¤ O(|V | log |E|) â‰¤ O(|V | Â· |E|). Finally,
the output step 5 takes O(|V |) time. As every step takes no more than O(|V | Â· |E|) time, so
and 2 take

in

Vâ€²

performs

does the entire algorithm.

8. Axiomatization of Approval Voting
In Setions 5 and 6 we have seen mostly negative results whih arise when trying to aommodate (weak) transitivity and RIIA. We have shown that although eah of the axioms an
be satised separately, there exists no general ranking system that satises both axioms.
Tennenholtz (2004) has previously shown a non-trivial ranking system that satises
(weak) transitivity, and in the previous setion we have seen suh a system for RIIA. However, we have not provided a representation theorem for our new system.
In this setion we provide a representation theorem for a ranking system that satises
RIIA but not weak transitivity  the approval voting ranking system (see Denition 2.5).
The axiomatization we provide in this setion shows the power of RIIA, as it shows that there
exists only one (interesting) ranking system that satises it without introduing transitive
eets.
Fishburn (1978) has axiomatized the Approval Voting ranking system in the ontext of
soial hoie, where the output of the algorithm is not a ranking, but rather a set of winners.
These two distint settings are very similar, and thus Fishburn's axiomatization of approval
voting is of great relevane to our work. We shall ompare these two axiomatizations later
in this setion.
In order to speify our axiomatization, reall the following lassial denitions from the
theory of soial hoie:

489

Altman & Tennenholtz
The positive response axiom (sometimes referred to as

positive responsiveness ) essentially

means that if an agent reeives additional votes, its rank must improve:

Denition 8.1.

F satises positive response if for
G = (V, E) and for all (v1 , v2 ) âˆˆ (V Ã— V ) \ E , v1 6= v2 , and for all v3 âˆˆ V :
(V, E âˆª (v1 , v2 )). If v3 FG v2 , then v3 â‰ºFGâ€² v2 .
Let

F

be a ranking system.

all graphs
Let

Gâ€² =

The anonymity and neutrality axioms mean that the names of the voters and alternatives
respetively do not matter for the ranking:

Denition 8.2.

A ranking system

Ï€ : V 7â†’ V , and
v2 â‡” v1 F(V,E â€² ) v2 .

permutations

v1 F(V,E)

for all

F satises anonymity if for all G = (V, E), for all
v1 , v2 âˆˆ V : Let E â€² = {(Ï€(v1 ), v2 )|(v1 , v2 ) âˆˆ E}. Then,

Denition 8.3.

A ranking system F satises neutrality if for all G = (V, E), for all perÏ€ : V 7â†’ V , and for all v1 , v2 âˆˆ V : Let E â€² = {(v1 , Ï€(v2 ))|(v1 , v2 ) âˆˆ E}. Then,
v2 â‡” Ï€(v1 ) F(V,E â€² ) Ï€(v2 ).

mutations

v1 F(V,E)

Arrow's lassial Independene of Irrelevant Alternatives axiom requires that the relative
rank of two agents be dependant only on the set of agents that preferred one over the other.

Denition 8.4.

F
G = (V, E),
PG (v1 ) \ PG (v2 ) = PGâ€² (v1 ) \ PGâ€² (v2 )
v1 FG v2 â‡” v1 FGâ€² v2 .

natives (AIIA)

A ranking system

if for all

satises

Arrow's Independene of Irrelevant Alter-

Gâ€² = (V, E â€² ), and for all v1 , v2 âˆˆ V : Let
PG (v2 ) \ PG (v1 ) = PGâ€² (v2 ) \ PGâ€² (v1 ). Then,

for all
and

Our representation theorem states that together with positive response and RIIA, any
one of the three independene onditions above (anonymity, neutrality, and AIIA) are essential and suient for a ranking system being

AV .

In addition, we show that as in the

lassial soial hoie setting when only onsidering two-level preferenes, positive response,
anonymity, neutrality, and AIIA are an essential and suient representation of approval
voting. This result extends the well known axiomatization of the majority rule due to May
(1952):

Proposition 8.5. (May's Theorem) A soial welfare funtional over two alternatives is a
majority soial welfare funtional if and only if it satises anonymity, neutrality, and positive
response.
We an now formally state our theorem:

Theorem 8.6. Let

equivalent:

F be a general ranking system. Then, the following statements are

1. F is the approval voting ranking system (F = AV )
2. F satises positive response, anonymity, neutrality, and AIIA
3. F satises positive response, RIIA, and either one of anonymity, neutrality, and AIIA
490

Axiomati Foundations for Ranking Systems

v

x

u
Figure 9: Example of graph

Proof.

It is easy to see that

AV

G

for the prole

h(1, 3, 3), (2, 4)i

satises positive response, RIIA, anonymity, neutrality, and

AIIA. It remains to show that (2) and (3) entail (1) above.

F satises positive response, anonymity, neutrality,
G = (V, E) be some graph and let v1 , v2 âˆˆ V be some agents. By AIIA,
ranking of v1 and v2 depends only on the sets PG (v1 ) \ PG (v2 ) and PG (v2 ) \

To prove (2) entails (1), assume that
and AIIA. Let
the relative

PG (v1 ).

We have now narrowed our onsideration to a set of agents with preferenes over

two alternatives, so we an apply Proposition 8.5 to omplete our proof.
To prove (3) entails (1), assume that
anonymity or neutrality or AIIA. As
parison proles. Let

f : P 7â†’ {0, 1}

F

F

satises positive response, RIIA and either

satises RIIA we an limit our disussion to om-

be the funtion from the denition of RIIA.

a â‰ƒ a for all a. By positive response it is
(1, 1, . . . , 1)  (1, 1, . . . , 1) i n â‰¤ m. Let P = h(a1 , . . . , an ), (b1 , . . . , bm )i
| {z }
| {z }

By the denition of RIIA, it is easy to see that
also easy to see that

n

m

G = (V, E) be the
h(1, 3, 3), (2, 4)i is in Figure 9):

be a omparison prole. Let
for the prole

V

following graph (an example of suh graph

= {x1 , . . . , xmax{an ,bm } } âˆª
âˆª{v1 , . . . , vn , v â€² 1 , . . . , vnâ€² , v} âˆª
âˆª{u1 , . . . , um , uâ€²1 , . . . , uâ€²m , u}

E = {(xi , vj )|i â‰¤ aj } âˆª {(xi , uj )|i â‰¤ bj } âˆª
âˆª{(vi , v)|i = 1, . . . , n} âˆª {(ui , u)|i = 1, . . . , m}.

491

Altman & Tennenholtz
It is easy to see that in the graph
permutation:

G, v

and

u

ï£± â€²
vi
ï£´
ï£´
ï£´
ï£´
ï£² vi
Ï€(x) =
uâ€²i
ï£´
ï£´
ï£´ ui
ï£´
ï£³
x

If

F

v

and

be the following

Otherwise .

F

satises:

E â€² = {(Ï€(x), y)|(x, y) âˆˆ E}. Note that in the graph (V, E â€² )
h(1, 1, . . . , 1), (1, 1, . . . , 1)i, and thus v F(V,E â€² ) u â‡” n â‰¤ m.
| {z } | {z }

u

satisfy the prole

n

arbitrary
If

F

v

and

satises neutrality, let

u

m

u F(V,E) v â‡” u F(V,E â€² ) v , thus proving
omparison prole P , and thus F = AV .

satisfy the prole

f (P ) = 1 â‡” n â‰¤ m

for an

E â€² = {(x, Ï€(y))|(x, y) âˆˆ E}. Note that in the graph (V, E â€² )
h(1, 1, . . . , 1), (1, 1, . . . , 1)i, and thus v F(V,E â€² ) u â‡” n â‰¤ m.
| {z } | {z }
n

an arbitrary

that

m

u F(V,E) v â‡” u F(V,E â€² ) v , again showing
omparison prole P , and thus F = AV .

By neutrality,

â€¢

Ï€

satises anonymity, let

By anonymity,

â€¢

Let

x = vi
x = viâ€²
x = ui
x = uâ€²i

The remainder of the proof depends on whih additional axiom

â€¢

P.

satisfy the prole

that

f (P ) = 1 â‡” n â‰¤ m

for

F satises AIIA, let E â€² = {(x, Ï€(y))|(x, y) âˆˆ E} as before. So, also v F(V,E â€² )
u â‡” n â‰¤ m. Note that PG (v) = P(V,E â€² ) (v) and PG (u) = P(V,E â€² ) (u), so by AIIA,
u F(V,E) v â‡” u F(V,E â€² ) v , and thus as before, F = AV .

If

Our axiomatization of approval voting, and speially the one in (2) above is related
to the previous axiomatization by Fishburn (1978). Both axiomatizations share the requirements of Anonymity

1

and Neutrality, but dier in the additional assumptions: Fishburn's

requirements refer to relations between the results on dierent voter sets, whih annot be
easily used in the ranking systems setting, as these voters are also alternatives, while our
requirements relate to hanges in the preferenes of a single agent and their ability (positive
response) or inability (AIIA) to inuene the nal result. Our requirements may be mapped
to Fishburn's setting and would probably lead to a distint axiomatization of approval voting
in that setting.

9. Conluding Remarks
Reasoning about preferenes and preferene aggregation is a fundamental task in reasoning
about multi-agent systems (see e.g. Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004;
Conitzer & Sandholm, 2002; LaMura & Shoham, 1998).

A typial instane of preferene

aggregation is the setting of ranking systems. Ranking systems are fundamental ingredients
of some of the most famous tools/tehniques in the Internet (e.g. Google's PageRank and
eBay's reputation systems, among many others).

1. Fishburn does not onsider Anonymity as an axiom, but rather denes his soial hoie model to allow
only for anonymous funtions.

492

Axiomati Foundations for Ranking Systems
Moreover, the task of building suessful and eetive on-line trading environments has
beome a entral hallenge to the AI ommunity (Boutilier, Shoham, & Wellman, 1997;
Monderer, Tennenholtz, & Varian, 2000; Sandholm, 2003). Ranking systems are believed
to be fundamental for the establishment of suh environments.

Although reputation has

always been a major issue in eonomis (see e.g. Kreps & Wilson, 1982; Milgrom & Roberts,
1982), reputation systems have beome so entral reently due to the fat that some of the
most inuential and powerful Internet sites and ompanies have put reputation systems in
the ore of their business.
Our aim in this paper was to treat ranking systems from an axiomati perspetive.
The lassial theory of soial hoie lay the foundations to a large part of the rigorous
work on multi-agent systems. Indeed, the most lassial results in the theory of mehanism
design, suh as the Gibbard-Satterthwaite Theorem (Gibbard, 1973; Satterthwaite, 1975) are
appliations of the theory of soial hoie. Moreover, previous work in AI has employed the
theory of soial hoie for obtaining foundations for reasoning tasks (Doyle & Wellman, 1989)
and multi-agent oordination (Kr-Dahav & Tennenholtz, 1996). It is however interesting
to note that ranking systems suggest a novel and new type of theory of soial hoie. We
see this point as espeially attrative, and as a main reason for onentrating on the study
of the axiomati foundations of ranking systems.
In this paper we identied two fundamental axioms for ranking systems, and onduted
a basi axiomati study of suh systems. In partiular, we presented surprising impossibility
results, omplemented by a new ranking algorithm, and a representation theorem for the
well-known approval voting sheme.

Aknowledgements
This work has been partially supported by a grant from the Israeli Siene Foundations
(ISF).

Referenes
Altman, A., & Tennenholtz, M. (2005). Ranking systems: the PageRank axioms. In

Proeedings of the 6th ACM onferene on Eletroni ommere,

EC '05:

pp. 18, New York,

NY, USA. ACM Press.
Altman, A., & Tennenholtz, M. (2006).
systems.. In

Pro. of AAAI-06.

Quantifying inentive ompatibility of ranking

Altman, A., & Tennenholtz, M. (2007a). An axiomati approah to personalized ranking
systems. In

Pro. 20th International Joint Conferene on Artiial Intelligene.

Altman, A., & Tennenholtz, M. (2007b). Inentive ompatible ranking systems. In

AAMAS-07.

Arrow, K. (1963).

Soial Choie and Individual Values (2nd Ed.).

Bogomolnaia, A., Moulin, H., & Stong, R. (2005).
mous preferenes.

Yale University Press.

Colletive hoie under dihoto-

Journal of Eonomi Theory, 122 (2),

165184.

http://ideas.repe.org/a/eee/jetheo/v122y2005i2p165-184.html.

493

Pro. of

available at

Altman & Tennenholtz
Boutilier, C., Shoham, Y., & Wellman, M. (1997). Speial issue on eonomi priniples of
multi-agent systems.

Artiial Intelligene, 94.

Boutilier, C., Brafman, R. I., Domshlak, C., Hoos, H. H., & Poole, D. (2004). Cp-nets: A tool
for representing and reasoning with onditional eteris paribus preferene statements..

J. Artif. Intell. Res. (JAIR), 21,

135191.

Brin, S., & Page, L. (1998). The anatomy of a large-sale hypertextual Web searh engine.

Computer Networks and ISDN Systems, 30 (17),

107117.

Conitzer, V., & Sandholm, T. (2002). Complexity of mehanism design. In

the 18th onferene on unertainity in Artiial Intelligene (UAI-02),

Proeedings of
pp. 103110.

Doyle, J., & Wellman, M. (1989). Impediments to Universal Preferene-Based Default The-

Proeedings of the 1st onferene on priniples of knowledge representation
and reasoning.

ories. In

Journal of Eonomi Theory, 19 (1), 180185. available at http://ideas.repe.org/a/eee/jetheo/v19y1978i1p180-

Fishburn, P. C. (1978). Axioms for approval voting: Diret proof.
185.html.
Gibbard, A. (1973). Manipulation of voting shemes.

Eonometria, 41, 587601.

Proeedings
of the 6th onferene on theoretial aspets of rationality and knowledge (TARK).

Kr-Dahav, N. E., & Tennenholtz, M. (1996). Multi-Agent Belief Revision. In

Journal of Eonomi

Kreps, D., & Wilson, R. (1982). Reputation and imperfet information.

Theory, 27, 253279.

LaMura, P., & Shoham, Y. (1998). Conditional, Hierarhial Multi-Agent Preferenes. In

Proeedings of Theoretial Aspets of Rationality and Knowledge,

May, K. O. (1952).

pp. 215224.

A set of independent, neessary and suient onditions for simple

majority deision.

Eonometria, 20 (4),

68084.

Milgrom, P., & Roberts, J. (1982). Predation, reputation and entry deterrene.

Eonomi Theory, 27, 280312.

Journal of

Monderer, D., Tennenholtz, M., & Varian, H. (2000). Game theory and artiial intelligene.
Speial issue of Games and Eonomi behavior.
Moulin, H. (1991).

Axioms of Cooperative Deision Making.

Cambridge University Press.

Page, L., Brin, S., Motwani, R., & Winograd, T. (1998). The PageRank itation ranking:
Bringing order to the web. Tehnial Report, Stanford University.
Palaios-Huerta, I., & Volij, O. (2004). The measurement of intelletual inuene.

metria, 73 (3).

Eono-

Resnik, P., & Zekhauser, R. (2001). Trust among strangers in internet transations: Empirial analysis of ebay's reputation system. Working Paper for the NBER workshop
on empirial studies of eletroni ommere.
Resnik, P., Zekhauser, R., Friedman, R., & Kuwabara, E. (2000).

Communiations of the ACM, 43 (12),

4548.

494

Reputation systems.

Axiomati Foundations for Ranking Systems
Sandholm, T. (2003). Making markets and demoray work: A story of inentives and om-

Proeedings of the International Joint Conferene on Artiial Intelligene
(IJCAI-03), pp. 16491671.

puting. In

Satterthwaite, M. (1975). Strategy proofness and arrow's onditions: Existene and orrespondene theorems for voting proedures and soial welfare funtions..

Eonomi Theory, 10, 187217.

Stokey, N. L., & Luas, R. E. (1989).

Journal of

Reursive Methods in Eonomi Dynamis.

Harvard

University Press.
Tennenholtz, M. (2004). Reputation systems: An axiomati approah. In

20th onferene on unertainity in Artiial Intelligene (UAI-04).

495

Proeedings of the

Journal of Artificial Intelligence Research 31 (2008) 591-656

Submitted 11/07; published 3/08

A Multiagent Approach to
Autonomous Intersection Management
Kurt Dresner
Peter Stone

kdresner@cs.utexas.edu
pstone@cs.utexas.edu

Department of Computer Sciences, University of Texas at Austin
1 University Station [C0500], Austin, TX 78712 USA

Abstract
Artificial intelligence research is ushering in a new era of sophisticated, mass-market
transportation technology. While computers can already fly a passenger jet better than a
trained human pilot, people are still faced with the dangerous yet tedious task of driving automobiles. Intelligent Transportation Systems (ITS) is the field that focuses on integrating
information technology with vehicles and transportation infrastructure to make transportation safer, cheaper, and more efficient. Recent advances in ITS point to a future in which
vehicles themselves handle the vast majority of the driving task. Once autonomous vehicles
become popular, autonomous interactions amongst multiple vehicles will be possible. Current methods of vehicle coordination, which are all designed to work with human drivers,
will be outdated. The bottleneck for roadway efficiency will no longer be the drivers, but
rather the mechanism by which those driversâ€™ actions are coordinated. While open-road
driving is a well-studied and more-or-less-solved problem, urban traffic scenarios, especially
intersections, are much more challenging.
We believe current methods for controlling traffic, specifically at intersections, will not
be able to take advantage of the increased sensitivity and precision of autonomous vehicles
as compared to human drivers. In this article, we suggest an alternative mechanism for
coordinating the movement of autonomous vehicles through intersections. Drivers and
intersections in this mechanism are treated as autonomous agents in a multiagent system.
In this multiagent system, intersections use a new reservation-based approach built around
a detailed communication protocol, which we also present. We demonstrate in simulation
that our new mechanism has the potential to significantly outperform current intersection
control technologyâ€”traffic lights and stop signs. Because our mechanism can emulate a
traffic light or stop sign, it subsumes the most popular current methods of intersection
control. This article also presents two extensions to the mechanism. The first extension
allows the system to control human-driven vehicles in addition to autonomous vehicles.
The second gives priority to emergency vehicles without significant cost to civilian vehicles.
The mechanism, including both extensions, is implemented and tested in simulation, and
we present experimental results that strongly attest to the efficacy of this approach.

1. Introduction
Few concepts, if any, embody the goals and aspirations of artificial intelligence as well
as fully autonomous robots. Countless films and stories have been made that focus on a
future filled with such humanoid agents which, when not violently overthrowing their human
masters, run errands, complete menial tasks, or perform duties that would be too difficult
or dangerous for humans. However, machines that sense, think about, and take actions in
the real world around us are no longer just the stuff of science fiction and fantasy. Research
c
2008
AI Access Foundation. All rights reserved.

Dresner & Stone

initiatives like Robocup (Noda, Jacoff, Bredenfeld, & Takahashi, 2006) and the DARPA
Grand Challenge (DARPA, 2007) have shown that current AI can produce autonomous,
embodied, competent agents for complex tasks like playing soccer or navigating the Mojave
Desert, respectively. While certainly no small feat, traversing a barren desert devoid of
pedestrians, narrow lanes, and multitudes of other fast-moving vehicles is not a typical
daily task for humans. As Gary Bradski, a researcher at Intel Corp. said following the
successful completion of the 2005 Grand Challenge by â€œStanley,â€ a modified Volkswagen
Touareg, â€œNow we need to teach them how to drive in trafficâ€ (Johnson, 2005). Since then,
competitors in the 2007 DARPA Urban Challenge took significant strides towards this next
milestone, though in the competition cars did not need to sense traffic signs or signals and
traffic was relatively sparseâ€”more characteristic of suburban than dense urban settings.
In modern urban settings, automobile traffic and collisions lead to endless frustration
as well as significant loss of life, property, and productivity. A 2004 study of 85 U.S.
cities by researchers at Texas A&M University estimated the annual time spent waiting in
traffic to be 46 hours per capita, up from 16 hours in 1982 (Texas Transportation Institute,
2004). Americans burn approximately 5.6 billion gallons of fuel each year simply idling their
engines. All told, the annual financial cost of traffic congestion has swollen from $14 billion
to more than $63 billion (in 2002 US dollars) in this period. The cost of all the wasted
time and fuel due to congestion pales in comparison to the costs associated with automobile
collisions. In a 2002 report, the National Highway Traffic Safety Administration (NHTSA)
put the annual societal cost of automobile collisions in the U.S. at $230 billion (National
Highway Traffic Safety Administration, 2002).
Fully autonomous vehicles may be able to spare us much, if not nearly all of these costs.
An autonomous driver agent can much more accurately judge distances and velocities,
attentively monitor its surroundings, and react instantly to situations that would leave a
(relatively) sluggish human driver helpless. Furthermore, an autonomous driver agent will
not get sleepy, impatient, angry, or drunk. Alcohol, speeding, and running red lights are
the top three causes of automobile collision fatalities. Autonomous driver agentsâ€”properly
programmedâ€”would eliminate all three.
A fully autonomous vehicle that will drive in traffic will have to do everything from
obeying the speed limit and staying in its lane to detecting and tracking pedestrians or
choosing the best route to the mall. While this is certainly a complex task, advances in artificial intelligence, and more specifically, Intelligent Transportation Systems (ITS), suggest
that it may soon be a reality (Bishop, 2005). Cars can already be equipped with features
of autonomy such as adaptive cruise control, GPS-based route planning (Rogers, Flechter,
& Langley, 1999; Schonberg, Ojala, Suomela, Torpo, & Halme, 1995), and autonomous
steering (Pomerleau, 1993; Reynolds, 1999). Some current production vehicles even sport
these features. DaimlerBenzâ€™s Mercedes-Benz S-Class has an adaptive cruise control system
that can maintain a safe following distance from the car in front of it, and will apply extra
braking power if it determines that the driver is not braking hard enough. Both Toyota and
BMW are currently selling vehicles that can parallel park completely autonomously, even
finding a space in which to park without any driver input. In 2008, General Motors (GM)
plans to release a nearly autonomous vehicle under its European â€œOpelâ€ brand. The 2008
Opel Vectra will be able to drive itself at speeds up to 60 miles per hour, even in heavy
traffic. Using a video camera, lasers, and a lot of processing power, the car will be able to
592

A Multiagent Approach to Autonomous Intersection Management

identify traffic signs, curves in the street, lane markings, as well as other vehicles. By the
end of the decade, GM hopes to incorporate the system into many other models.
Autonomous vehicles are coming. In this article, we present a well-defined multiagent
framework to manage large numbers of autonomous vehicles at intersections. While there
still exist many technical hurdles and rigorous safety tests, we show in simulation that this
framework may someday dramatically improve the safety and efficiency of our roadways.
1.1 Multiagent Systems
As autonomous vehicles become more and more prevalent, the possibility of autonomous
interactions among multiple vehicles becomes more interesting. Multiagent Systems (MAS)
is the subfield of AI that aims to provide both principles for construction of complex systems involving multiple agents and mechanisms for coordination of independent agentsâ€™
behaviors (Stone & Veloso, 2000). Automobile traffic is a vast multiagent system involving millions of heterogeneous agents: commuters, truck drivers, pedestrians, cyclists, and
even traffic-directing police officers. The mechanism that coordinates the behavior of these
agents is a complex conglomeration of laws, signs, and signaling systems that vary slightly
from state to state and widely from country to country. The mechanism is designed to
work closely with the agentsâ€”the humansâ€”that populate the multiagent system. Traffic
lights leave time in between green lights to allow slower or perhaps impatient drivers to
clear intersections. Street signs are colored brightly to make them easier to see and use
simple designs to make them easy to understand. Drivers must maintain a sufficient following distance to make up for slow reaction times. Speed limits ensure that humans have
enough time to process all the necessary information about the position and velocities of
other vehicles. Safety buffers of myriad sorts are built into almost every part of the system
to compensate for the limitations of humans.
The first generation of autonomous vehicles will undoubtedly need to work within this
system. Processing-intensive vision algorithms will identify and extract semantic information from signs and signals, special subroutines will ensure that the vehicles do not exceed
the speed limit, and in the middle of the night, with not another moving vehicle for blocks,
an autonomous vehicle will come to a stop at a red light. However, once most vehicles are
autonomous and the limitations are eliminated, it will not make sense to use a mechanism
designed to control fundamentally different agentsâ€”it will be inefficient, both in terms of
processing power and getting vehicles to their destinations quickly.
Replacing this soon-to-be-outdated mechanism is inherently a multiagent challenge for
several reasons. First, there are no viable single-agent solutions; one computer cannot
handle all the vehicles in the world. Second, with vehicles constantly entering and leaving
countries, states, cities, and towns, any solution will have to be flexible and distributed.
Third, the different agents have separate, and sometimes conflicting objectives. As with
human-driven vehicles, autonomous vehicles will act in their own self-interest, attempting
to minimize travel time, distance, and fuel use. Other types of agents may aim to maximize
social welfare, minimizing these quantities for the average vehicle. Finally, even if a single
computer could control a cityâ€™s worth of traffic, it would be a very sensitive point of failure.
593

Dresner & Stone

1.2 Intersections
On the open road, automobiles can be more or less completely autonomous. Furthermore,
there is little need for more than a simple reactive behavior that keeps the vehicle in the
lane, maintains a reasonable distance from other vehicles, and avoids obstacles. Even lane
changing can be safely and efficiently accomplished by an autonomous vehicle (Hatipo,
Redmill, & Ozguner, 1997). The algorithmic and AI aspects of open-road driving are
essentially solved. The problem itself is not too difficult: there are no pedestrians or cyclists
and vehicles travel in the same direction at similar velocities; relative movement is smooth
and rare.
Intersections are a completely different story: vehicles constantly cross paths, in many
different directions. A vehicle approaching an intersection can quickly find itself in a situation in which a collision is unavoidable, even when it has acted optimally. Traffic statistics
support the sensitive nature of intersections. Vehicle collisions at intersections account for
anywhere between 25% and 45% of all collisions. As intersections make up a very small
portion of the roadway, this is a wildly disproportionate amount. Collisions at intersections tend to involve cars traveling in different directions, and thus they frequently result in
greater injury and damage. Most modern-day intersections are controlled with traffic lights
or stop signs, the former usually reserved for larger, busier intersections. At the busiest
of intersectionsâ€”freeway interchangesâ€”large, extremely expensive cloverleaf junctions are
built.
With the vastly improved precision control and sensing that autonomous vehicles will
offer, there must be a more efficient and safe way to manage intersections. Imagine the
scenario in which an autonomous vehicle stops at a red light in the middle of the night with
no other vehicles nearby. At the very least, the vehicle should be able to communicate its
presence to the intersection, which can verify that no other vehicles are nearby, and turn the
light green for the stopped vehicle. In a more ambitious implementation, the intersection
could turn the light green preemptively, obviating the stop altogether. In this article, we go
a step further, allowing vehicles to â€œcall aheadâ€ and reserve space-time in the intersection.
The remainder of this article is organized as follows. In Section 2, we describe the problem of autonomous intersection management and a framework with which we will attempt
to solve this problem. In Section 3, we describe the implementation of the solution framework. Section 4 presents our experiments and empirical results. In Section 5, we conduct a
failure mode analysis of the proposed mechanism. Related work is discussed in Section 6.
Section 7 briefly explores some avenues for future research and concludes.

2. Problem Statement and Solution Framework
Automobile traffic is already a huge multiagent system with millions of human driver agents,
various signaling and control mechanisms, and a complicated protocol governing the actions
of the driver agents, in the form of traffic laws. However, if human drivers are to be
replaced by autonomous driving agents, the other elements of the multiagent system should
be rethought. Traffic lights, stop signs, and our current traffic laws are all designed with
human drivers in mind and fail to take advantage of the increased sensitivity and precision of
computerized driver agents. If we want autonomous vehicles to operate with high efficiency
and safety, we must design a new way to coordinate them. In this section, we formulate
594

A Multiagent Approach to Autonomous Intersection Management

the problem we are trying to solve and present a framework within which we believe the
problem can best be solved.
2.1 Desiderata
In designing a mechanism by which traffic is controlled at intersections, we aim to satisfy
the following list of properties.
Autonomy Each vehicle should be an autonomous agent. If the entire mechanism were
centrally controlled, it would be more susceptible to single-point failure, require massive
amounts of computational power, and exert unnecessary control over vehicles in situations
where they are perfectly capable of controlling themselves.
Low Communication Complexity By keeping the number of messages and amount of
information transmitted to a minimum, the system can afford to put more communication
reliability measures in place. Furthermore, each vehicle, as an autonomous agent, may have
privacy concerns which should be respected. Keeping the communication complexity low
will also make the system more scalable.
Sensor Model Realism Each agent should have access only to sensors that are available
with current-day technology. The mechanism should not rely on fictional sensor technology
that may never materialize.
Protocol Standardization The mechanism should employ a simple, standardized protocol for communication between agents. Without a standardized protocol, each agent
would need to understand the internal workings of every agent with which it interacts. This
requirement would forbid the introduction of new agents into the system. An open, standardized protocol would make adoption of the system easier and simpler for private vehicle
manufacturers.
Deadlock/Starvation Avoidance Deadlocks and starvation should not occur in the
system. Every vehicle approaching an intersection should eventually cross, even if it is
better for the rest of the agents to leave that vehicle stranded.
Incremental Deployability The system should be incrementally deployable, in two
senses. First, it should be possible to set up selected intersections to use the system, and
then slowly expand to other intersections as needed. Second, the system should function
even with few or no autonomous vehicles. At each stage of deployment, whether it is an
increase in the proportion of autonomous vehicles or the number of equipped intersections,
overall performance of the system should improve. At no point should a net disincentive to
continue deploying the system exist.
Safety Excepting for gross vehicle malfunction or extraordinary circumstances (e.g. natural disasters), as long as they follow the protocol, vehicles should never collide in the
intersection. Note that no stronger guarantee is possibleâ€”as with modern mechanisms, a
suicidal human driver can always steer a vehicle into oncoming traffic. Furthermore, the
system should be safe in the event of total communication failure. If messages are dropped
or corrupted, the safety of the system should not be compromised. It is impossible to prevent all negative effects due to communication failures, but those negative effects should
595

Dresner & Stone

be isolated to efficiency. If a message gets dropped, it can make someone arrive 10 seconds
later at their destination, but it should not cause a collision. In the rare but unpreventable
case of gross vehicle malfunction, the system should react and attempt to minimize damage
and casualties.
Efficiency Vehicles should get across the intersection and on their way in as little time
as possible. To quantify efficiency, we introduce delay, defined as the amount of additional
travel time incurred by the vehicle as the result of passing through the intersection.
2.2 The Reservation Idea
Of the desiderata, modern-day traffic lights and stop signs completely satisfy all but the
last one. While many accidents take place at intersections governed by traffic lights, these
accidents are rarely, if ever, the fault of the traffic light system itself, but rather that of the
human drivers. However, as we will show, traffic lights and stop signs are terribly inefficient.
Not only do vehicles traversing intersections equipped with these mechanisms experience
large delays, but the intersections themselves can only manage a somewhat limited amount
of traffic. Any stretch of open road can accommodate a certain level of traffic at a given
velocity. The capacity of an intersection involving a road is trivially bounded above by the
capacity of the road. As we will also show, the capacity of traffic lights and stop signs is
much less than that of the roads that feed into them. The aim of this research is to create
an intersection control mechanism that exceeds the efficiency of traffic lights and stop signs,
while maintaining each of the other desiderata.
With the desiderata in mind, we developed a multiagent approach to direct vehicles
through intersections more efficiently. In this approach, computer programs called driver
agents control the vehicles, while an arbiter agent called an intersection manager is placed
at each intersection. The driver agents â€œcall aheadâ€ and attempt to reserve a block of
space-time in the intersection. The intersection manager decides whether to grant or reject requested reservations according to an intersection control policy. Figure 1 shows one
interaction between a driver agent and an intersection manager. The system functions
analogously to a human attempting to make a reservation at a hotelâ€”the potential guest
specifies when he or she will be arriving, how much space is required, and how long the stay
will be; the human reservation agent determines whether or not to grant the reservation,
according to the hotelâ€™s reservation policy. Just as the guest does not need to understand
the hotelâ€™s decision process, the driver agents should not require any knowledge of the
intersection control policy used by the intersection manager.
When a vehicle approaches the intersection, the vehicleâ€™s driver agent transmits a reservation request, which includes parameters such as time of arrival, velocity of arrival, as well
as vehicle characteristics like size and acceleration/deceleration capabilities, to the intersection manager. The intersection manager then passes this information to the policy, which
determines whether or not it is safe for the vehicle to cross the intersection. If the policy
deems it to be safe, the intersection manager responds to the driver agent with a message
indicating the reservation has been accepted and including any supplemental restrictions
the driver must observe in order to guarantee the safety of the traversal. Otherwise, the
intersection manager sends a message indicating that the reservation request has been rejected, possibly including the grounds for rejection. In addition to confirming or rejecting
596

A Multiagent Approach to Autonomous Intersection Management

REQUEST

Driver
Agent

REJECT

Postprocess

Preprocess

No, Reason

Yes,
Restrictions

Intersection
Control Policy

CONFIRM

Intersection Manager
Figure 1: One of the driver agents attempts to make a reservation. The intersection manager responds based on the decision of an intersection control policy.

the request, the intersection manager may respond with a counter-offer. The driver agent
may not pilot the vehicle into the intersection without a reservation. Even with a reservation, a driver agent may only proceed through the intersection according to the parameters
and restrictions associated with the reservation. For the sake of brevity, we may refer to
a vehicle having or obtaining a reservation, rather than specifically stating that the driver
agent of that vehicle has or obtains a reservation.

3. Building The System
This section describes the realization of the reservation idea as an implemented algorithm.
This process involved developing a simulator in which to run the algorithm, as well as
creating behaviors for each of the agents and a protocol by which they can communicate.
3.1 Custom Simulator
In order to empirically evaluate the reservation idea, we built a custom time-based simulator.
The simulator models an area that is 250 m Ã— 250 m. The intersection is located at the
center of that area, and its size is determined by the number of lanes traveling in each
direction, which is variable. We assume throughout that vehicles drive on the right side
of the road, however this assumption is not required for the system to work properly.
Figure 2 shows a screenshot of the simulatorâ€™s graphical display. During each time step, the
simulator:
1.
2.
3.
4.
5.

Probabilistically spawns new vehicles
Provides sensor input to all vehicles
Allows all driver agents to act
Updates the position of all vehicles according to the physical model
Removes any vehicles outside the simulated area that have completed their journey

3.1.1 Vehicles
Vehicles in the simulator have the following properties:
597

Dresner & Stone

Figure 2: A screenshot of the simulator in action.

â€¢ Vehicle Identification Number (VIN)
â€¢ Length
â€¢ Width
â€¢ Distance from front of vehicle to front axle
â€¢ Distance from front of vehicle to rear axle
â€¢ Maximum velocity
â€¢ Maximum acceleration
â€¢ Minimum acceleration
â€¢ Maximum steering angle
â€¢ Sensor range
and the following state variables:
â€¢ Position
â€¢ Velocity
â€¢ Heading
â€¢ Acceleration
â€¢ Steering angle
The driver agent assigned to pilot the vehicle may access each of these quantities, with
or without noise, depending on the configuration of the simulator. The driver agent may
also access several simulated external sensors: a list of all vehicles within the sensor range,
and a simplified laser range finder. A detailed description of the simplified laser range finder
can be found in Appendix A.
The steering angle is the angle of the front wheels with respect to the vehicle. This
angle can be changed by the driver agent, but the simulator limits the rate at which it
can be changed. This limitation simulates the fact that even a computerized driver cannot
move the steering wheel infinitely fast. By introducing this limitation, we more accurately
approximate vehicle turning, including some of the more dangerous aspects. If the driver
598

A Multiagent Approach to Autonomous Intersection Management

cannot turn the wheels instantaneously, it must ensure that it does not drive around corners
at too high a velocityâ€”it may not be able to straighten out quickly enough and wind up
veering off the road instead.
The constants representing the distance from the front of the vehicle to the front and
rear axles allow more accurate simulation of vehicle turning. Specifically, they allow the
simulator to treat different styles of vehicle differently. The distance between the front
and rear axles is known as the wheelbase. Vehicles with shorter wheelbases can turn more
sharply than those with longer wheelbasesâ€”if the simulator is to accurately model turning,
it needs access to these important parameters. Furthermore, a vehicle with a long hood
will turn differently than a vehicle whose front wheels are located nearer to the front of the
vehicle.
3.1.2 Lanes
Lanes in our system consist of a directed line segment, a width, left and right borders that
vehicles may or may not be permitted to cross, and references to which lanes, if any, border
on the right and left side. In a real-life implementation, this would be a software construct
the vehicles and driver agents would use to perform lane following and changing. If a vehicle
wants to change lanes to the left or right, it must first establish that the vehicle is allowed
to cross the border between the lanes, after which it can feed its lane-following algorithm
the reference to the desired lane.
3.1.3 Physical Model
At each time step, the simulator must update the position of every vehicle. Because we
model only planar vehicle kinematics and not dynamics, we must make a few assumptions.
First, we assume that vehicles do not skid on the road. Second, we assume that vehicles
move according to the following differential equations for non-holonomic motion:
âˆ‚x
= v Â· cos(Ï†)
âˆ‚t
âˆ‚y
= v Â· sin(Ï†)
âˆ‚t
âˆ‚Ï†
tan Ïˆ
=vÂ·
âˆ‚t
L
In these equations, x, y, and Ï† describe the vehicleâ€™s position and orientation, v represents the vehicleâ€™s velocity, Ïˆ describes the vehicleâ€™s steering angle, and L is the vehicleâ€™s
wheelbase. We solve these equations holding v and Ïˆ constant for each time step.
3.1.4 Measuring Delay
In Section 2.1, we introduced delayâ€”the increase in travel time for a vehicle due to the
presence of the intersection. In the simulation, this is measured by first assuming that
on the open road, a vehicle can maintain its velocity at the speed limit. Each vehicle is
timestamped when it enters the simulation and keeps track of how far it has traveled. When
the vehicle is removed from simulation, its total delay is calculated as the difference between
how long it actually took to travel as far as it did and how long it would take were the
599

Dresner & Stone

vehicle to travel at the speed limit for the entire journey. By this measure, a zero delay is
not possible when the vehicle is turning, as it needs to slow down in order to safely make
the turn. In practice, we compare the delays of all vehicles to delays using a policy that
allows vehicles through the intersection unhindered, which will also be non-zero if any of
the vehicles turn or if the road is congested. In this way, we can quantify the effect of
the intersection on the vehicle, both directly (not being able to go through the intersection
because requests were rejected) and indirectly (having to decelerate because another vehicle
cannot get through).
3.2 Communication Protocol
This section presents a detailed communication protocol by which vehicles and intersections
can coordinate their behavior. The protocol as presented here offers three major benefits:
â€¢ All information between the agents goes through one monitorable channel, which
makes reasoning about the communication straightforward.
â€¢ By limiting the interactions of the agents to a few message types, we can ensure that
no agent has an unrealistic amount of control over another.
â€¢ The agents have a way to communicate that is identical for any intersection management policy or driver agent policy. Thus, a vehicle can cross an intersection without
having any idea what policy the intersection manager is usingâ€”it simply sends and
receives messages and obeys the rules.
The protocol consists of several message types for each kind of agent, as well as some
rules governing when the messages should be sent and what sorts of guarantees accompany
them. Driver agents can send Request, Change-Request, Cancel, and Done messages. Request and Change-Request are used when the driver agent wants to make a
reservation or change an existing reservation, respectively. Both types of request message
include all the relevant properties of the vehicle. Driver agents send a Cancel message
when they want to cancel an existing reservation. When a vehicle has successfully crossed
the intersection, its driver agent sends a Done message to the intersection manager. Both
the Cancel and Done messages include the VIN of the vehicle, as well as an identifier for
the reservation to be cancelled or reported as complete.
Intersection managers can send Confirm, Reject, and Acknowledge messages, as
well as a special Emergency-Stop message, which is only used when the intersection
manager detects a major problem in the intersection (see Section 5). Confirm is sent
when the intersection manager approves a Request or Change-Request message. It
includes information describing the reservationâ€”a unique identifier for the reservation, a
start time, a start lane, a departure lane (which will be identical to the start lane unless the
vehicle is turning), and a list of constraints for the vehicleâ€™s acceleration while it is in the
intersection. The Reject message is used to reject either a Request or Change-Request
message. The intersection sends an Acknowledge message in response to Cancel and
Done messages sent by the vehicles. A more detailed specification of the protocol including
full syntax and semantics can be found in Appendix B.
600

A Multiagent Approach to Autonomous Intersection Management

3.2.1 Message Corruption and Loss
We assume that messages can be digitally signed, such that the possibility of an undetected
message corruption is acceptably small. The protocol is designed specifically to be robust
to message loss. If a message is sent but not receivedâ€”or deemed corruptedâ€”the worst
thing that can happen is additional delay. No collisions can occur due to lost messages.
When a vehicle makes a reservation request, it does not assume the space is reserved until it
receives a confirmation from the intersection manager. If a Request message is dropped,
no Confirm message will follow. If a Confirm or Reject message is dropped, the vehicle
will simply try againâ€”it wonâ€™t assume that it has a valid reservation.
3.2.2 Enabling Policy Switching
The protocol hides the implementation of the policy from the driver agents â€” they have
no idea how the intersection manager is making its decisions, they are just guaranteed that
if they follow them, they will be safe. Thus, there are no stipulations that the policy must
remain fixed. An intersection manager could use one policy one moment and then switch
to a more appropriate policy later, provided it can still guarantee that vehicles following
the protocol make it safely across the intersection.
3.2.3 Intersection Manager
The intersection manager acts as a stable communication interface between the driver agents
and the intersection control policy and therefore does not contain a lot of functionality.
However, regardless of how the policy makes its decision, the intersection manager must
present the same interface to the driver agents. The general intersection manager algorithm
is shown in Algorithm 1. In it, Cancel messages and Done messages are treated almost
identicallyâ€”when a Done message is received, the intersection manager knows that the
policy can erase any information about the related reservation. However, the Done message
also may contain information that is useful to the intersection manager and policy. For
example, when a vehicle sends a Done message, it could include the delay it experienced
crossing the intersection, providing the intersection manager with a sort of reward signal,
by which it can judge its performance.
3.3 Driver Agent
The vast majority of this research focuses on how to make a better intersection manager
and control policy. These parts are designed to work with any driver agent that follows the
protocol. However, for testing purposes, a driver agent implementation is required. Despite
the fact that a lot of work went into the driver agent (it is probably the most intricate
part of the system), it is not the focus of this article. We refer the interested reader to
Appendix C, which explains the driver agent in detail. In brief, the driver agent estimates
the time and velocity at which it will reach the intersection, and requests an appropriate
reservation. If granted a reservation, it attempts to arrive on schedule. If it determines
that it is unable to keep the reservation, it cancels the reservation. If it believes it will be
substantially early, it attempts to change to an earlier reservation. If it is unable to get a
reservation, it decelerates (down to a minimum velocity) and requests again. It does not
601

Dresner & Stone

Algorithm 1 The intersection manager algorithm. Vehicle V sends a message to the
intersection manager, which responds according to policy P .
1: loop
2:
receive message from V
3:
if message type is Request then
4:
process request for new reservation with P
5:
if P accepts the request then
6:
send Confirm message to V containing the reservation returned by P
7:
else
8:
send Reject message to V
9:
else if message type is Change-Request then
10:
process request for change of reservation with P
11:
if P accepts the request then
12:
send Confirm message to V containing the reservation returned by P
13:
else
14:
send Reject message to V
15:
else if message type is Cancel then
16:
process cancel with P
17:
send Acknowledge message to V
18:
else if message type is Done then
19:
record any statistics supplied in message
20:
process cancel with P
21:
send Acknowledge message to V

enter the intersection without a reservation. On the open road, the driver agent employs a
simple lane-following algorithm, and maintains a following distance of one second between
its vehicle and the vehicle in front of it.
3.4 The FCFS Policy
To this point, weâ€™ve described the substrate infrastructure that enables our research. The
remainder of Section 3 introduces the core contribution of this article and the main payoff for
creating this infrastructure, namely an intersection control policy that enables fine-grained
coordination of vehicles at intersections, and a subsequent dramatic decrease in delays.
While the intersection manager communicates directly with the driver agents, the intersection control policy is the â€œbrainsâ€ behind the operation. Here we describe an intersection
control policy created from the reservation idea as discussed in Section 2.2. Because of the
â€œFirst Come, First Servedâ€ nature of the policy, we name this policy FCFS. The main part
of the policyâ€”the request processingâ€”is shown in Algorithm 2.
Recall that FCFS enables a car to reserve in advance the space-time it needs to cross
the intersection. Planning ahead allows vehicles coming from all directions to traverse the
intersection simultaneously with minimal delay. The policy works as follows:
â€¢ The intersection is divided into an n Ã— n grid of reservation tiles, where n is the
granularity of the policy.
602

A Multiagent Approach to Autonomous Intersection Management

â€¢ Upon receiving the reservation parameters from an approaching driver agent, the policy runs an internal simulation of the trajectory of the vehicle across the intersection
using these parameters.
â€¢ At each time step of the internal simulation, the policy determines which reservation
tiles will be occupied by the vehicle
â€¢ If at any time during the simulation the requesting vehicle occupies a reservation tile
that is already reserved by another vehicle, the policy rejects the request. Otherwise,
the policy accepts the reservation and reserves the appropriate tiles for the times they
will be required.
Figure 3 shows a graphical depiction of the concept behind the FCFS policy.

(a) Successful

(b) Rejected

Figure 3: The internal simulation of a granularity-8 FCFS policy. The black rectangles represent vehicles, and the shaded tiles are tiles that are currently reserved. In 3(a),
a vehicleâ€™s request is accepted, and the intersection reserves a set of tiles at time
t. In 3(b), a second vehicleâ€™s request is rejected because during the simulation of
its trajectory, the policy determines that it requires a tile (darkly shaded) already
reserved by the first vehicle at time t.

While the concept behind FCFS is sound, it requires some modifications before it will
work reliably, safely, and efficientlyâ€”even in simulation. In the remainder of this section, we
present these modifications, most of which were created in response to early experimental
results documented in Section 4.
3.4.1 Determining the Outbound Lane
In our first implementation of the reservation system, vehicles were capable of traveling
only in straight lines. Once we allowed vehicles to turn, it became apparent that the
driver agents should not determine which lane they use to exit the intersection. Instead,
the intersection manager, which has more information about the intersection, makes this
decision. Driver agents indicate in their request message which way they intend to turn,
or for more complicated intersections, which direction they intend to go. The intersection
control policy then decides in which outbound lane to place the vehicle. For all experiments
documented in this article, the FCFS policy chooses the most natural lane: for left and
603

Dresner & Stone

right turns, it chooses the nearest lane, whereas for vehicles that are not going to turn, it
chooses the lane in which they are planning to arrive at the intersection. However, a policy
could behave differently if configured to do so. For example, the policy can create a priority
list of outbound lanes based on the inbound lane, and then run internal simulations using
each of these lanes until it found an acceptable configuration. For turning vehicles, this list
would be the set of outbound lanes in the correct direction, sorted from nearest to farthest.
For vehicles not turning, it would â€œspiralâ€ out from the lane in which they arriveâ€”first the
arrival lane, then the lane to the left, then the lane to the right, then two lanes to the left,
and so forth. In this manner, a vehicle that might otherwise have had its request rejected
can obtain a reservation for a different path through the intersection.
3.4.2 Acceleration In The Intersection
Given a set of reservation parameters, there are an infinite number of possible trajectories
a vehicle can take, if it is allowed to accelerate in the intersection. This is because at
each time step, the driver agent could set its vehicleâ€™s acceleration to any value within the
limits of the vehicleâ€™s capabilities. Depending on the trajectory, the intersection manager
may or may not be able to grant the reservationâ€”one set of accelerations may cause it to
collide with another vehicle, while a second set might let the vehicle through safely. For
this reason, acceleration in the intersection must be constrained by the intersection control
policy. Allowing driver agents to decide their own acceleration within the intersection would
require the policy to be much more conservative in estimating vehicle trajectories, thereby
reducing efficiency substantially. Instead, it is the responsibility of the intersection control
policy to choose a safe and efficient acceleration schedule and include it in the Confirm
message, if the driver agentâ€™s request is accepted.
Choosing the best acceleration schedule for the requesting vehicle, or on an even more
basic level, finding a schedule for which the intersection manager can grant the reservation, is a difficult challenge for the intersection control policy. Our initial solution was to
allow no acceleration within the intersection; driver agents were required to maintain the
same velocity throughout the entire trajectory. This approach had several major flaws, the
most severe of which was causing a deadlock scenario as vehicles traversed the intersection
more and more slowly, unable to recover from the slightest decelerations. This scenario is
described in much more detail in Section 4.2.
The FCFS policy, as we have implemented it still takes a fairly straightforward approach
to the problem of determining acceleration schedules for reservation requests. It first attempts a trajectory in which the requesting vehicle accelerates as quickly as possible to
maximum velocity as soon as it enters the intersection. If it cannot grant a reservation
based on that trajectory, it tries one in which the requesting vehicle maintains a constant
velocity throughout the intersection. If neither work, it rejects the request. Furthermore, if
the request indicates that the vehicle will arrive at a sufficiently slow velocityâ€”in our case
10 m/sâ€”it does not grant a fixed-velocity reservation. Were it to grant arbitrarily slow
reservations, a vehicle could use an excessively large amount of space-time in the intersection, causing other vehicles undue delay. By enforcing a minimum velocity for fixed-velocity
reservations, the policy ensures that no vehicle will spend too long in the intersection. While
more complex solutions exist, this solution is good for several reasons. First, it is compu604

A Multiagent Approach to Autonomous Intersection Management

d
dâ€™

Figure 4: Several vehicles are waiting at the intersection. With a reservation distance of
d, the front (white) vehicle is incapable of obtaining a reservation because the
vehicles behind it (shaded) hold conflicting reservations. Once the white vehicleâ€™s
request is rejected, the reservation distance is decreased to d0 . Once the shaded
vehicles cancel their reservations, the white vehicle can obtain a reservation uncontested.

tationally tractable: the policy runs at most two internal simulations per request. Second,
it allows vehicles that are stopped or moving very slowly at the intersection to clear the intersection in a timely manner once they get a reservation. Third, it eliminates the deadlock
scenario presented in Section 4.2 by allowing vehicles to recover from decelerating when
they cannot obtain a reservation; even a vehicle that comes to a full stop at the intersection
can accelerate back up to a reasonable velocity as it crosses the intersection.
3.4.3 Reservation Distance
Allowing accelerations in the intersection helps eliminate deadlocks, but other problems
arose in our prototype implementation that significantly impaired the performance of the
system. Frequently, a lane of traffic would become congested when many vehicles were
spawned in that lane. Even when the simulator stopped spawning vehicles in that lane, the
lane would remain congested. The problem is that FCFS, as first described, does nothing
to control how vehicles in the same lane are alloted reservations. At best, the frontmost
vehicle will get a reservation and make it through the intersection unhindered. However,
this is often not the case. Sometimes the vehicle in front cannot obtain a reservation (due
to congestion), and must decelerate. As shown in Figure 4, driver agents in vehicles further
back may expect to accelerate soon and successfully reserve space-time in the intersection
that the frontmost vehicle needs. While all vehicles will eventually make it through (a vehicle
might get a reservation immediately after vehicles behind it cancel), this process can repeat
many times before the frontmost vehicle gets a reservation. In the worst scenarios, a single
vehicle can continue for quite some time to obtain reservations that prevent the front car
from crossing the intersection.
If we could maintain the invariant that vehicles do not get reservations unless all cars
in front of them (in their lane) have reservations, this scenario could be avoided entirely. A
605

Dresner & Stone

simple way to enforce this would be to insist that no vehicle can get a reservation unless the
vehicle in front of it already has one. Unfortunately, there is no way to strictly enforce this:
vehicles do not communicate their positions (and even if they did, they could be untruthful).
However, because the vehicles communicate the time at which they plan to arrive at the
intersection, as well as what their velocity will be when they get there (quantities which
the vehicles have no incentive to misrepresent), it is possible to approximate a vehicleâ€™s
distance from the intersection, given a reservation request by that vehicle. We approximate
this distance, which we call the reservation distance, as va (ta âˆ’ t), where va is the proposed
arrival velocity of the vehicle (at the intersection), ta is the proposed arrival time of the
vehicle, and t is the current time. This approximation assumes the vehicle is maintaining a
constant velocity.
The policy uses the approximation as follows. For each lane i, the policy has a variable
di , initialized to âˆž. For each reservation request r in lane i, the policy computes the
reservation distance, d(r). If d(r) > di , r is rejected. If, on the other hand, d(r) â‰¤ di , r is
processed as normal. If r is rejected after being processed as normal, d i â† min(di , d(r)).
Otherwise, di â† âˆž.
While this does not guarantee that vehicles only get reservations if all vehicles in front
of them already have reservations, it makes it much more likely. Two properties make the
approximation particularly well-suited to this problem. First, if a vehicle is stopped at
the intersection, its reservation distance will be approximated as zero. This means that no
vehicle behind it will be granted a reservation before it isâ€”no smaller reservation distance
is possible. Furthermore, because the reservation distance is the product of the arrival
velocity and the time until the vehicle arrives, as vehicles approach the intersection and
slow down, the reservation distance gets smaller and more accurate. Thus, vehicles most
susceptible to the problem described in Figure 4 are the most likely to be protected against
it. The second property is that because the estimate uses the arrival velocity of the vehicle,
it overestimates the distance of vehicles expecting to accelerate significantly before reaching
the intersection. It is this expectation that causes driver agents to reserve space-time that
is needed by vehicles in front of them. Note also that this heuristic only works within a
single laneâ€”each lane keeps track of its own reservation distance.
In the example of Figure 4, the white vehicleâ€™s rejected reservation request would shorten
the maximum allowed reservation distance for its lane. This, in turn, would cause future
requests by the shaded vehicles to be immediately rejected, giving the white vehicle exclusive
access (within the lane) to the reservation mechanism. Once the white vehicle secured a
reservation, the maximum allowed reservation distance would be reset to the maximum,
and all vehicles would once again have equal priority.
3.4.4 Timeouts
Once a driver agentâ€™s reservation request is rejected, that driver agent may immediately
make a new request. Unless the new request is significantly different, it will most likely
be rejected as well. With the exception of the request made immediately after the first
rejected request, a driver agentâ€™s estimate of its arrival at the intersection is not likely to
change much in the instant between consecutive requests. Eventually, after the vehicle has
decelerated enough or the driver agents with conflicting reservations have canceled, the ve606

A Multiagent Approach to Autonomous Intersection Management

hicle will obtain a reservation and make it through the intersection. From the standpoint
of the intersection manager, each of the requests before the successful one are wasted effort.
While our policy runs at most two internal simulations per request, those simulations may
be computationally expensive, especially if the FCFS policy has a high granularity. Furthermore, if each rejected vehicle makes a request at every possible instant, the work can
add up very quickly.
In order to keep the required amount of computation down and discourage driver agents
from overloading the intersection manager with requests, the policy employs a system of
timeouts. Once a driver agentâ€™s request is rejected, subsequent requests will not be considered until a period of time (determined by the reservation parameters) has elapsed. When
rejecting a request, the policy includes in the rejection message the time after which it
will consider further requests from the driver agent. In our implementation, this time is
equal to t + min( 12 , (ta2âˆ’t) ), where t is the current time and ta is the time of arrival in
the request message. This process serves two purposes. First, it dramatically reduces the
amount of computation the policy needs to do, because the intersection manager receives
fewer requests. Vehicles may not obtain reservations at the earliest moment possible, but
the computational savings are more than worth it. Second, it gives preference to vehicles
that will enter the intersection sooner. If a vehicle is stopped at the intersection, it can send
requests as quickly as it wishes, giving it the best chance of getting a reservation approved.
A vehicle farther away, however, may have to wait the full half-second before attempting
to make another reservation. As a vehicle approaches the intersection, if it is unable to
procure a reservation, the frequency of opportunities to send reservation requests increases.
In practice, timeouts significantly improve the performance of the system, allowing it to
handle much higher traffic loads while avoiding backups.
3.4.5 Buffers: Static vs. Time
In any system involving physical robots, noise in sensor readings and errors in actuators will
inevitably manifest themselves. Even in simulation, artifacts resulting from the discretization of time are enough to weaken the reservation tilesâ€™ guarantees of exclusivity. In the
intersection, where vehicles move at high speeds in all different directions, these potential
sources of calamity cannot be ignored. For example, what happens when a driver agent
realizes that it will not make its reservation exactly on time, close enough to the intersection
that it is not possible to stop before entering the intersection? Some sort of safety buffer is
required. Two types of buffers are most natural: static buffers and time buffers.
Static buffersâ€”buffers whose size is constantâ€”certainly suffice for safety purposes. If the
intersection manager assumes each vehicle is ten times as large in each dimension, certainly
no vehicle should even get close to another vehicle. However, this defeats the point of the
intersection manager, which is to leverage the increased precision of autonomous vehicles.
Furthermore, a static buffer does not take into account the direction of motion of the vehicle.
Two vehicles whose paths would never intersect may begin to interfere with one anotherâ€™s
reservation process if a large static buffer is used, as in Figure 5(a).
Time buffers, on the other hand, do take into account the motion of the vehicles. If
the intersection manager instead assumes that the vehicle might be early or late, the actual
area restricted by this buffer will shrink and grow with the vehicleâ€™s velocity, and only in the
607

Dresner & Stone















 
 
 
 


 
 
 





(a) Static buffer

(b) Time buffer, low velocity

 
 
 
 
 







 
 
 
 
 







(c) Time buffer, high velocity

(d) Hybrid buffer

Figure 5: Various styles of buffers designed to cope with sensor noise and actuator errors.
The hatched areas show where buffers would cause reservation conflicts: only one
of each pair of conflicting vehicles would be granted a reservation.

direction of movement. Figures 5(b) and 5(c) show how the buffer scales with the speed of
the vehicle. Thus, if two vehicles are traveling along parallel lines, the time buffers for those
vehicles should not interfere unless those vehicles could potentially collide (they are in the
same lane or the lanes are too close together for the vehiclesâ€™ width). Alone, time buffers
are not sufficient to guarantee safety â€” a small error in lateral positioning (orthogonal to
the direction of motion) may still cause a collision. Figure 5(d) shows the best solution:
a hybrid buffer. The hybrid buffer has a time buffer that scales with velocity, as well as a
small static buffer that protects against lateral positioning errors and serves as a minimum
buffer for slow-moving vehicles.
3.4.6 Edge Tiles
When driving on the open road, vehicles must maintain a reasonable following interval
(usually measured as an amount of time) between one another. If a vehicle decelerates suddenly, it puts the vehicle behind it in a dangerous situationâ€”if the rear vehicle doesnâ€™t react
quickly enough, it may collide with the front vehicle. In the intersection, following intervals
are not very practical, because vehicles are traveling in many different directions. Vehicles
in the intersection cannot react normally to their sensor readings, because the intersection
manager may orchestrate some â€œclose callsâ€ that would look like a potential collision to a
vehicle operating in â€œopen roadâ€ mode. Instead, the vehicles trust the constraints given
to them by the intersection manager. This does not pose a problem in the intersection,
but when a vehicle exits the intersection, it may enounter a vehicle that also just left the
intersection, but at a much slower velocity. As shown in Figures 6(a) and 6(b), this may
lead to an unavoidable collision, with the later vehicle being unable to stop quickly enough.
Even with autonomous vehicles, which can react almost instantaneously, some amount of
following interval is required for vehicles leaving the intersection.
608

A Multiagent Approach to Autonomous Intersection Management

B

A

B

A

A

B

(a) A turns right in front of
B.

(b) B cannot stop in time.

(c) B must slow down preemptively.

Figure 6: Edge tiles prevent collisions after vehicles leave the intersection. In 6(a), vehicle
A turns in front of vehicle B, traveling slowly because it is making a right turn.
In 6(b), vehicle B gets through the intersection without incident, but finds that
once it leaves the intersection, it cannot stop before colliding with vehicle A. The
extra buffers on edge tiles, as shown in 6(c), prevent vehicle B from obtaining a
reservation which would cause it to exit the intersection too close to vehicle A.
The shaded tiles are edge tiles, while the darkly shaded tiles are the specific tiles
that would prevent the collision in 6(a) and 6(b).

A first-cut solution to this problem is simply to increase the time buffers on all reservation tiles to the desired following interval. Thus, if vehicles require a following interval
of one second when exiting the intersection, then no vehicle will be able to reserve a tile
within one second of another vehicle. This ensures that vehicles leaving the intersection
in the same lane will not exit within one second of each other, and there will be a gap of
at least one second between the vehicles. Unfortunately, this wreaks havoc with FCFSâ€™s
ability to conduct vehicles efficiently through the intersection. The â€œclose callsâ€ from which
the system gets its efficiency advantages will no longer be possible.
Instead, we divide the reservation tiles into two groups. Internal tiles are tiles that
are surrounded on all sides by other reservation tiles. Edge tiles, which are shown shaded
in Figure 6(c), are tiles that abut the intersection. At sufficiently high granularities, edge
tiles are a relatively small fraction of the total number of tiles. It is only on these tiles
that we increase the time buffer to the desired following interval. Because (at sufficiently
high granularities) only vehicles leaving by the same lane will require the same edge tiles,
this modification enforces the desired following intervals without otherwise preventing the
intersection from exploiting its ability to interleave vehicles closely.
3.5 Other Policies
Because of the layer of abstraction provided by the protocol, the intersection manager can
work in an emulation mode, imitating modern-day control mechanisms, such as the stop
sign and traffic light. Here we briefly explain the implementation of two intersection control
policies designed to mimic these mechanisms.
609

Dresner & Stone

Algorithm 2 FCFSâ€™s request processing algorithm. FCFS has persistent state variables:
tiles, a map from tiles and times to vehicles, reservations, a map from vehicles to sets of
tiles, and timeouts, a map from vehicles to times.
1: tc â† the current time
2: if timeouts[vehicle id] < tc then
3:
reject the request
4: ta â† proposed arrival time
5: timeouts[vehicle id] â† tc + min(0.5, (ta âˆ’ tc )/2)
6: for acceleration in {true, false} do
7:
tile times â† {}
8:
t â† ta
9:
V â† temporary vehicle initialized according to reservation parameters
10:
while V is in the intersection do
11:
S â† tiles occupied by V and V â€™s static buffer at time t
12:
tile times â† tile times âˆª {(t, S)}
13:
for all s âˆˆ S do
14:
if s is an edge tile then
15:
buf â† edge tile buffer
16:
else
17:
buf â† internal tile buffer
18:
for i = âˆ’buf to buf do
19:
if tiles[s, t + i] is reserved by another vehicle then
20:
if acceleration then
21:
goto line 29
22:
else
23:
reject the request
24:
t â† t + time step
25:
move V according to physical model
26:
if acceleration then
27:
increase V â€™s velocity by V â€™s maximum acceleration
28:
break
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:

if request is a change then
old tile times â† reservations[vehicle id]
for all (ti , Si ) âˆˆ old tile times do
for all s âˆˆ Si do
clear reserved status of tiles[s, ti ]
for all (ti , Si ) âˆˆ tile times do
for all s âˆˆ Si do
tiles[s, ti ] â† vehicle id
reservations[vehicle id] â† tile times
accept request, return reservation constraints (incl. accelerations)

610

A Multiagent Approach to Autonomous Intersection Management

Stop-Sign Stop signs are traditionally used at intersections with very light traffic. While
they are much more cost-effective and reliable, they cannot provide the throughput
and efficiency of a traffic light. Thus, there would never be a reason for our system
to emulate a stop sign, however we include a description for completeness.
Stop-Sign is exactly like FCFS, except that it only accepts reservations from vehicles
that are stopped at the intersection. Any other reservation requests are rejected
with a message indicating the vehicle must stop at the intersection. The intersection
determines whether a vehicle is stopped at the intersection by examining the difference
between the current time and the arrival time in the request message.
Traffic-Light When the Traffic-Light policy receives a reservation request message,
it calculates the next time after the proposed arrival time that the light for sending
vehicleâ€™s lane will be green. It then responds with a confirmation message that reflects
this information. Because confirmation messages have maximum tolerable errors associated with them, the intersection manager uses these errors to encode the beginning
and end of the green light period.
3.6 Compatibility With Human Drivers
While an intersection control mechanism for autonomous vehicles will someday be very
useful, there will always be people who enjoy driving. Additionally, there will be a fairly
long transitional period between the current situation (all human drivers) and one in which
human drivers are a rarity. Even if switching to a system comprised solely of autonomous
vehicles were possible, pedestrians and cyclists must also be able to traverse intersections in
a controlled and safe manner. For this reason, it is necessary to create intersection control
policies that are aware of and able to accommodate humans, whether they are on a bicycle,
walking to the corner store, or driving a â€œclassicâ€ car for entertainment purposes. In this
section we explain how we have extended the FCFS policy and the reservation framework
to incorporate human drivers. In order to accommodate human drivers, a control policy
must be able to direct both human and autonomous vehicles, while coordinating them,
despite having much less control and information regarding where and when the human
drivers will be. The main concept behind our extension is the assumption that there is
a human-driven vehicle anywhere one could be. While this may be less efficient than an
approach which attempts to more precisely model human behavior, it is guaranteed to be
safe, one of the desiderata on which we are unwilling to compromise. Adding pedestrians
and cyclists follows naturally, and we give brief descriptions of how this would differ from
the extensions for human drivers.
Compatibility with human drivers offers more than the ability to handle the occasional
human driver once the levels of human drivers in everyday traffic reaches a steady state. It
will also help facilitate the transition from the current standardâ€”all human-driven vehicles
â€” to this steady state, in which human drivers are scarce. In Section 2.1, we emphasized the
need for incremental deployability. As we will show experimentally, human compatibility
adds significantly to the incremental deployability of the reservation system. We will also
show that the specifics of the implementation offer further benefits: incentives for both
communities and private individuals to adopt autonomous vehicle technology.
611

Dresner & Stone

3.6.1 Using Existing Infrastructure
A reliable method of communicating with human drivers is a prerequisite for including
them in the system. The simplest and best solution is to use something human drivers
already know and understand â€” traffic lights. Traffic light infrastructure is already present
at many intersections and the engineering and manufacturing of traffic light systems is well
developed. For pedestrians and cyclists, standard â€œpush-buttonâ€ crossing signals can be
used that give enough time for a person to traverse the intersection. These can also serve
to alert the intersection to their presence.
3.6.2 Light Models
If real traffic lights are to be used to communicate to human drivers, they must be controlled
and understood by the intersection manager. Thus, we add a new component to each
intersection control policy, called a light model. The light model controls the physical lights
as well as providing information to the policy with which it can make decisions. In more
complicated scenarios, the light model can be modified by the control policy, for example,
in order to adapt to changing traffic conditions. The lights have the same semantics as
modern-day lights: red (do not enter), yellow (if possible, do not enter; light will soon be
red), and green (enter). Each control policy requires a light model so that human users
know what to do. For instance, the light model for FCFS keeps all the lights red at all
times, indicating to humans that it is never safe to enter. The Traffic-Light policyâ€™s light
model, on the other hand, corresponds exactly to the light system the policy is emulating.
Here, we describe a few light models used in our experiments.
All-Lanes In this model, which is very similar to some current traffic light systems, each
direction in succession gets green lights in all lanes. Thus, all northbound traffic (turning
and going straight) has green lights while the eastbound, westbound, and southbound traffic
all have red lights. The green lights then cycle through the directions. As it is similar
to some current traffic lights, this light model is particularly well-suited to controlling
distributions of vehicles with significant contingents of human drivers. We demonstrate this
fact experimentally in Section 4.5. Figure 7 shows a graphical depiction of this light model.

Figure 7: The All-Lanes light model. Each direction gets all green lights in a cycle: north,
east, south, west. During each phase, the only available paths for autonomous
vehicles with red lights are right turns.

Single-Lane In the Single-Lane light model, the green light rotates through the lanes
one at a time instead of by direction. For example, the left turn lane of the northbound traffic
612

A Multiagent Approach to Autonomous Intersection Management

would have a green light, while all other lanes would have a red light. Next, the straight
lane of the northbound traffic would have a green light, then the right turn. Next, the green
light would go through each lane of eastbound traffic, and so forth. A graphical description
of the modelâ€™s cycle can be seen in Figure 8. This light model does not work very well if
most of the vehicles are human-driven, but as we will show, is very useful for intersections
which control mostly autonomous vehicles but need also to handle an occasional human
driver.

Figure 8: The Single-Lane light model. Each individual lane gets a green light (left turn,
straight, then right turn), and this process is repeated for each direction. Note
how a smaller part of the intersection is used by human vehicles at any given
time. The rest of the intersection is available to autonomous vehicles.

3.6.3 The FCFS-Light Policy
In order to obtain some of the benefits of the FCFS policy while still accommodating human
drivers, a policy needs to do two things:
1. If a light is green, ensure that it is safe for any vehicle (autonomous or human-driven)
to drive through the intersection in the lane the light regulates.
2. Grant reservations to driver agents whenever possible. Autonomous vehicles can thus
move through red lights (whereas humans cannot), provided they have a reservationâ€”
similar to a â€œright on redâ€, but extended much further to other safe situations.
The policy FCFS-Light, which does both of these, is described as follows:
â€¢ As with FCFS, the intersection is divided into a grid of n Ã— n tiles.
â€¢ Upon receiving a request message, the policy uses the parameters in the message to
establish when the vehicle will arrive at the intersection.
â€¢ If the light controlling the lane in which the vehicle will arrive at the intersection will
be green at that time, the reservation is confirmed.
â€¢ If the light controlling the lane will be yellow, the reservation is rejected.
â€¢ If the light controlling the lane will be red, the journey of the vehicle is simulated as
in FCFS (Section 3.4).
â€¢ If throughout the simulation, no required tile is reserved by another vehicle or in use
by a lane with a green or yellow light, the policy reserves the tiles and confirms the
reservation. Otherwise, the request is rejected.
613

Dresner & Stone

REQUEST
Preprocess

Yes,
Restrictions

Red

Light Model

No, Reason

FCFS

REJECT

Postprocess

Yellow

Driver
Agent

Green

CONFIRM

Intersection Manager

Figure 9: FCFS-Light is the combination of FCFS and a light model. When a request
is received, FCFS-Light first checks to see what color the light will be. If it
is green, it grants the request. If it is yellow, it rejects. If it is red, it defers to
FCFS.

Off-Limits Tiles Unfortunately, simply deferring to FCFS does not guarantee the safety
of the vehicle. If the vehicle were granted a reservation that conflicts with a vehicle following
the physical lights, a collision could easily ensue. To determine which tiles are in use by
the light system at any given time, we associate a set of off-limits tiles with each light.
For example, if the light for the northbound left turn lane is green (or yellow), all tiles
that could be used by a vehicle turning left from that lane are considered reserved for the
purposes of FCFS. The length of the yellow light is adjusted so that vehicles entering the
intersection have enough time to clear the intersection before those tiles are no longer off
limits.
FCFS-Light Subsumes FCFS Using a traffic lightâ€“like light model (for example AllLanes), FCFS-Light can behave exactly like Traffic-Light if all drivers are human.
With a light model that keeps all lights constantly red, FCFS-Light behaves exactly like
FCFS. In this case, if any human drivers are present it will fail spectacularly, leaving the
humans stuck at the intersection indefinitely. However, in the absence of human drivers, it
will perform exceptionally well. FCFS is just a special case of FCFS-Light. We can thus
alter FCFS-Lightâ€™s behavior to vary from strictly superior to Traffic-Light to exactly
that of FCFS.
3.7 Emergency Vehicles
In current traffic laws there are special procedures involving emergency vehicles such as
ambulances, fire trucks, and police cars. Vehicles are required to pull over to the side of
the road and come to a complete stop until the emergency vehicle has passed. This is
both because the emergency vehicle may be traveling quickly, posing a danger to other
vehicles, and because the emergency vehicle must arrive at its destination as quickly as
possibleâ€”lives may be at stake. Hopefully, once a system such as this is implemented,
automobile accidentsâ€”a major reason emergency vehicles are dispatchedâ€”will be all but
eradicated. Nonetheless, emergency vehicles will still be required from time to time as fires,
heart attacks, and other emergencies will still exist. While we have previously proposed
other methods for giving priority to emergency vehicles (Dresner & Stone, 2006), here we
present a new, simpler method, which is fully implemented and tested.
614

A Multiagent Approach to Autonomous Intersection Management

3.7.1 Augmenting The Protocol
In order to accommodate emergency vehicles, the intersection manager must first be able
to detect their presence. The easiest way to accomplish this is to add a new field to all
request messages. In our implementation, this field is simply a flag that indicates to the
intersection manager that the requesting vehicle is an emergency vehicle in an emergency
situation (lights flashing and siren blaring). In practice, however, safeguards would need
to be incorporated to prevent normal vehicles from abusing this feature in order to obtain
preferential treatment. This could be accomplished using some sort of secret key instead of
simply a boolean value, or even some sort of public/private key challenge/response mechanism. This details of the implementation, however, are beyond the scope of this project
and are already a well-studied area of cryptography and computer security.
3.7.2 The FCFS-Emerg Policy
Now that the intersection control policy can detect emergency vehicles, it can process reservation requests while giving priority to the emergency vehicles. A first-cut solution is simply
to deny reservations to any vehicles that are not emergency vehicles. However, this solution
is not satisfactory, because if all the traffic comes to a stop due to rejected reservation
requests, any emergency vehicles may get stuck in the resulting congestion. Instead, the
FCFS-Emerg policy keeps track of which lanes currently contain approaching emergency
vehicles. As long as at least one emergency vehicle is approaching the intersection, the
policy grants reservations only to vehicles in those lanes. This ensures that vehicles in front
of the emergency vehicles will also receive priority. Due to this increase in priority, lanes
with emergency vehicles tend to empty very rapidly, allowing emergency vehicles to proceed
relatively unhindered.
3.8 Summary
In this section, we have explained how we created a reservation-based intersection control
mechanism in simulation. We described the construction of the simulator itself, as well
as the communication protocol, the intersection manager, the driver agent, and several
intersection control policies. The first policy, FCFS is only for fully autonomous vehicles.
FCFS-Light extends FCFS to allow human interoperability using existing traffic light
infrastructure. The last policy, FCFS-Emerg, extends FCFS to give priority to emergency
vehicles without significant increasing delays for other vehicles.

4. Experimental Results
In this section, we fully test all of the features introduced in Section 3 and demonstrate that
the reservation system can reduce delay by two orders of magnitude. Our experiments evaluate the performance of the reservation system using different intersection control policies,
amounts of traffic, granularities, levels of human drivers, and the presence of emergency
vehicles. We first compare the system using FCFS to traffic lights of varying cycle periods
using a prototype simulator. We then show results from the full version, including the stop
sign control policy as implemented under our protocol, comparing these results to those from
the traffic light experiments. Next, we experiment with allowing vehicles to turn from any
615

Dresner & Stone

laneâ€”something that would be extremely dangerous without the reservation-based mechanism. Finally, we evaluate the two extensions to FCFS: FCFS-Light and FCFS-Emerg.
Videos of the simulator in action, including many scenarios from this section, as well as other
supplementary materials can be found at http://www.cs.utexas.edu/~kdresner/aim/.
4.1 Low-Granularity FCFS vs. the Traffic Light
The simplest implementation of FCFS has granularity 1â€”the entire intersection is a single reservation tile. While only one vehicle may be in the intersection at a time, if that
vehicle is traveling sufficiently fast, the total amount of time for which it will occupy the
intersection is small. If we increase the granularity to 2, the intersection is no longer entirely exclusive. For example, non-turning vehicles traveling north no longer compete for
the same reservation tiles as non-turning vehicles traveling south (similarly, eastbound and
westbound non-turning vehicles no longer compete). Here we present our initial results
comparing these two instances of the reservation mechanism and several incarnations of a
traffic light.
4.1.1 Experimental Setup
These experiments were carried out using a prototype version of the simulator, which is fully
described in an earlier publication (Dresner & Stone, 2004). In this version of the simulator,
vehicles are not allowed to turn or accelerate while in the intersection. These restrictions do
not detract from the core challenge of the problem, and the results are relevant even when
the restrictions are relaxed. Each simulation contains one lane traveling in each direction,
the speed limits of which are 25 meters per second. Traffic spawning probability varies from
0.0001 to 0.02 in increments of 0.0001, and each configuration runs for 500,000 steps in the
simulator, which corresponds to approximately 2.5 hours of simulated time.
4.1.2 Results
Figure 10(a) shows delay times for traffic light systems with varying periods, ranging from
extremely short (10 seconds) to fairly long (50 seconds). As expected from real-life experience, short-period traffic lights control light traffic well, while traffic lights with longer
periods work better in heavy-traffic scenarios. When traffic is sparse, a short period allows
vehicles to wait a shorter time before getting a green light. In many cities, traffic light
periods are shortened during early hours of the morning to take advantage of this fact. In
scenarios with more densely packed vehicles, the per-vehicle costs of slowing to a stop and
accelerating back to full speed, as well as the intervals needed to clear out the intersection
(the time during which there is a yellow light, or all lights are red), tend to dominate.
This makes the longer-period lights better in these situations. In the Figure 10(a), above a
certain traffic level, each of the traffic light systems reaches what appears to be a maximum
delay level. This is an artifact of the simulatorâ€”when the traffic level gets high enough,
the vehicles back up so far that the simulator cannot keep track of them (it cannot spawn
new vehicles, for lack of a place to put them). At this point, vehicles are arriving at the
intersection faster than the traffic lights can safely coordinate their passage. Thus, the
point at which the delay spikes upwards indicates the maximum throughput of each traffic
configuration.
616

100
90
80
70
60
50
40
30
20
10
0

0.7
Period 10

0.6

Period 30

Average Delay (s)

Average Delay (s)

A Multiagent Approach to Autonomous Intersection Management

Period 50

Granularity 1

0.5
0.4
0.3
Granularity 1
0.2
Granularity 2

0.1
0
0.2

0.4

0.6

0.8

1

0.2

Traffic Level (vehicles/s)

0.4

0.6

0.8

1

Traffic Level (vehicles/s)

(a) Reservation vs. Traffic Light

(b) Increasing Granularity

Figure 10: 10(a) shows average delays for traffic light systems with period 10, 30, and 50 seconds plotted against varying traffic levels along with a 1-tiled reservation-based
system. 10(b) shows average delays for granularity 1 and 2 FCFS policies with
varying traffic levels. Spawning probability was varied in increments of 0.0001,
and each configuration was run for 1,000,000 steps of simulation (approximately
5.5 hours of simulated time). Each direction has 1 lane.

Also in Figure 10(a) are the delays for the granularity-1 and 2 FCFS policies. With
the car spawning probability below about 0.013, the granularity-1 policyâ€™s delay is visually
indistinguishable from the x-axis, while this is true for the granularity-2 reservation system
for the whole graph. Figure 10(b) shows the bottom 0.7% of the graph, enlarged to show
these results in more detail. At the vehicle spawning rate of 0.02, all of the traffic light
systems are already beyond maximum capacity, while the granularity-2 system is allowing
vehicles through without even adding a tenth of a second to the average vehicleâ€™s travel
time.
4.2 Choosing Granularity
Of note in Figure 10(a) is the spike in delay for the granularity-1 FCFS policy. The system looks as though it is behaving chaoticallyâ€”in Figure 10(b), delay slowly and steadily
increases with the traffic level, until spiking off the graph when the probability of spawning
a vehicle each time step reaches about 0.013.
With the granularity-1 system, vehicles traveling parallel to one another compete for
the same tiles. This also happens to vehicles in the lanes closest to the middle of the
road whenever the granularity is a small, odd number, as in Figure 11(b). Recall that in
the prototype simulator, acceleration in the intersection is forbidden. Thus, if a vehicle
slows down because it cannot obtain a reservation, when it finally does get a reservation
it will be moving slowly for the entirety of the reservation and occupy the reservation
tiles for a longer period of time. The next car to approach the intersection is therefore
more likely to slow down as well. This process feeds itself and the vehicles slow down
more and more. For small to average amounts of traffic, delays increase, but the system
recovers during probabilistically generated periods of light traffic. However, for very heavy
617

Dresner & Stone

traffic, the intersection will eventually reach a deadlocked state. Because traffic is generated
stochastically, this could happen early or late in the experiment. If it happens early, it will
have a large effect on the average delay, whereas if it happens late, the effect will be smaller.
Deadlocking is difficult to measure quantitatively, because as it progresses, driver agents
make reservations for very long periods of timeâ€”so long, in fact, that they overflow the
memory of the computer running the simulator. This effect can be seen in the rough line in
Figure 10(a). To further explore the effects of granularity, we ran several more experiments,
varying the granularity as well as the number of lanes.

(a) Granularity 8

(b) Granularity 9

Figure 11: Increasing the granularity does not always improve performance. In 11(a), a
granularity of 8 suffices. In 11(b), increasing the granularity to 9 actually hurts
performanceâ€”vehicles traveling parallel to each other (but in opposite directions) are competing for the middle row of tiles.

4.2.1 Experimental Setup
These experiments were also used the prototype simulator as described in Section 4.1.1.
Each data point represents 500,000 steps of simulation (approximately 2.5 hours of simulated
time). The traffic level is fixed at 0.2 vehicles per second.
4.2.2 Results
As shown in Figure 12, with 2 lanes in each direction, a 2 Ã— 2 grid performs better than
a 3 Ã— 3 grid. Increasing to a 4 Ã— 4 grid is better than 2 Ã— 2, but increasing it to 5 Ã— 5 is
again worse. An increase in granularity should correspond to a decrease in delay. However,
for small granularities, incrementing the granularity from a small even number to a small
odd number actually increases delay. In the case of maximum delay, even the granularity-2
618

A Multiagent Approach to Autonomous Intersection Management

0.14

3

0.12

2.5

0.1

Maximum Delay (s)

Average Delay (s)

system performs better than the granularity-5 system; the ill effects of odd granularities as
shown in Figure 11 tend to slow down a few unfortunate vehicles.

0.08
0.06
0.04

2

1.5

1

0.5

0.02
0

0
2

3

4

5

2

Granularity

3

4

5

Granularity

(a) Average delay

(b) Maximum delay

Figure 12: Simulation statistics for FCFS policies with varying granularity. There are 2
lanes in each direction and the traffic level is 0.2 vehicles per second. Each
experiment is run for 500,000 simulation steps. Note that increasing the granularity does not always improve performance.
This experiment suggests that FCFS should always be run with granularity high enough
such that vehicles that never cross paths never compete for the same reservation tiles. As
Figure 13 shows, more lanes require a higher granularity (though even with low granularity,
the system out-performs the traffic light). However, because the computational complexity
of the system increases proportional to the square of the granularity, the granularity should
not be increased indiscriminately.
4.3 The Full Power of FCFS
While earlier experiments used a prototype simulator, these experiments use the full power
of FCFSâ€”turning, acceleration, and all the modifications from Section 3.4. Because vehicles
turn, and thus do not always travel within a line of reservation tiles, increasing granularity
beyond twice the number of lanes can improve performance even more. In addition to
FCFS, we evaluate the stop sign policy as presented in Section 3.2.
Technically, the optimal delay for an individual vehicle is no delay at all. However,
although a vehicle could experience delay as low as 0 seconds, turning vehicles may need to
slow to avoid losing control. In order to create a worthwhile benchmark against which to
compare the reservation system, we empirically measure the optimal average delay for an
intersection manager. To do this, we use a special control policy that accepts all requests.
We also deactivate each vehicleâ€™s ability to detect other vehicles, eliminating the interactions
between them. These results are presented as the â€œoptimalâ€ control policy, which while
optimal in terms of delay, provides no safety guarantees.
Small intersections with slow-moving traffic tend not to be amenable to control by traffic
lights. Very light traffic can usually regulate itself fairly effectively. For example, consider an
intersection with a stop signâ€”all vehicles must come to a stop, but afterwards may proceed
619

Dresner & Stone

6 Lanes
3 Lanes
2 Lanes
1 Lane

0.14

Average Delay (s)

0.12
0.1
0.08
0.06
0.04
0.02
0
1

2

6
Granularity

12

48

Figure 13: Average delays for the FCFS policy with independently varying numbers of lanes
and granularity. Increasing the granularity beyond twice the number of lanes
results in only marginal improvements. All simulations were run for at least
500,000 steps. 6 lanes with 1 tile deadlocks and overflows the system memory
before 500,000 steps can complete.

if the intersection is clear. In these situations, a stop sign is often much more efficient than
a traffic light, because vehicles are never stuck waiting for a light to change when there is
no cross-traffic. The protocol enables us to define such a control policy, and we compare it
experimentally to the other policies. Note that this policy is much more efficient than an
actual stop sign, because once the vehicle has stopped at the intersection, the driver agent
and intersection can determine when the car may safely proceed much more precisely and
much less conservatively than a human driver.
4.3.1 Experimental Setup
The simulator simulates 3 lanes in each of the 4 cardinal directions. The speed limit in all
lanes is 25 meters per second. Every configuration shown is run for at least 100,000 steps in
the simulator, which corresponds to approximately half an hour of simulated time. Vehicles
that are spawned turn with probability 0.1, and turning vehicles turn left or right with
equal probability. Vehicles turning right are spawned in the right lane, whereas vehicles
turning left are spawned in the left lane. Vehicles that are not turning are distributed
probabilistically amongst the lanes such that the traffic in each lane is as equal as possible.
FCFS and the stop sign (implemented as an extension of FCFSâ€”see Section 3.5) both have
a granularity of 24.
4.3.2 Results
The results for the experiments are shown in Figure 14. As expected, the average delay for
the optimal system is positive and nonzero, but very small.
620

A Multiagent Approach to Autonomous Intersection Management

FCFS performs very well, nearly matching the performance of the optimal policy. At
higher levels of traffic, the average delay for a vehicle gets as high as 0.35 seconds, but is
never more than 1 second above optimal. Under none of the tested conditions does FCFS
even approach the delay of the traffic light system from the previous experiment, shown in
Figure 10(a).
The stop sign does not perform as well as FCFS, but for low amounts of traffic, it
still performs fairly well, with average delay only about 3 seconds greater than optimal.
However, as the traffic level increases, performance degrades. It is difficult to imagine a
scenario in which this implementation of the stop sign would actually be usedâ€”it requires
the same technology as the reservation system, but does not have any advantages over
FCFS.
5
4.5

Stop Sign

4
3.5
Delay (s)

Traffic Light Minimum
3
2.5
2
1.5
1

Optimal

0.5

FCFS

0
0

0.5

1

1.5

2

2.5

Traffic Level (vehicles/s)

Figure 14: Delays for varying amounts of traffic for FCFS, the stop sign, and the optimal
system.

4.4 Allowing Turns from Any Lane
In traditional traffic systems, especially those with traffic lights, vehicles wishing to turn
onto the cross street must do so from specially designated turning lanes. This helps prevent
cars that want to turn from holding up non-turning traffic. However, with a system like
the reservation system, this restriction is no longer necessary. There is nothing inherent
in the reservation system that demands vehicles turn from any specific lane. Investigating
the effects of allowing turning from any lane produced some surprising results. As seen in
Figure 15, relaxing the restriction actually hurts FCFSâ€™s performance slightly. While one
621

Dresner & Stone

might think this allows the vehicles more flexibility, on average it increases the resources
used by any one turning vehicle. By making left turns from the left lane and right turns
from the right lane, vehicles both travel a shorter distance and reserve reservation tiles that
are less heavily used. However, these experiments may be misleading. Vehicles changing
lanes to get into a designated turn lane could potentially delay vehicles behind them in the
process. Because we do not currently model lane changing before the intersection, we have
not been able to experimentally verify this conjecture.
1
Fixed Lane
Any Lane

Delay (s)

0.8

0.6

0.4

0.2

0
0

0.5

1
1.5
Traffic Level (vehicles/s)

2

2.5

Figure 15: Comparison of an FCFS policy with traditional turns to one allowing turning
from any lane. Allowing turns from any lane decreases performance slightly,
producing longer delays.

4.5 The Effects of Human Interoperability
In Section 4.3, we showed that once all vehicles are autonomous, intersection-associated
delays can be reduced dramatically. The following experiments suggest a stronger result:
by using the two light models presented in Section 3.6.2, delays can be reduced at each stage
of adoption. Furthermore, additional incentives exist at each stage for drivers to switch to
autonomous vehicles.
4.5.1 Experimental Setup
For these experiments, the simulator models 3 lanes in each of the 4 cardinal directions.
The speed limit in all lanes is 25 meters per second. For each intersection control policy
with reservation tiles, the granularity is 24. The simulator spawns all vehicles turning left in
the left lane, all vehicles turning right in the right lane, and all vehicles traveling straight in
622

A Multiagent Approach to Autonomous Intersection Management

the center lane1 . Unless otherwise specified, each data point represents 180000 time steps,
or one hour of simulated time. Our simulated human-driven vehicles use a two-second
following distance, but use the same lane-following algorithm as the autonomous drivers.
They also employ a â€œpoint-of-no-returnâ€ mechanism for reacting to lightsâ€”if the vehicle
can stop at a yellow or red light, it does, otherwise it proceeds.
4.5.2 Results
We present the experimental results for the human-compatible policies in two parts. The
first focuses on how these policies can facilitate a smooth transition to an all-autonomous or
mostly-autonomous vehicle system. The second focuses on the incentives throughout this
process, both global and individual, to continue deployment of the system. Combined, these
results suggest that an incremental deployment (one of the desiderata) is both technically
possible and desirable.
Transition To Full Deployment The purpose of a hybrid intersection control policy
is to confer the benefits of autonomy to passengers with driver-agent controlled vehicles
while still allowing human users to participate in the system. Figure 16 shows a smooth
and monotonically improving transition from modern-day traffic lights (represented by the
Traffic-Light policy) to a completely or mostly autonomous vehicle mechanism (FCFSLight with the Single-Lane light model). In early stages (100%-10% human), the AllLanes light model is used. Later on (less than 10% human), the Single-Lane light model
is introduced. At each change (both in driver populations and light models), delays are
decreased. Notice the rather drastic drop in delay from FCFS-Light with the All-Lanes
light model to FCFS-Light with the Single-Lane light model. Although none of the
results is quite as close to the minimum as pure FCFS, the Single-Lane light model
allows for greater use of the intersection by the FCFS portion of the FCFS-Light policy,
which translates to higher efficiency and lower delay.
For systems with a significant proportion of human drivers, the All-Lanes light model
works wellâ€”human drivers have the same experience they would with the Traffic-Light
policy, but autonomous driver agents have extra opportunities to make it through the
intersection. A small amount of this benefit is passed on to the human drivers, who may
find themselves closer to the front of the lane while waiting for a red light to turn green. To
explore how much the average vehicle would benefit, we ran our simulator with the FCFSLight policy, the All-Lanes light model, and a 100%, 50%, and 10% rate of human drivers.
This means that when a vehicle is spawned, it receives a human driver (instead of a driver
agent) with probability 1, .5, and .1 respectively. As seen in Figure 17, as the proportion of
human drivers decreases, the delay experienced by the average driver also decreases. While
these decreases are not as large as those brought about by the Single-Lane light model,
they are at least possible with significant numbers of human drivers.
Incentives For Individuals Even without any sort of autonomous intersection control
mechanism, there are incentives for humans to switch to autonomous vehicles. Not having
1. This is a constraint we will likely relax in the future. It is included in this work to give the Single-Lane
light model more flexibility and for a fair comparison to the FCFS policy, which performs even better
in its absence.

623

Dresner & Stone

60

50

5% Human

Delay (s)

40

30
100% Human
20
1% Human

10% Human
10

Fully Autonomous
0
0

0.5

1
1.5
Traffic Level (vehicles/s)

2

2.5

Figure 16: Average delays for all vehicles as a function of traffic level for FCFS-Light with
two different light models: the All-Lanes light model, which is well-suited to
high percentages of human-driven vehicles, and the Single-Lane light model,
which only works well with relatively few human-driven vehicles. As adoption
of autonomous vehicles increases, average delays decrease.

20

Delay (s)

15

10

5
TRAFFIC-LIGHT
FCFS-LIGHT 50% Human
FCFS-LIGHT 10% Human
0
0

0.25

0.5
Traffic Level (vehicles/s)

0.75

1

Figure 17: Average delays for all vehicles as a function of traffic level for FCFS-Light
with the All-Lanes light model. Shown are the results for 100%, 50%, and
10% human-driven vehicles. The 100% case is equivalent to the Traffic-Light
policy. Note that the average delay decreases as the percentage of human-driven
vehicles decreases.

to do the driving, as well as the myriad safety benefits are strong incentives to promote
autonomous vehicles in the marketplace. Our experimental results suggest additional incentives. Using our reservation system, autonomous vehicles experience lower average delays
than human-driven vehicles and this difference increases as autonomous vehicles become
more prevalent.
Figure 18 shows the average delays for human drivers as compared to autonomous driver
agents for the FCFS-Light policy using the All-Lanes light model. In this experiment,
half of the drivers are human. Humans experience slightly longer delays than autonomous
vehicles, but not worse than with the Traffic-Light policy. Thus, by putting some
624

A Multiagent Approach to Autonomous Intersection Management

autonomous vehicles on the road, all drivers experience equal or smaller delays as compared
to the current situation. This is expected because the autonomous driver can do everything
the human driver does and more.
35
Humans
Autonomous
30

Delay (s)

25
20
15
10
5
0
0

0.25

0.5
Traffic Level (vehicles/s)

0.75

1

Figure 18: Average delays for human-driven vehicles and all vehicles as a function of traffic
level for FCFS-Light with the All-Lanes light model. In this experiment,
50% of vehicles are human driven. Autonomous vehicles experience slightly
lower delays across the board, and human drivers experience delays no worse
than the Traffic-Light policy.

Once the reservation system is in widespread use and autonomous vehicles make up
a vast majority of those on the road, the door is opened to an even more efficient light
model for the FCFS-Light policy. With a very low concentration of human drivers, the
Single-Lane light model can drastically reduce delays, even at levels of overall traffic that
the Traffic-Light policy can not handle. Using this light model, autonomous drivers can
pass through red lights even more frequently because fewer tiles are off-limits at any given
time. In Figure 19 we compare the delays experienced by autonomous drivers to those of
human drivers when only 5% of drivers are human and thus the Single-Lane light model
can be used. While the improvements using the All-Lanes light model benefit all drivers
to some extent, the Single-Lane light modelâ€™s sharp decrease in average delays (Figure 16)
comes at a high price to human drivers.
As shown in Figure 19, human drivers experience much higher delays than average. For
lower traffic levels, these delays are even higher than those associated with the TrafficLight policy. Figure 16 shows that despite this, at high levels of traffic, human drivers
benefit relative to Traffic-Light. Additionally, intersections using FCFS-Light will still
be able to handle far more traffic than those using Traffic-Light.
The Singleâ€“Lane light model effectively gives the humans a high, but fairly constant
delay. Because the green light for any one lane only comes around after each other lane has
had a green light, a human-driven vehicle may find itself sitting at a red light for some time
before the light changes. However, since this light model would only be put in operation
once human drivers are fairly scarce, the huge benefit to the other 95% or 99% of vehicles
far outweighs this cost. A light model that detects and reacts to the presence of human
625

Dresner & Stone

60
Humans
Autonomous
50

Delay (s)

40

30

20

10

0
0

0.25

0.5
Traffic Level (vehicles/s)

0.75

1

Figure 19: Average delays for human-driven vehicles and all vehicles as a function of traffic
level for FCFS-Light with the Single-Lane light model. Humans experience
worse delay than with Traffic-Light, but average delay for all vehicles is much
lower. In this experiment, 5% of vehicles are human-driven.

drivers might be able to achieve even better overall performance, without causing the human
drivers to wait as long.
These data suggest that there will be an incentive to both early adopters (persons
purchasing vehicles capable of interacting with the reservation system) and to cities or
towns. Those with properly equipped vehicles will get where they are going faster (not
to mention more safely). Cities and towns that equip their intersections to utilize the
reservation paradigm will experience fewer traffic jams and more efficient use of the roadways
(along with fewer collisions and less wasted gasoline). Because there is no penalty to the
human drivers (which would presumably be a majority at this point), there would be no
reason for any party involved to oppose the introduction of such a system. Later, when
most drivers have made the transition to autonomous vehicles, and the Single-Lane light
model is introduced, the incentive to move to the new technology is increasedâ€”both for
cities and individuals. By this time, autonomous vehicle owners will far outnumber human
drivers, who will still benefit when traffic is at its worst.
4.6 Emergency Vehicle Experiments
While we have already shown that FCFS on its own can significantly reduce average delays
for all vehicles, FCFS-Emerg helps reduce delays for emergency vehicles even further.
4.6.1 Experimental Setup
To demonstrate this improvement, we ran the simulator with varying amounts of traffic,
while keeping the proportion of emergency vehicles fixed at 0.1% (that is, a spawned vehicle
is made into an emergency vehicle with probability 0.001). Because of the very small number
of emergency vehicles created with realistically low proportions, we ran each configuration
(data point) for 100 hours of simulated timeâ€”much longer than the other experiments.
626

A Multiagent Approach to Autonomous Intersection Management

4.6.2 Results
As shown in Figure 20, the emergency vehicles on average experience lower delays than
the normal vehicles. The amount by which the emergency vehicles outperform the normal
vehicles increases as the traffic increases, suggesting that as designed, FCFS-Emerg helps
most when more traffic is contending for space-time in the intersection.
10

Delay (s)

8

6

4

2
All Vehicles
Emergency Vehicles
0
0

1

2
3
Traffic Level (vehicles/s)

4

5

Figure 20: Average delays for all vehicles and emergency vehicles as a function of traffic
level for the FCFS-Emerg policy. One out of a thousand vehicles (on average)
is an emergency vehicle. Delays for the emergency vehicles are lower for all data
points.

5. Performance in Failure Modes
Fully autonomous vehicles promise enormous gains in safety, efficiency, and economy for
transportation. However, before such gains can be realized, a plethora of safety and reliability concerns must be addressed. In the previous sections, we have assumed that all
vehicles perform without gross malfunctions. In this section, we relax that assumption and
demonstrate how our reservation-based mechanism reacts to scenarios in which such malfunctions occur. Additionally, we intentionally disable some elements of the system in order
to investigate both their necessity and efficacy.
5.1 Causes of Accidents
A collision in purely autonomous traffic can have any number of causes, including software
errors in the driver agent, a physical malfunction in the vehicle, or even meteorological
phenomena. In modern-day traffic, such factors are largely ignored for two reasons. First,
the exclusively human-populated system, with its generous margins for error, is not as
sensitive to small or moderate aberrations. Second, none of these are significant with
respect to driver error as causes of accidents (Wierwille, Hanowski, Hankey, Kieliszewski,
Lee, Medina, Keisler, & Dingus, 2002). However, in the future of infallible autonomous
driver agents, it is exactly these issues which will be the prevalent causes of automobile
collisions. The safety allowances explained in Sections 3.4.5 and 3.4.6 are adjustableâ€”given
some maximum allowable error in vehicle positioning, the buffers can be extended to handle
627

Dresner & Stone

that errorâ€”but no reasonable adjustment can account for gross mechanical malfunction like
a blowout or failed brakes. Because these types of issues are infrequent, we believe the safety
of the intersection control mechanism will be acceptable even if individual occurrences are
slightly worse than accidents today.
5.2 Adding a Safety Net
One can easily imagine how badly an accident in such an efficient system could be without
any reactive safety measures in place. Here, we explain how the system deals with these
rare, but dangerous events. As we will show in Section 5.3, disabling the safety measures
leaves the system prone to spectacular failure modes, sometimes involving dozens of vehicles.
Intact, the measures make such events much more manageable.
5.2.1 Assumptions
In Section 5.3, we will show how our reactive safety measures can reduce the average number
of vehicles involved in a crash from dozens to one or two. However, in order to employ these
safety measures fully, we must make a few additional assumptions.
Detecting The Problem First, we assume that the intersection manager is able to detect
when something has gone wrong. While this is certainly a non-trivial assumption, without
it, no substantial mitigation is possible. Simply put, the intersection manager cannot react
to something it cannot detect. There are two basic ways by which the intersection manager
could detect that a vehicle has encountered some sort of problem: the vehicle can inform
the intersection manager, or the intersection manager can detect the vehicle directly. For
instance, in the event of a collision, a device similar to that which triggers an airbag can
send a signal to the intersection manager. Devices like this already exist in aircraft to emit
distress signals and locator beacons in the event of a crash. The intersection manager itself
might notice a less severe problem, such as a vehicle that is not where it is supposed to be,
using cameras or sensors at the intersection. However, this method of detection is likely
to be much slower to react to a problem. Each has advantages and disadvantages, and a
combination of the two would most likely be the safest. The specifics of the implementation
are beyond the scope of this analysis. What is important is that whenever a vehicle violates
its reservation in any way, the intersection manager should become aware as soon as possible.
Because our simulations only deal with collisions, we assume that the colliding vehicle sends
a signal and the intersection manager becomes aware of the situation immediately.
As described in Appendix B, our protocol includes a Done message that vehicles transmit when they complete their reservations. One way to reliably sense when a vehicle is in
distress would be to notice a missing Done message. This approach has two drawbacks.
First, the Done message is optional, mainly because there is no incentive for the driver
agent to transmit it. Second, the intersection manager may not be able to notice the missing message until some time after the incident has occurred. We intend to investigate this
alternative in future work.
Informing Other Vehicles We also assume that there exists a way for the intersection
manager to broadcast the fact that something is wrong to the vehicles. Since the intersection manager can already communicate with the vehicles, this is not a big assumption.
628

A Multiagent Approach to Autonomous Intersection Management

However, the mode of communication is a bit different from that employed in the rest of the
communication protocol (see Appendix B). Under normal operating conditions, individual
messages each containing multiple pieces of information are transmitted between agents.
Because we cannot verify the receipt of these messages without a response, the semantics of
the protocol ensure that whenever a message is sent, the sending agent makes the most conservative assumptionâ€”in the case of a Request message, that it was not received; in the
case of a Confirm message, that it was. In the event of a collision, however, the intersection
manager needs to communicate one bit of information to as many vehicles as possible: that
something is wrong. Because it is very important that all vehicles receive this message, it
is transmitted repeatedly, to all vehicles, to the exclusion of all other messages. While we
would like to assume that all vehicles receive this message, we will show in Section 5.3 that
even when a significant number of vehicles do not, the safety measures in place still protect
many vehicles that would otherwise wind up crashing.
5.2.2 Incident Mitigation
When a vehicle deviates significantly from its planned course through the intersection resulting in physical harm to the vehicle or its presumed occupants, we refer to the situation
as an incident. Once an incident has occurred, the first priority is to ensure the safety of
all persons and vehicles nearby. Because we expect such incidents to be very infrequent
occurrences, re-establishing normal operation of the intersection is a lower priority and the
optimization of that process is left to future work.
Intersection Manager Response As soon as the intersection manager detects or is
notified of an incident, it immediately stops granting reservations. All subsequent received
requests are rejected without consideration. Due to the nature of the protocol, the intersection manager cannot revoke reservations, as driver agents would have no incentive to
acknowledge their receipt. However, the intersection manager can send a message to the
vehicles that an incident has occurred. This message is the special Emergency-Stop message, which the intersection manager may only send in an emergency situation, and which
(as with the rest of the protocol) it must assume has not been received.
The Emergency-Stop message lets vehicles know that an event has taken place in the
intersection such that:
â€¢ no further reservations will be accepted
â€¢ vehicles able to come to a stop before entering the intersection should do so
â€¢ vehicles in the intersection should no longer assume that â€œnear missesâ€ will not result
in collisions
For human-compatible policies, such as FCFS-Light, the intersection manager also
turns all lights red. In a real-world implementation, a more conspicuous visual cue could
be provided, but semantically it is only important that the intersection informs the human
drivers that they may not enter.
Vehicle Response For the Emergency-Stop message to be useful in any way, driver
agents must react to it. Here we explain the specific actions our implementation of the driver
agent takes when it receives this message. Normally, when approaching the intersection,
our driver agent ignores any vehicles sensed in the intersection. This is because what might
otherwise appear to be an imminent collision on the open road is almost certainly a precisely
629

Dresner & Stone

coordinated â€œnear-missâ€ in the intersection. However, once the driver agent receives the
Emergency-Stop message from the intersection manager, it disables this behavior. If the
vehicle is in the intersection, the driver agent will not blindly drive into another vehicle if
it can help it. If the vehicle is not in the intersection and can stop in time, it will not enter,
even if it has a reservation.
While our first inclination was to make the driver agent immediately decelerate to a
stop, we quickly realized that this is not the safest behavior. If all vehicles that receive the
message come to a stop, vehicles that would otherwise have cleared the intersection without
colliding may find themselves stuck in the intersectionâ€”another object for other vehicles
to run into. This is especially true if the vehicle that caused the incident is on the edge of
the intersection where it is unlikely to be hit. Trying to stop all the other vehicles in the
intersection just makes the situation worse.
If a driver agent does detect an impending collision, it should take evasive actions or
apply the brakes. Since this is a true multiagent system with self-interested agents, we
cannot prevent driver agents from doing so, even if it is detrimental to vehicles overall.
Thus, our driver agent brakes if it believes a collision is imminent.
5.3 Experiments
In order to evaluate the effects of our reactive safety measures, we performed several experiments in which various components were intentionally disabled. The various configurations
can be separated into three classes. An oblivious intersection manager takes no action at all
upon detecting an incident. An intersection manager utilizing passive safety measures stops
accepting reservations, but does not send any Emergency-Stop messages to nearby driver
agents. Finally, the active configuration of the intersection managerâ€”which corresponds
to the full version of the protocol as specified in Appendix Bâ€”has all safety features in
place. In addition to considering these three incarnations of the intersection manager, we
also study the effects of unreliable communication in the active case. Note that when no
vehicles receive the Emergency-Stop message, the active and passive configurations are
identical.
5.3.1 Experimental Setup
With the great efficiency of the reservation-based system comes an extreme sensitivity to
error. While buffering might protect against minute discrepancies, it cannot hope to cover
gross mechanical malfunctions. To determine just how much of an effect such a malfunction
would have, we created a simulation in which individual vehicles could be â€œcrashedâ€, causing
them to immediately stop and remain stopped. Whenever a vehicle that is not crashed
comes into contact with one that is, it becomes crashed as well. While this does not model
the specifics of individual impacts, it does allow us to estimate how a malfunction might
lead to collisions.
In order to ensure that we included malfunctions in all different parts of the intersection,
we triggered each incident by choosing a random (x, y) coordinate pair inside the intersection, and crashing the first vehicle to cross either the x or y coordinate. This is akin to
creating two infinitesimally thin walls, one horizontal and the other vertical, that intersect
at (x, y). Figure 21 provides a visual depiction of this process.
630

A Multiagent Approach to Autonomous Intersection Management

Figure 21: Triggering an incident in the intersection simulator. The dark vehicle turning
left is crashed because it has crossed the randomly chosen x coordinate. If a different vehicle had crossed that x coordinate or the randomly chosen y coordinate
earlier, it would be crashed instead.

After initiating an incident, we ran the simulator for an additional 60 seconds, observing
any subsequent collisions and recording when they occurred. Using this information, we
constructed a crash log, which is essentially a histogram of crashed vehicles. For each step
of the remaining simulation, the crash log indicates how many vehicles were crashed by
that step. By averaging over many such crash logs for each configuration, we were able to
construct an â€œaverageâ€ crash log, which gives a picture of what a typical incident would
produce.
Because our system is compatible with humans, we included experiments with a humancompatible intersection control policy. As demonstrated in Section 4.5, when a significant
number of human drivers are present, the FCFS-Light cannot offer much of a performance
benefit over traditional traffic light systems. As such, we limited our experimentation to
scenarios in which 5% of the vehicles are controlled by simulated human drivers, and used
a Single-Lane light model (see Section 3.6.2). With only 5% human drivers, an FCFSLight policy can still create a lot of the precarious situations that are the focus of this
investigation.
For these experiments, we ran our simulator with scenarios of 3, 4, 5, and 6 lanes in
each of the four cardinal directions, although we will discuss results only for the 3- and
6-lane cases (other results were similar) for the sake of brevity. As with earlier experiments,
vehicles are spawned equally likely in all directions, and are generated via a Poisson process
which is controlled by the probability that a vehicle will be generated at each step. Vehicles
are generated with a set destinationâ€”15% of vehicles turn left, 15% turn right, and the
remaining 70% go straight. As before, the leftmost lane is always a left turn lane, while the
right lane is always a right turn lane. Turning vehicles are always spawned in the correct
lane, and non-turning vehicles are not spawned in the turn lanes. In scenarios involving only
autonomous vehicles, we set the traffic level at an average of 1.667 vehicles per second per
lane in each direction. This equates to 5 total vehicles per second for 3 lanes, and 10 total
631

Dresner & Stone

vehicles per second for 6 lanes. Scenarios with human-driven vehicles had one third the
traffic of the fully autonomous scenariosâ€”the intersection cannot be nearly as efficient with
human drivers present. We chose these amounts of traffic as they are toward the high end of
the spectrum of manageable traffic for the respective variants of the intersection manager.
While we wanted traffic to be flowing smoothly, we also wanted the intersection to be full
of vehicles to test situations that likely lead to the most destructive possible collisions.
5.3.2 How Bad Is It?
As we suspected, the average crash log of the oblivious intersection manager is quite grisly.
As explained in Section 5.2.2, driver agents must ignore their sensors while in the intersection, because many of the â€œclose callsâ€ would appear to be impending collisions. Without
any way to react the situation going awry, vehicles careen into the intersection, piling up
until the entire intersection is filled and crashed vehicles protrude into the incoming lanes.
Figure 22 shows that for both 6-lane casesâ€”fully autonomous and 5% human driversâ€”the
rate of collisions does not abate until over 70 vehicles have crashed. Even a full 60 seconds
after the incident begins, vehicles are still colliding. In the 3-lane case, the intersection
is much smaller and thus fills much more rapidly; by 50 seconds, the number of collided
vehicles levels off.
100

60
6 Lanes
3 Lanes

90

6 Lanes
3 Lanes
50

80

Cars Crashed

Cars Crashed

70
60
50
40

40

30

20

30
20

10

10
0

10

20

30

40

50

60

0

Time (s)

10

20

30

40

50

60

Time (s)

(a) All autonomous

(b) 5% humans

Figure 22: Average crash logs (with 95% confidence interval) for 3- and 6-lane oblivious
intersections. In 22(a), the intersection manages only autonomous vehicles,
while 22(b) includes 5% human drivers.

In both of the scenarios with human drivers, shown in Figure 22(b), the number of vehicles involved in the average incident is noticeably smaller. This outcome is likely the result
of two factors. First and foremost, the FCFS-Light policy must make broad allowances
to accommodate the human drivers, and thus overall is inherently less dangerous. The
characteristic â€œclose callsâ€ from the standard FCFS policy are less common. Second, the
simulated human driver agents do not drive â€œblindlyâ€ into the intersectionâ€”trusting to the
intersection managerâ€”the way the autonomous vehicles do. Also of note in Figure 22(b)
is the visible periodicity of the light model portion of the policy. As paths open up for
632

A Multiagent Approach to Autonomous Intersection Management

autonomous vehicles due to changes in the lights, they drive unwittingly into the growing
mass of crashed cars.
5.3.3 Reducing the Number of Collisions
There are two main components to the safety mechanism introduced in Section 5.2. First,
the intersection manager stops accepting reservations. Second, the intersection manager
sends messages informing the driver agents that an incident has taken place. There is a
possibility that this second part might not always work perfectly; some vehicles might not
receive the message. To investigate the effects of these potential communication failures,
we intentionally disabled some of the vehiclesâ€™ ability to receive the Emergency-Stop
message. A parameter in our simulator controls the fraction of vehicles created with this
property, and by varying this parameter, we could observe its subsequent effect on the
average number of vehicles involved in incidents.
As compared to the oblivious intersection manager, the number of vehicles involved in
the average incident for an active intersection manager decreases dramatically. Table 1
shows the numerical results for both the 3- and 6-lane intersections, along with a 95%
confidence interval. The average crash logs for these runs are not shown in Figure 22, as
they would be indistinguishable from one another at that scale. Instead, we present them
in Figure 23.

Oblivious
Passive
Active
20% receiving
40% receiving
60% receiving
80% receiving
100% receiving

Fully Autonomous
3 Lanes
6 Lanes
27.9 Â± 1.3 90.9 Â± 4.9
2.63 Â± .13 3.23 Â± .16

5% Human
3 Lanes
6 Lanes
19.3 Â± 1.1 49.3 Â± 2.7
2.23 Â± .10 2.35 Â± .13

2.44 Â± .13
2.28 Â± .12
1.89 Â± .10
1.71 Â± .08
1.36 Â± .06

2.07 Â± .10
1.91 Â± .10
1.72 Â± .09
1.46 Â± .07
1.22 Â± .05

3.15 Â± .17
2.90 Â± .16
2.69 Â± .15
2.30 Â± .13
1.77 Â± .10

2.29 Â± .13
2.07 Â± .12
1.98 Â± .11
1.65 Â± .09
1.50 Â± .09

Table 1: Average number of simulated vehicles involved in incidents for 3- and 6-lane intersections. Even with only the passive safety measures, the number of crashed
vehicles is dramatically decreased from the oblivious intersection manager. In the
active configuration, as more vehicles receive the emergency signal, the number of
crashed vehicles decreases further.
Figure 23 shows the effects of the reactive safety measures in intersections with 6 lanes,
with the proportion of receiving vehicles varying from 0% (passive) to 100% in increments
of 20%. Even in the passive configuration, the overall number of vehicles involved in the
average incident decreases by a factor of almost 30 in the fully autonomous scenario, and
a factor of over 20 in the scenario with 5% human drivers, as compared to the oblivious
intersection manager. As expected in the active configuration, when more vehicles receive
the emergency signal, fewer wind up crashing. The graphs in Figure 23 only show the first
633

Dresner & Stone

15 seconds of the incident, because in no case did a collision occur more than 15 seconds
after the incident started.
3.5

2.4
Passive
20% receiving
40% receiving
60% receiving
80% receiving
100% receiving

2
Cars Crashed

Cars Crashed

3

Passive
20% receiving
40% receiving
60% receiving
80% receiving
100% receiving

2.2

2.5

2

1.8
1.6
1.4

1.5
1.2
1

1
0

2

4

6

8

10

12

14

0

Time (s)

2

4

6

8

10

12

14

Time (s)

(a) All autonomous

(b) 5% humans

Figure 23: The first 15 seconds of average crash logs for 6-lane passive and active intersections. As more vehicles react to the signal, safety improves.

5.3.4 Reducing the Severity of Collisions
While it is reassuring to know that the number of vehicles involved in the average incident
can be kept fairly low, these data do not give the entire picture. For example, compare an
incident in which 30 vehicles each lose a hubcap to one in which two vehicles are completely
destroyed and all occupants killed. While we do not currently have any plans to model the
intricate physics of each individual collision with high fidelity, our simulations do allow us
to observe the velocity at which the collisions occur. In the previous example, we might
notice that the 30 vehicles all bumped into one another at low velocities, while the two
vehicles were traveling at full speed. To quantify this information, we record not only when
a collision happens, but the velocity at which it happens. In a collision, the amount of
damage done is approximately proportional to the amount of kinetic energy that is lost.
Because kinetic energy is proportional to the square of velocity, we can use a running total
of the squares of these crash velocities to create a rough estimate of the amount of damage
caused by the incident. Figure 24 shows an average â€œdamage logâ€ of a 6-lane intersection
of autonomous vehicles. Qualitatively similar results were found for the other intersection
types.
As Figure 24(a) shows, the effect of our safety measures under this metric is quite
dramatic as well. In the passive case the total accumulated squared velocity decreases by
a factor of over 25. In the active case, with all vehicles receiving the signal, it decreases
by another factor of 2. Of particular note is the zoomed-in graph in Figure 24(b). In the
passive configuration, the total squared velocity accumulates as if the intersection manager
were oblivious, until the first vehicles stop short of the intersection at around 3 seconds;
without a reservation, they may not enter. In the active scenario, when all the vehicles
receive the message, the improvement is almost immediate.
634

A Multiagent Approach to Autonomous Intersection Management

1800
Oblivious
Passive
Active

2 2

25000

Accumulated Squared Velocity (m /s )

2 2

Accumulated Squared Velocity (m /s )

30000

20000

15000

10000

5000

0

Oblivious
Passive
Active

1600
1400
1200
1000
800
600
400
200

0

10

20

30

40

50

60

0

1

2

3

Time (s)

4

5

6

7

Time (s)

(a) the average incident

(b) zoomed in

Figure 24: Average total squared velocity of crashed vehicles for a 6-lane intersection with
only autonomous vehicles. Sending the emergency message to vehicles not only
causes fewer collisions, but also makes the collisions that do happen less dangerous.

5.3.5 Delayed Incident Detection
Implicit in these results is the assumption that intersection managers become aware of
incidents instantaneously. While this could be the case in many collisionsâ€”vehicles should
communicate when they have collidedâ€”if a vehicleâ€™s communications are faulty, or if the
vehicle does not realize it has collided, the intersection may not discover the problem for a
few seconds, when another vehicle or sensor will detect the problem. To assess the effects
of delayed incident detection, we artificially delayed the intersection managerâ€™s response in
some of our simulations. Figure 25 shows the results from these experiments.
4

5
Number of crashed vehicles

Number of crashed vehicles

5s delay
3.5
3

3s delay

2.5
1s delay

2

No delay

1.5
1

4.5
g

vin

ei

4
%

3.5

,0

ay

3

5s

l
de

c
re

g

2s delay, 50% receivin

2.5
2
1.5
1

0

2

4

6

8

10

0

Time (s)

2

4

6

8

10

Time (s)

(a) delaying detection

(b) delays and faulty communication

Figure 25: Crash logs showing the effects of delayed incident detection.
In Figure 25(a), the intersection managerâ€™s reaction was delayed 0, 1, 3, and 5 seconds.
Note that the total number of crashed vehicles with a delay of 5 seconds is on par with the
number in the experiment in which the intersection manager reacts immediately, but none of
635

Dresner & Stone

the vehicles receive the message, shown in Figure 23(a). Figure 25(b) shows what happens
with both delayed detection and faulty communication. This graph, along with the earlier
results, suggests that for small values, each second of delay is approximately equivalent to
20% of vehicles not receiving the Emergency-Stop message, and that when combined,
delayed detection and faulty communication have an additive effect. For larger delays, the
number of vehicles involved can be approximated using the data shown in Figure 22(a),
because in these cases, the number of vehicles that crash after the intersection is much
smaller than the number that crash before it reacts.
5.4 Safety Discussion
The results in this section suggest that it may be possible to improve efficiency while also
improving safety. But of course before deployment in the real world, extensive testing with
real vehicles would be needed in order to verify both the suggested efficiency benefits, as
well as the safety properties of the system. People are often hesitant to put their wellbeing (physical or otherwise) in the hands of a computer unless they can be convinced that
they will receive a significant safety benefit in exchange for surrendering precious control.
Humans often suffer from the overconfidence effect, erroneously believing they are more
skillful than others. In a 1981 survey of Swedish drivers, respondents were asked to rate
their driving ability in relation to others. A full 80% of those asked placed themselves in
the top 30% of drivers (Svenson, 1981). It is this effect that creates the high standard to
which computerized systems are held. It is insufficient for such systems to be marginally
safer, or safer for the average user; they must be the very paragon of safety.
In our experiments, we showed that the number of vehicles involved in individual incidents can be drastically reduced by utilizing a fairly straightforward reactive safety mechanism. In fact, in the active configuration with 3 lanes, 75% of the incidents involved only
one vehicle: the one we intentionally crashed (60% for 6 lanes). Even in the passive case
with 6 lanes of traffic, an average of only 3.23 vehicles were involved. But how does this
compare with current systems? If we conservatively assume that accidents in traffic today
involve only one vehicle, this represents a 223% increase per occurrence. Thus, all other
things being equal, if the frequency of accidents can be reduced by 70%, these experiments
suggest that an autonomous intersection management system will be safer overall. A 2002
report for the U.S. Federal Highway Administration blamed over 95% of all accidents on
driver error (Wierwille et al., 2002). The remaining accidents were divided equally between
vehicle failures and problems with roads. It is important to note that these numbers are for
all driving, not just intersection driving. Accidents in intersections are even more likely to
be caused by driver error, sometimes even by drivers willfully disobeying the law: running
red lights and stop signs or making illegal â€œUâ€-turns.
Even if we make overly conservative assumptionsâ€”that all driving is as dangerous as intersection driving, and that driver error is no more accountable for intersection crashes than
it is in other types of drivingâ€”our data suggest that automobile traffic with autonomous
driver agents and an intersection control mechanism like ours will reduce collisions in intersections by over 80%. We believe that in reality, the improvement will be much greater.
The safety measures presented in this section constitute just one approach for mitigating
the systemâ€™s failure modes. More sophisticated methods involving explicit cooperation
636

A Multiagent Approach to Autonomous Intersection Management

amongst vehicles may create an even safer system. We have not shown (or attempted
to show) that this particular solution is the best possible. Rather we have demonstrated
that even with a simple and straightforward response to accidents, the overall safety of the
system can be maintained, without sacrificing the benefits of vastly improved efficiency.

6. Related Work
Traffic control is a vast area of research for computer scientists and engineers alike. The field
of Intelligent Transportation Systems (ITS) is concerned with applying information, computing, and sensor technologies to solve problems in traffic and road management (Bishop,
2005). ITS includes intelligent vehicles (IV) as well as infrastructure, such as intersections. Unfortunately, while both aspects of ITS are heavily studied, relatively little current
research considers how intelligent or autonomous vehicles and infrastructure can work together to improve the efficiency and safety of the overall traffic system. The Berkeley
PATH project has produced a lot of interesting work, including work on a fully-automated
highway (Alvarez & Horowitz, 1997).
In this section, we describe some work related to our own, both directly and tangentially. Some of this work is specifically concerned with intersection control, some takes a
multiagent approach to other aspects of traffic management, and some represents work on
the technologies necessary to bring fully autonomous vehicles into the mainstream.
6.1 Requisite Technology
Before autonomous vehicles can take over the roads, they will need to be able to interact
with all the aspects of roadways, including pedestrians, other vehicles, and lanes. As early
as 1991, a driver agent system named â€œUlyssesâ€ had been developed in simulation (Reece
& Shafer, 1991). While most systems currently under development for implementation on
real vehicles are geared toward assisting human drivers, many of the technologies created
through these efforts are applicable to the creation of a completely autonomous driver
agent. Such a successful driver agent needs to do three main things: detect other entities
on the road, keep its vehicle in the lane, and maintain safe distances from other vehicles.
Fortunately, each of these three subtasks currently attracts an extensive amount of research.
6.1.1 Object Detection and Tracking
A fully autonomous vehicle must be able to reliably detect, classify, and track various objects
that may be in the roadway. From pedestrians and bicycles to cars and trucks, autonomous
vehicles will require robust sensors that can monitor the world around them in all manner
of lighting conditions and weather. Without such abilities, any amount of higher reasoning
a driver agent can do is irrelevant. Fortunately, researchers are attacking this problem with
many techniques.
In 2004, Honda introduced an intelligent night vision system to the Japanese market
capable of detecting pedestrians (Liu & Fujimura, 2003). The system uses two far-IR
(FIR) cameras on the front of the vehicle to detect heat-emitting objects beyond the range
illuminated by the vehicleâ€™s headlights. The two cameras allow the system to obtain distance
information about the detected pedestrians and can then warn the driver. DaimlerChrysler
637

Dresner & Stone

is developing a similar system that also extrapolates the trajectories of classified objects
in order to predict possible outcomes sooner (Gavrila, Giebel, & Munder, 2004). MaÌˆhlisch
et al. (2005) have developed a sensor fusion technique that can glean information about
pedestrians reliably even from low-resolution images.
The Ford Motor Company has been investigating how to track vehicles using both color
and shape information (She, Bebis, Gu, & Miller, 2004). Gepperth et al. (2005) have
demonstrated that with only gray-valued videos (no color), a two-stage (initial detection
and confirmation) mechanism using a simple neural network for confirmation can reliably
and quickly classify other vehicles.
Vehicle and pedestrian classification and tracking is a well-studied area of IV research
that is progressing quickly. A glance at any IV-related conference or symposium will reveal
a plethora of articles aimed at using lidar, FIR, normal video, and any combination of these
sensors with algorithms like Kalman filters, particle filters, and neural networks to track
and classify other objects on the road.
6.1.2 Lane Following
As with pedestrian and vehicle detection and tracking, lane following is a heavily studied area of IV research. Varying from passive lane- and road-departure warning systems
(LDWS/RDWS) to active lane keeping assistance (LKA), many systems are already showing up in production vehicles.
As far as RDWS go, Kohl et al. (2006) have used neuroevolution to create a warning
system that can warn drivers of both road departure and impending crashes with other
vehicles. The system was tested both in simulation and with a robotic vehicle. This work is
sponsored by Toyota, who have also currently have an LDWS on the market in Japan. This
system is unique in that it uses a rear-facing camera to predict and warn of impending lane
departures. While LDWS and RDWS promise extensive benefits to drivers, they only warn
of imminent road and lane departures, and do not provide information on what specific
action should be taken. Autonomous vehicles will need to ensure they do not reach a point
where a lane or road departure is imminent.
Lane keeping, on the other hand, provides and executes actions. For example, the â€œNo
Hands Across Americaâ€ project in 1995 drove a vehicle 2,849 miles from Pittsburgh to Los
Angeles. For 98.2% of the journey, the vehicle steered itself (Pomerleau, 1993). More recent
projects have concentrated on making such systems robust to varying speed, inclement
weather and poor lighting conditions such as beneath overpasses and in tunnels. Wu et
al. (2005) have proposed and tested a vision-based lane-keeping system that can operate at
varying speed while providing smooth human-like steering. Watanabe and Nishida (2005),
working for Toyota, have developed a lane detection algorithm specifically designed for
steering assistance systems that is extremely robust to varying road conditions and lighting.
While several LKA systems are on the market in Japan, these systems are not intended
to allow autonomous driving. Rather, they attempt to reduce driver fatigue and make
turning more stable (Bishop, 2005). Production systems that allow autonomous steering
are almost invariably based on specially painted lines and are limited to special vehicles on
closed courses.
638

A Multiagent Approach to Autonomous Intersection Management

Even without the benefit of explicitly designated lanes, autonomous vehicles can keep
themselves on the roadway. In the 2005 DARPA Grand Challenge (DARPA, 2007), the
winning vehicle, â€œStanleyâ€, used a technique fusing short-range laser range finders with
long-range video cameras to follow a rough dirt path. First, the vehicle found smooth areas
in front of it using the laser range finders. Then it mapped this information onto video
images from forward-facing cameras. By determining the color of the area in the image
corresponding to the smooth areas found by the laser range finder, Stanley was able to
extrapolate using a flood-fill-type algorithm to find which areas of the video image were on
the dirt path (NOVA, 2006). RamstroÌˆm and Christensen (2005) achieved a similar goal by
using a strategy based on a probabilistic generative model.
6.1.3 Adaptive Cruise Control
If lane-keeping systems represent the main lateral component of an autonomous vehicleâ€™s
driver agent, then adaptive cruise control (ACC) is the main longitudinal component. ACC
allows a vehicle to maintain a safe following distance and can react quicker than a human
driver in the case of sudden deceleration by the vehicle in front. ACC systems are already
available on the marketâ€”DaimlerChryslerâ€™s Mercedes-Benz S-class, for example, comes with
a system that will automatically apply the brake if it detects that the driver is not slowing
sufficiently fast. Jaguar, Honda, and BMW offer similar systems. Nissan and Toyota have
recently begun offering â€œlow-speed followingâ€ systems, which can follow other vehicles in
slower, denser, urban traffic scenarios (Bishop, 2005). ACC relies on robust sensing and
uses radar, lidar, and traditional machine vision algorithms. By combining various â€œflavorsâ€
of ACC â€” low speed, high speed, etc.â€”an agent could control the longitudinal motion of a
vehicle in all situations. Recently, the notion of cooperative adaptive cruise control (CACC)
has emerged (LaumoÌ‚nier, Desjardins, & Chaib-draa, 2006). This concept goes much further
toward realizing the goal of fully autonomous vehicles. By allowing vehicles to collaborate
and take advantage of the precision of autonomous driver agents, vehicles can use the
existing road space much more efficiently.
6.2 Intersection Collision Avoidance
To date, much of the ITS work relating to intersections has focused on Intersection Collision
Avoidance (ICA). This work seeks to warn the driver when the vehicle may be entering an
intersection unsafely. With the aid of high-precision digital maps and GPS equipment, the
vehicle detects and classifies the state of the traditional signaling systems placed at the
intersection (Lindner, Kressel, & Kaelberer, 2004). ICA systems typically do not take any
action on behalf of the driver, but simply provide a visual or auditory warning.
Rasche and Naumann (1997, 1998, 1997) have worked extensively on decentralized solutions to intersection collision avoidance problems, including those involving autonomous
vehicles. This work is very similar to ours in that it uses â€œpotential points of collisionâ€
to restrict access to the intersection. Only one vehicle may occupy any potential point of
collision at a time. Vehicles attempt to obtain a token (similar to a token-ring in computer networking) for each point needed to cross the intersection. Once a vehicle has all
the necessary tokens, it may cross. Rasche and Naumannâ€™s system also includes a priority
model that allows emergency vehicles to cross more quickly and prevents deadlocks amongst
639

Dresner & Stone

normal vehicles. However, the system fails to satisfy several of our desiderata. It does not
make any guarantees, nor do the authors provide any results regarding the efficiency of the
system as compared to a traditional system. Furthermore, the distributed algorithm is not
shown to be resilient to unreliable communication. The authors also do not provide any
insight into how the system could be adapted to work with a mixed human/autonomous
vehicle population. The most striking difference, however, is that the mechanism does not
seem to have any notion of planning ahead. Tokens for the potential points of collision
are either taken or not takenâ€”a vehicle can not seek to obtain a token for some point in
the future, thus allowing it to proceed toward the intersection without slowing down while
other vehicles have the tokens.
In the context of video games and animation, Reynolds (1999) has developed autonomous steering algorithms that attempt to avoid collisions in intersections that do not
have any signaling mechanisms. Such a system would have the enormous advantage of not
requiring any special infrastructure or agent at the intersectionâ€”vehicles equipped with
such algorithms could operate at any intersection. Unfortunately, the two main drawbacks
of the system make it unsuitable for use with real-life traffic. First, the algorithm does not
let the agent choose which path it will take out of the intersection; a vehicle may even find
itself exiting the intersection the same way it came in, due to efforts to avoid colliding with
other vehicles. Second, the algorithm only attempts to avoid collisionsâ€”it does not make
any guarantees about safety.
Cooperative intersection collision avoidance is a form of cooperative vehicle-highway system (CVHS) in which the intersection is allowed to participate in the ICA problem. ICA
systems contained entirely in individual vehicles cannot account for gaps in sensor views
or other sources of incomplete information. Thus, a CVHS approach is required. As with
many other ITS technologies, production systems still assume a human driver and attempt
to warn them when a violation is about to occur, or in some cases, punish them after the
fact, as with cameras that detect when a vehicle has run a red light and automatically
issues the driver a citation. The U.S. Department of Transportation is sponsoring several ICA projects including both infrastructure-only and cooperative approaches (USDOT,
2003). The intention is to first deploy the infrastructure-only systems, and then as the
market penetration of ICA-equipped vehicles increases, to roll out the cooperative systems.
Significant work on ICA is also underway in Japan (Bishop, 2005).
While these systems are a large step toward enabling autonomous vehicles to take to the
roads, none are designed to work specifically with autonomous vehicles. With the exception
of the algorithm designed for games, each assumes both a human driver and traditional
signaling systemsâ€”a clumsy, inefficient interface that will find itself all but obsolete due to
autonomous vehicle technology.
6.3 Optimizing Traffic Signal Timing
The vast majority of deployed technology for intersection control involves calibrating the
timing of traditional traffic lights in order to create a â€œwave of greenâ€ such that once vehicles
reach one green light, they continue through all subsequent intersections without having to
stop. Unfortunately, in practice, such waves tend to be sporadic and short-lived due to
640

A Multiagent Approach to Autonomous Intersection Management

rapidly changing traffic patterns. However, they do offer substantial benefits compared to
systems without this coordination.
TRANSYT, the Traffic Network Study Tool, is an off-line system that, given average
traffic flows, can determine optimum fixed-time coordinated traffic signal timings (Robertson, 1969). TRANSYT requires extensive data gathering and analysis, but is used very
heavily all over the world. Unfortunately, this system is very brittle because it does not
have the ability to react to unusual changes in traffic flow. For example, at the end of a
major sporting event, thousands of vehicles may all be attempting to cross an intersection
in a direction which under normal circumstances is rarely used. Because the light timings
are set up to reflect these normal circumstances, the length of time for which the departing
vehicles get a green light may be significantly less than the cross traffic, of which there may
be little.
SCOOT, the Split, Cycle, and Offset Optimisation Technique, represents an advancement over TRANSYT (Hunt, Robertson, Bretherton, & Winton, 1981). SCOOT is an
on-line adaptive traffic control system that can react to changes in traffic levels, give priority to vehicles such as buses, and even estimate vehicle emissions. While SCOOT has been
shown to reduce traffic delays by an average of 20% over systems like TRANSYT, it still
relies on traditional signaling systems and vehicles. Furthermore, SCOOT requires reliable
traffic data in order to adapt, and thus may be slow to react to changes in traffic flow.
6.4 MAS and Traffic
Automobile traffic is a great example of a multiagent system, and it is not surprising that
there is a lot of research into modelling and studying traffic using multiagent techniques.
Many of these approaches consider systems consisting only of traffic-light-controlling agents
or driver agents, as opposed to a heterogeneous multiagent system with many kinds of
agents. Nevertheless, many of the ideas involved could potentially be adapted to work
within the framework of the reservation system.
6.4.1 Cooperative Traffic Signals
Much of MAS traffic research focuses on improving current technology (systems of traffic
lights). For example, Roozemond (1999) allows intersections to act autonomously while
sharing the data they gather. The intersections then use this information to make both
short- and long-term predictions about the traffic and adjust accordingly. This strategy
attempts to overcome one of the weaknesses of SCOOT: the need for large amounts of
reliable traffic data. If multiple intersections can share data, each intersection will get a
more accurate picture of the current traffic situation.
Bazzan (2005) has used a decentralized approach combining MAS and evolutionary
game theory. The approach models each intersection as an individually-motivated agent
which must focus not only on local goals (getting vehicles through the intersection), but
also on global goals (reducing travel times for all vehicles). Both Bazzan and Roozemondâ€™s
techniques still assume traditional signaling mechanisms and human drivers.
641

Dresner & Stone

6.4.2 Platoons
In addition to multi-intersection systems, multi-vehicle systems are the focus of a lot of
research. Much of this research centers on creating platoons of vehicles in order to minimize
the effects of stop-and-go driving. Consider a line of cars stopped at a red light. When the
light turns green, the first car begins to move. Eventually, the car behind it notices that
it has enough space to accelerate as well. Some time later, the vehicle at the back of the
line will begin to move, but this may be too late to actually get through the intersection
during the current green phase of the light. If, on the other hand, all the vehicles were to
simultaneously and uniformly accelerate, more vehicles could make it through each green
phase, because the vehicles would more efficiently use the space-time available to them to
cross the intersection.
Clement (2002) has proposed a model called â€œSimple Platoon Advancementâ€ (SPA),
which addresses this exact problem. SPA boasts the ability to get nearly twice as many
vehicles through a green light (increasing the lightâ€™s throughput) as compared to normal
human drivers, in addition to any safety and delay benefits associated with automated control. One the vehicles are through the intersection and dispersed to safe following distances,
control is returned to the human driver.
HalleÌ and Chaib-draa (2005) have used the platoon approach to facilitate collaborative
driving in general. They allow vehicles, which are controlled by separate agents, to form
such platoons, with varying degrees of autonomy. Vehicles merge and split with platoons
using carefully crafted maneuvers, during which each vehicle in the platoon has a specific
responsibility. They present both centralized version, in which a master vehicle gives orders
to the rest of the platoon, and a decentralized version, in which social laws dictate each
agentâ€™s role, while the platoonâ€™s leader acts only as a representative to other platoons.
Both platooning systems assume automated control of vehicles, but use ordinary traffic
lights for intersection control. By using platoons, these methods attempt to solve a problem
inherent in the traffic lights themselvesâ€”they are designed for humans to use, and are not
well suited to automated vehicle control. The work presented in this article attempts to
free autonomous vehicles from the control of traffic lights and instead design a new system
that specifically utilizes the capabilities of fully autonomous vehicles.
6.4.3 History-Based Traffic Control
Taking a different approach to intersection control, Balan and Luke (2006) use a historybased method to maximize fairness (all vehicles experience similar delays) as opposed to
efficiency (the average vehicle experiences short delays). Under this paradigm, vehicles
which have historically (previously in their journey) experienced long delays should be
more likely to experience shorter delays at subsequent intersections. In addition to being
a multi-intersection approach, this method uses a marketplace model involving a system of
credits that can be given and taken in exchange for shorter and longer delays, respectively.
Coordination at individual intersections is still done with traditional traffic lights, the timings of which are part of the mechanism. Interestingly, the fairness approach actually yields
results that are also reasonably efficient.
642

A Multiagent Approach to Autonomous Intersection Management

6.5 Machine Learning and Traffic
Abdulhai et al. (2003) have used Q-learning, a simple, yet powerful form of reinforcement
learning, to do on-line adaptive signal control. In the work, the authors explore both an
isolated intersection as well as a linear chain of intersections. They demonstrate that Qlearning can significantly reduce delays for vehicles and quickly adapt to changing traffic
patterns. Bull et al. (2004) have shown how Learning Classifier Systems (LCS) can also make
traditional traffic signals more efficient. Wiering (2000) has demonstrated that multiagent,
model-based reinforcement learning can also be used to optimize signal timings in more
complex networks of intersections.
While not focusing on intersections, Moriarty and Langley (1998) have shown that
reinforcement learningâ€”specifically neuro-evolutionâ€”can train efficient driver agents for
lane, speed, and route selection during freeway driving, all of which are critical components
for a fully autonomous vehicle. Additionally, many of the object tracking and detection
examples mentioned previously use neural networks to classify objects.
6.6 Physical Robots
On real autonomous vehicles, Kolodko and Vlacic (2003) have created a small-scale system
for intersection control which is very similar to the granularity-1 FCFS policy. The authors
developed the mechanism for small Cooperative Autonomous Mobile Robots (CAMRs),
which are about 30 cm in diameter and have a top speed of 10 cm/s. The CAMRs were
programmed to follow Australian traffic laws, and communicate with several different types
of messages. Once demonstrated on the CAMRs, the mechanism was scaled up to use Imara
vehicles, which are much larger (capable of carrying two human passengers) and faster (top
speed of 30 km/h). The system is completely distributed and does not require extensive
infrastructure at the intersection. However, it does assume that all vehicles cooperate with
one another.
6.7 Safety Analysis
Section 5 includes a failure-mode analysis for our proposed intersection control mechanism. To the best of our knowledge, this is the first study of the impact of any other
such autonomous intersection protocol on driver safety. However, there is an enormous
body of work regarding safety properties of traditional intersections. This includes the
generalâ€”correlating traffic level and accident frequency (Sayed & Zein, 1999) and analyses
of particular types of intersections (Bonneson & McCoy, 1993; Harwood, Bauer, Potts, Torbic, Richard, Rabbani, Hauer, Elefteriadou, & Griffith, 2003; Persaud, Retting, Gardner,
& Lord, 2001)â€”as well as plenty of more esoteric work, such as characterizing the role
of Alzheimerâ€™s Disease in intersection collisions (Rizzo, McGehee, Dawson, & Anderson,
2001). However, because it concerns only human-operated vehicles, none of this work is
particularly applicable to the setting we are concerned with.

7. Conclusion and Future Work
The reservation system as presented is a large step toward easing our traffic woes, in terms
of both wasted time and injury or loss of life. However, substantial work must still be done
643

Dresner & Stone

before the system is ready to deploy. Some of this work represents possible future directions
for this line of research. For example, more detailed studies of the safety properties of the
systemâ€”how it reacts to various failures and whether the effects of those failures can be
mitigatedâ€”are required. Another area ripe for improvement is the intersection manager.
A manager that can switch among several different policies, learning from reservation histories which policy is best suited to particular traffic conditions, could significantly improve
performance. Furthermore, a light model that could react not only to traffic conditions, but
also to the presence of individual vehicles, might better be able to exploit the abilities of
autonomous vehicles, without adversely affecting human drivers. Framing the intersection
as a marketplace and space-time as a commodity could allow the system to handle vehicle priorities more intelligently or allow driver agents to exchange a long wait on one day
for quick passage on some later, more important day. Finally, the driver agent itself may
be able to benefit from some machine learning techniques, perhaps learning to make more
accurate reservations and thus needing to cancel less frequently.

This article makes three main contributions. First, it defines the problem of autonomous
intersection management, including a set of desiderata by which potential solutions can be
evaluated. Second, it presents a framework that can meet all of these desiderata, and an
algorithm (FCFS) that shows the advantages of the framework over current intersection
control methods. Third, it demonstrates how the framework can be extended to allow
human-driven (not autonomous) vehicles to use the system, while still exploiting the abilities
of the autonomous vehicles to increase throughput and subsequently decrease delays.

Getting from where we are today to a future in which humans are no longer burdened
with the mundane yet dangerous task of piloting automobiles will involve a vast amount of
work in many different disciplines. While it does not extensively address the engineering or
societal challenges involved in building and deploying such a system, this article suggests
that it is both algorithmically feasible and worthwhile (in terms of decreasing delay) to do
so.

Acknowledgments

This research is supported by NSF CAREER award IIS-0237699, and experiments were
carried out on machines provided by NSF grant EIA-0303609.
644

A Multiagent Approach to Autonomous Intersection Management

Appendix A. Simplified Laser Range Finder
This appendix describes an implementation detail of the driver agentâ€™s sensor model. Recall
from Section 3.1.1 that each driver has access to a set of simulated external sensors. In this
set is a simplified laser range finder, which is intended to give the agent the same type of
information as an actual laser range finder, but without the expensive computation required
to fully simulate the sensor. Instead, the simplified laser range finder sensor examines each
vehicle within sensor range and determines which is closest to the front of the sensing
vehicle. Then, it records the point on that vehicle that is closest to the sensing vehicle and
provides the distance and angle to this point.
Modern laser range finders and distance sensors can provide a large amount of distance
and angle data to a mobile agent. In a real life setting, this information would definitely
prove useful in fine-tuning a driver agent. However, in a simple simulation, we must process
sensor information for all vehicles simultaneously, and accurately simulating a full laserrange finder is not feasible. Thus, we use this simple, yet pertinent sensor reading which
the driver agent can use to control its actions with respect to the other vehicles. A purely
straight-ahead sensor suffices when vehicles are traveling only in straight lines. However,
when a vehicle turns, it must also take into account what is going on in the direction in
which it is turning. To complicate matters, when a vehicle is turning it must still take into
account what is going on directly in front of it because at any point it might straighten
its wheels and continue on its current heading. A sensor that points in the same direction
as the wheels will not be sufficient because vehicles coming out of turns may run into
vehicles ahead of them. Instead, our sensorâ€™s scope widens in the direction of the turn,
while narrowing slightly from the other side. Figure 26 shows a scenario that demonstrates
the concept. A testament to the sensorâ€™s usefulness, vehicles equipped with only the sensor
(i.e. no intersection manager is present) are able to avoid many collisions in the intersection,
even with moderate amounts of traffic.

Appendix B. Communication Protocol
Section 3.2 gave a brief introduction to the communication protocol used by the agents in
the reservation system. In this appendix, we specify the protocol with much greater detail.
The protocol consists of several message types for each kind of agent, as well as some rules
governing when the messages should be sent and what sorts of guarantees accompany them.
In this section we present those aspects that are essential to understanding the remainder
of the article.
B.1 Message Types
The vehicles and intersection manager are each restricted to a few types of messages with
which they must coordinate.
B.1.1 Vehicle â†’ Intersection
There are four types of messages that can be sent from vehicles to the intersection.
645

Dresner & Stone

Figure 26: A depiction of the sensor model for the driver agents. The sensor is focused
between the gray lines and does not provide information outside of them. The
black line represents the reading provided to the driver agent.

1. Request â€” This is the message a vehicle sends when it does not have a reservation
and wishes to make one. It contains the properties of the vehicle (ID number, performance, size, etc.) as well as some properties of the proposed reservation (arrival time,
arrival velocity, type of turn, arrival lane, etc.). The message also communicates the
vehicleâ€™s status as an emergency vehicle (in an emergency situation). In practice, this
would be implemented using a secure method such that normal vehicles could not
impersonate emergency vehicles. Such methods are well understood and the details
of the implementation are beyond the scope of this research.
This message has 15 fields:
vehicle id â€” a unique identifier for the vehicle.
arrival time â€” the absolute time at which the vehicle agrees to arrive at the intersection.
arrival lane â€” a unique identifier for the lane in which the vehicle will be when it
arrives at the intersection.
turn â€” which way the vehicle will turn when it reaches the intersection.
arrival velocity â€” the velocity at which the vehicle agrees to be traveling when
it arrives at the intersection.
maximum velocity â€” the maximum velocity at which the vehicle can travel.
maximum acceleration â€” the maximum rate at which the vehicle can accelerate.
646

A Multiagent Approach to Autonomous Intersection Management

minimum acceleration â€” the minimum rate at which the vehicle can accelerate (i.e.
negative number representing maximum deceleration).
vehicle length â€” the length of the vehicle.
vehicle width â€” the width of the vehicle.
front wheel displacement â€” the distance between the front of the vehicle and the
front axle.
rear wheel displacement â€” the distance between the front of the vehicle and the
rear axle.
max steering angle â€” the maximum angle to which the front wheels can be turned
for the purposes of steering.
max turn per second â€” the rate at which the vehicle can turn its wheels.
emergency â€” whether or not this is an emergency vehicle in an emergency situation.
2. Change-Request â€” This is the message a vehicle sends when it has a reservation,
but would like to switch to a different set of parameters. If the new parameters are
not acceptable to the intersection, the vehicle may keep its old reservation. It is
identical to the request message, except that it includes a unique reservation ID for
the reservation the vehicle currently has.
This message is identical to the Request message, except for one added field:
reservation id â€” an identifier for the reservation to be changed.
3. Cancel â€” This is the message a vehicle sends when it no longer desires its current
reservation.
It has 2 fields:
vehicle id â€” a unique identifier for the vehicle.
reservation id â€” an identifier for the reservation to be cancelled.
4. Done â€” This message is sent when the vehicle has completed its traversal of the
intersection. While it communicates the same information as the Cancel message,
there may be behavior tied to the Cancel message which should not occur when a vehicle successfully completes the trip across the intersection. Additionally, this message
could be extended in order to communicate statistics for each vehicle, which could
then be recorded in order to analyze the performance of the intersection manager.
This message can be used to collect statistics for each vehicle, which can be recorded
in order to analyze and improve the performance of the intersection manager.
It has 2 fields:
vehicle id â€” a unique identifier for the vehicle.
reservation id â€” an identifier for the reservation that was just completed.
647

Dresner & Stone

B.1.2 Intersection â†’ Vehicle
There are four types of messages that can be sent from the intersection to the individual
vehicles.
1. Confirm â€” This message is a response to a vehicleâ€™s Request (or Change-Request)
message. It does not always mean that the parameters transmitted by the vehicle are
acceptable. It could, for example, contain a counter-offer by the intersection. The
reservation parameters in this message are implicitly accepted by the vehicle, and
must be explicitly cancelled if the driver agent of the vehicle does not approve. Note
that this is safe even with faulty communicationâ€”the worst that can happen is that
the intersection reserves space that does not get used. Included in the message are
acceleration constraints determined by the intersection. This is just a list of rates and
durations. How the list is created depends on the intersection manager. However, the
vehicleâ€™s safety must be guaranteed if it adheres to the list.
This message has 7 fields:
reservation id â€” a unique identifier for the reservation just created.
arrival time â€” the absolute time at which the vehicle is expected to arrive.
early error â€” the tolerable error (early) in arrival time for the vehicle.
late error â€” the tolerable error (late) in arrival time for the vehicle. Note that
the intersection manager must assume that the car could arrive and traverse the
intersection at any time within the resulting bounds
arrival lane â€” a unique identifier for the lane in which the vehicle should be when
it arrives at the intersection.
arrival velocity â€” the velocity at which the vehicle is expected to be traveling
when it arrives at the intersection. A negative number signifies that any velocity
is acceptable.
accelerations â€” a run-length encoded description of the expected acceleration of
the vehicle as it travels through the intersection. Here, a run-length encoded description is a sequence of order pairs of acceleration and durationâ€”starting
with the instant the vehicle enters the intersection, it should maintain each
acceleration for the duration with which it is paired. If the sequence is empty,
any accelerations are acceptable.
2. Reject â€” By sending this message, an intersection can inform a vehicle that the
parameters sent in the latest Request (or Change-Request) were not acceptable,
and that the intersection either could not or did not want to make a counter-offer.
This message also indicates whether or not the rejection was because the reservation
manager requires the vehicle to stop at the intersection before entering. This lets the
driver agent know that it should not attempt any more reservations until it reaches
the intersection.
This message has 1 field:
648

A Multiagent Approach to Autonomous Intersection Management

stop required â€” a boolean value indicating whether the vehicle must first come to
a full stop before entering the intersection.
3. Acknowledge â€” This message acknowledges the receipt of a Cancel or Done
message.
It has 1 field:
reservation id â€” a unique identifier for the reservation just cancelled or completed.
4. Emergency-Stop â€” This message is only sent when the intersection manager has
determined that a collision or similar problem has occurred in the intersection. This
message informs the receiving driver agent that no further reservation requests will
be granted, and if possible, the vehicle should attempt to stop instead of entering the
intersection, even if it has a reservation. The specifics of how this message is used
are discussed in Section 5.2.2. This message has no fields, as it only communicates a
single bit of information.
B.1.3 Vehicle â†’ Vehicle
There is currently no protocol for communication between vehicles.
B.2 Protocol Actions
In addition to message types, the agents involved (the vehicles and the intersection) must
obey a set of rules. These are not entirely unlike the rules that human drivers follow when
driving.
B.2.1 Vehicle Actions
These are the rules that the vehicles are expected to follow in order to allow the intersection
to function efficiently.
1. A vehicle may not enter the intersection without a reservation.
2. If a vehicle is going to cross the intersection, it must do everything reasonable within
its power to cross in accordance with the parameters included in the most recent
Confirm message it has received from the intersection.
3. If a vehicle sends another message before the intersection manager has sent a response,
the intersection manager may choose to ignore it. Thus, a vehicle should only send a
message if it has received a response to its previous message.
4. If a vehicle has not yet entered the intersection and does not have a reservation, it
may send a Request message. If it has not yet entered the intersection and does
have a reservation, it may send either a Change-Request or Cancel message. If
it sends any of these messages when it is not allowed to, the intersection may choose
to ignore them.
5. If a vehicle has a reservation and has successfully crossed the intersection, it may send
a Done message.
649

Dresner & Stone

6. If a vehicle receives a Confirm message, it is considered to have a reservation.
B.2.2 Intersection Actions
These are the rules representing the obligations the intersection manager is expected to
fulfill.
1. When an intersection receives a Request message, it must respond with either a
Confirm or a Reject message. If it responds with a Confirm message, it is guaranteeing that no cross-traffic will interfere with the vehicle if it crosses the intersection
in accordance with the parameters in the message.
2. When an intersection receives a Change-Request message, it must respond with
either a Confirm or a Reject message. If it responds with a Confirm message, it
is guaranteeing that no cross-traffic will interfere with the vehicle if it crosses the intersection in accordance with the parameters in the message. Any previous guarantees
are nullified.
3. When an intersection receives a Cancel message, it must respond with an Acknowledge message. Any guarantee that had been made to the sending vehicle is nullified.

Appendix C. Driver Agent
As stated in Section 3.3, the main focus of this work is on improving the framework and
algorithms for intersection control. However, in order to do this we require some sort of
driver agent. Furthermore, the efficiency of the reservation framework depends on driver
agents being reasonably intelligent, which is non-trivial. This appendix describes the driver
agent implementation used in our experiments.
Containing both behaviors to control turning vehicles as well as optimizations to increase
peformance of the system overall, the driver agent represents the single most intricate component of the reservation mechanism. Algorithm 3 gives a high-level pseudocode description
of the driver agent.
C.1 Lane Following
Given the model of lanes, each driver must be able to drive the vehicles in those lanes.
We accomplish this by means of a lane following behavior that acts only by modifying the
steering angle of the vehicle. This behavior is entirely independent of the rest of the agentâ€™s
behavior, which controls the vehicleâ€™s acceleration and communicates with the intersection
manager. This behavior is active at all timesâ€”the vehicle is always attempting to stay
in its current lane. The lane-following behavior is designed to be robust to sudden lane
reassignment, and this is how both turning and lane changing are implemented: the driver
agent simply changes which lane is its â€œcurrentâ€ lane, and the lane-following behavior steers
the vehicle into the correct lane. This process is entirely smooth, provided the vehicle is
traveling at a reasonable velocityâ€”a condition enforced by other parts of the driver agentâ€™s
behavior.
Because lanes are modeled as directed line segments, the lane-following behavior attempts to keep the vehicle evenly straddling the lane. The line segment represents the
650

A Multiagent Approach to Autonomous Intersection Management

middle of the lane, and thus this condition is equivalent to keeping the vehicle centered in
the lane. The driver agent accomplishes this by turning the front wheels toward a point on
the segment. This point, which we call the aim point is farther along the segment than the
vehicle. The aim point is computed by first projecting the point at the front and center of
the vehicle onto the line segment, and then displacing this point in the direction of the line
segment by an amount we call the lead distance. For the most part, the lead distance is
proportional to the velocity of the vehicle. The proportion is smaller inside the intersection
so that vehicles will pull more strongly into their new lane if they are turningâ€”they must
be entirely in the correct lane before they leave the intersection so that they do not collide
with other vehicles outside the intersection. The proportional lead distance is necessary
because otherwise at high velocities, the required steering angle may change faster than the
driver agent can steer, resulting in either wildly erratic steering or the vehicle driving in
circles. The lead distance also has a minimum value of 1 meter. If the lead distance gets
too small, the effect is the same as if the velocity were too largeâ€”by ensuring the aim point
is at least a meter farther down the lane, we can ensure that the vehicle will end up in
a stable configuration traveling in the proper direction. Figure 27 depicts how the driver
agent determines the lead distance (and subsequent aim point) for different velocities.

a

b

c

Figure 27: A vehicle is attempting to follow the lane. To do so, it first calculates the point
that represents the projection of its position onto the directed line segment
running down the center of the lane (a). Then, depending on its velocity, it
displaces the resulting point in the direction of travel by a small or large amount
to obtain the point at which it should aim its front wheels. For low velocities,
the point will not be displaced muchâ€”only enough to ensure the vehicle moves
in the correct direction (b). For higher velocities, the aim point must be farther
along the lane, so that the vehicleâ€™s steering will be more gradual and thus more
stable (c).

This method of lane following is only one possible method, and was selected because it
is sufficient for our purposes. Furthermore, the reservation systemâ€™s functionality does not
depend on the driver agent using this particular method, but will work with any method,
provided the driver agent turns within some mutually understood constraints.
651

Dresner & Stone

C.2 Optimistic and Pessimistic Driver Agents
A naÄ±Ìˆve driver agent can perform poorly when, for example, it makes a reservation while
stuck behind a slower-moving vehicle. If the vehicle in front eventually accelerates, it would
ideally accelerate as well (possibly switching to an earlier reservation).
To account for situations like this, we introduce the notion of an optimistic or pessimistic
driver agent. An optimistic agent makes a reservation assuming it will arrive at the intersection in the minimum possible time. An agent which finds itself no longer stuck behind
a slower vehicle will become optimistic and attempt to make a new, earlier reservation. A
pessimistic agent assumes it will be stuck at its current velocity until it reaches the intersection. If an agent has to cancel its reservation because there is no way for it to arrive
on time, it becomes pessimistic. Due to the relatively infrequent and smooth transitions
through these â€œmoodsâ€, our driver agent can take advantage of improving circumstances
without causing it to send excessive numbers of messages when things change.
As shown in Figure 2, the addition of optimism and pessimism to the driver agent
reduced both the average number of reservations made as well as the average number of
messages transmitted. As expected, the effect was less pronounced for lower amounts of
traffic.

With
Without

Messages
560.85
5.97

Reservations
165.89
1.02

Table 2: For a moderate amount of traffic, the average number of messages sent and reservations made by driver agents with and without the optimism/pessimism heuristic.

C.3 Estimating Time To Intersection
A driver agentâ€™s estimate of how long it will take to get to the intersection must be very
precise so that vehicles can arrive on time for their reservations. If, at this point, the
vehicle is not certain whether or not it will arrive on schedule, it cannot safely continue.
The pessimistic driver agent simply divides the distance to the intersection by its current
velocityâ€”it assumes it will not be able to accelerate. An optimistic driver first determines
what its velocity will be when it arrives. If it is turning, for example, this velocity may be
lower than the speed limit. Otherwise, it may be limited by the amount the vehicle can
accelerate before reaching the intersection. It then computes the minimum possible time
to reach the intersection at that velocity, that is, it assumes it can accelerate as much as
possible before decelerating to its arrival velocity.
652

A Multiagent Approach to Autonomous Intersection Management

Algorithm 3 The driver agent behavior. All driver agents are initialized as optimistic.
1: determine aim point and attempt to point wheels at it
2: t â† current time
3: if Velocity is below speed limit then
4:
Accelerate
5: if Before the intersection then
6:
if Optimistic then
7:
ti â† optimisitic estimate of time to intersection
8:
else
9:
ti â† pessimistic estimate of time to intersection
10:
if Do not have a reservation then
11:
if t + ti is after scheduled arrival then
12:
Cancel reservation
13:
become pessimistic
14:
else if t + ti is significantly before scheduled arrival then
15:
Become optimistic
16:
Attempt to change reservation to earlier time
17:
else
18:
Try to make reservation according to ti
19:
if Reservation request rejected then
20:
Decelerate
21: else if In the intersection then
22:
Set acceleration according to parameters of reservation
23: if Not in the intersection and less than 1 second behind car in front then
24:
Decelerate

References
Abdulhai, B., Pringle, R., & Karakoulas, G. J. (2003). Reinforcement learning for true
adaptive traffic signal control. Journal of Transportation Engineering, 129 (3), 278â€“
285.
Alvarez, L., & Horowitz, R. (1997). Traffic flow control in automated highway systems.
Tech. rep. UCB-ITS-PRR-97-47, University of California, Berkeley, Berkeley, California, USA.
Balan, G., & Luke, S. (2006). History-based traffic control. In Proceedings of the Fifth
International Joint Conference on Autonomous Agents and Multiagent Systems, pp.
616â€“621, Hakodate, Japan.
Bazzan, A. L. C. (2005). A distributed approach for coordination of traffic signal agents.
Autonomous Agents and Multi-Agent Systems, 10(2), 131â€“164.
Bishop, R. (2005). Intelligent Vehicle Technology and Trends. Artech House.
Bonneson, J. A., & McCoy, P. T. (1993). Estimation of safety at two-way stopâ€“controlled
intersections on rural highways. Transportation Research Record, 1401, 83â€“89.
653

Dresner & Stone

Bull, L., Shaâ€™Aban, J., Tomlinson, A., Addison, J. D., & Heydecker, B. G. (2004). Towards
distributed adaptive control for road traffic junction signals using learning classifier
systems. In Bull, L. (Ed.), Applications of Learning Classifier Systems, pp. 276â€“299.
Springer.
Clement, S. (2002). The SPA model with smooth acceleration. In 24th Conference of
Australian Institutes of Transport Research (CAITR-2002), Sydney, Australia.
DARPA (2007). The DARPA urban challenge.. http://www.darpa.mil/grandchallenge.
Dresner, K., & Stone, P. (2004). Multiagent traffic management: A reservation-based intersection control mechanism. In The Third International Joint Conference on Autonomous Agents and Multiagent Systems, pp. 530â€“537, New York, NY, USA.
Dresner, K., & Stone, P. (2006). Multiagent traffic management: Opportunities for multiagent learning. In K. Tuyls et al. (Ed.), LAMAS 2005, Vol. 3898 of Lecture Notes In
Artificial Intelligence, pp. 129â€“138. Springer Verlag, Berlin.
Gavrila, D. M., Giebel, J., & Munder, S. (2004). Vision-based pedestrian detection: The
PROTECTOR+ system. In Proceedings of the IEEE Intelligent Vehicles Symposium
(IV2004), Parma, Italy.
Gepperth, A., Edelbrunner, J., & BuÌˆcher, T. (2005). Real-time detection and classification
of cars in video sequences. In Proceedings of the IEEE Intelligent Vehicle Symposium
(IV2005), pp. 625â€“631, Las Vegas, NV, USA.
HalleÌ, S., & Chaib-draa, B. (2005). A collaborative driving system based on multiagent
modelling and simulations. Journal of Transportation Research Part C (TRC-C):
Emergent Technologies, 13, 320â€“345.
Harwood, D. W., Bauer, K. M., Potts, I. B., Torbic, D. J., Richard, K. R., Rabbani, E.
R. K., Hauer, E., Elefteriadou, L., & Griffith, M. S. (2003). Safety effectiveness of
intersection left- and right-turn lanes. Transportation Research Record, 1840, 131â€“139.
Hatipo, C., Redmill, K., & Ozguner, U. (1997). Steering and lane change: A working system.
In IEEE Conference on Intelligent Transportation Systems, pp. 272â€“277.
Hunt, P. B., Robertson, D. I., Bretherton, R. D., & Winton, R. I. (1981). SCOOT - a traffic
responsive method of co-ordinating signals. Tech. rep. TRRL-LR-1014, Transport and
Road Research Laboratory.
Johnson, R. C. (2005). Steady pace takes DARPA race. EE Times. Accessed at http:
//www.eetimes.com.
Kohl, N., Stanley, K., Miikkulainen, R., Samples, M., & Sherony, R. (2006). Evolving a
real-world vehicle warning system. In Proceedings of the Genetic and Evolutionary
Computation Conference 2006, Seattle, WA, USA.
Kolodko, J., & Vlacic, L. (2003). Cooperative autonomous driving at the intelligent control
systems laboratory. IEEE Intelligent Systems, 18 (4), 8â€“11.
LaumoÌ‚nier, J., Desjardins, C., & Chaib-draa, B. (2006). Cooperative adaptive cruise control:
a reinforcement learning approach. In The Fourth Workshop on Agents in Traffic and
Transportation, Hakodate, Hokkaido, Japan.
654

A Multiagent Approach to Autonomous Intersection Management

Lindner, F., Kressel, U., & Kaelberer, S. (2004). Robust recognition of traffic signals. In
Proceedings of the IEEE Intelligent Vehicles Symposium (IV2004), Parma, Italy.
Liu, X., & Fujimura, K. (2003). Pedestrian detection using stereo night vision. In IEEE
International Conference on Intelligent Transportation Systems, Shanghai, China.
MaÌˆhlisch, M., OberlaÌˆnder, M., LoÌˆhlein, O., Gavrila, D., & Ritter, W. (2005). A multiple
detector approach to low-resolution FIR pedestrian recognition. In Proceedings of the
IEEE Intelligent Vehicles Symposium (IV2005), Las Vegas, NV, USA.
Moriarty, D., & Langley, P. (1998). Learning cooperative lane selection strategies for highways. In Proceedings of the Fifteenth National Conference on Artificial Intelligence,
pp. 684â€“691, Madison, WI. AAAI Press.
National Highway Traffic Safety Administration (2002). Economic impact of U.S. motor
vehicle crashes reaches $230.6 billion, new NHTSA study shows. NHTSA Press Release
38-02. http://www.nhtsa.dot.gov.
Naumann, R., & Rasche, R. (1997). Intersection collision avoidance by means of decentralized security and communication management of autonomous vehicles. In Proceedings
of the 30th ISATA - ATT/IST Conference.
Naumann, R., Rasche, R., & Tacken, J. (1998). Managing autonomous vehicles at intersections. IEEE Intelligent Systems, 13 (3), 82â€“86.
Noda, I., Jacoff, A., Bredenfeld, A., & Takahashi, Y. (Eds.). (2006). RoboCup-2005: Robot
Soccer World Cup IX. Springer Verlag, Berlin.
NOVA (2006). The great robot race.. Originally aired 28 March 2006 on PBS, available
online at http://www.pbs.org/wgbh/nova/darpa.
Persaud, B. N., Retting, R. A., Gardner, P. E., & Lord, D. (2001). Safety effect of roundabout conversions in the united states: Empirical bayes observational before-after
study. Transportation Research Record, 1751, 1â€“8.
Pomerleau, D. A. (1993). Neural Network Perception for Mobile Robot Guidance. Kluwer
Academic Publishers.
RamstroÌˆm, O., & Christensen, H. (2005). A method for following umarked roads. In
Proceedings of the IEEE Intelligent Vehicle Symposium (IV2005), pp. 650â€“655, Las
Vegas, NV, USA.
Rasche, R., Naumann, R., Tacken, J., & Tahedl, C. (1997). Validation and simulation
of decentralized intersection collision avoidance algorithm. In Proceedings of IEEE
Conference on Intelligent Transportation Systems (ITSC 97).
Reece, D. A., & Shafer, S. (1991). A computational model of driving for autonomous
vehicles. Tech. rep. CMU-CS-91-122, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA.
Reynolds, C. W. (1999). Steering behaviors for autonomous characters. In Proceedings of
the Game Developers Conference, pp. 763â€“782.
Rizzo, M., McGehee, D. V., Dawson, J. D., & Anderson, S. N. (2001). Simulated car crashes
at intersections in drivers with Alzheimer disease. Alzheimer Disease and Associated
Disorders, 15 (1), 10â€“20.
655

Dresner & Stone

Robertson, D. I. (1969). TRANSYT â€” a traffic network study tool. Tech. rep. TRRL-LR253, Transport and Road Research Laboratory.
Rogers, S., Flechter, C.-N., & Langley, P. (1999). An adaptive interactive agent for route
advice. In Etzioni, O., MuÌˆller, J. P., & Bradshaw, J. M. (Eds.), Proceedings of the Third
International Conference on Autonomous Agents (Agentsâ€™99), pp. 198â€“205, Seattle,
WA, USA. ACM Press.
Roozemond, D. A. (1999). Using intelligent agents for urban traffic control systems. In Proceedings of the International Conference on Artificial Intelligence in Transportation
Systems and Science, pp. 69â€“79.
Sayed, T., & Zein, S. (1999). Traffic conflict standards for intersections. Transportation
Planning and Technology, 22 (4), 309â€“323.
Schonberg, T., Ojala, M., Suomela, J., Torpo, A., & Halme, A. (1995). Positioning an
autonomous off-road vehicle by using fused DGPS and inertial navigation. In 2nd
IFAC Conference on Intelligent Autonomous Vehicles, pp. 226â€“231.
She, K., Bebis, G., Gu, H., & Miller, R. (2004). Vehicle tracking using on-line fusion of
color and shape features. In Proceedings of the IEEE International Conference on
Intelligent Transportation Systems, Washington, DC, USA.
Stone, P., & Veloso, M. (2000). Multiagent systems: A survey from a machine learning
perspective. Autonomous Robots, 8 (3), 345â€“383.
Svenson, O. (1981). Are we all less risky and more skillful than our fellow drivers?. Acta
Psychologica, 47 (2), 143â€“148.
Texas Transportation Institute (2004). 2004 urban mobility report.. Accessed at http:
//mobility.tamu.edu/ums in December 2004.
USDOT (2003). Inside the USDOTâ€™s â€˜intelligent intersectionâ€™ test facility. Newsletter of
the ITS Cooperative Deployment Network. Accessed online 17 May 2006 at http:
//www.ntoctalks.com/icdn/intell_intersection.php.
Watanabe, A., & Nishida, M. (2005). Lane detection for a steering assistance system. In
Proceedings of the IEEE Intelligent Vehicle Symposium (IV2005), pp. 159â€“164, Las
Vegas, NV, USA.
Wiering, M. A. (2000). Multi-agent reinforcement learning for traffic light control. In
Langley, P. (Ed.), Proceedings of the Seventeenth International Conference on Machine
Learning (ICMLâ€™2000), pp. 1151â€“1158.
Wierwille, W. W., Hanowski, R. J., Hankey, J. M., Kieliszewski, C. A., Lee, S. E., Medina,
A., Keisler, A. S., & Dingus, T. A. (2002). Identification and evaluation of driver
errors: Overview and recommendations. Tech. rep. FHWA-RD-02-003, Virginia Tech
Transportation Institute, Blacksburg, Virginia, USA. Sponsored by the Federal Highway Administration.
Wu, S.-J., Chiang, H.-H., Perng, J.-W., Lee, T.-T., & Chen, C.-J. (2005). The automated
lane-keeping design for an intelligent vehicle. In Proceedings of the IEEE Intelligent
Vehicle Symposium (IV2005), pp. 508â€“513, Las Vegas, NV, USA.

656

Journal of Artificial Intelligence Research 31 (2008) 157-204

Submitted 06/07; published 01/08

Conjunctive Query Answering for the Description Logic
SHIQ
Birte Glimm
Ian Horrocks

birte.glimm@comlab.ox.ac.uk
ian.horrocks@comlab.ox.ac.uk

Oxford University Computing Laboratory, UK

Carsten Lutz

clu@tcs.inf.tu-dresden.de

Dresden University of Technology, Germany

Ulrike Sattler

sattler@cs.man.ac.uk

The University of Manchester, UK

Abstract
Conjunctive queries play an important role as an expressive query language for Description Logics (DLs). Although modern DLs usually provide for transitive roles, conjunctive
query answering over DL knowledge bases is only poorly understood if transitive roles are
admitted in the query. In this paper, we consider unions of conjunctive queries over knowledge bases formulated in the prominent DL SHIQ and allow transitive roles in both the
query and the knowledge base. We show decidability of query answering in this setting
and establish two tight complexity bounds: regarding combined complexity, we prove that
there is a deterministic algorithm for query answering that needs time single exponential
in the size of the KB and double exponential in the size of the query, which is optimal.
Regarding data complexity, we prove containment in co-NP.

1. Introduction
Description Logics (DLs) are a family of logic based knowledge representation formalisms
(Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). Most DLs are fragments
of First-Order Logic restricted to unary and binary predicates, which are called concepts and
roles in DLs. The constructors for building complex expressions are usually chosen such that
the key inference problems, such as concept satisfiability, are decidable and preferably of low
computational complexity. A DL knowledge base (KB) consists of a TBox, which contains
intensional knowledge such as concept definitions and general background knowledge, and
an ABox, which contains extensional knowledge and is used to describe individuals. Using
a database metaphor, the TBox corresponds to the schema, and the ABox corresponds to
the data. In contrast to databases, however, DL knowledge bases adopt an open world
semantics, i.e., they represent information about the domain in an incomplete way.
Standard DL reasoning services include testing concepts for satisfiability and retrieving
certain instances of a given concept. The latter retrieves, for a knowledge base consisting of
an ABox A and a TBox T , all (ABox) individuals that are instances of the given (possibly
complex) concept expression C, i.e., all those individuals a such that T and A entail that a
is an instance of C. The underlying reasoning problems are well-understood, and it is known
that the combined complexity of these reasoning problems, i.e., the complexity measured in
the size of the TBox, the ABox, and the query, is ExpTime-complete for SHIQ (Tobies,
c
2008
AI Access Foundation. All rights reserved.

Glimm, Horrocks, Lutz, & Sattler

2001). The data complexity of a reasoning problem is measured in the size of the ABox
only. Whenever the TBox and the query are small compared to the ABox, as is often the
case in practice, the data complexity gives a more useful performance estimate. For SHIQ,
instance retrieval is known to be data complete for co-NP (Hustadt, Motik, & Sattler,
2005).
Despite the high worst case complexity of the standard reasoning problems for very
expressive DLs such as SHIQ, there are highly optimized implementations available, e.g.,
FaCT++ (Tsarkov & Horrocks, 2006), KAON21 , Pellet (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz, 2006), and RacerPro2 . These systems are used in a wide range of applications,
e.g., configuration (McGuinness & Wright, 1998), bio informatics (Wolstencroft, Brass,
Horrocks, Lord, Sattler, Turi, & Stevens, 2005), and information integration (Calvanese,
De Giacomo, Lenzerini, Nardi, & Rosati, 1998b). Most prominently, DLs are known for
their use as a logical underpinning of ontology languages, e.g., OIL, DAML+OIL, and
OWL (Horrocks, Patel-Schneider, & van Harmelen, 2003), which is a W3C recommendation (Bechhofer, van Harmelen, Hendler, Horrocks, McGuinness, Patel-Schneider, & Stein,
2004).
In data-intensive applications, querying KBs plays a central role. Instance retrieval
is, in some aspects, a rather weak form of querying: although possibly complex concept
expressions are used as queries, we can only query for tree-like relational structures, i.e.,
a DL concept cannot express arbitrary cyclic structures. This property is known as the
tree model property and is considered an important reason for the decidability of most
Modal and Description Logics (GraÌˆdel, 2001; Vardi, 1997). Conjunctive queries (CQs)
are well known in the database community and constitute an expressive query language
with capabilities that go well beyond standard instance retrieval. For an example, consider
a knowledge base that contains an ABox assertion (âˆƒhasSon.(âˆƒhasDaughter.>))(Mary),
which informally states that the individual (or constant in FOL terms) Mary has a son
who has a daughter; hence, that Mary is a grandmother. Additionally, we assume that
both roles hasSon and hasDaughter have a transitive super-role hasDescendant. This implies that Mary is related via the role hasDescendant to her (anonymous) grandchild. For
this knowledge base, Mary is clearly an answer to the conjunctive query hasSon(x, y) âˆ§
hasDaughter(y, z) âˆ§ hasDescendant(x, z), when we assume that x is a distinguished variable
(also called answer or free variable) and y, z are non-distinguished (existentially quantified)
variables.
If all variables in the query are non-distinguished, the query answer is just true or false
and the query is called a Boolean query. Given a knowledge base K and a Boolean CQ q, the
query entailment problem is deciding whether q is true or false w.r.t. K. If a CQ contains
distinguished variables, the answers to the query are those tuples of individual names for
which the knowledge base entails the query that is obtained by replacing the free variables
with the individual names in the answer tuple. The problem of finding all answer tuples is
known as query answering. Since query entailment is a decision problem and thus better
suited for complexity analysis than query answering, we concentrate on query entailment.
This is no restriction since query answering can easily be reduced to query entailment as
we illustrate in more detail in Section 2.2.
1. http://kaon2.semanticweb.org
2. http://www.racer-systems.com

158

Conjunctive Query Answering for the DL SHIQ

Devising a decision procedure for conjunctive query entailment in expressive DLs such as
SHIQ is a challenging problem, in particular when transitive roles are admitted in the query
(Glimm, Horrocks, & Sattler, 2006). In the conference version of this paper, we presented
the first decision procedure for conjunctive query entailment in SHIQ. In this paper, we
generalize this result to unions of conjunctive queries (UCQs) over SHIQ knowledge bases.
We achieve this by rewriting a conjunctive query into a set of conjunctive queries such that
each resulting query is either tree-shaped (i.e., it can be expressed as a concept) or grounded
(i.e., it contains only constants/individual names and no variables). The entailment of both
types of queries can be reduced to standard reasoning problems (Horrocks & Tessaris, 2000;
Calvanese, De Giacomo, & Lenzerini, 1998a).
The paper is organized as follows: in Section 2, we give the necessary definitions, followed
by a discussion of related work in Section 3. In Section 4, we motivate the query rewriting
steps by means of an example. In Section 5, we give formal definitions for the rewriting
procedure and show that a Boolean query is indeed entailed by a knowledge base K iff the
disjunction of the rewritten queries is entailed by K. In Section 6, we present a deterministic
algorithm for UCQ entailment in SHIQ that runs in time single exponential in the size of
the knowledge base and double exponential in the size of the query. Since the combined
complexity of conjunctive query entailment is already 2ExpTime-hard for the DL ALCI
(Lutz, 2007), it follows that this problem is 2ExpTime-complete for SHIQ. This shows
that conjunctive query entailment for SHIQ is strictly harder than instance checking,
which is also the case for simpler DLs such as EL (Rosati, 2007b). We further show that
(the decision problem corresponding to) conjunctive query answering in SHIQ is co-NPcomplete regarding data complexity, and thus not harder than instance retrieval.
The presented decision procedure gives not only insight into query answering; it also has
an immediate consequence on the field of extending DL knowledge bases with rules. From
the work by Rosati (2006a, Thm. 11), the consistency of a SHIQ knowledge base extended
with (weakly-safe) Datalog rules is decidable iff the entailment of unions of conjunctive
queries in SHIQ is decidable. Hence, we close this open problem as well.
This paper is an extended version of the conference paper: Conjunctive Query Answering for the Description Logic SHIQ. Proceedings of the Twentieth International Joint
Conference on Artificial Intelligence (IJCAIâ€™07), Jan 06 - 12, 2007.

2. Preliminaries
We introduce the basic terms and notations used throughout the paper. In particular, we
introduce the DL SHIQ (Horrocks, Sattler, & Tobies, 2000) and (unions of) conjunctive
queries.
2.1 Syntax and Semantics of SHIQ
Let NC , NR , and NI be countably infinite sets of concept names, role names, and individual
names. We assume that the set of role names contains a subset NtR âŠ† NR of transitive role
names. A role is an element of NR âˆª {râˆ’ | r âˆˆ NR }, where roles of the form râˆ’ are called
inverse roles. A role inclusion is of the form r v s with r, s roles. A role hierarchy R is a
finite set of role inclusions.
159

Glimm, Horrocks, Lutz, & Sattler

An interpretation I = (âˆ†I ,Â·I ) consists of a non-empty set âˆ†I , the domain of I, and a
function Â·I , which maps every concept name A to a subset AI âŠ† âˆ†I , every role name r âˆˆ NR
to a binary relation rI âŠ† âˆ†I Ã— âˆ†I , every role name r âˆˆ NtR to a transitive binary relation
rI âŠ† âˆ†I Ã— âˆ†I , and every individual name a to an element aI âˆˆ âˆ†I . An interpretation
I satisfies a role inclusion r v s if rI âŠ† sI and a role hierarchy R if it satisfies all role
inclusions in R.
We use the following standard notation:
1. We define the function Inv over roles as Inv(r) := râˆ’ if r âˆˆ NR and Inv(r) := s if
r = sâˆ’ for a role name s.
2. For a role hierarchy R, we define v* R as the reflexive transitive closure of v over
R âˆª {Inv(r) v Inv(s) | r v s âˆˆ R}. We use r â‰¡R s as an abbreviation for r v
* R s and
sv
* R r.
3. For a role hierarchy R and a role s, we define the set TransR of transitive roles as
{s | there is a role r with r â‰¡R s and r âˆˆ NtR or Inv(r) âˆˆ NtR }.
4. A role r is called simple w.r.t. a role hierarchy R if, for each role s such that s v* R r,
sâˆˆ
/ TransR .
The subscript R of v* R and TransR is dropped if clear from the context. The set of SHIQconcepts (or concepts for short) is the smallest set built inductively from NC using the
following grammar, where A âˆˆ NC , n âˆˆ IN, r is a role and s is a simple role:
C ::= > | âŠ¥ | A | Â¬C | C1 u C2 | C1 t C2 | âˆ€r.C | âˆƒr.C |6 n s.C |> n s.C.
Given an interpretation I, the semantics of SHIQ-concepts is defined as follows:
>I
âŠ¥I
(âˆ€r.C)I
(âˆƒr.C)I
(6 n s.C)I
(> n s.C)I

=
=
=
=
=
=

âˆ†I
(C u D)I = C I âˆ© DI
(Â¬C)I = âˆ†I \ C I
âˆ…
(C t D)I = C I âˆª DI
{d âˆˆ âˆ†I | if (d, d0 ) âˆˆ rI , then d0 âˆˆ C I }
{d âˆˆ âˆ†I | there is a (d, d0 ) âˆˆ rI with d0 âˆˆ C I }
{d âˆˆ âˆ†I | ](sI (d, C)) â‰¤ n}
{d âˆˆ âˆ†I | ](sI (d, C)) â‰¥ n}

where ](M ) denotes the cardinality of the set M and sI (d, C) is defined as
{d0 âˆˆ âˆ†I | (d, d0 ) âˆˆ sI and d0 âˆˆ C I }.
A general concept inclusion (GCI) is an expression C v D, where both C and D are
concepts. A finite set of GCIs is called a TBox. An interpretation I satisfies a GCI C v D
if C I âŠ† DI , and a TBox T if it satisfies each GCI in T .
.
An (ABox) assertion is an expression of the form C(a), r(a, b), Â¬r(a, b), or a =
6 b, where
C is a concept, r is a role, a, b âˆˆ NI . An ABox is a finite set of assertions. We use Inds(A) to
denote the set of individual names occurring in A. An interpretation I satisfies an assertion
.
C(a) if aI âˆˆ C I , r(a, b) if (aI , bI ) âˆˆ rI , Â¬r(a, b) if (aI , bI ) âˆˆ
/ rI , and a =
6 b if aI 6= bI . An
160

Conjunctive Query Answering for the DL SHIQ

interpretation I satisfies an ABox if it satisfies each assertion in A, which we denote with
I |= A.
A knowledge base (KB) is a triple (T , R, A) with T a TBox, R a role hierarchy, and A
an ABox. Let K = (T , R, A) be a KB and I = (âˆ†I ,Â·I ) an interpretation. We say that I
satisfies K if I satisfies T , R, and A. In this case, we say that I is a model of K and write
I |= K. We say that K is consistent if K has a model.
2.1.1 Extending SHIQ to SHIQu
In the following section, we show how we can reduce a conjunctive query to a set of ground
or tree-shaped conjunctive queries. During the reduction, we may introduce concepts that
contain an intersection of roles under existential quantification. We define, therefore, the
extension of SHIQ with role conjunction/intersection, denoted as SHIQu and, in the
appendix, we show how to decide the consistency of SHIQu knowledge bases.
In addition to the constructors introduced for SHIQ, SHIQu allows for concepts of
the form
C ::= âˆ€R.C | âˆƒR.C |6 n S.C |> n S.C,
where R := r1 u . . . u rn , S := s1 u . . . u sn , r1 , . . . , rn are roles, and s1 , . . . , sn are simple
roles. The interpretation function is extended such that (r1 u . . . u rn )I = r1 I âˆ© . . . âˆ© rn I .
2.2 Conjunctive Queries and Unions of Conjunctive Queries
We now introduce Boolean conjunctive queries since they are the basic form of queries we
are concerned with. We later also define non-Boolean queries and show how they can be
reduced to Boolean queries. Finally, unions of conjunctive queries are just a disjunction of
conjunctive queries.
For simplicity, we write a conjunctive query as a set instead of as a conjunction of atoms.
For example, we write the introductory example from Section 1 as
{hasSon(x, y), hasDaughter(y, z), hasDescendant(x, z)}.
For non-Boolean queries, i.e., when we consider the problem of query answering, the
answer variables are often given in the head of the query, e.g.,
(x1 , x2 , x3 ) â† {hasSon(x1 , x2 ), hasDaughter(x2 , x3 ), hasDescendant(x1 , x3 )}
indicates that the query answers are those tuples (a1 , a2 , a3 ) of individual names that,
substituted for x1 , x2 , and x3 respectively, result in a Boolean query that is entailed by the
knowledge base. For simplicity and since we mainly focus on query entailment, we do not
use a query head even in the case of a non-Boolean query. Instead, we explicitly say which
variables are answer variables and which ones are existentially quantified. We now give a
definition of Boolean conjunctive queries.
Definition 1. Let NV be a countably infinite set of variables disjoint from NC , NR , and NI .
A term t is an element from NV âˆª NI . Let C be a concept, r a role, and t, t0 terms. An atom
is an expression C(t), r(t, t0 ), or t â‰ˆ t0 and we refer to these three different types of atoms
as concept atoms, role atoms, and equality atoms respectively. A Boolean conjunctive query
161

Glimm, Horrocks, Lutz, & Sattler

q is a non-empty set of atoms. We use Vars(q) to denote the set of (existentially quantified)
variables occurring in q, Inds(q) to denote the set of individual names occurring in q, and
Terms(q) for the set of terms in q, where Terms(q) = Vars(q) âˆª Inds(q). If all terms in q
are individual names, we say that q is ground. A sub-query of q is simply a subset of q
(including q itself). As usual, we use ](q) to denote the cardinality of q, which is simply the
number of atoms in q, and we use |q| for the size of q, i.e., the number of symbols necessary
to write q. A SHIQ conjunctive query is a conjunctive query in which all concepts C that
occur in a concept atom C(t) are SHIQ-concepts.
Since equality is reflexive, symmetric and transitive, we define â‰ˆ* as the transitive,
reflexive, and symmetric closure of â‰ˆ over the terms in q. Hence, the relation â‰ˆ* is an
equivalence relation over the terms in q and, for t âˆˆ Terms(q), we use [t] to denote the
equivalence class of t by â‰ˆ* .
Let I = (âˆ†I ,Â·I ) be an interpretation. A total function Ï€ : Terms(q) â†’ âˆ†I is an evaluation if (i) Ï€(a) = aI for each individual name a âˆˆ Inds(q) and (ii) Ï€(t) = Ï€(t0 ) for all tâ‰ˆ* t0 .
We write
â€¢ I |=Ï€ C(t) if Ï€(t) âˆˆ C I ;
â€¢ I |=Ï€ r(t, t0 ) if (Ï€(t), Ï€(t0 )) âˆˆ rI ;
â€¢ I |=Ï€ t â‰ˆ t0 if Ï€(t) = Ï€(t0 ).
If, for an evaluation Ï€, I |=Ï€ at for all atoms at âˆˆ q, we write I |=Ï€ q. We say that I
satisfies q and write I |= q if there exists an evaluation Ï€ such that I |=Ï€ q. We call such a
Ï€ a match for q in I.
Let K be a SHIQ knowledge base and q a conjunctive query. If I |= K implies I |= q,
we say that K entails q and write K |= q.
4
The query entailment problem is defined as follows: given a knowledge base K and a
query q, decide whether K |= q.
Â¯ over atoms in q as follows:
For brevity and simplicity of notation, we define the relation âˆˆ
0
* 0
Â¯
Â¯ q if
C(t) âˆˆ q if there is a term t âˆˆ Terms(q) such that tâ‰ˆ t and C(t0 ) âˆˆ q, and r(t1 , t2 ) âˆˆ
0
0
0
0
0
0
* 0
* 0
there are terms t1 , t2 âˆˆ Terms(q) such that t1â‰ˆ t1 , t2â‰ˆ t2 , and r(t1 , t2 ) âˆˆ q or Inv(r)(t2 , t1 ) âˆˆ q.
This is clearly justified by definition of the semantics, in particular, because I |= r(t, t0 )
implies that I |= Inv(r)(t0 , t).
When devising a decision procedure for CQ entailment, most complications arise from
cyclic queries (Calvanese et al., 1998a; Chekuri & Rajaraman, 1997). In this context, when
we say cyclic, we mean that the graph structure induced by the query is cyclic, i.e., the graph
obtained from q such that each term is considered as a node and each role atom induces
an edge. Since, in the presence of inverse roles, a query containing the role atom r(t, t0 ) is
equivalent to the query obtained by replacing this atom with Inv(r)(t0 , t), the direction of
the edges is not important and we say that a query is cyclic if its underlying undirected
graph structure is cyclic. Please note also that multiple role atoms for two terms are not
considered as a cycle, e.g., the query {r(t, t0 ), s(t, t0 )} is not a cyclic query. The following is
a more formal definition of this property.
Definition 2. A query q is cyclic if there exists a sequence of terms t1 , . . . , tn with n > 3
such that
162

Conjunctive Query Answering for the DL SHIQ

Â¯ q,
1. for each i with 1 â‰¤ i < n, there exists a role atom ri (ti , ti+1 ) âˆˆ
2. t1 = tn , and
3. ti 6= tj for 1 â‰¤ i < j < n.

4

In the above definition, Item 3 makes sure that we do not consider queries as cyclic just
because they contain two terms t, t0 for which there are more than two role atoms using the
Â¯ here, which implicitly uses the relation
two terms. Please note that we use the relation âˆˆ
*
â‰ˆ and abstracts from the directedness of role atoms.
Â¯ q with s(t1 , t2 ), . . . , s(tnâˆ’1 , tn ) for
In the following, if we write that we replace r(t, t0 ) âˆˆ
0
t = t1 and t = tn , we mean that we first remove any occurrences of r(tÌ‚, tË†0 ) and Inv(r)(tË†0 , tÌ‚)
* 0
such that tÌ‚â‰ˆ* t and tË†0â‰ˆ
t from q, and then add the atoms s(t1 , t2 ), . . . , s(tnâˆ’1 , tn ) to q.
W.l.o.g., we assume that queries are connected. More precisely, let q be a conjunctive
query. We say that q is connected if, for all t, t0 âˆˆ Terms(q), there exists a sequence t1 , . . . , tn
Â¯ q.
such that t1 = t, tn = t0 and, for all 1 â‰¤ i < n, there exists a role r such that r(ti , ti+1 ) âˆˆ
A collection q1 , . . . , qn of queries is a partitioning of q if q = q1 âˆª . . . âˆª qn , qi âˆ© qj = âˆ… for
1 â‰¤ i < j â‰¤ n, and each qi is connected.
Lemma 3. Let K be a knowledge base, q a conjunctive query, and q1 , . . . , qn a partitioning
of q. Then K |= q iff K |= qi for each i with 1 â‰¤ i â‰¤ n.
A proof is given by Tessaris (2001, 7.3.2) and, with this lemma, it is clear that the
restriction to connected queries is indeed w.l.o.g. since entailment of q can be decided by
checking entailment of each qi at a time. In what follows, we therefore assume queries to
be connected without further notice.
Definition 4. A union of Boolean conjunctive queries is a formula q1 âˆ¨ . . . âˆ¨ qn , where each
disjunct qi is a Boolean conjunctive query.
A knowledge base K entails a union of Boolean conjunctive queries q1 âˆ¨ . . . âˆ¨ qn , written
as K |= q1 âˆ¨ . . . âˆ¨ qn , if, for each interpretation I such that I |= K, there is some i such that
I |= qi and 1 â‰¤ i â‰¤ n.
4
W.l.o.g. we assume that the variable names in each disjunct are different from the
variable names in the other disjuncts. This can always be achieved by naming variables
apart. We further assume that each disjunct is a connected conjunctive query. This is
w.l.o.g. since a UCQ which contains unconnected disjuncts can always be transformed
into conjunctive normal form; we can then decide entailment for each resulting conjunct
separately and each conjunct is a union of connected conjunctive queries. We describe
this transformation now in more detail and, for a more convenient notation, we write a
conjunctive query {at1 , . . . , atk } as at1 âˆ§ . . . âˆ§ atk in the following proof, instead of the usual
set notation.
Lemma 5. Let K be a knowledge base, q = q1 âˆ¨ . . . âˆ¨ qn a union of conjunctive queries such
that, for 1 â‰¤ i â‰¤ n, qi1 , . . . , qiki is a partitioning of the conjunctive query qi . Then K |= q iff
^
(q1i1 âˆ¨ . . . âˆ¨ qnin ).
K |=
(i1 ,...,in )âˆˆ{1,...,k1 }Ã—...Ã—{1,...,kn }

163

Glimm, Horrocks, Lutz, & Sattler

Again, a detailed proof is given by Tessaris (2001, 7.3.3). Please note that, due to the
transformation into conjunctive normal form, the resulting number of unions of connected
conjunctive queries for which we have to test entailment can be exponential in the size of
the original query. When analysing the complexity of the decision procedures presented
in Section 6, we show that the assumption that each CQ in a UCQ is connected does not
increase the complexity.
We now make the connection between query entailment and query answering clearer. For
query answering, let the variables of a conjunctive query be typed: each variable can either
be existentially quantified (also called non-distinguished ) or free (also called distinguished or
answer variables). Let q be a query in n variables (i.e., ](Vars(q)) = n), of which v1 , . . . , vm
(m â‰¤ n) are answer variables. The answers of K = (T , R, A) to q are those m-tuples
(a1 , . . . , am ) âˆˆ Inds(A)m such that, for all models I of K, I |=Ï€ q for some Ï€ that satisfies
Ï€(vi ) = ai I for all i with 1 â‰¤ i â‰¤ m. It is not hard to see that the answers of K to q can be
computed by testing, for each (a1 , . . . , am ) âˆˆ Inds(A)m , whether the query q[v1 ,...,vm /a1 ,...,am ]
obtained from q by replacing each occurrence of vi with ai for 1 â‰¤ i â‰¤ m is entailed by K.
The answer to q is then the set of all m-tuples (a1 , . . . , am ) for which K |= q[v1 ,...,vm /a1 ,...,am ] .
Let k = ](Inds(A)) be the number of individual names used in the ABox A. Since A is finite,
clearly k is finite. Hence, deciding which tuples belong to the set of answers can be checked
with at most k m entailment tests. This is clearly not very efficient, but optimizations can
be used, e.g., to identify a (hopefully small) set of candidate tuples.
The algorithm that we present in Section 6 decides query entailment. The reasons for
devising a decision procedure for query entailment instead of query answering are twofold: first, query answering can be reduced to query entailment as shown above; second, in
contrast to query answering, query entailment is a decision problem and can be studied in
terms of complexity theory.
In the remainder of this paper, if not stated otherwise, we use q (possibly with subscripts)
for a connected Boolean conjunctive query, K for a SHIQ knowledge base (T , R, A), I for
an interpretation (âˆ†I ,Â·I ), and Ï€ for an evaluation.

3. Related Work
Very recently, an automata-based decision procedure for positive existential path queries
over ALCQIbreg knowledge bases has been presented (Calvanese, Eiter, & Ortiz, 2007).
Positive existential path queries generalize unions of conjunctive queries and since a SHIQ
knowledge base can be polynomially reduced to an ALCQIbreg knowledge base, the presented algorithm is a decision procedure for (union of) conjunctive query entailment in
SHIQ as well. The automata-based technique can be considered more elegant than our
rewriting algorithm, but it does not give an NP upper bound for the data complexity as
our technique.
Most existing algorithms for conjunctive query answering in expressive DLs assume,
however, that role atoms in conjunctive queries use only roles that are not transitive. As a
consequence, the example query from the introductory section cannot be answered. Under
this restriction, decision procedures for various DLs around SHIQ are known (Horrocks &
Tessaris, 2000; Ortiz, Calvanese, & Eiter, 2006b), and it is known that answering conjunctive
queries in this setting is data complete for co-NP (Ortiz et al., 2006b). Another common
164

Conjunctive Query Answering for the DL SHIQ

restriction is that only individuals named in the ABox are considered for the assignments
of variables. In this setting, the semantics of queries is no longer the standard First-Order
one. With this restriction, the answer to the example query from the introduction would be
false since Mary is the only named individual. It is not hard to see that conjunctive query
answering with this restriction can be reduced to standard instance retrieval by replacing
the variables with individual names from the ABox and then testing the entailment of
each conjunct separately. Most of the implemented DL reasoners, e.g., KAON2, Pellet,
and RacerPro, provide an interface for conjunctive query answering in this setting and
employ several optimizations to improve the performance (Sirin & Parsia, 2006; Motik,
Sattler, & Studer, 2004; Wessel & MoÌˆller, 2005). Pellet appears to be the only reasoner
that also supports the standard First-Order semantics for SHIQ conjunctive queries under
the restriction that the queries are acyclic.
To the best of our knowledge, it is still an open problem whether conjunctive query
entailment is decidable in SHOIQ. Regarding undecidability results, it is known that
conjunctive query entailment in the two variable fragment of First-Order Logic L2 is undecidable (Rosati, 2007a) and Rosati identifies a relatively small set of constructors that
causes the undecidability.
Query entailment and answering have also been studied in the context of databases
with incomplete information (Rosati, 2006b; van der Meyden, 1998; Grahne, 1991). In this
setting, DLs can be used as schema languages, but the expressivity of the considered DLs
is much lower than the expressivity of SHIQ. For example, the constructors provided by
logics of the DL-Lite family (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007)
are chosen such that the standard reasoning tasks are in PTime and query entailment
is in LogSpace with respect to data complexity. Furthermore, TBox reasoning can be
done independently of the ABox and the ABox can be stored and accessed using a standard
database SQL engine. Since the considered DLs are considerable less expressive than SHIQ,
the techniques used in databases with incomplete information cannot be applied in our
setting.
Regarding the query language, it is well known that an extension of conjunctive queries
with inequalities is undecidable (Calvanese et al., 1998a). Recently, it has further been
shown that even for DLs with low expressivity, an extension of conjunctive queries with
inequalities or safe role negation leads to undecidability (Rosati, 2007a).
A related reasoning problem is query containment. Given a schema (or TBox) S and
two queries q and q 0 , we have that q is contained in q 0 w.r.t. S iff every interpretation I
that satisfies S and q also satisfies q 0 . It is well known that query containment w.r.t. a
TBox can be reduced to deciding query entailment for (unions of) conjunctive queries w.r.t.
a knowledge base (Calvanese et al., 1998a). Hence a decision procedure for (unions of)
conjunctive queries in SHIQ can also be used for deciding query containment w.r.t. to a
SHIQ TBox.
Entailment of unions of conjunctive queries is also closely related to the problem of
adding rules to a DL knowledge base, e.g., in the form of Datalog rules. Augmenting a
DL KB with an arbitrary Datalog program easily leads to undecidability (Levy & Rousset,
1998). In order to ensure decidability, the interaction between the Datalog rules and the
DL knowledge base is usually restricted by imposing a safeness condition. The DL+log
framework (Rosati, 2006a) provides the least restrictive integration proposed so far. Rosati
165

Glimm, Horrocks, Lutz, & Sattler

presents an algorithm that decides the consistency of a DL+log knowledge base by reducing
the problem to entailment of unions of conjunctive queries, and he proves that decidability
of UCQs in SHIQ implies the decidability of consistency for SHIQ+log knowledge bases.

4. Query Rewriting by Example
In this section, we motivate the ideas behind our query rewriting technique by means of
examples. In the following section, we give precise definitions for all rewriting steps.
4.1 Forest Bases and Canonical Interpretations
The main idea is that we can focus on models of the knowledge base that have a kind of
tree or forest shape. It is well known that one reason for Description and Modal Logics
being so robustly decidable is that they enjoy some form of tree model property, i.e., every
satisfiable concept has a model that is tree-shaped (Vardi, 1997; GraÌˆdel, 2001). When going
from concept satisfiability to knowledge base consistency, we need to replace the tree model
property with a form of forest model property, i.e., every consistent KB has a model that
consists of a set of â€œtreesâ€, where each root corresponds to a named individual in the ABox.
The roots can be connected via arbitrary relational structures, induced by the role assertions
given in the ABox. A forest model is, therefore, not a forest in the graph theoretic sense.
Furthermore, transitive roles can introduce â€œshort-cutâ€ edges between elements within a
tree or even between elements of different trees. Hence we talk of â€œa form ofâ€ forest model
property.
We now define forest models and show that, for deciding query entailment, we can
restrict our attention to forest models. The rewriting steps are then used to transform cyclic
subparts of the query into tree-shaped ones such that there is a â€œforest-shaped matchâ€ for
the rewritten query into the forest models.
In order to make the forest model property even clearer, we also introduce forest bases,
which are interpretations that interpret transitive roles in an unrestricted way, i.e., not
necessarily in a transitive way. For a forest base, we require in particular that all relationships between elements of the domain that can be inferred by transitively closing a role are
omitted. In the following, we assume that the ABox contains at least one individual name,
i.e., Inds(A) is non-empty. This is w.l.o.g. since we can always add an assertion >(a) to the
ABox for a fresh individual name a âˆˆ NI . For readers familiar with tableau algorithms, it
is worth noting that forest bases can also be thought of as those tableaux generated from a
complete and clash-free completion tree (Horrocks et al., 2000).
Definition 6. Let IN denote the non-negative integers and INâˆ— the set of all (finite) words
over the alphabet IN. A tree T is a non-empty, prefix-closed subset of INâˆ— . For w, w0 âˆˆ T ,
we call w0 a successor of w if w0 = w Â· c for some c âˆˆ IN, where â€œÂ·â€ denotes concatenation.
We call w0 a neighbor of w if w0 is a successor of w or vice versa. The empty word Îµ is
called the root.
A forest base for K is an interpretation J = (âˆ†J ,Â·J ) that interprets transitive roles in
an unrestricted (i.e., not necessarily transitive) way and, additionally, satisfies the following
conditions:
T1 âˆ†J âŠ† Inds(A) Ã— INâˆ— such that, for all a âˆˆ Inds(A), the set {w | (a, w) âˆˆ âˆ†J } is a tree;
166

Conjunctive Query Answering for the DL SHIQ

T2 if ((a, w), (a0 , w0 )) âˆˆ rJ , then either w = w0 = Îµ or a = a0 and w0 is a neighbor of w;
T3 for each a âˆˆ Inds(A), aJ = (a, Îµ);
An interpretation I is canonical for K if there exists a forest base J for K such that I is
identical to J except that, for all non-simple roles r, we have
[
(sJ )+
rI = rJ âˆª
s v* R r, sâˆˆTransR

In this case, we say that J is a forest base for I and if I |= K we say that I is a canonical
model for K.
4
For convenience, we extend the notion of successors and neighbors to elements in canonical models. Let I be a canonical model with (a, w), (a0 , w0 ) âˆˆ âˆ†I . We call (a0 , w0 ) a
successor of (a, w) if either a = a0 and w0 = w Â· c for some c âˆˆ IN or w = w0 = Îµ. We call
(a0 , w0 ) a neighbor of (a, w) if (a0 , w0 ) is a successor of (a, w) or vice versa.
Please note that the above definition implicitly relies on the unique name assumption
(UNA) (cf. T3). This is w.l.o.g. as we can guess an appropriate partition among the individual names and replace the individual names in each partition with one representative
individual name from that partition. In Section 6, we show how the partitioning of individual names can be used to simulate the UNA, hence, our decision procedure does not rely
on the UNA. We also show that this does not affect the complexity.
Lemma 7. Let K be a SHIQ knowledge base and q = q1 âˆ¨ . . . âˆ¨ qn a union of conjunctive
queries. Then K 6|= q iff there exists a canonical model I of K such that I 6|= q.
A detailed proof is given in the appendix. Informally, for the only if direction, we can
take an arbitrary counter-model for the query, which exists by assumption, and â€œunravelâ€
all non-tree structures. Since, during the unraveling process, we only replace cycles in the
model by infinite paths and leave the interpretation of concepts unchanged, the query is
still not satisfied in the unravelled canonical model. The if direction of the proof is trivial.
4.2 The Running Example
We use the following Boolean query and knowledge base as a running example:
Example 8. Let K = (T , R, A) be a SHIQ knowledge base with r, t âˆˆ NtR , k âˆˆ IN
T = { Ck v > k p.>,
C3 v > 3 p.>,
D2 v âˆƒsâˆ’ .> u âˆƒt.>
}
R = { t v tâˆ’ ,
sâˆ’ v r
}
A = { r(a, b),
(âˆƒp.Ck u âˆƒp.C u âˆƒrâˆ’ .C3 )(a),
(âˆƒp.D1 u âˆƒr.D2 )(b)
}
and q = {r(u, x), r(x, y), t(y, y), s(z, y), r(u, z)} with Inds(q) = âˆ… and Vars(q) = {u, x, y, z}.
167

Glimm, Horrocks, Lutz, & Sattler

For simplicity, we choose to use a CQ instead of a UCQ. In case of a UCQ, the rewriting
steps are applied to each disjunct separately.
r

(a, Îµ)
p
(a, 1) Ck
p
(a, 11)

(a, 12)

p
...

p

r

âˆ’

r

(a, 2) C

p

(a, 1k)

r
r

(a, 31)

p

(a, 32)

p

D1 (b, 1)
r

(a, 3) C3

p

(b, Îµ)
r

p
(a, 33)

r

t, tâˆ’

(b, 2)
r D2
âˆ’
r, s âˆ’
t, t
(b, 21)

t, tâˆ’

(b, 22)

Figure 1: A representation of a canonical interpretation I for K.
Figure 1 shows a representation of a canonical model I for the knowledge base K from
Example 8. Each labeled node represents an element in the domain, e.g., the individual
name a is represented by the node labeled (a, Îµ). The edges represent relationships between
individuals. For example, we can read the r-labeled edge from (a, Îµ) to (b, Îµ) in both
I
directions, i.e., (aI , bI ) = ((a, Îµ), (b, Îµ)) âˆˆ rI and (bI , aI ) = ((b, Îµ), (a, Îµ)) âˆˆ râˆ’ . The
â€œshort-cutsâ€ due to transitive roles are shown as dashed lines, while the relationship between
the nodes that represent ABox individuals is shown in grey. Please note that we did not
indicate the interpretations of all concepts in the figure.
Since I is a canonical model for K, the elements of the domain are pairs (a, w), where
a indicates the individual name that corresponds to the root of the tree, i.e., aI = (a, Îµ)
and the elements in the second place form a tree according to our definition of trees. For
each individual name a in our ABox, we can, therefore, easily define the tree rooted in a as
{w | (a, w) âˆˆ âˆ†I }.
(a, Îµ)
p
(a, 1)
p
(a, 11)

(a, 12)

p
...

p
(a, 2)

(a, 1k)

r

p
(a, 3)
p

p
(a, 31)

(b, Îµ)

r
âˆ’

p

(a, 32)

(b, 1)
p
(a, 33)

r
(b, 2)
r, sâˆ’ âˆ’
t, t
(b, 21)

(b, 22)

Figure 2: A forest base for the interpretation represented by Figure 1.
Figure 2 shows a representation of a forest base for the interpretation from Figure 1
above. For simplicity, the interpretation of concepts is no longer shown. The two trees,
rooted in (a, Îµ) and (b, Îµ) respectively, are now clear.
A graphical representation of the query q from Example 8 is shown in Figure 3, where
the meaning of the nodes and edges is analogous to the ones given for interpretations. We
call this query a cyclic query since its underlying undirected graph is cyclic (cf. Definition 2).
Figure 4 shows a match Ï€ for q and I and, although we consider only one canonical
model here, it is not hard to see that the query is true in each model of the knowledge base,
i.e., K |= q.
168

Conjunctive Query Answering for the DL SHIQ

x
r

r

u

t
y

r
s
z

Figure 3: A graph representation of the query from Example 8.
(a, Îµ)
râˆ’
(a, 1)

(a, 11)

(a, 12)

...

(a, 2)

(a, 1k)

(a, 31)

x
(b, Îµ)

r
r
(a, 3)

(a, 32)

u

(a, 33)

r

r

r

t, tâˆ’

r
(b, 1)
r

r

y (b, 2)
r, sâˆ’ âˆ’
t, t

z

(b, 21)

t, tâˆ’
(b, 22)

Figure 4: A match Ï€ for the query q from Example 8 onto the model I from Figure 1.
The forest model property is also exploited in the query rewriting process. We want to
rewrite q into a set of queries q1 , . . . , qn of ground or tree-shaped queries such that K |= q
iff K |= q1 âˆ¨ . . . âˆ¨ qn . Since the resulting queries are ground or tree-shaped queries, we can
explore the known techniques for deciding entailment of these queries. As a first step, we
transform q into a set of forest-shaped queries. Intuitively, forest-shaped queries consist
of a set of tree-shaped sub-queries, where the roots of these trees might be arbitrarily
interconnected (by atoms of the form r(t, t0 )). A tree-shaped query is a special case of a
forest-shaped query. We will call the arbitrarily interconnected terms of a forest-shaped
query the root choice (or, for short, just roots). At the end of the rewriting process, we
replace the roots with individual names from Inds(A) and transform the tree parts into
a concept by applying the so called rolling-up or tuple graph technique (Tessaris, 2001;
Calvanese et al., 1998a).
In the proof of the correctness of our procedure, we use the structure of the forest bases
in order to explicate the transitive â€œshort-cutsâ€ used in the query match. By explicating we
mean that we replace each role atom that is mapped to such a short-cut with a sequence
of role atoms such that an extended match for the modified query uses only paths that are
in the forest base.
4.3 The Rewriting Steps
The rewriting process for a query q is a six stage process. At the end of this process, the
rewritten query may or may not be in a forest shape. As we show later, this â€œdonâ€™t knowâ€
non-determinism does not compromise the correctness of the algorithm. In the first stage,
we derive a collapsing qco of q by adding (possibly several) equality atoms to q. Consider,
169

Glimm, Horrocks, Lutz, & Sattler

for example, the cyclic query q = {r(x, y), r(x, y 0 ), s(y, z), s(y 0 , z)} (see Figure 5), which can
be transformed into a tree-shaped one by adding the equality atom y â‰ˆ y 0 .
x

x
r

r

r

y, y 0
s

y0

y
s

s

z

z

Figure 5: A representation of a cyclic query and of the tree-shaped query obtained by adding
the atom y â‰ˆ y 0 to the query depicted on the left hand side.
A common property of the next three rewriting steps is that they allow for substituting
the implicit short-cut edges with explicit paths that induce the short-cut. The three steps
aim at different cases in which these short-cuts can occur and we describe their goals and
application now in more detail:
The second stage is called split rewriting. In a split rewriting we take care of all role
atoms that are matched to transitive â€œshort-cutsâ€ connecting elements of two different trees
and by-passing one or both of their roots. We substitute these short-cuts with either one or
two role atoms such that the roots are included. In our running example, Ï€ maps u to (a, 3)
and x to (b, Îµ). Hence I |=Ï€ r(u, x), but the used r-edge is a transitive short-cut connecting
the tree rooted in a with the tree rooted in b, and by-passing (a, Îµ). Similar arguments hold
for the atom r(u, z), where the path that implies this short-cut relationship goes via the
two roots (a, Îµ) and (b, Îµ). It is clear that r must be a non-simple role since, in the forest
base J for I, there is no â€œdirectâ€ connection between different trees other than between the
roots of the trees. Hence, (Ï€(u), Ï€(x)) âˆˆ rI holds only because there is a role s âˆˆ TransR
such that s v
* R r. In case of our example, r itself is transitive. A split rewriting eliminates
transitive short-cuts between different trees of a canonical model and adds the â€œmissingâ€
variables and role atoms matching the sequence of edges that induce the short-cut.
ux

r
r

x
r
t

r

u

y
s
z

Figure 6: A split rewriting qsr for the query shown in Figure 3.
Figure 6 depicts the split rewriting
qsr = { r(u, ux), r(ux, x), r(x, y), t(y, y), s(z, y),
r(u, ux), r(ux, x), r(x, z)}
170

Conjunctive Query Answering for the DL SHIQ

of q that is obtained from q by replacing (i) r(u, x) with r(u, ux) and r(ux, x) and (ii) r(u, z)
with r(u, ux), r(ux, x), and r(x, z). Please note that we both introduced a new variable (ux)
and re-used an existing variable (x). Figure 7 shows a match for qsr and the canonical model
I of K in which the two trees are only connected via the roots. For the rewritten query, we
also guess a set of roots, which contains the variables that are mapped to the roots in the
canonical model. For our running example, we guess that the set of roots is {ux, x}.
(a, Îµ)

ux

x
(b, Îµ)

r
râˆ’

(a, 1)

r
(a, 3)

(a, 2)

(b, 1)

u

t , tâˆ’
y (b, 2)

r

sâˆ’, r
(a, 11)

(a, 12)

...

(a, 1k)

(a, 31)

(a, 32)

(a, 33)

z

(b, 21)

(b, 22)

Figure 7: A split match Ï€sr for the query qsr from Figure 6 onto the canonical interpretation
from Figure 1.
In the third step, called loop rewriting, we eliminate â€œloopsâ€ for variables v that do not
correspond to roots by replacing atoms r(v, v) with two atom r(v, v 0 ) and r(v 0 , v), where v 0
can either be a new or an existing variable in q. In our running example, we eliminate the
loop t(y, y) as follows:
q`r = { r(u, ux), r(ux, x), r(x, y), t(y, y 0 ), t(y 0 , y), s(z, y),
r(u, ux), r(ux, x), r(x, z)}
is the query obtained from qsr (see Figure 6) by replacing t(y, y) with t(y, y 0 ) and t(y 0 , y) for
a new variable y 0 . Please note that, since t is defined as transitive and symmetric, t(y, y)
is still implied, i.e., the loop is also a transitive short-cut. Figure 8 shows the canonical
interpretation I from Figure 1 with a match Ï€`r for q`r . The introduction of the new variable
y 0 is needed in this case since there is no variable that could be re-used and the individual
(b, 22) is not in the range of the match Ï€sr .
(a, Îµ)

ux

x
(b, Îµ)

r
râˆ’

(a, 1)

(a, 11)

(a, 12)

...

(a, 2)

(a, 1k)

(a, 31)

r
(a, 3)

(a, 32)

u

(a, 33)

(b, 1)

(b, 2)
r y
sâˆ’, r âˆ’
t, t
z

(b, 21)

(b, 22)
y0

Figure 8: A loop rewriting q`r and a match for the canonical interpretation from Figure 1.
The forth rewriting step, called forest rewriting, allows again the replacement of role
atoms with sets of role atoms. This allows the elimination of cycles that are within a single
171

Glimm, Horrocks, Lutz, & Sattler

tree. A forest rewriting qf r for our example can be obtained from q`r by replacing the role
atom r(x, z) with r(x, y) and r(y, z), resulting in the query
qf r = { r(u, ux), r(ux, x), r(x, y), t(y, y 0 ), t(y 0 , y), s(z, y),
r(u, ux), r(ux, x), r(x, y), r(y, z)}.
Clearly, this results in tree-shaped sub-queries, one rooted in ux and one rooted in x.
Hence qf r is forest-shaped w.r.t. the root terms ux and x. Figure 9 shows the canonical
interpretation I from Figure 1 with a match Ï€f r for qf r .
(a, Îµ)

ux

x
(b, Îµ)

r
râˆ’

(a, 1)

(a, 2)

r
(a, 3)

u

(b, 1)

y (b, 2)
r, sâˆ’ âˆ’
t, t

(a, 11)

(a, 12)

...

(a, 1k)

(a, 31)

(a, 32)

(a, 33)

z

(b, 21)

(b, 22)
y0

Figure 9: A forest rewriting qf r and a forest match Ï€f r for the canonical interpretation from
Figure 1.
In the fifth step, we use the standard rolling-up technique (Horrocks & Tessaris, 2000;
Calvanese et al., 1998a) and express the tree-shaped sub-queries as concepts. In order to
do this, we traverse each tree in a bottom-up fashion and replace each leaf (labeled with a
concept C, say) and its incoming edge (labeled with a role r, say) with the concept âˆƒr.C
added to its predecessor. For example, the tree rooted in ux (i.e., the role atom r(u, ux))
can be replaced with the atom (âˆƒrâˆ’ .>)(ux). Similarly, the tree rooted in x (i.e., the role
atoms r(x, y), r(y, z), s(z, y), t(y, y 0 ), and t(y 0 , y)) can be replaced with the atom
(âˆƒr.((âˆƒ(r u Inv(s)).>) u (âˆƒ(t u Inv(t)).>))(x).
Please note that we have to use role conjunctions in the resulting query in order to capture
the semantics of multiple role atoms relating the same pair of variables.
Recall that, in the split rewriting, we have guessed that x and ux correspond to roots and,
therefore, correspond to individual names in Inds(A). In the sixth and last rewriting step,
we guess which variable corresponds to which individual name and replace the variables with
the guessed names. A possible guess for our running example would be that ux corresponds
to a and x to b. This results in the (ground) query
{(âˆƒrâˆ’ .>)(a), r(a, b), (âˆƒr.((âˆƒ(r u Inv(s)).>) u (âˆƒ(t u Inv(t)).>)))(b)},
which is entailed by K.
Please note that we focused in the running example on the most reasonable rewriting.
There are several other possible rewritings, e.g., we obtain another rewriting from qf r by
replacing ux with b and x with a in the last step. For a UCQ, we apply the rewriting steps
to each of the disjuncts separately.
172

Conjunctive Query Answering for the DL SHIQ

At the end of the rewriting process, we have, for each disjunct, a set of ground queries
and/or queries that were rolled-up into a single concept atom. The latter queries result from
forest rewritings that are tree-shaped and have an empty set of roots. Such tree-shaped
rewritings can match anywhere in a tree and can, thus, not be grounded. Finally, we check
if our knowledge base entails the disjunction of all the rewritten queries. We show that
there is a bound on the number of (forest-shaped) rewritings and hence on the number of
queries produced in the rewriting process.
Summing up, the rewriting process for a connected conjunctive query q involves the
following steps:
1. Build all collapsings of q.
2. Build all split rewritings of each collapsing w.r.t. a subset R of roots.
3. Build all loop rewritings of the split rewritings.
4. Build all (forest-shaped) forest rewritings of the loop rewritings.
5. Roll up each tree-shaped sub-query in a forest-rewriting into a concept atom and
6. replace the roots in R with individual names from the ABox in all possible ways.
Let q1 , . . . , qn be the queries resulting from the rewriting process. In the next section, we
define each rewriting step and prove that K |= q iff K |= q1 âˆ¨Â· Â· Â·âˆ¨qn . Checking entailment for
the rewritten queries can easily be reduced to KB consistency and any decision procedure
for SHIQu KB consistency could be used in order to decide if K |= q. We present one such
decision procedure in Section 6.

5. Query Rewriting
In the previous section, we have used several terms, e.g., tree- or forest-shaped query,
rather informally. In the following, we give definitions for the terms used in the query
rewriting process. Once this is done, we formalize the query rewriting steps and prove the
correctness of the procedure, i.e., we show that the forest-shaped queries obtained in the
rewriting process can indeed be used for deciding whether a knowledge base entails the
original query. We do not give the detailed proofs here, but rather some intuitions behind
the proofs. Proofs in full detail are given in the appendix.
5.1 Tree- and Forest-Shaped Queries
In order to define tree- or forest-shaped queries more precisely, we use mappings between
queries and trees or forests. Instead of mapping equivalence classes of terms by â‰ˆ* to nodes
in a tree, we extend some well-known properties of functions as follows:
Definition 9. For a mapping f : A â†’ B, we use dom(f ) and ran(f ) to denote f â€™s domain
*
A and range B, respectively. Given an equivalence relation â‰ˆ
on dom(f ), we say that f is
0
0
*
injective modulo â‰ˆ
if, for all a, a âˆˆ dom(f ), f (a) = f (a ) implies aâ‰ˆ* a0 and we say that f
*
is bijective modulo â‰ˆ
if f is injective modulo â‰ˆ* and surjective. Let q be a query. A tree
mapping for q is a total function f from terms in q to a tree such that
173

Glimm, Horrocks, Lutz, & Sattler

*
1. f is bijective modulo â‰ˆ
,

Â¯ q, then f (t) is a neighbor of f (t0 ), and,
2. if r(t, t0 ) âˆˆ
3. if a âˆˆ Inds(q), then f (a) = Îµ.
The query q is tree-shaped if ](Inds(q)) â‰¤ 1 and there is a tree mapping for q.
A root choice R for q is a subset of Terms(q) such that Inds(q) âŠ† R and, if t âˆˆ R and
* 0
tâ‰ˆ t , then t0 âˆˆ R. For t âˆˆ R, we use Reach(t) to denote the set of terms t0 âˆˆ Terms(q) for
which there exists a sequence of terms t1 , . . . , tn âˆˆ Terms(q) such that
1. t1 = t and tn = t0 ,
Â¯ q, and,
2. for all 1 â‰¤ i < n, there is a role r such that r(ti , ti+1 ) âˆˆ
3. for 1 < i â‰¤ n, if ti âˆˆ R, then tiâ‰ˆ* t.
We call R a root splitting w.r.t. q if either R = âˆ… or if, for ti , tj âˆˆ R, ti 6 â‰ˆ* tj implies that
Reach(ti ) âˆ© Reach(tj ) = âˆ…. Each term t âˆˆ R induces a sub-query
Â¯ q | the terms in at occur in Reach(t)}\
subq(q, t) := {at âˆˆ
Â¯ q}.
{r(t, t) | r(t, t) âˆˆ
A query q is forest-shaped w.r.t. a root splitting R if either R = âˆ… and q is tree-shaped or
each sub-query subq(q, t) for t âˆˆ R is tree-shaped.
4
For each term t âˆˆ R, we collect the terms that are reachable from t in the set Reach(t).
By Condition 3, we make sure that R and â‰ˆ* are such that each t0 âˆˆ Reach(t) is either not in
R or tâ‰ˆ* t0 . Since queries are connected by assumption, we would otherwise collect all terms
in Reach(t) and not just those t0 âˆˆ
/ R. For a root splitting, we require that the resulting sets
are mutually disjoint for all terms t, t0 âˆˆ R that are not equivalent. This guarantees that all
paths between the sub-queries go via the root nodes of their respective trees. Intuitively, a
forest-shaped query is one that can potentially be mapped onto a canonical interpretation
I = (âˆ†I ,Â·I ) such that the terms in the root splitting R correspond to roots (a, Îµ) âˆˆ âˆ†I .
Â¯ q, as these parts of
In the definition of subq(q, t), we exclude loops of the form r(t, t) âˆˆ
the query are grounded later in the query rewriting process and between ground terms, we
allow arbitrary relationships.
Consider, for example, the query qsr of our running example from the previous section
(cf. Figure 6). Let us again make the root choice R := {ux, x} for q. The sets Reach(ux)
and Reach(x) w.r.t. qsr and R are {ux, u} and {x, y, z} respectively. Since both sets are
disjoint, R is a root splitting w.r.t. qsr . If we choose, however, R := {x, y}, the set R is not
a root splitting w.r.t. qsr since Reach(x) = {ux, u, z} and Reach(y) = {z} are not disjoint.
5.2 From Graphs to Forests
We are now ready to define the query rewriting steps. Given an arbitrary query, we exhaustively apply the rewriting steps and show that we can use the resulting queries that are
forest-shaped for deciding entailment of the original query. Please note that the following
definitions are for conjunctive queries and not for unions of conjunctive queries since we
apply the rewriting steps for each disjunct separately.
174

Conjunctive Query Answering for the DL SHIQ

Definition 10. Let q be a Boolean conjunctive query. A collapsing qco of q is obtained by
adding zero or more equality atoms of the form t â‰ˆ t0 for t, t0 âˆˆ Terms(q) to q. We use co(q)
to denote the set of all queries that are a collapsing of q.
Let K be a SHIQ knowledge base. A query qsr is called a split rewriting of q w.r.t. K
Â¯ q, to either:
if it is obtained from q by choosing, for each atom r(t, t0 ) âˆˆ
1. do nothing,
2. choose a role s âˆˆ TransR such that s v* R r and replace r(t, t0 ) with s(t, u), s(u, t0 ), or
3. choose a role s âˆˆ TransR such that s v* R r and replace r(t, t0 ) with s(t, u), s(u, u0 ),
s(u0 , t0 ),
where u, u0 âˆˆ NV are possibly fresh variables. We use srK (q) to denote the set of all pairs
(qsr , R) for which there is a query qco âˆˆ co(q) such that qsr is a split rewriting of qco and R
is a root splitting w.r.t. qsr .
A query q`r is called a loop rewriting of q w.r.t. a root splitting R and K if it is obtained
Â¯ q with t âˆˆ
from q by choosing, for all atoms of the form r(t, t) âˆˆ
/ R, a role s âˆˆ TransR such
that s v* R r and by replacing r(t, t) with two atoms s(t, t0 ) and s(t0 , t) for t0 âˆˆ NV a possibly
fresh variable. We use lrK (q) to denote the set of all pairs (q`r , R) for which there is a tuple
(qsr , R) âˆˆ srK (q) such that q`r is a loop rewriting of qsr w.r.t. R and K.
For a forest rewriting, fix a set V âŠ† NV of variables not occurring in q such that
](V ) â‰¤ ](Vars(q)). A forest rewriting qf r w.r.t. a root splitting R of q and K is obtained
Â¯ q or
from q by choosing, for each role atom r(t, t0 ) such that either R = âˆ… and r(t, t0 ) âˆˆ
Â¯ subq(q, tr ) to either
there is some tr âˆˆ R and r(t, t0 ) âˆˆ
1. do nothing, or
2. choose a role s âˆˆ TransR such that s v
* R r and replace r(t, t0 ) with ` â‰¤ ](Vars(q)) role
atoms s(t1 , t2 ), . . . , s(t` , t`+1 ), where t1 = t, t`+1 = t0 , and t2 , . . . , t` âˆˆ Vars(q) âˆª V .
We use frK (q) to denote the set of all pairs (qf r , R) for which there is a tuple (q`r , R) âˆˆ lrK (q)
such that qf r is a forest-shaped forest rewriting of q`r w.r.t. R and K.
4
If K is clear from the context, we say that q 0 is a split, loop, or forest rewriting of
q instead of saying that q 0 is a split, loop, or forest rewriting of q w.r.t. K. We assume
that srK (q), lrK (q), and frK (q) contain no isomorphic queries, i.e., differences in (newly
introduced) variable names only are neglected.
In the next section, we show how we can build a disjunction of conjunctive queries
q1 âˆ¨ Â· Â· Â· âˆ¨ q` from the queries in frK (q) such that each qi for 1 â‰¤ i â‰¤ ` is either of the form
C(v) for a single variable v âˆˆ Vars(qi ) or qi is ground, i.e., qi contains only constants and
no variables. It then remains to show that K |= q iff K |= q1 âˆ¨ Â· Â· Â· âˆ¨ q` .
5.3 From Trees to Concepts
In order to transform a tree-shaped query into a single concept atom and a forest-shaped
query into a ground query, we define a mapping f from the terms in each tree-shaped subquery to a tree. We then incrementally build a concept that corresponds to the tree-shaped
query by traversing the tree in a bottom-up fashion, i.e., from the leaves upwards to the
root.
175

Glimm, Horrocks, Lutz, & Sattler

Definition 11. Let q be a tree-shaped query with at most one individual name. If a âˆˆ
Inds(q), then let tr = a otherwise let tr = v for some variable v âˆˆ Vars(q). Let f be a tree
mapping such that f (tr ) = Îµ. We now inductively assign, to each term t âˆˆ Terms(q), a
concept con(q, t) as follows:
d
â€¢ if f (t) is a leaf of ran(f ), then con(q, t) := C(t)âˆˆÂ¯ q C,
â€¢ if f (t) has successors f (t1 ), . . . , f (tk ), then
con(q, t) :=

d

d

Cu

d
Â¯ q r .con(q, ti ).
r(t,ti )âˆˆ
1â‰¤iâ‰¤k âˆƒ
Â¯q
C(t)âˆˆ

Finally, the query concept of q w.r.t. tr is con(q, tr ).

4

Please note that the above definition takes equality atoms into account. This is because
*
the function f is bijective modulo â‰ˆ
and, in case there are concept atoms C(t) and C(t0 )
Â¯.
for tâ‰ˆ* t0 , both concepts are conjoined in the query concept due to the use of the relation âˆˆ
Similar arguments can be applied to the role atoms.
The following lemma shows that query concepts indeed capture the semantics of q.
Lemma 12. Let q be a tree-shaped query with tr âˆˆ Terms(q) as defined above, Cq =
con(q, tr ), and I an interpretation. Then I |= q iff there is a match Ï€ and an element
d âˆˆ Cq I such that Ï€(tr ) = d.
The proof given by Horrocks, Sattler, Tessaris, and Tobies (1999) easily transfers from
DLR to SHIQ. By applying the result from the above lemma, we can now transform a
forest-shaped query into a ground query as follows:
Definition 13. Let (qf r , R) âˆˆ frK (q) for R 6= âˆ…, and Ï„ : R â†’ Inds(A) a total function such
that, for each a âˆˆ Inds(q), Ï„ (a) = a and, for t, t0 âˆˆ R, Ï„ (t) = Ï„ (t0 ) iff tâ‰ˆ* t0 . We call such a
mapping Ï„ a ground mapping for R w.r.t. A. We obtain a ground query ground(qf r , R, Ï„ )
of qf r w.r.t. the root splitting R and ground mapping Ï„ as follows:
â€¢ replace each t âˆˆ R with Ï„ (t), and,
â€¢ for each a âˆˆ ran(Ï„ ), replace the sub-query qa = subq(qf r , a) with con(qa , a).
We define the set groundK (q) of ground queries for q w.r.t. K as follows:
groundK (q) := {q 0 | there exists some (qf r , R) âˆˆ frK (q) with R 6= âˆ…
and some ground mapping Ï„ w.r.t. A and R
such that q 0 = ground(qf r , R, Ï„ )}
We define the set of treesK (q) of tree queries for q as follows:
treesK (q) := {q 0 | there exists some (qf r , âˆ…) âˆˆ frK (q) and
v âˆˆ Vars(qf r ) such that q 0 = (con(qf r , v))(v)}
176

4

Conjunctive Query Answering for the DL SHIQ

Going back to our running example, we have already seen that (qf r , {ux, x}) belongs to
the set frK (q) for
qf r = {r(u, ux), r(ux, x), r(x, y), t(y, y 0 ), t(y 0 , y), s(z, y), r(y, z)}.
There are also several other queries in the set frK (q), e.g., (q, {u, x, y, z}), where q is the
original query and the root splitting R is such that R = Terms(q), i.e., all terms are in the
root choice for q. In order to build the set groundK (q), we now build all possible ground
mappings Ï„ for the set Inds(A) of individual names in our ABox and the root splittings for
the queries in frK (q). The tuple (qf r , {ux, x}) âˆˆ frK (q) contributes two ground queries for
the set groundK (q):
ground(qf r , {ux, x}, {ux 7â†’ a, x 7â†’ b}) =
{r(a, b), (âˆƒInv(r).>)(a), (âˆƒr.((âˆƒ(r u Inv(s)).>) u (âˆƒ(t u Inv(t)).>)))(b)},
where âˆƒInv(r).> is the query concept for the (tree-shaped) sub-query subq(qf r , ux) and
âˆƒr.((âˆƒ(r u Inv(s)).>) u (âˆƒ(t u Inv(t)).>) is the query concept for subq(qf r , x) and
ground(qf r , {ux, x}, {ux 7â†’ b, x 7â†’ a}) =
{r(b, a), (âˆƒInv(r).>)(b), (âˆƒr.((âˆƒ(r u Inv(s)).>) u (âˆƒ(t u Inv(t)).>)))(a)}.
The tuple (q, {u, x, y, z}) âˆˆ frK (q), however, does not contribute a ground query since, for
a ground mapping, we require that Ï„ (t) = Ï„ (t0 ) iff tâ‰ˆ* t0 and there are only two individual
names in Inds(A) compared to four terms q that need a distinct value. Intuitively, this is
not a restriction, since in the first rewriting step (collapsing) we produce all those queries
in which the terms of q have been identified with each other in all possible ways. In our
example, K |= q and K |= q1 âˆ¨ Â· Â· Â· âˆ¨ q` , where q1 âˆ¨ Â· Â· Â· âˆ¨ q` are the queries from treesK (q) and
groundK (q) since each model I of K satisfies qi = ground(qf r , {ux, x}, {ux 7â†’ a, x 7â†’ b}).
5.4 Query Matches
Even if a query is true in a canonical model, it does not necessarily mean that the query
is tree- or forest-shaped. However, a match Ï€ for a canonical interpretation can guide the
process of rewriting a query. Similarly to the definition of tree- or forest-shaped queries, we
define the shape of matches for a query. In particular, we introduce three different kinds
of matches: split matches, forest matches, and tree matches such that every tree match is
a forest match, and every forest match is a split match. The correspondence to the query
shapes is as follows: given a split match Ï€, the set of all root nodes (a, Îµ) in the range
of the match define a root splitting for the query, if Ï€ is additionally a forest match, the
query is forest-shaped w.r.t. the root splitting induced by Ï€, and if Ï€ is additionally a tree
match, then the whole query can be mapped to a single tree (i.e., the query is tree-shaped
or forest-shaped w.r.t. an empty root splitting). Given an arbitrary query match into a
canonical model, we can first obtain a split match and then a tree or forest match, by using
the structure of the canonical model for guiding the application of the rewriting steps.
Definition 14. Let K be a SHIQ knowledge base, q a query, I = (âˆ†I ,Â·I ) a canonical
model of K, and Ï€ : Terms(q) â†’ âˆ†I an evaluation such that I |=Ï€ q. We call Ï€ a split match
Â¯ q, one of the following holds:
if, for all r(t, t0 ) âˆˆ
177

Glimm, Horrocks, Lutz, & Sattler

1. Ï€(t) = (a, Îµ) and Ï€(t0 ) = (b, Îµ) for some a, b âˆˆ Inds(A); or
2. Ï€(t) = (a, w) and Ï€(t0 ) = (a, w0 ) for some a âˆˆ Inds(A) and w, w0 âˆˆ INâˆ— .
We call Ï€ a forest match if, additionally, for each term tr âˆˆ Terms(q) with Ï€(tr ) = (a, Îµ)
and a âˆˆ Inds(A), there is a total and bijective mapping f from {(a, w) | (a, w) âˆˆ ran(Ï€)} to
Â¯ subq(q, tr ) implies that f (Ï€(t)) is a neighbor of f (Ï€(t0 )). We
a tree T such that r(t, t0 ) âˆˆ
call Ï€ a tree match if, additionally, there is an a âˆˆ Inds(A) such that each element in ran(Ï€)
is of the form (a, w).
A split match Ï€ for a canonical interpretation induces a (possibly empty) root splitting
R such that t âˆˆ R iff Ï€(t) = (a, Îµ) for some a âˆˆ Inds(A). We call R the root splitting induced
by Ï€.
4
For two elements (a, w) and (a, w0 ) in a canonical model, the path from (a, w) to (a, w0 )
is the sequence (a, w1 ), . . . , (a, wn ) where w = w1 , w0 = wn , and, for 1 â‰¤ i < n, wi+1 is a
successor of wi . The length of the path is n. Please note that, for a forest match, we do
not require that w is a neighbor of w0 or vice versa. This still allows to map role atoms to
paths in the canonical model of length greater than two, but such paths must be between
ancestors and not between elements in different branches of the tree. The mapping f to a
tree also makes sure that if R is the induced root splitting, then each sub-query subq(q, t)
* 0
for t âˆˆ R is tree-shaped. For a tree match, the root splitting is either empty or tâ‰ˆ
t for
0
*
each t, t âˆˆ R, i.e., there is a single root modulo â‰ˆ , and the whole query is tree-shaped.
5.5 Correctness of the Query Rewriting
The following lemmas state the correctness of the rewriting step by step for each of the
rewriting stages. Full proofs are given in the appendix. As motivated in the previous
section, we can use a given canonical model to guide the rewriting process such that we
obtain a forest-shaped query that also has a match into the model.
Lemma 15. Let I be a model for K.
1. If I |= q, then there is a collapsing qco of q such that I |=Ï€co qco for Ï€co an injection
*
modulo â‰ˆ
.
2. If I |=Ï€co qco for a collapsing qco of q, then I |= q.
Given a model I that satisfies q, we can simply add equality atoms for all pairs of terms
that are mapped to the same element in I. It is not hard to see that this results in a
mapping that is injective modulo â‰ˆ* . For the second part, it is easy to see that a model that
satisfies a collapsing also satisfies the original query.
Lemma 16. Let I be a model for K.
1. If I is canonical and I |=Ï€ q, then there is a pair (qsr , R) âˆˆ srK (q) and a split match
Ï€sr such that I |=Ï€sr qsr , R is the induced root splitting of Ï€sr , and Ï€sr is an injection
*
modulo â‰ˆ
.
2. If (qsr , R) âˆˆ srK (q) and I |=Ï€sr qsr for some match Ï€sr , then I |= q.

178

Conjunctive Query Answering for the DL SHIQ

For the first part of the lemma, we proceed exactly as illustrated in the example section
and use the canonical model I and the match Ï€ to guide the rewriting steps. We first build
a collapsing qco âˆˆ co(q) as described in the proof of Lemma 15 such that I |=Ï€co qco for Ï€co
*
an injection modulo â‰ˆ
. Since I is canonical, paths between different trees can only occur
due to non-simple roles, and thus we can replace each role atom that uses such a short-cut
with two or three role atoms such that these roots are explicitly included in the query (cf.
the query and match in Figure 4 and the obtained split rewriting and with a split match
in Figure 7). The second part of the lemma follows immediately from the fact that we use
only transitive sub-roles in the replacement.
Lemma 17. Let I be a model of K.
1. If I is canonical and I |= q, then there is a pair (q`r , R) âˆˆ lrK (q) and a mapping Ï€`r
*
such that I |=Ï€`r q`r , Ï€`r is an injection modulo â‰ˆ
, R is the root splitting induced by
Â¯ q`r , t âˆˆ R.
Ï€`r and, for each r(t, t) âˆˆ
2. If (q`r , R) âˆˆ lrK (q) and I |=Ï€`r q`r for some match Ï€`r , then I |= q.
The second part is again straightforward, given that we can only use transitive sub-roles
in the loop rewriting. For the first part, we proceed again as described in the examples
section and use the canonical model I and the match Ï€ to guide the rewriting process. We
first build a split rewriting qsr and its root splitting R as described in the proof of Lemma 16
such that (qsr , R) âˆˆ srK (q) and I |=Ï€sr qsr for a split match Ï€sr . Since I is a canonical
model, it has a forest base J . In a forest base, non-root nodes cannot be successors of
themselves, so each such loop is a short-cut due to some transitive role. An element that
is, say, r-related to itself has, therefore, a neighbor that is both an r- and Inv(r)-successor.
Depending on whether this neighbor is already in the range of the match, we can either
re-use an existing variable or introduce a new one, when making this path explicit (cf. the
loop rewriting depicted in Figure 8 obtained from the split rewriting shown in Figure 7).
Lemma 18. Let I be a model of K.
1. If I is canonical and I |= q, then there is a pair (qf r , R) âˆˆ frK (q) such that I |=Ï€f r qf r
for a forest match Ï€f r , R is the induced root splitting of Ï€f r , and Ï€f r is an injection
*
modulo â‰ˆ
.
2. If (qf r , R) âˆˆ frK (q) and I |=Ï€f r qf r for some match Ï€f r , then I |= q.
The main challenge is again the proof of (1) and we just give a short idea of it here.
At this point, we know from Lemma 17 that we can use a query q`r for which there is a
root splitting R and a split match Ï€`r . Since Ï€`r is a split match, the match for each such
sub-query is restricted to a tree and thus we can transform each sub-query of q`r induced
by a term t in the root choice separately. The following example is meant to illustrate why
the given bound of ](Vars(q)) on the number of new variables and role atoms that can be
introduced in a forest rewriting suffices. Figure 10 depicts the representation of a tree from
a canonical model, where we use only the second part of the names for the elements, e.g.,
we use just Îµ instead of (a, Îµ). For simplicity, we also do not indicate the concepts and
roles that label the nodes and edges, respectively. We use black color to indicate the nodes
179

Glimm, Horrocks, Lutz, & Sattler

and edges that are used in the match for a query and dashed lines for short-cuts due to
transitive roles. In the example, the grey edges are also those that belong to the forest base
and the query match uses only short-cuts.
Îµ

1

11

12

111

Figure 10: A part of a representation of a canonical model, where the black nodes and
edges are used in a match for a query and dashed edges indicate short-cuts due
to transitive roles.

The forest rewriting aims at making the short-cuts more explicit by replacing them with
as few edges as necessary to obtain a tree match. In order to do this, we need to include
the â€œcommon ancestorsâ€ in the forest base between each two nodes used in the match. For
w, w0 âˆˆ INâˆ— , we therefore define the longest common prefix (LCP) of w and w0 as the longest
wÌ‚ âˆˆ INâˆ— such that wÌ‚ is a prefix of both w and w0 . For a forest rewriting, we now determine
the LCPs of any two nodes in the range of the match and add a variable for those LCPs
that are not yet in the range of the match to the set V of new variables used in the forest
rewriting. In the example from Figure 10 the set V contains a single variable v1 for the
node 1.
We now explicate the short-cuts as follows: for any edge used in the match, e.g., the
edge from Îµ to 111 in the example, we define its path as the sequence of elements on the
path in the forest base, e.g., the path for the edge from Îµ to 111 is Îµ, 1, 11, 111. The relevant
path is obtained by dropping all elements from the path that are not in the range of the
mapping or correspond to a variable in the set V , resulting in a relevant path of Îµ, 1, 111
for the example. We now replace the role atom that was matched to the edge from Îµ to 111
with two role atoms such that the match uses the edge from Îµ to 1 and from 1 to 111. An
appropriate transitive sub-role exists since otherwise there could not be a short-cut. Similar
arguments can be used to replace the role atom mapped to the edge from 111 to 12 and
for the one that is mapped to the edge from Îµ to 12, resulting in a match as represented
by Figure 11. The given restriction on the cardinality of the set V is no limitation since
the number of LCPs in the set V is maximal if there is no pair of nodes such that one is
an ancestor of the other. We can see these nodes as n leaf nodes of a tree that is at least
binarily branching. Since such a tree can have at most n inner nodes, we need at most n
new variables for a query in n variables.
180

Conjunctive Query Answering for the DL SHIQ

Îµ

1

11

12

111

Figure 11: The match for a forest rewriting obtained from the example given in Figure 10.

For the bound on the number of role atoms that can be used in the replacement of a
single role atom, consider, for example, the cyclic query
q = {r(x1 , x2 ), r(x2 , x3 ), r(x3 , x4 ), t(x1 , x4 )},
for the knowledge base K = (T , R, A) with T = âˆ…, R = {r v t} with t âˆˆ TransR and
A = {(âˆƒr.(âˆƒr.(âˆƒr.>)))(a)}. It is not hard to check that K |= q. Similarly to our running
example from the previous section, there is also a single rewriting that is true in each
canonical model of the KB, which is obtained by building only a forest rewriting and doing
nothing in the other rewriting steps, except for choosing the empty set as root splitting in
the split rewriting step. In the forest rewriting, we can explicate the short-cut used in the
mapping for t(x1 , x4 ) by replacing t(x1 , x4 ) with t(x1 , x2 ), t(x2 , x3 ), t(x3 , x4 ).
By using Lemmas 15 to 18, we get the following theorem, which shows that we can use
the ground queries in groundK (q) and the queries in treesK (q) in order to check whether K
entails q, which is a well understood problem.
Theorem 19. Let K be a SHIQ knowledge base, q a Boolean conjunctive query, and
{q1 , . . . , q` } = treesK (q) âˆª groundK (q). Then K |= q iff K |= q1 âˆ¨ . . . âˆ¨ q` .
We now give upper bounds on the size and number of queries in treesK (q) and groundK (q).
As before, we use ](S) to denote the cardinality of a set S. The size |K| (|q|) of a knowledge
base K (a query q) is simply the number of symbols needed to write it over the alphabet
of constructors, concept names, and role names that occur in K (q), where numbers are
encoded in binary. Obviously, the number of atoms in a query is bounded by its size, hence
](q) â‰¤ |q| and, for simplicity, we use n as the size and the cardinality of q in what follows.
Lemma 20. Let q be a Boolean conjunctive query, K = (T , R, A) a SHIQ knowledge base,
|q| := n and |K| := m. Then there is a polynomial p such that
1. ](co(q)) â‰¤ 2p(n) and, for each q 0 âˆˆ co(q), |q 0 | â‰¤ p(n),
2. ](srK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ srK (q), |q 0 | â‰¤ p(n),
3. ](lrK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ lrK (q), |q 0 | â‰¤ p(n),
181

Glimm, Horrocks, Lutz, & Sattler

4. ](frK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ frK (q), |q 0 | â‰¤ p(n),
5. ](treesK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ treesK (q), |q 0 | â‰¤ p(n), and
6. ](groundK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ groundK (q), |q 0 | â‰¤ p(n).
As a consequence of the above lemma, there is a bound on the number of queries in
groundK (q) and treesK (q) and it is not hard to see that the two sets can be computed in
time polynomial in m and exponential in n.
In the next section, we present an algorithm that decides entailment of unions of conjunctive queries, where each of the queries is either a ground query or consists of a single
concept atom C(x) for an existentially quantified variable x. By Theorem 19 and Lemma 20,
such an algorithm is a decision procedure for arbitrary unions of conjunctive queries.
5.6 Summary and Discussion
In this section, we have presented the main technical foundations for answering (unions
of) conjunctive queries. It is known that queries that contain non-simple roles in cycles
among existentially quantified variables are difficult to handle. By applying the rewriting
steps from Definition 10, we can rewrite such cyclic conjunctive queries into a set of acyclic
and/or ground queries. Both types of queries are easier to handle and algorithms for both
types exist. At this point, any reasoning algorithm for SHIQu knowledge base consistency
can be used for deciding query entailment. In order to obtain tight complexity results, we
present in the following section a decision procedure that is based on an extension of the
translation to looping tree automata given by Tobies (2001).
It is worth mentioning that, for queries with only simple roles, our algorithm behaves
exactly as the existing rewriting algorithms (i.e., the rolling-up and tuple graph technique)
since, in this case, only the collapsing step is applicable. The need for identifying variables
was first pointed out in the work of Horrocks et al. (1999) and is also required (although
not mentioned) for the algorithm proposed by Calvanese et al. (1998a).
The new rewriting steps (split, loop, and forest rewriting) are only required for and
applicable to non-simple roles and, when replacing a role atom, only transitive sub-roles of
the replaced role can be used. Hence the number of resulting queries is in fact not determined
by the size of the whole knowledge base, but by the number of transitive sub-roles for the
non-simple roles in the query. Therefore, the number of resulting queries really depends on
the number of transitive roles and the depth of the role hierarchy for the non-simple roles
in the query, which can, usually, expected to be small.

6. The Decision Procedure
We now devise a decision procedure for entailment of unions of Boolean conjunctive queries
that uses, for each disjunct, the queries obtained in the rewriting process as defined in the
previous section. Detailed proofs for the lemmas and theorems in this section can again be
found in the appendix. For a knowledge base K and a union of Boolean conjunctive queries
q1 âˆ¨ . . . âˆ¨ q` , we show how we can use the queries in treesK (qi ) and groundK (qi ) for 1 â‰¤ i â‰¤ `
in order to build a set of knowledge bases K1 , . . . , Kn such that K |= q1 âˆ¨ . . . âˆ¨ q` iff all the
Ki are inconsistent. This gives rise to two decision procedures: a deterministic one in which
182

Conjunctive Query Answering for the DL SHIQ

we enumerate all Ki , and which we use to derive a tight upper bound for the combined
complexity; and a non-deterministic one in which we guess a Ki , and which yields a tight
upper bound for the data complexity. Recall that, for combined complexity, the knowledge
base K and the queries qi both count as input, whereas for the data complexity only the
ABox A counts as an input, and all other parts are assumed to be fixed.
6.1 A Deterministic Decision Procedure for Query Entailment in SHIQ
We first define the deterministic version of the decision procedure and give an upper bound
for its combined complexity. The given algorithm takes as input a union of connected
conjunctive queries and works under the unique name assumption (UNA). We show afterwards how it can be extended to an algorithm that does not make the UNA and that takes
arbitrary UCQs as input, and that the complexity results carry over.
We construct a set of knowledge bases that extend the original knowledge base K both
w.r.t. the TBox and ABox. The extended knowledge bases are such that a given KB K
entails a query q iff all the extended KBs are inconsistent. We handle the concepts obtained
from the tree-shaped queries differently to the ground queries: the axioms we add to the
TBox prevent matches for the tree-shaped queries, whereas the extended ABoxes contain
assertions that prevent matches for the ground queries.
Definition 21. Let K = (T , R, A) be a SHIQ knowledge base and q = q1 âˆ¨ . . . âˆ¨ q` a union
of Boolean conjunctive queries. We set
1. T := treesK (q1 ) âˆª . . . âˆª treesK (q` ),
2. G := groundK (q1 ) âˆª . . . âˆª groundK (q` ), and
3. Tq := {> v Â¬C | C(v) âˆˆ T }.
An extended knowledge base Kq w.r.t. K and q is a tuple (T âˆª Tq , R, A âˆª Aq ) such that Aq
contains, for each q 0 âˆˆ G, at least one assertion Â¬at with at âˆˆ q 0 .
4
Informally, the extended TBox T âˆª Tq ensures that there are no tree matches. Each
extended ABox A âˆª Aq contains, for each ground query q 0 obtained in the rewriting process,
at least one assertion Â¬at with at âˆˆ q 0 that â€œspoilsâ€ a match for q 0 . A model for such an
extended ABox can, therefore, not satisfy any of the ground queries. If there is a model for
any of the extended knowledge bases, we know that this is a counter-model for the original
query.
We can now use the extended knowledge bases in order to define the deterministic
version of our algorithm for deciding entailment of unions of Boolean conjunctive queries in
SHIQ.
Definition 22. Given a SHIQ knowledge base K = (T , R, A) and a union of connected
Boolean conjunctive queries q as input, the algorithm answers â€œK entails qâ€ if each extended
knowledge base w.r.t. K and q is inconsistent and it answers â€œK does not entail qâ€ otherwise.
4
The following lemma shows that the above described algorithm is indeed correct.
183

Glimm, Horrocks, Lutz, & Sattler

Lemma 23. Let K be a SHIQ knowledge base and q a union of connected Boolean conjunctive queries. Given K and q as input, the algorithm from Definition 22 answers â€œK
entails qâ€ iff K |= q under the unique name assumption.
In the proof of the if direction for the above lemma, we can use a canonical model I
of K in order to guide the rewriting process. For the only if direction, we assume to the
contrary of what is to be shown that there is no consistent extended knowledge base, but
K 6|= q. We then use a model I of K such that I 6|= q, which exists by assumption, and
show that I is also a model of some extended knowledge base.
6.1.1 Combined Complexity of Query Entailment in SHIQ
According to the above lemma, the algorithm given in Definition 22 is correct. We now
analyse its combined complexity and thereby prove that it is also terminating.
For the complexity analysis, we assume, as usual (Hustadt et al., 2005; Calvanese,
De Giacomo, Lembo, Lenzerini, & Rosati, 2006; Ortiz et al., 2006b), that all concepts in
concept atoms and ABox assertions are literals, i.e., concept names or negated concept
names. If the input query or ABox contains non-literal atoms or assertions, we can easily
transform these into literal ones in a truth preserving way: for each concept atom C(t) in
the query where C is a non-literal concept, we introduce a new atomic concept AC âˆˆ NC ,
add the axiom C v AC to the TBox, and replace C(t) with AC (t); for each non-literal
concept assertion C(a) in the ABox, we introduce a new atomic concept AC âˆˆ NC , add
an axiom AC v C to the TBox, and replace C(a) with AC (a). Such a transformation is
obviously polynomial, so without loss of generality, it is safe to assume that the ABox and
query contain only literal concepts. This has the advantage that the size of each atom and
ABox assertion is constant.
Since our algorithm involves checking the consistency of a SHIQu knowledge base,
we analyse the complexity of this reasoning service. Tobies (2001) shows an ExpTime
upper bound for deciding the consistency of SHIQ knowledge bases (even with binary
coding of numbers) by translating a SHIQ KB to an equisatisfiable ALCQIb knowledge
base. The b stands for safe Boolean role expressions built from ALCQIb roles using the
operator u (role intersection), t (role union), and Â¬ (role negation/complement) such that,
when transformed into disjunctive normal form, every disjunct contains at least one nonnegated conjunct. Given a query q and a SHIQ knowledge base K = (T , R, A), we reduce
query entailment to deciding knowledge base consistency of an extended SHIQu knowledge
base Kq = (T âˆª Tq , R, A âˆª Aq ). Recall that Tq and Aq are the only parts that contain
role conjunctions and that we use role negation only in ABox assertions. We extend the
translation given for SHIQ so that it can be used for deciding the consistency of SHIQu
KBs. Although the translation works for all SHIQu KBs, we assume the input KB to be
of exactly the form of extended knowledge bases as described above. This is so because the
translation for unrestricted SHIQu is no longer polynomial, as in the case of SHIQ, but
exponential in the size of the longest role conjunction under a universal quantifier. Since
role conjunctions occur only in the extended ABox and TBox, and since the size of each role
conjunction is, by Lemma 20, polynomial in the size of q, the translation is only exponential
in the size of the query in the case of extended knowledge bases.
184

Conjunctive Query Answering for the DL SHIQ

We assume here, as usual, that all concepts are in negation normal form (NNF); any
concept can be transformed in linear time into an equivalent one in NNF by pushing negation
inwards, making use of de Morganâ€™s laws and the duality between existential and universal
restrictions, and between atmost and atleast number restrictions (6 n r.C and > n r.C
respectively) (Horrocks et al., 2000). For a concept C, we use Â¬C
Ë™ to denote the NNF of
Â¬C.
We define the closure cl(C, R) of a concept C w.r.t. a role hierarchy R as the smallest
set satisfying the following conditions:
â€¢ if D is a sub-concept of C, then D âˆˆ cl(C, R),
â€¢ if D âˆˆ cl(C, R), then Â¬D
Ë™ âˆˆ cl(C, R),
â€¢ if âˆ€r.D âˆˆ cl(C, R), s v* R r, and s âˆˆ TransR , then âˆ€s.D âˆˆ cl(C, R).
We now show how we can extend the translation from SHIQ to ALCQIb given by
Tobies. We first consider SHIQu -concepts and then extend the translation to KBs.
Definition 24. For a role hierarchy R and roles r, r1 , . . . , rn , let
l
â†‘(r, R) =
s and
â†‘(r1 u . . . u rn , R) =â†‘(r1 , R) u . . . u â†‘(rn , R).
r v* R s

4

Please note that, since r v* R r, r occurs in â†‘(r, R).
Lemma 25. Let R be a role hierarchy, and r1 , . . . , rn roles. For every interpretation I
such that I |= R, it holds that (â†‘(r1 u . . . u rn , R))I = (r1 u . . . u rn )I .
With the extended definition of â†‘ on role conjunctions, we can now adapt the definition
(Def. 6.22) that Tobies provides for translating SHIQ-concepts into ALCQIb-concepts.
Definition 26. Let C be a SHIQu -concept in NNF and R a role hierarchy. For every
concept âˆ€(r1 u . . . u rn ).D âˆˆ cl(C, R), let Xr1 u...urn ,D âˆˆ NC be a unique concept name that
does not occur in cl(C, R). Given a role hierarchy R, we define the function tr inductively
on the structure of concepts by setting
tr(A, R)
tr(Â¬A, R)
tr(C1 u C2 , R)
tr(C1 t C2 , R)
tr(./ n(r1 u . . . u rn ).D, R)
tr(âˆ€(r1 u . . . u rn ).D, R)
tr(âˆƒ(r1 u . . . u rn ).D, R)

=
=
=
=
=
=
=

A for all A âˆˆ NC
Â¬A for all A âˆˆ NC
tr(C1 , R) u tr(C2 , R)
tr(C1 , R) t tr(C2 , R)
(./ n â†‘(r1 u . . . u rn , R).tr(D, R))
Xr1 u...urn ,D
Â¬(Xr1 u...urn ,Â¬D
Ë™ )

where ./ stands for 6 or >. Set tc((r1 u . . . u rn ), R) := {(t1 u . . . u tn ) | ti v* R ri and ti âˆˆ
TransR for each i such that 1 â‰¤ i â‰¤ n} and define an extended TBox TC,R as
TC,R ={Xr1 u...urn ,D â‰¡ âˆ€ â†‘(r1 u . . . u rn , R).tr(D, R)| âˆ€(r1 u . . . u rn ).D âˆˆ cl(C, R)} âˆª
4
{Xr1 u...urn ,D v âˆ€ â†‘(T, R).XT,D
| T âˆˆ tc(r1 u . . . u rn , R)}
Lemma 27. Let C be a SHIQu -concept in NNF, R a role hierarchy, and tr and TC,R
as defined in Definition 26. The concept C is satisfiable w.r.t. R iff the ALCQIb-concept
tr(C, R) is satisfiable w.r.t. TC,R .

185

Glimm, Horrocks, Lutz, & Sattler

Given Lemma 25, the proof of Lemma 27 is a long, but straightforward extension of the
proof given by Tobies (2001, Lemma 6.23).
We now analyse the complexity of the above described problem. Let m := |R| and
r1 u . . . u rn the longest role conjunction occurring in C, i.e., the maximal number of roles
that occur in a role conjunction in C is n. The TBox TC,R can contain exponentially
many axioms in n since the cardinality of the set tc((r1 u . . . u rn ), R) for the longest role
conjunction can only be bounded by mn because each ri can have more than one transitive
sub-role. It is not hard to check that the size of each axiom is polynomial in |C|. Since
deciding whether an ALCQIb concept C is satisfiable w.r.t. an ALCQIb TBox T is an
ExpTime-complete problem (even with binary coding of numbers) (Tobies, 2001, Thm.
p(n)
4.42), the satisfiability of a SHIQu -concept C can be checked in time 2p(m)2 .
We now extend the translation from concepts to knowledge bases. Tobies assumes that
all role assertions in the ABox are of the form r(a, b) with r a role name or the inverse of a
role name. Extended ABoxes contain, however, also negated roles in role assertions, which
require a different translation. A positive role assertion such as r(a, b) is translated in the
standard way by closing the role upwards. The only difference of using â†‘ directly is that we
additionally split the conjunction (â†‘(r, R))(a, b) = (r1 u . . . u rn )(a, b) into n different role
assertions r1 (a, b), . . . , rn (a, b), which is clearly justified by the semantics. For negated roles
in a role assertion such as Â¬r(a, b), we close the role downwards instead of upwards and add
a role atom Â¬s(a, b) for each sub-role s of r. This is again justified by the semantics. Let
K = (T âˆª Tq , R, A âˆª Aq ) be an extended knowledge base. More precisely, we set
tr(T âˆª Tq , R) := {tr(C, R) v tr(D, R) | C v D âˆˆ T âˆª Tq },
tr(A âˆª Aq , R) := {(tr(C, R))(a) | C(a) âˆˆ A âˆª Aq } âˆª
{s(a, b) | r(a, b) âˆˆ A âˆª Aq and r v* R s} âˆª
{Â¬s(a, b) | Â¬r(a, b) âˆˆ A âˆª Aq and s v
* R r},
and we use tr(K, R) to denote the ALCQIb knowledge base (tr(T âˆª Tq , R), tr(A âˆª Aq , R)).
For the complexity of deciding the consistency of a translated SHIQu knowledge base,
we can apply the same arguments as above for concept satisfiability, which gives the following result:
Lemma 28. Given a SHIQu knowledge base K = (T , R, A) where m := |K| and the size
of the longest role conjunction is n, we can decide consistency of K in deterministic time
p(n)
2p(m)2
with p a polynomial.
We are now ready to show that the algorithm given in Definition 22 runs in deterministic
time single exponential in the size of the input KB and double exponential in the size of
the input query.
Lemma 29. Let K = (T , R, A) be a SHIQ knowledge base with m = |K| and q a union
of connected Boolean conjunctive queries with n = |q|. Given K and q as input, the algorithm given in Definition 22 decides whether K |= q under the unique name assumption in
p(n)
deterministic time in 2p(m)2 .

186

Conjunctive Query Answering for the DL SHIQ

In the proof of the above lemma, we show that there is some polynomial p such that we
p(n)
extended knowledge bases for consistency and that each
have to check at most 2p(m)2
consistency check can be done in this time bound as well.
More precisely, let q = q1 âˆ¨. . .âˆ¨q` , T = treesK (q1 )âˆª. . .âˆªtreesK (q` ), and G = groundK (q1 )âˆª
. . . âˆª groundK (q` ). Together with Lemma 20, we get that ](T ) and ](G) are bounded by
2p(n)Â·log p(m) for some polynomial p and that the size of each query in G and T is polynomial
in n. Each of the 2p(n)Â·log p(m) ground queries in G contributes at most p(n) negated assertion
p(n)
to an extended ABox Aq . Hence, there are at most 2p(m)2
extended ABoxes Aq and,
p(n)
p(m)2
extended knowledge bases that have to be tested for consistency.
therefore, 2
Given the bounds on the cardinalities of T and G and the fact that the size of each
query in T and G is polynomial in n, it is not hard to check that the size of each extended
knowledge base Kq = (T âˆª Tq , R, A âˆª Aq ) is bounded by 2p(n)Â·log p(m) and that each Kq
can be computed in this time bound as well. Since only the extended parts contain role
conjunctions and the number of roles in a role conjunction is polynomial in n, there is a
polynomial p such that
1. |tr(T , R)| â‰¤ p(m),
2. |tr(Tq , R)| â‰¤ 2p(n)Â·log p(m) ,
3. |tr(A, R)| â‰¤ p(m),
4. |tr(Aq , R)| â‰¤ 2p(n)Â·log p(m) , and, hence,
5. |tr(Kq , R)| â‰¤ 2p(n)Â·log p(m) .
p(n)

for some polynomial
By Lemma 28, each consistency check can be done in time 2p(m)2
p(n)
p(m)2
p. Since we have to check at most 2
extended knowledge bases for consistency, and
p(n)
each check can be done in time 2p(m)2 , we obtain the desired upper bound.
We now show that this result carries over even when we do not restrict interpretations
to the unique name assumption.
Definition 30. Let K = (T , R, A) be a SHIQ knowledge base and q a SHIQ union
of Boolean conjunctive queries. For a partition P of Inds(A), a knowledge base KP =
(T , R, AP ) and a query q P are called an A-partition w.r.t. K and q if AP and q P are
obtained from A and q as follows:
For each P âˆˆ P
1. Choose one individual name a âˆˆ P .
2. For each b âˆˆ P , replace each occurrence of b in A and q with a.
4
Please note that w.l.o.g. we assume that all constants that occur in the query occur
in the ABox as well and that thus a partition of the individual names in the ABox also
partitions the query.
Lemma 31. Let K = (T , R, A) be a SHIQ knowledge base and q a union of Boolean
conjunctive queries. K 6|= q without making the unique name assumption iff there is an
A-partition KP = (T , R, AP ) and q P w.r.t. K and q such that KP 6|= q P under the unique
name assumption.
187

Glimm, Horrocks, Lutz, & Sattler

Let K = (T , R, A) be a knowledge base in a Description Logic DL, C be the complexity
class such that deciding whether K |= q under the unique name assumption is in C, and let
n = 2|A| . Since the number of partitions for an ABox is at most exponential in the number
of individual names that occur in the ABox, the following is a straightforward consequence
of the above lemma: for a Boolean conjunctive DL query q, deciding whether K |= q without
making the unique name assumption can be reduced to deciding n times a problem in C.
In order to extend our algorithm to unions of possibly unconnected Boolean conjunctive
queries, we first transform the input query q into conjunctive normal form (CNF). We
then check entailment for each conjunct qi , which is now a union of connected Boolean
conjunctive queries. The algorithm returns â€œK entails qâ€ if each entailment check succeeds
and it answers â€œK does not entail qâ€ otherwise. By Lemma 5 and Lemma 23, the algorithm
is correct.
Let K be a knowledge base in a Description Logic DL, q a union of connected Boolean
conjunctive DL queries, and C the complexity class such that deciding whether K |= q is in
C. Let q 0 be a union of possibly unconnected Boolean conjunctive queries and cnf(q 0 ) the
CNF of q 0 . Since the number of conjuncts in cnf(q 0 ) is at most exponential in |q 0 |, deciding
0
whether K |= q 0 can be reduced to deciding n times a problem in C, with n = 2p(|q |) and p
a polynomial.
The above observation together with the results from Lemma 29 gives the following
general result:
Theorem 32. Let K = (T , R, A) be a SHIQ knowledge base with m = |K| and q a union
of Boolean conjunctive queries with n = |q|. Deciding whether K |= q can be done in
p(n)
deterministic time in 2p(m)2 .
A corresponding lower bound follows from the work by Lutz (2007). Hence the above
result is tight. The result improves the known co-3NExpTime upper bound for the setting
where the roles in the query are restricted to simple ones (Ortiz, Calvanese, & Eiter, 2006a).
Corollary 33. Let K be a SHIQ knowledge base with m = |K| and q a union of Boolean
conjunctive queries with n = |q|. Deciding whether K |= q is a 2 ExpTime-complete problem.
Regarding query answering, we refer back to the end of Section 2.2, where we explain
that deciding which tuples belong to the set of answers can be checked with at most mkA
entailment tests, where k is the number of answer variables in the query and mA is the
number of individual names in Inds(A). Hence, at least theoretically, this is absorbed by
the combined complexity of query entailment in SHIQ.
6.2 A Non-Deterministic Decision Procedure for Query Entailment in SHIQ
In order to study the data complexity of query entailment, we devise a non-deterministic
decision procedure which provides a tight bound for the complexity of the problem. Actually,
the devised algorithm decides non-entailment of queries: we guess an extended knowledge
base Kq , check whether it is consistent, and return â€œK does not entail qâ€ if the check succeeds
and â€œK entails qâ€ otherwise.
Definition 34. Let T be a SHIQ TBox, R a SHIQ role hierarchy, and q a union of
Boolean conjunctive queries. Given a SHIQ ABox A as input, the algorithm guesses an
188

Conjunctive Query Answering for the DL SHIQ

A-partition KP = (T , R, AP ) and q P w.r.t. K = (T , R, A) and q. The query q P is then
transformed into CNF and one of the resulting conjuncts, say qiP , is chosen. The algorithm
P
P
then guesses an extended knowledge base KqPi = (T âˆª Tqi , R, AP âˆª AP
qi ) w.r.t. K and qi
P
and returns â€œK does not entail qâ€ if Kqi is consistent and it returns â€œK entails qâ€ otherwise.
4
Compared to the deterministic version of the algorithm given in Definition 22, we do not
make the UNA but guess a partition of the individual names. We also non-deterministically
choose one of the conjuncts that result from the transformation into CNF. For this conjunct,
we guess an extended ABox and check whether the extended knowledge base for the guessed
ABox is consistent and, therefore, a counter-model for the query entailment.
In its (equivalent) negated form, Lemma 23 says that K 6|= q iff there is an extended
knowledge base Kq w.r.t. K and q such that Kq is consistent. Together with Lemma 31 it
follows, therefore, that the algorithm from Definition 34 is correct.
6.2.1 Data Complexity of Query Entailment in SHIQ
We now analyze the data complexity of the algorithm given in Definition 34 and show that
deciding UCQ entailment in SHIQ is indeed in co-NP for data complexity.
Theorem 35. Let T be a SHIQ TBox, R a SHIQ role hierarchy, and q a union of
Boolean conjunctive queries. Given a SHIQ ABox A with ma = |A|, the algorithm from
Definition 34 decides in non-deterministic polynomial time in ma whether K 6|= q for K =
(T , R, A).
Clearly, the size of an ABox AP in an A-partition is bounded by ma . Since the query
is no longer an input, its size is constant and the transformation to CNF can be done in
constant time. We then non-deterministically choose one of the resulting conjuncts. Let
this conjunct be qi = q(i,1) âˆ¨ . . . âˆ¨ q(i,`) . As established in Lemma 32, the maximal size of an
P
P
extended ABox AP
qi is polynomial in ma . Hence, |A âˆª Aqi | â‰¤ p(ma ) for some polynomial
p. Due to Lemma 20 and since the size of q, T , and R is fixed by assumption, the sets
treesKP (q(i,j) ) and groundKP (q(i,j) ) for each j such that 1 â‰¤ j â‰¤ ` can be computed in time
polynomial in ma . From Lemma 29, we know that the translation of an extended knowledge
base into an ALCQIb knowledge base is polynomial in ma and a close inspection of the
algorithm by Tobies (2001) for deciding consistency of an ALCQIb knowledge base shows
that its runtime is also polynomial in ma .
The bound given in Theorem 35 is tight since the data complexity of conjunctive query
entailment is already co-NP-hard for the ALE fragment of SHIQ (Schaerf, 1993).
Corollary 36. Conjunctive query entailment in SHIQ is data complete for co-NP.
Due to the correspondence between query containment and query answering (Calvanese
et al., 1998a), the algorithm can also be used to decide containment of two unions of
conjunctive queries over a SHIQ knowledge base, which gives the following result:
Corollary 37. Given a SHIQ knowledge base K and two unions of conjunctive queries q
and q 0 , the problem whether K |= q âŠ† q 0 is decidable.

189

Glimm, Horrocks, Lutz, & Sattler

By using the result of Rosati (2006a, Thm. 11), we further show that the consistency of
a SHIQ knowledge base extended with (weakly-safe) Datalog rules is decidable.
Corollary 38. The consistency of SHIQ+log-KBs (both under FOL semantics and under
NM semantics) is decidable.

7. Conclusions
With the decision procedure presented for entailment of unions of conjunctive queries in
SHIQ, we close a long standing open problem. The solution has immediate consequences
on related areas, as it shows that several other open problems such as query answering,
query containment and the extension of a knowledge base with weakly safe Datalog rules
for SHIQ are decidable as well. Regarding combined complexity, we present a deterministic
algorithm that needs time single exponential in the size of the KB and double exponential
in the size of the query, which gives a tight upper bound for the problem. This result
shows that deciding conjunctive query entailment is strictly harder than instance checking
for SHIQ. We further prove co-NP-completeness for data complexity. Interestingly, this
shows that regarding data complexity deciding UCQ entailment is (at least theoretically)
not harder than instance checking for SHIQ, which was also a previously open question.
It will be part of our future work to extend this procedure to SHOIQ, which is the
DL underlying OWL DL. We will also attempt to find more implementable algorithms for
query answering in SHIQ. Carrying out the query rewriting steps in a more goal directed
way will be crucial to achieving this.

Acknowledgments
This work was supported by the EU funded IST-2005-7603 FET Project Thinking Ontologies (TONES). Birte Glimm was supported by an EPSRC studentship.

190

Conjunctive Query Answering for the DL SHIQ

Appendix A. Complete Proofs
Lemma (7). Let K be a SHIQ knowledge base and q = q1 âˆ¨ . . . âˆ¨ qn a union of conjunctive
queries, then K 6|= q iff there exists a canonical model I of K such that I 6|= q.

Proof of Lemma 7. The â€œifâ€ direction is trivial.
For the â€œonly ifâ€ direction, since an inconsistent knowledge base entails every query, we
0
0
can assume that K is consistent. Hence, there is an interpretation I 0 = (âˆ†I , Â·I ) such that
I 0 |= K and I 0 6|= q. From I 0 , we construct a canonical model I for K and its forest base J
0
as follows: we define the set P âŠ† (âˆ†I )âˆ— of paths to be the smallest set such that
0

â€¢ for all a âˆˆ Inds(A), aI is a path;
â€¢ d1 Â· Â· Â· dn Â· d is a path, if
â€“ d1 Â· Â· Â· dn is a path,
0

â€“ (dn , d) âˆˆ rI for some role r,
0

â€“ if there is an a âˆˆ Inds(A) such that d = aI , then n > 2.
For a path p = d1 Â· Â· Â· dn , the length len(p) of p is n. Now fix a set S âŠ† Inds(A) Ã— INâˆ— and a
bijection f : S â†’ P such that
(i) Inds(A) Ã— {Îµ} âŠ† S,
(ii) for each a âˆˆ Inds(A), {w | (a, w) âˆˆ S} is a tree,
0

(iii) f ((a, Îµ)) = aI ,
(iv) if (a, w), (a, w0 ) âˆˆ S with w0 a successor of w, then f ((a, w0 )) = f ((a, w)) Â· d for some
0
d âˆˆ âˆ†I .
For all (a, w) âˆˆ S, set Tail((a, w)) := dn if f ((a, w)) = d1 Â· Â· Â· dn . Now, define a forest base
J = (âˆ†J ,Â·J ) for K as follows:
(a) âˆ†J := S;
(b) for each a âˆˆ Inds(A), aJ := (a, Îµ) âˆˆ S;
(c) for each b âˆˆ NI \ Inds(A), bJ = aJ for some fixed a âˆˆ Inds(A);
0

(d) for each C âˆˆ NC , (a, w) âˆˆ C J if (a, w) âˆˆ S and Tail((a, w)) âˆˆ C I ;
(e) For all roles r, ((a, w), (b, w0 )) âˆˆ rJ if either
0

0

0

(I) w = w0 = Îµ and (aI , bI ) âˆˆ rI or
0

(II) a = b, w0 is a neighbor of w and (Tail((a, w)), Tail((b, w0 ))) âˆˆ rI .
191

Glimm, Horrocks, Lutz, & Sattler

It is clear that J is a forest base for K due to the definition of S and the construction
of J from S.
Let I = (âˆ†I ,Â·I ) be an interpretation that is identical to J except that, for all non-simple
roles r, we set
[
(sJ )+
rI = rJ âˆª
s v* R r, sâˆˆTransR

It is tedious but not too hard to verify that I |= K and that J is a forest base for I. Hence
I is a canonical model for K.
Therefore, we only have to show that I 6|= q. Assume to the contrary that I |= q.
Then there is some Ï€ and i with 1 â‰¤ i â‰¤ n such that I |=Ï€ qi . We now define a mapping
0
Ï€ 0 : Terms(qi ) â†’ âˆ†I by setting Ï€ 0 (t) := Tail(Ï€(t)) for all t âˆˆ Terms(qi ). It is not difficult to
0
0
check that I 0 |=Ï€ qi and hence I 0 |=Ï€ q, which is a contradiction.
Lemma (15). Let I be a model for K.
1. If I |= q, then there is a collapsing qco of q such that I |=Ï€co qco for Ï€co an injection
*
modulo â‰ˆ
.
2. If I |=Ï€co qco for a collapsing qco of q, then I |= q.
Proof of Lemma 15. For (1), let Ï€ be such that I |=Ï€ q, let qco be the collapsing of q that
is obtained by adding an atom t â‰ˆ t0 for all terms t, t0 âˆˆ Terms(q) for which Ï€(t) = Ï€(t0 ).
*
By definition of the semantics, I |=Ï€ qco and Ï€ is an injection modulo â‰ˆ
.
Ï€
Condition (2) trivially holds since q âŠ† qco and hence I |= co q.
Lemma (16). Let I be a model for K.
1. If I is canonical and I |=Ï€ q, then there is a pair (qsr , R) âˆˆ srK (q) and a split match
Ï€sr such that I |=Ï€sr qsr , R is the induced root splitting of Ï€sr , and Ï€sr is an injection
*
modulo â‰ˆ
.
2. If (qsr , R) âˆˆ srK (q) and I |=Ï€sr qsr for some match Ï€sr , then I |= q.

Proof of Lemma 16. The proof of the second claim is relatively straightforward: since
(qsr , R) âˆˆ srK (q), there is a collapsing qco of q such that qsr is a split rewriting of qco .
Since all roles replaced in a split rewriting are non-simple and I |= qsr by assumption, we
have that I |= qco . By Lemma 15 (2), we then have that I |= q as required.
We go through the proof of the first claim in more detail: let qco be in co(q) such
that I |=Ï€co qco for a match Ï€co that is injective modulo â‰ˆ* . Such a collapsing qco and
match Ï€co exist due to Lemma 15. If Ï€co is a split match w.r.t. q and I already, we are
done, since a split match induces a root splitting R and (qco , R) is trivially in srK (q). If
Â¯ qco such that
Ï€co is not a split match, there are at least two terms t, t0 with r(t, t0 ) âˆˆ
Ï€co (t) = (a, w), Ï€co (t0 ) = (a0 , w0 ), a 6= a0 , and w 6= Îµ or w0 6= Îµ. We distinguish two cases:
192

Conjunctive Query Answering for the DL SHIQ

1. Both t and t0 are not mapped to roots, i.e., w 6= Îµ and w0 6= Îµ. Since I |=Ï€co r(t, t0 ),
we have that (Ï€co (t), Ï€co (t0 )) âˆˆ rI . Since I is a canonical model for K, there must be
a role s with s v* R r and s âˆˆ TransR such that
{(Ï€co (t), (a, Îµ)), ((a, Îµ), (a0 , Îµ)), ((a0 , Îµ), Ï€co (t0 ))} âŠ† sI .
If there is some tÌ‚ âˆˆ Terms(qco ) such that Ï€co (tÌ‚) = (a, Îµ), then let u = tÌ‚, otherwise let u
be a fresh variable. Similarly, if there is some tË†0 âˆˆ Terms(qco ) such that Ï€co (tË†0 ) = (a0 , Îµ),
then let u0 = tË†0 , otherwise let u0 be a fresh variable. Hence, we can define a split
rewriting qsr of qco by replacing r(t, t0 ) with s(t, u), s(u, u0 ), and s(u0 , t0 ). We then
define a new mapping Ï€sr that agrees with Ï€co on all terms that occur in qco and that
maps u to (a, Îµ) and u0 to (a0 , Îµ).
2. Either t or t0 is mapped to a root. W.l.o.g., let this be t, i.e., Ï€(t) = (a, Îµ). We can use
the same arguments as above: since I |=Ï€co r(t, t0 ), we have that (Ï€(t), Ï€(t0 )) âˆˆ rI and,
since I is a canonical model for K, there must be a role s with s v* R r and s âˆˆ TransR
such that {(Ï€(t), (a0 , Îµ)), ((a0 , Îµ), Ï€(t0 ))} âŠ† sI . If there is some tÌ‚ âˆˆ Terms(qco ) such
that Ï€co (tÌ‚) = (a0 , Îµ), then let u = tÌ‚, otherwise let u be a fresh variable. We then define
a split rewriting qsr of qco by replacing r(t, t0 ) with s(t, u), s(u, t0 )and a mapping Ï€sr
that agrees with Ï€co on all terms that occur in qco and that maps u to (a0 , Îµ).
It immediately follows that I |=Ï€sr qsr . We can proceed as described above for each role
atom r(t, t0 ) for which Ï€(t) = (a, w) and Ï€(t0 ) = (a0 , w0 ) with a 6= a0 and w 6= Îµ or w0 6=
Îµ. This will result in a split rewriting qsr and a split match Ï€sr such that I |=Ï€sr qsr .
Furthermore, Ï€sr is injective modulo â‰ˆ* since we only introduce new variables, when the
variable is mapped to an element that is not yet in the range of the match. Since Ï€sr is a
split match, it induces a root splitting R and, hence, (qsr , R) âˆˆ srK (q) as required.
Lemma (17). Let I be a model of K.
1. If I is canonical and I |= q, then there is a pair (q`r , R) âˆˆ lrK (q) and a mapping Ï€`r
*
such that I |=Ï€`r q`r , Ï€`r is an injection modulo â‰ˆ
, R is the root splitting induced by
Â¯
Ï€`r and, for each r(t, t) âˆˆ q`r , t âˆˆ R.
2. If (q`r , R) âˆˆ lrK (q) and I |=Ï€`r q`r for some match Ï€`r , then I |= q.
Proof of Lemma 17. The proof of (2) is analogous to the one given in Lemma 16 since, by
definition of loop rewritings, all roles replaced in a loop rewriting are again non-simple.
For (1), let (qsr , R) âˆˆ srK (q) be such that I |=Ï€sr qsr , Ï€sr is a split match, and R is
the root splitting induced by Ï€sr . Such a split rewriting qsr and match Ï€sr exist due to
Lemma 16 and the canonicity of I.
Â¯ qsr for t âˆˆ
Let r(t, t) âˆˆ
/ R. Since R is the root splitting induced by Ï€sr and since
tâˆˆ
/ R, Ï€sr (t) = (a, w) for some a âˆˆ Inds(A) and w 6= Îµ. Now, let J be a forest base for
I. We show that there exists a neighbor d of Ï€sr (t) and a role s âˆˆ TransR such that s v
* Rr
and (Ï€sr (t), d) âˆˆ sI âˆ© Inv(s)I . Since I |=Ï€sr qsr , we have (Ï€sr (t), Ï€sr (t)) âˆˆ rI . Since J
is a forest base and since w 6= Îµ, we have (Ï€sr (t), Ï€sr (t)) âˆˆ
/ rJ . It follows that there is a
I
sequence d1 , . . . , dn âˆˆ âˆ† and a role s âˆˆ TransR such that s v
* R r, d1 = Ï€sr (t) = dn , and
193

Glimm, Horrocks, Lutz, & Sattler

(di , di+1 ) âˆˆ sJ for 1 â‰¤ i < n and di 6= d1 for each i with 1 < i < n. Then it is not hard
to see that, because {w0 | (a, w0 ) âˆˆ âˆ†I } is a tree and w 6= Îµ, we have d2 = dnâˆ’1 . Since
(d1 , d2 ) âˆˆ sJ and (dnâˆ’1 , dn ) âˆˆ sJ with dnâˆ’1 = d2 and dn = d1 , the role s and the element
Â¯ qsr with t âˆˆ
d = d2 is as required. For each r(t, t) âˆˆ
/ R, select an element dr,t and a role
sr,t as described above. Now let q`r be obtained from qsr by doing the following for each
Â¯ qsr with t âˆˆ
r(t, t) âˆˆ
/ R:
â€¢ if dr,t = Ï€sr (t0 ) for some t0 âˆˆ Terms(qsr ), then replace r(t, t) with sr,t (t, t0 ) and sr,t (t0 , t);
â€¢ otherwise, introduce a new variable vr,t âˆˆ NV and replace r(t, t) with sr,t (t, vr,t ) and
sr,t (vr,t , t).
Let Ï€`r be obtained from Ï€sr by extending it with Ï€`r (vr,t ) = dr,t for each newly introduced
variable vr,t . By definition of q`r and Ï€`r , q`r is connected, Ï€`r is injective modulo â‰ˆ* , and
I |=Ï€`r q`r .
Lemma (18). Let I be a model of K.
1. If I is canonical and I |= q, then there is a pair (qf r , R) âˆˆ frK (q) such that I |=Ï€f r qf r
for a forest match Ï€f r , R is the induced root splitting of Ï€f r , and Ï€f r is an injection
*
modulo â‰ˆ
.
2. If (qf r , R) âˆˆ frK (q) and I |=Ï€f r qf r for some match Ï€f r , then I |= q.
Proof of Lemma 18. The proof of (2) is again analogous to the one given in Lemma 16. For
(1), let (q`r , R) âˆˆ lrK (q) be such that I |=Ï€`r q`r , R is the root splitting induced by Ï€`r , Ï€`r
Â¯ q`r , t âˆˆ R. Such a loop rewriting and match Ï€`r
is injective modulo â‰ˆ* and, for each r(t, t) âˆˆ
exist due to Lemma 17 and the canonicity of I. By definition, R is a root splitting w.r.t.
q`r and K.
For w, w0 âˆˆ INâˆ— , the longest common prefix (LCP) of w, w0 is the longest wâˆ— âˆˆ INâˆ— such
that wâˆ— is prefix of both w and w0 . For the match Ï€`r we now define the set D as follows:
D := ran(Ï€`r ) âˆª {(a, w) âˆˆ âˆ†I | w is the LCP of some w, w0
with (a, w0 ), (a, w00 ) âˆˆ ran(Ï€`r )}.
Let V âŠ† NV \ Vars(q`r ) be such that, for each d âˆˆ D \ ran(Ï€`r ), there is a unique vd âˆˆ V .
We now define a mapping Ï€f r as Ï€`r âˆª {vd âˆˆ V 7â†’ d}. By definition of V and vd , Ï€f r is a
split match as well. The set V âˆª Vars(q`r ) will be the set of variables for the new query qf r .
Note that ran(Ï€f r ) = D.
Fact (a) if (a, w), (a, w0 ) âˆˆ ran(Ï€f r ), then (a, w00 ) âˆˆ ran(Ï€f r ), where w00 is the LCP of w
and w0 ;
Fact (b) ](V ) â‰¤ ](Vars(q`r )) (Because, in the worst case, all (a, w) in ran(Ï€`r ) are â€œincomparableâ€ and can thus be seen as leaves of a binarily branching tree. Now, a tree that
has n leaves and is at least binarily branching at every non-leaf has at most n inner
nodes, and thus ](V ) â‰¤ ](Vars(q`r )).
194

Conjunctive Query Answering for the DL SHIQ

For a pair of individuals d, d0 âˆˆ âˆ†I , the path from d to d0 is the (unique) shortest sequence
of elements d1 , . . . , dn âˆˆ âˆ†I such that d1 = d, dn = d0 , and di+1 is a neighbor of di for all
1 â‰¤ i < n. The length of a path is the number of elements in it, i.e., the path d1 , . . . , dn is
of length n. The relevant path d01 , . . . , d0` from d to d0 is the sub-sequence of d1 , . . . , dn that
is obtained by dropping all elements di âˆˆ
/ D.
Â¯ subq(q`r , tr ) for some tr âˆˆ R and let d01 , . . . , d0` be the relevant path
Claim 1. Let r(t, t0 ) âˆˆ
from d = d01 = Ï€`r (t) to d0 = d0` = Ï€`r (t0 ). If ` > 2, there is a role s âˆˆ TransR such that
s v* R r and (d0i , d0i+1 ) âˆˆ sI for all 1 â‰¤ i < `.
Proof. Let d1 , . . . , dn be the path and d01 , . . . , d0` the relevant path from Ï€`r (t) to Ï€`r (t0 ).
Then ` > 2 implies n > 2. We have to show that there is a role s as in the claim. Let J
be a forest base for I. Since I |=Ï€`r q`r , n > 2 implies (Ï€`r (t), Ï€`r (t0 )) âˆˆ rI \ rJ . Since I is
based on J , it follows that there is an s âˆˆ TransR such that s v* R r, and (di , di+1 ) âˆˆ sJ for
all 1 â‰¤ i < n. By construction of I from J , it follows that (d0i , d0i+1 ) âˆˆ sI for all 1 â‰¤ i < `,
which finishes the proof of the claim.
Â¯ subq(q`r , tr ) with
Now let qf r be obtained from q`r as follows: for each role atom r(t, t) âˆˆ
0
0
0
tr âˆˆ R, if the length of the relevant path d1 , . . . , d` from d = d1 = Ï€`r (t) to d0 = d0` = Ï€`r (t0 )
is greater than 2, then select a role s and variables tj âˆˆ D such that Ï€f r (tj ) = d0j as in
Claim 1 and replace the atom r(t, t0 ) with s(t1 , t2 ), . . . , s(t`âˆ’1 , t` ), where t = t1 , t0 = t` .
Please note that these tj can be chosen in a â€œdonâ€™t careâ€ non-deterministic way since Ï€f r is
injective modulo â‰ˆ* , i.e., if Ï€f r (tj ) = dj = Ï€f r (t0j ), then tj â‰ˆ* t0j and we can pick any of these.
We now have to show that
(i) I |=Ï€f r qf r , and
(ii) Ï€f r is a forest match.
Â¯ q`r \ qf r and let s(t1 , t2 ), . . . , s(t`âˆ’1 , t` ) be the atoms that replaced
For (i), let r(t, t0 ) âˆˆ
0
Ï€
`r
r(t, t ). Since I |= q`r , I |=Ï€`r r(t, t0 ) and (Ï€`r (t), Ï€`r (t0 )) âˆˆ rI . Since r(t, t0 ) was replaced
in qf r , the length of the relevant path from Ï€`r (t) to Ï€`r (t0 ) is greater than 2. Hence, it must
be the case that (Ï€`r (t), Ï€`r (t0 )) âˆˆ rI \ rJ . Let d1 , . . . , dn with d1 = Ï€`r (t) and dn = Ï€`r (t0 )
be the path from Ï€`r (t) to Ï€`r (t0 ) and d01 , . . . , d0` the relevant path from Ï€`r (t) to Ï€`r (t0 ). By
construction of I from J , this means that there is a role s âˆˆ TransR such that s v* R r and
(di , di+1 ) âˆˆ sJ for all 1 â‰¤ i < n. Again by construction of I, this means (d0i , d0i+1 ) âˆˆ sI for
1 â‰¤ i < ` as required. Hence I |=Ï€f r s(ti , ti+1 ) for each i with â‰¤ i < ` by definition of Ï€f r .
For (ii): the mapping Ï€f r differs from Ï€`r only for the newly introduced variables.
Furthermore, we only introduced new role atoms within a sub-query subq(q`r , tr ) and Ï€`r
is a split match by assumption. Hence, Ï€f r is trivially a split match and we only have to
show that Ï€f r is a forest match. Since Ï€f r is a split match, we can do this â€œtree by treeâ€.
For each a âˆˆ Inds(A), let Ta := {w | (a, w) âˆˆ ran(Ï€f r )}. We need to construct a mapping
f as specified in Definition 14, and we start with its root tr . If Ta 6= âˆ…, let tr âˆˆ Terms(q)
be the unique term such that Ï€f r (tr ) = (a, wr ) and there is no t âˆˆ Terms(q) such that
Ï€f r (t) = (a, w) and w is a proper prefix of wr . Such a term exists since Ï€f r is a split match
and it is unique due to Fact (a) above. Define a trace to be a sequence wÌ„ = w1 Â· Â· Â· wn âˆˆ Ta+
such that
â€¢ w1 = wr ;
195

Glimm, Horrocks, Lutz, & Sattler

â€¢ for all 1 â‰¤ i < n, wi is the longest proper prefix of wi+1 .
Since I is canonical, each wi âˆˆ Ta is in IN. It is not hard to see that T = {wÌ„ | wÌ„ is a trace}âˆª
{Îµ} is a tree. For a trace wÌ„ = w1 Â· Â· Â· wn , let Tail(wÌ„) = wn . Define a mapping f that maps
each term t with Ï€f r (t) = (a, w) âˆˆ Ta to the unique trace wÌ„t such that w = Tail(wÌ„t ). Let
r(t, t0 ) âˆˆ qf r such that Ï€f r (t), Ï€f r (t0 ) âˆˆ Ta . By construction of qf r , this implies that the
length of the relevant path from Ï€f r (t) to Ï€f r (t0 ) is exactly 2. Thus, f (t) and f (t0 ) are
neighbors in T and, hence, Ï€f r is a forest match as required.
Theorem (19). Let K be a SHIQ knowledge base, q a Boolean conjunctive query, and
{q1 , . . . , q` } = treesK (q) âˆª groundK (q). Then K |= q iff K |= q1 âˆ¨ . . . âˆ¨ q` .
Proof of Theorem 19. For the â€œifâ€ direction: let us assume that K |= q1 âˆ¨ . . . âˆ¨ q` . Hence,
for each model I of K, there is a query qi with 1 â‰¤ i â‰¤ ` such that I |= qi . We distinguish
two cases: (i) qi âˆˆ treesK (q) and (ii) qi âˆˆ groundK (q).
For (i): qi is of the form C(v) where C is the query concept for some query qf r w.r.t.
v âˆˆ Vars(qf r ) and (qf r , âˆ…) âˆˆ frK (q). Hence I |=Ï€ qi for some match Ï€, and thus I |=Ï€ C(v).
Let d âˆˆ âˆ†I with d = Ï€(v) âˆˆ C I . By Lemma 12, we then have that I |= qf r and, by
Lemma 18, we then have that I |= q as required.
For (ii): since qi âˆˆ groundK (q), there is some pair (qf r , R) âˆˆ frK (q) such that qi =
ground(qf r , R, Ï„ ). We show that I |=Ï€f r qf r for some match Ï€f r . Since I |= q1 , there
is a match Ï€i such that I |=Ï€i qi . We now construct the match Ï€f r . For each t âˆˆ R,
qi contains a concept atom C(Ï„ (t)) where C = con(subq(qf r , t), t) is the query concept of
subq(qf r , t) w.r.t. t. Since I |=Ï€i C(Ï„ (t)) and by Lemma 12, there is a match Ï€t such that
I |=Ï€t subq(qf r , t). We now define Ï€f r as the union of Ï€t , for each t âˆˆ R. Please note that
Ï€f r (t) = Ï€i (Ï„ (t)). Since Inds(qf r ) âŠ† R and Ï„ is such that, for each a âˆˆ Inds(qf r ), Ï„ (a) = a
Â¯ qf r such that at
and Ï„ (t) = Ï„ (t0 ) iff tâ‰ˆ* t0 , it follows that I |=Ï€f r at for each atom at âˆˆ
Ï€
f
r
contains only terms from the root choice R and hence I |=
qf r as required.
For the â€œonly ifâ€ direction we have to show that, if K |= q, then K |= q1 âˆ¨ . . . âˆ¨ q` , so let
us assume that K |= q. By Lemma 7 in its negated form we have that K |= q iff all canonical
models I of K are such that I |= q. Hence, we can restrict our attention to the canonical
models of K. By Lemma 18, I |= K and I |= q implies that there is a pair (qf r , R) âˆˆ frK (q)
such that I |=Ï€f r qf r for a forest match Ï€f r , R is the induced root splitting of Ï€f r , and Ï€f r
*
is an injection modulo â‰ˆ
. We again distinguish two cases:
(i) R = âˆ…, i.e., the root splitting is empty and Ï€f r is a tree match, and
(ii) R 6= âˆ…, i.e., the root splitting is non-empty and Ï€f r is a forest match but not a tree
match.
For (i): since (qf r , âˆ…) âˆˆ frK (q), there is some v âˆˆ Terms(qf r ) such that C = con(qf r , v) and
qi = C(v). By Lemma 12 and, since I |= qf r , there is an element d âˆˆ âˆ†I such that d âˆˆ C I .
Hence I |=Ï€ C(v) with Ï€ : v 7â†’ d as required.
For (ii): since R is the root splitting induced by Ï€f r , for each t âˆˆ R there is some
at âˆˆ Inds(A) such that Ï€f r (t) = (at , Îµ). We now define the mapping Ï„ : R â†’ Inds(A) as
follows: for each t âˆˆ R, Ï„ (t) = at iff Ï€f r (t) = (at , Îµ). By definition of ground(qf r , R, Ï„ ),
qi = ground(qf r , R, Ï„ ) âˆˆ groundK (q). Since I |=Ï€f r qf r , I |= subq(qf r , t) for each t âˆˆ R.
196

Conjunctive Query Answering for the DL SHIQ

Since qf r is forest-shaped, each subq(qf r , t) is tree-shaped. Then, by Lemma 12, I |= qi0 ,
where qi0 is the query obtained from qf r by replacing each sub-query subq(qf r , t) with C(t)
for C the query concept of subq(qf r , t) w.r.t. t. By definition of Ï„ from the forest match
Ï€f r , it is clear that I |= ground(qf r , R, Ï„ ) as required.
Lemma (20). Let q be a Boolean conjunctive query, K = (T , R, A) a SHIQ knowledge
base, |q| := n and |K| := m. Then there is a polynomial p such that
1. ](co(q)) â‰¤ 2p(n) and, for each q 0 âˆˆ co(q), |q 0 | â‰¤ p(n),
2. ](srK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ srK (q), |q 0 | â‰¤ p(n),
3. ](lrK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ lrK (q), |q 0 | â‰¤ p(n),
4. ](frK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ frK (q), |q 0 | â‰¤ p(n),
5. ](treesK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ treesK (q), |q 0 | â‰¤ p(n), and
6. ](groundK (q)) â‰¤ 2p(n)Â·log p(m) , and, for each q 0 âˆˆ groundK (q), |q 0 | â‰¤ p(n).
Proof of Lemma 20.
1. The set co(q) contains those queries obtained from q by adding at most n equality
atoms to q. The number of collapsings corresponds, therefore, to building all equivalence classes over the terms in q by â‰ˆ* . Hence, the cardinality of the set co(q) is at
most exponential in n. Since we add at most one equality atom for each pair of terms,
the size of a query q 0 âˆˆ co(q) is at most n + n2 , and |q 0 | is, therefore, polynomial in n.
2. For each of the at most n role atoms, we can choose to do nothing, replace the
atom with two atoms, or with three atoms. For every replacement, we can choose to
introduce a new variable or re-use one of the existing variables. If we introduce a new
variable every time, the new query contains at most 3n terms. Since K can contain at
most m non-simple roles that are a sub-role of a role used in role atoms of q, we have
at most m roles to choose from when replacing a role atom. Overall, this gives us at
most 1 + m(3n) + m(3n)(3n) choices for each of the at most n role atoms in a query
and, therefore, the number of split rewritings for each query q 0 âˆˆ co(q) is polynomial
in m and exponential in n. In combination with the results from (1), this also shows
that the overall number of split rewritings is polynomial in m and exponential in n.
Since we add at most two new role atoms for each of the existing role atoms, the size
of a query q 0 âˆˆ srK (q) is linear in n.
3. There are at most n role atoms of the form r(t, t) in a query q 0 âˆˆ srK (q) that could
give rise to a loop rewriting, at most m non-simple sub-roles of r in K that can be
used in the loop rewriting, and we can introduce at most one new variable for each
role atom r(t, t). Therefore, for each query in srK (q), the number of loop rewritings
is again polynomial in m and exponential in n. Combined with the results from (2),
this bound also holds for the cardinality of lrK (q).
In a loop rewriting, one role atom is replaced with two role atoms, hence, the size of
a query q 0 âˆˆ lrK (q) at most doubles.
197

Glimm, Horrocks, Lutz, & Sattler

4. We can use similar arguments as above in order to derive a bound that is exponential
in n and polynomial in m for the number of forest rewritings in frK (q).
Since the number of role atoms that we can introduce in a forest rewriting is polynomial in n, the size of each query q 0 âˆˆ frK (q) is at most quadratic in n.
5. The cardinality of the set treesK (q) is clearly also polynomial in m and exponential in
n since each query in frK (q) can contribute at most one query to the set treesK (q). It
is not hard to see that the size of a query q 0 âˆˆ treesK (q) is polynomial in n.
6. By (1)-(4) above, the number of terms in a root splitting is polynomial in n and there
are at most m individual names occurring in A that can be used for the mapping Ï„
from terms to individual names. Hence the number of different ground mappings Ï„ is
at most polynomial in m and exponential in n. The number of ground queries that a
single tuple (qf r , R) âˆˆ frK (q) can contribute is, therefore, also at most polynomial in m
and exponential in n. Together with the bound on the number of forest rewritings from
(4), this shows that the cardinality of groundK (q) is polynomial in m and exponential
in n. Again it is not hard to see that the size of each query q 0 âˆˆ groundK (q) is
polynomial in n.

Lemma (23). Let K be a SHIQ knowledge base and q a union of connected Boolean
conjunctive queries. The algorithm from Definition 22 answers â€œK entails qâ€ iff K |= q
under the unique name assumption.
Proof of Lemma 23. For the â€œonly ifâ€-direction: let q = q1 âˆ¨ . . . âˆ¨ q` . We show the contrapositive and assume that K 6|= q. We can assume that K is consistent since an inconsistent
knowledge base trivially entails every query. Let I be a model of K such that I 6|= q. We
show that I is also a model of some extended knowledge base Kq = (T âˆª Tq , R, A âˆª Aq ).
We first show that I is a model of Tq . To this end, let > v Â¬C in Tq . Then C(v) âˆˆ T
and C = con(qf r , v) for some pair (qf r , âˆ…) âˆˆ frK (q1 ) âˆª . . . âˆª frK (q` ) and v âˆˆ Vars(qf r ). Let i
be such that (qf r , âˆ…) âˆˆ frK (qi ). Now C I 6= âˆ… implies, by Lemma 12, that I |= qf r and, by
Lemma 18, I |= qi and, hence, I |= q, contradicting our assumption. Thus I |= > v Â¬C
and, thus, I |= Tq .
Next, we define an extended ABox Aq such that, for each q 0 âˆˆ G,
â€¢ if C(a) âˆˆ q 0 and aI âˆˆ Â¬C I , then Â¬C(a) âˆˆ Aq ;
â€¢ if r(a, b) âˆˆ q 0 and (aI , bI ) âˆˆ
/ rI , then Â¬r(a, b) âˆˆ Aq .
Now assume that we can have a query q 0 = ground(qf r , R, Ï„ ) âˆˆ groundK (q1 )âˆª. . .âˆªgroundK (q` )
such that there is no atom at âˆˆ q 0 with Â¬at âˆˆ Aq . Then trivially I |= q 0 . Let i be such that
(qf r , R) âˆˆ frK (qi ). By Theorem 19, I |= qi and thus I |= q, which is a contradiction. Hence
Kq is an extended knowledge base and I |= Kq as required.
For the â€œifâ€-direction, we assume that K |= q, but the algorithm answers â€œK does not
entail qâ€. Hence there is an extended knowledge base Kq = (T âˆª Tq , R, A âˆª Aq ) that is
consistent, i.e., there is a model I such that I |= Kq . Since Kq is an extension of K,
198

Conjunctive Query Answering for the DL SHIQ

I |= K. Moreover, we have that I |= Tq and hence, for each d âˆˆ âˆ†I , d âˆˆ Â¬C I for each
C(v) âˆˆ treesK (q1 ) âˆª . . . âˆª treesK (q` ). By Lemma 12, we then have that I 6|= q 0 for each
q 0 âˆˆ treesK (q1 ) âˆª . . . âˆª treesK (q` ) and, by Lemma 18, I 6|= qi for each i with 1 â‰¤ i â‰¤ `.
By definition of extended knowledge bases, Aq contains an assertion Â¬at for at least one
atom at in each query q 0 = ground(qf r , R, Ï„ ) from groundK (q1 ) âˆª . . . âˆª groundK (q` ). Hence
I 6|= q 0 for each q 0 âˆˆ groundK (q1 ) âˆª . . . âˆª groundK (q` ). Then, by Theorem 19, I 6|= q, which
contradicts our assumption.
Lemma (25). Let R be a role hierarchy, and r1 , . . . , rn roles. For every interpretation I
such that I |= R, it holds that (â†‘(r1 u . . . u rn , R))I = (r1 u . . . u rn )I .
Proof of Lemma 25. The proof is a straightforward extension of Lemma 6.19 by Tobies
(2001). By definition, â†‘ (r1 u . . . u rn , R) =â†‘ (r1 , R) u . . . u â†‘ (rn , R) and, by definition of the semantics of role conjunctions, we have that (â†‘(r1 , R) u . . . u â†‘(rn , R))I =
â†‘(r1 , R)I âˆ© . . . âˆ© â†‘(rn , R)I . If s v* R r, then {s0 | r v* R s0 } âŠ† {s0 | s v* R s0 } and hence
â†‘(s, R)I âŠ† â†‘(r, R)I . If I |= R, then rI âŠ† sI for every s with r v* R s. Hence, â†‘(r, R)I = rI
and (â†‘(r1 u . . . u rn , R))I = (â†‘(r1 , R) u . . . u â†‘(rn , R))I = â†‘(r1 , R)I âˆ© . . . âˆ© â†‘(rn , R)I =
r1 I âˆ© . . . âˆ© rn I = (r1 u . . . u rn )I as required.
Lemma (28). Given a SHIQu knowledge base K = (T , R, A) where m := |K| and the size
of the longest role conjunction is n, we can decide consistency of K in deterministic time
p(n)
2p(m)2
with p a polynomial.
Proof of Lemma 28. We first translate K into an ALCQIb knowledge base tr(K, R) =
(tr(T , R), tr(A, R)). Since the longest role conjunction is of size n, the cardinality of each
set tc(R, R) for a role conjunction R is bounded by mn . Hence, the TBox tr(T , R) can
contain exponentially many axioms in n. It is not hard to check that the size of each axiom
is polynomial in m. Since deciding whether an ALCQIb KB is consistent is an ExpTimecomplete problem (even with binary coding of numbers) (Tobies, 2001, Theorem 4.42), the
p(n)
consistency of tr(K, R) can be checked in time 2p(m)2 .
Lemma (29). Let K = (T , R, A) be a SHIQ knowledge base with m := |K| and q a
union of connected Boolean conjunctive queries with n := |q|. The algorithm given in
Definition 22 decides whether K |= q under the unique name assumption in deterministic
p(n)
time in 2p(m)2 .
Proof of Lemma 29. We first show that there is some polynomial p such that we have
p(n)
to check at most 2p(m)2
extended knowledge bases for consistency and then that each
p(n)
p(n)
consistency check can be done in time 2p(m)2 , which gives an upper bound of 2p(m)2
on the time needed for deciding whether K |= q.
Let q := q1 âˆ¨ . . . âˆ¨ q` . Clearly, we can use n as a bound for `, i.e., ` â‰¤ n. Moreover, the
size of each query qi with 1 â‰¤ i â‰¤ ` is bounded by n. Together with Lemma 20, we get that
](T ) and ](G) are bounded by 2p(n)Â·log p(m) for some polynomial p and it is clear that the
sets can be computed in this time bound as well. The size of each query q 0 âˆˆ G w.r.t. an
ABox A is polynomial in n and, when constructing Aq , we can add a subset of (negated)
199

Glimm, Horrocks, Lutz, & Sattler

p(n)

atoms from each q 0 âˆˆ G to Aq . Hence, there are at most 2p(m)2
extended ABoxes Aq
p(n)
p(m)2
extended knowledge bases that have to be tested for consistency.
and, therefore, 2
Due to Lemma 20 (5), the size of each query q 0 âˆˆ T is polynomial in n. Computing a
query concept Cq0 of q 0 w.r.t. some variable v âˆˆ Vars(q 0 ) can be done in time polynomial
in n. Thus the TBox Tq can be computed in time 2p(n)Â·log p(m) . The size of an extended
ABox Aq is maximal if we add, for each of the 2p(n)Â·log p(m) ground queries in G, all atoms
in their negated form. Since, by Lemma 20 (6), the size of these queries is polynomial in n,
the size of each extended ABox Aq is bounded by 2p(n)Â·log p(m) and it is clear that we can
compute an extended ABox in this time bound as well. Hence, the size of each extended
KB Kq = (T âˆª Tq , R, A âˆª Aq ) is bounded by 2p(n)Â·log p(m) . Since role conjunctions occur only
in Tq or Aq , and the size of each concept in Tq and Aq is polynomial in n, the length of the
longest role conjunction is also polynomial in n.
When translating an extended knowledge base into an ALCQIb knowledge base, the
number of axioms resulting from each concept C that occurs in Tq or Aq can be exponential
in n. Thus, the size of each extended knowledge base is bounded by 2p(n)Â·log p(m) .
Since deciding whether an ALCQIb knowledge base is consistent is an ExpTimecomplete problem (even with binary coding of numbers) (Tobies, 2001, Theorem 4.42),
p(n)
it can be checked in time 2p(m)2
if K is consistent or not.
p(n)
Since we have to check at most 2p(m)2
knowledge bases for consistency, and each
p(n)
p(n)
p(m)2
check can be done in time 2
, we obtain the desired upper bound of 2p(m)2
for
deciding whether K |= q.
Lemma (31). Let K = (T , R, A) be a SHIQ knowledge base and q a union of Boolean
conjunctive queries. K 6|= q without making the unique name assumption iff there is an
A-partition KP = (T , R, AP ) and q P w.r.t. K and q such that KP 6|= q P under the unique
name assumption.
Proof of Lemma 31. For the â€œonly ifâ€-direction: Since K 6|= q, there is a model I of K
such that I 6|= q. Let f : Inds(A) â†’ Inds(A) be a total function such that, for each set of
individual names {a1 , . . . , an } for which a1 I = ai I for 1 â‰¤ i â‰¤ n, f (ai ) = a1 . Let AP and
q P be obtained from A and q by replacing each individual name a in A and q with f (a).
P
Clearly, KP = (T , R, AP ) and q P are an A-partition w.r.t. K and q. Let I P = (âˆ†I , Â·I )
be an interpretation that is obtained by restricting Â·I to individual names in Inds(AP ). It
is easy to see that I P |= KP and that the unique name assumption holds in I P . We now
0
show that I P 6|= q P . Assume, to the contrary of what is to be shown, that I P |=Ï€ q P for
some match Ï€ 0 . We define a mapping Ï€ : Terms(q) â†’ âˆ†I from Ï€ 0 such Ï€(a) = Ï€ 0 (f (a)) for
each individual name a âˆˆ Inds(q) and Ï€(v) = Ï€ 0 (v) for each variable v âˆˆ Vars(q). It is easy
to see that I |=Ï€ q, which is a contradiction.
P
For the â€œifâ€-direction: Let I P = (âˆ†I , Â·I ) be such that I P |= KP under UNA and
I P 6|= q P and let f : Inds(A) â†’ Inds(AP ) be a total function such that f (a) is the individual
that replaced a in AP and q P . Let I = (âˆ†I ,Â·I ) be an interpretation that extends I P such
P
that aI = f (a)I . We show that I |= K and that I 6|= q. It is clear that I |= T . Let
C(a) be an assertion in A such that a was replaced with aP in AP . Since I P |= C(aP )
P

and aI = f (a)I = aP

IP

P

âˆˆ C I , I |= C(a). We can use a similar argument for (possibly
200

Conjunctive Query Answering for the DL SHIQ

.
negated) role assertions. Let a =
6 b be an assertion in A such that a was replaced with aP
P
.
and b with bP in AP , i.e., f (a) = aP and f (b) = bP . Since I P |= aP =
6 bP , aI = f (a)I =
P
IP
IP
.
aP 6= bP = f (b)I = bI and I |= a =
6 b as required. Therefore, we have that I |= K as
required.
Assume that I |=Ï€ q for a match Ï€. Let Ï€ P : Terms(q P ) â†’ âˆ†I be a mapping such that
P
Ï€ (v) = Ï€(v) for v âˆˆ Vars(q P ) and Ï€ P (aP ) = Ï€(a) for aP âˆˆ Inds(q P ) and some a such that
aP = f (a). Let C(aP ) âˆˆ q P be such that C(a) âˆˆ q and a was replaced with aP , i.e., f (a) =
P

IP

= Ï€ P (aP ) âˆˆ C I
aP . By assumption, Ï€(a) âˆˆ C I , but then Ï€(a) = aI = f (a)I = aP
P
P
and I |= C(a ). Similar arguments can be used to show entailment for role and equality
atoms, which yields the desired contradiction.
P

Theorem (35). Let K = (T , R, A) be a SHIQ knowledge base with m := |K| and q :=
q1 âˆ¨ . . . âˆ¨ q` a union of Boolean conjunctive queries with n := |q|. The algorithm given in
Definition 34 decides in non-deterministic time p(ma ) whether K 6|= q for ma := |A| and p
a polynomial.
Proof of Theorem 35. Clearly, the size of an ABox AP in an A-partition is bounded by ma .
As established in Lemma 32, the maximal size of an extended ABox AP
q is polynomial in
ma . Hence, |AP âˆª AP
|
â‰¤
p(m
)
for
some
polynomial
p.
Due
to
Lemma
20 and since the
a
q
size of q, T , and R is fixed by assumption, the sets treesKP (qi ) and groundKP (qi ) for each
i such that 1 â‰¤ i â‰¤ ` can be computed in time polynomial in ma . From Lemma 29, we
know that the translation of an extended knowledge base into an ALCQIb knowledge base
is polynomial in ma and a close inspection of the algorithm by Tobies (2001) for deciding
consistency of an ALCQIb knowledge base shows that its runtime is also polynomial in
ma .

References
Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2003). The Description Logic Handbook. Cambridge University Press.
Bechhofer, S., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L., PatelSchneider, P. F., & Stein, L. A. (2004). OWL web ontology language reference. Tech.
rep., World Wide Web Consortium. http://www.w3.org/TR/2004/REC-owl-ref-20040210/.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Data
complexity of query answering in description logics. In Doherty, P., Mylopoulos, J., &
Welty, C. A. (Eds.), Proceedings of the 10th International Conference on Principles of
Knowledge Representation and Reasoning (KR 2006), pp. 260â€“270. AAAI Press/The
MIT Press.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning and efficient query answering in description logics: The dl-lite family. Journal of Automated Reasoning, 39 (3), 385â€“429.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998a). On the decidability of query
containment under constraints. In Proceedings of the 17th ACM SIGACT-SIGMOD201

Glimm, Horrocks, Lutz, & Sattler

SIGART Symposium on Principles of Database Systems (PODS 1998), pp. 149â€“158.
ACM Press and Addison Wesley.
Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998b). Description
logic framework for information integration. In Proceedings of the 6th International
Conference on Principles of Knowledge Representation and Reasoning (KR 1998).
Calvanese, D., Eiter, T., & Ortiz, M. (2007). Answering regular path queries in expressive description logics: An automata-theoretic approach. In Proceedings of the 22th
National Conference on Artificial Intelligence (AAAI 2007).
Chekuri, C., & Rajaraman, A. (1997). Conjunctive query containment revisited. In Proceedings of the 6th International Conference on Database Theory (ICDT 1997), pp.
56â€“70, London, UK. Springer-Verlag.
Glimm, B., Horrocks, I., & Sattler, U. (2006). Conjunctive query answering for description
logics with transitive roles. In Proceedings of the 19th International Workshop on
Description Logics (DL 2006). http://www.cs.man.ac.uk/~glimmbx/download/GlHS06a.pdf.
GraÌˆdel, E. (2001). Why are modal logics so robustly decidable?. In Paun, G., Rozenberg,
G., & Salomaa, A. (Eds.), Current Trends in Theoretical Computer Science, Entering
the 21th Century, Vol. 2, pp. 393â€“408. World Scientific.
Grahne, G. (1991). Problem of Incomplete Information in Relational Databases. SpringerVerlag.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). From SHIQ and RDF
to OWL: The making of a web ontology language. Journal of Web Semantics, 1 (1),
7â€“26.
Horrocks, I., Sattler, U., Tessaris, S., & Tobies, S. (1999). Query containment using a DLR ABox. Ltcs-report LTCS-99-15, LuFG Theoretical Computer Science,
RWTH Aachen, Germany. Available online at http://www-lti.informatik.rwth-aachen.
de/Forschung/Reports.html.
Horrocks, I., Sattler, U., & Tobies, S. (2000). Reasoning with Individuals for the Description
Logic SHIQ. In McAllester, D. (Ed.), Proceedings of the 17th International Conference on Automated Deduction (CADE 2000), No. 1831 in Lecture Notes in Artificial
Intelligence, pp. 482â€“496. Springer-Verlag.
Horrocks, I., & Tessaris, S. (2000). A conjunctive query language for description logic aboxes.
In Proceedings of the 17th National Conference on Artificial Intelligence (AAAI 2000),
pp. 399â€“404.
Hustadt, U., Motik, B., & Sattler, U. (2005). Data complexity of reasoning in very expressive
description logics. In Proceedings of the International Joint Conference on Artificial
Intelligence (IJCAI 2005), pp. 466â€“471.
Levy, A. Y., & Rousset, M.-C. (1998). Combining horn rules and description logics in
CARIN. Artificial Intelligence, 104 (1â€“2), 165â€“209.
Lutz, C. (2007). Inverse roles make conjunctive queries hard. In Proceedings of the 20th
International Workshop on Description Logics (DL 2007).
202

Conjunctive Query Answering for the DL SHIQ

McGuinness, D. L., & Wright, J. R. (1998). An industrial strength description logic-based
configuration platform. IEEE Intelligent Systems, 13 (4).
Motik, B., Sattler, U., & Studer, R. (2004). Query answering for OWL-DL with rules.
In Proceedings of the 3rd International Semantic Web Conference (ISWC 2004), Hiroshima, Japan.
Ortiz, M., Calvanese, D., & Eiter, T. (2006a). Data complexity of answering unions of
conjunctive queries in SHIQ. In Proceedings of the 19th International Workshop on
Description Logics (DL 2006).
Ortiz, M. M., Calvanese, D., & Eiter, T. (2006b). Characterizing data complexity for
conjunctive query answering in expressive description logics. In Proceedings of the
21th National Conference on Artificial Intelligence (AAAI 2006).
Rosati, R. (2006a). DL+log: Tight integration of description logics and disjunctive datalog. In Proceedings of the Tenth International Conference on Principles of Knowledge
Representation and Reasoning (KR 2006), pp. 68â€“78.
Rosati, R. (2006b). On the ddecidability and finite controllability of query processing in
databases with incomplete information. In Proceedings of the 25th ACM SIGACT
SIGMOD Symposium on Principles of Database Systems (PODS-06), pp. 356â€“365.
ACM Press and Addison Wesley.
Rosati, R. (2007a). The limits of querying ontologies. In Proceedings of the Eleventh
International Conference on Database Theory (ICDT 2007), Vol. 4353 of Lecture Notes
in Computer Science, pp. 164â€“178. Springer-Verlag.
Rosati, R. (2007b). On conjunctive query answering in EL. In Proceedings of the 2007
Description Logic Workshop (DL 2007). CEUR Workshop Proceedings.
Schaerf, A. (1993). On the complexity of the instance checking problem in concept languages
with existential quantification. Journal of Intelligent Information Systems, 2 (3), 265â€“
278.
Sirin, E., & Parsia, B. (2006). Optimizations for answering conjunctive abox queries. In
Proceedings of the 19th International Workshop on Description Logics (DL 2006).
Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2006). Pellet: A practical
OWL-DL reasoner. Accepted for the Journal of Web Semantics, Available online at
http://www.mindswap.org/papers/PelletJWS.pdf.
Tessaris, S. (2001). Questions and answers: reasoning and querying in Description Logic.
PhD thesis, University of Manchester.
Tobies, S. (2001). Complexity Results and Practical Algorithms for Logics in Knowledge
Representation. PhD thesis, RWTH Aachen.
Tsarkov, D., & Horrocks, I. (2006). FaCT++ description logic reasoner: System description.
In Furbach, U., & Shankar, N. (Eds.), Proceedings of the Third International Joint
Conference on Automated Reasoning (IJCAR 2006), Vol. 4130 of Lecture Notes in
Computer Science, pp. 292 â€“ 297. Springer-Verlag.
203

Glimm, Horrocks, Lutz, & Sattler

van der Meyden, R. (1998). Logical approaches to incomplete information: A survey. In
Logics for Databases and Information Systems, pp. 307â€“356. Kluwer Academic Publishers.
Vardi, M. Y. (1997). Why is modal logic so robustly decidable?. In Descriptive Complexity
and Finite Models: Proceedings of a DIMACS Workshop, Vol. 31 of DIMACS: Series
in Discrete Mathematics and Theoretical Computer Science, pp. 149â€“184. American
Mathematical Society.
Wessel, M., & MoÌˆller, R. (2005). A high performance semantic web query answering engine.
In Proceedings of the 18th International Workshop on Description Logics.
Wolstencroft, K., Brass, A., Horrocks, I., Lord, P., Sattler, U., Turi, D., & Stevens, R.
(2005). A Little Semantic Web Goes a Long Way in Biology. In Proceedings of the
2005 International Semantic Web Conference (ISWC 2005).

204

Journal of Artificial Intelligence Research 31 (2008) 353-398

Submitted 09/07; published 02/08

Gesture Salience as a Hidden Variable for Coreference
Resolution and Keyframe Extraction
Jacob Eisenstein
Regina Barzilay
Randall Davis

jacobe@csail.mit.edu
regina@csail.mit.edu
davis@csail.mit.edu

Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
77 Massachusetts Avenue
Cambridge, MA 02139 USA

Abstract
Gesture is a non-verbal modality that can contribute crucial information to the understanding of natural language. But not all gestures are informative, and non-communicative
hand motions may confuse natural language processing (NLP) and impede learning. People have little difficulty ignoring irrelevant hand movements and focusing on meaningful
gestures, suggesting that an automatic system could also be trained to perform this task.
However, the informativeness of a gesture is context-dependent and labeling enough data
to cover all cases would be expensive. We present conditional modality fusion, a conditional
hidden-variable model that learns to predict which gestures are salient for coreference resolution, the task of determining whether two noun phrases refer to the same semantic
entity. Moreover, our approach uses only coreference annotations, and not annotations of
gesture salience itself. We show that gesture features improve performance on coreference
resolution, and that by attending only to gestures that are salient, our method achieves
further significant gains. In addition, we show that the model of gesture salience learned
in the context of coreference accords with human intuition, by demonstrating that gestures
judged to be salient by our model can be used successfully to create multimedia keyframe
summaries of video. These summaries are similar to those created by human raters, and
significantly outperform summaries produced by baselines from the literature.1

1. Introduction
Gesture is a nearly ubiquitous feature of face-to-face natural language communication and
may be used to supplement speech with additional information or to reinforce the meaning
already conveyed (McNeill, 1992). In either case, gesture can increase the robustness of
natural language processing (NLP) systems to the inevitable disfluency of spontaneous
1. This article is an extension and unification of two conference publications (Eisenstein, Barzilay, & Davis,
2007; Eisenstein & Davis, 2007). It extends prior published work with several new, unpublished results:
stability analysis with respect to initialization weights (Section 4.3); analysis of verbal features in terms
of centering theory (Section 5.1); interrater agreement analysis on coreference annotations (Section 6);
evaluation of coreference using a global metric (Section 6.2); expanded empirical evaluation on the
coreference task with additional fusion models (Section 6.2); analysis of different types of gesture features
for multimodal coreference resolution (Section 6.4.1); a study of the interaction between gestural and
verbal features (Section 6.4.2); and interrater agreement on keyframe extraction (Section 7.3). Source
code and data are available at http : //mug.csail.mit.edu/publications/2008/Eisenstein JAIR/

c
2008
AI Access Foundation. All rights reserved.

Eisenstein, Barzilay, & Davis

And this top one clears this area here, and goes
all the way up to the top...

So this moves up. And it â€“ everything moves up.

1

2

Figure 1: An excerpt of an explanatory narrative in which gesture helps to disambiguate
meaning.

speech. For example, consider the following excerpt from a presentation in which the
speaker describes a mechanical device:
â€œSo this moves up, and it â€“ everything moves up. And this top one clears this area
here, and goes all the way up to the top.â€

The references in this passage are difficult to disambiguate, but meaning becomes clearer
when set in the context of the accompanying hand gestures (Figure 1).
Despite the apparent benefits offered by gestural cues, obtaining concrete gains for natural language understanding is difficult. A key problem is how to combine gesture and
linguistic features. Existing systems typically address this issue by directly concatenating
low-level visual information (e.g., hand position and speed) with traditional textual features (Eisenstein & Davis, 2006), or by combining the posteriors from separately-trained
models (Chen, Harper, & Huang, 2006). An appealing alternative is to consider the inherent linguistic quality of gesture, as distinguished from other hand movements that may be
meaningful for the desired language understanding task (Goodwin & Goodwin, 1986).2 We
show that better results can be obtained by focusing on the hand movements that are likely
to correspond to relevant gestures.
To move beyond a low-level representation of gesture, one could attempt to develop a
general-purpose taxonomy of gestures based on their relation to language. Such taxonomies
have proved useful for psychological and linguistic research on gesture, but their application
to corpus-based statistical language processing is not immediately practical. Gesture is a
multifaceted phenomenon, and the key features for understanding a gestureâ€™s meaning may
be highly context-dependent (Lascarides & Stone, 2006). For example, the flexion of a
2. All hand motions â€“ or even the absence of hand motion â€“ may be â€œmeaningfulâ€ in some sense. However,
for a specific language processing problem, only some gestures will be directly relevant. In the remainder
of this article, the terms â€œmeaningfulâ€ and â€œmeaninglessâ€ should always be assumed to be framed within
the context of a specific language processing task. Hand motions that are meaningless for coreference
resolution may indeed be quite useful for another problem, such as sentiment classification.

354

Gesture Salience as a Hidden Variable

single finger might be a crucial component of one gesture and an irrelevant detail in another
context. Is it possible to create a formal annotation scheme expressive enough to capture
all such details, yet compact enough to be tractable? This is a topic of ongoing research.
But even if possible, such annotation would be very time-consuming, particularly on the
scale necessary for corpus-based NLP.
In this paper we propose a middle path: a model that learns to attend to salient gestures
without explicit gesture annotation. Instead of a top-down approach that attempts to
analyze gestures according to a universal taxonomy, we work bottom-up from a specific
language understanding problem: coreference resolution. When a speaker produces similar,
meaningful deictic3 gestures during two noun phrases, it is a good indication that the noun
phrases are coreferent (Eisenstein & Davis, 2006). We automatically identify the gestures
that are relevant for coreference resolution, from among all hand motions that co-occur
with noun phrases. This approach is shown to enhance the contribution of low-level gesture
features towards coreference.
More concretely, we employ a conditional model with a hidden variable that governs
whether gesture features are included in the determination of coreference for each pair of
noun phrases. With this model, it is possible to learn gesture salience jointly with coreference. As a baseline, we demonstrate that even a low-level concatenative approach to
gesture-speech fusion4 yields a small but statistically significant improvement for coreference resolution, compared to textual features alone. More importantly, we show that the
contribution of the gesture features increases substantially when gesture and speech are
combined using our structured model.
If the model of gesture salience that we learn were relevant only for coreference resolution, it would be useful only from an engineering perspective. An interesting question
is whether these estimates of gesture salience are related to how humans perceive multimodal communication. To answer this, we examine whether our model of gesture salience
is relevant to other language processing tasks. We demonstrate that the model learned
for coreference resolution can be applied to the selection of keyframes for generating visual
summaries of instructional presentations. Without any explicit training on the keyframe
extraction task, our approach selects keyframes that cohere meaningfully with those chosen
by human annotators.
The main contributions of this paper can be summarized as follows.
New applications of gesture: We demonstrate the benefits of incorporating gesture in
two tasks: coreference resolution and video keyframe extraction. On the coreference
task, we substantially improve on our previous work that showed that gesture similarity can help predict coreference resolution (Eisenstein & Davis, 2006); the application
of linguistic analysis of gesture to video keyframe extraction is novel. In previous
research, gesture information has been shown to boost performance of sentence segmentation, a local syntactic phenomenon. Our work demonstrates gestureâ€™s usefulness
to non-local, discourse-level tasks. To this end, we introduce a novel set of features
that tightly combine linguistic and gestural information.
3. Deictic gestures are those that communicate meaning through spatial location (McNeill, 1992).
4. We use the term â€œspeechâ€ to indicate that we are dealing with spoken language, but note that hand
transcriptions rather than automatic speech recognition (ASR) are used throughout our experiments.
The applicability of our techniques in the context of noisy ASR transcripts is a topic for future work.

355

Eisenstein, Barzilay, & Davis

Gesture salience in language: We develop the idea that gesture information should be
considered for language processing only when the gesture is salient. As in prior research (e.g., Chen, Liu, Harper, & Shriberg, 2004), our model uses low-level features
extracted directly from a vision-based hand tracker, avoiding the need for manual annotation of gesture features. However, the relevance of these low-level features depends
on the linguistic context. By modeling this relationship through gesture salience, we
obtain significant performance gains. In addition, we present a set of features designed
to capture the salience of gesture to the associated speech.
Hidden-variable modeling of gesture salience: We develop a framework in which gesture salience can be modeled jointly with coreference resolution. We show that gesture salience can be expressed as a hidden variable and learned without explicit labels,
leveraging only coreference annotations. This novel framework is realized within a conditional model, enabling the use of arbitrary and possibly non-independent features.
Further experiments demonstrate that the estimates of gesture salience obtained by
this model can be applied to extract keyframes containing salient deictic gestures.
In Section 2, we consider prior work relating to existing models and taxonomies of
gesture from the psychology literature, as well as previous efforts to incorporate gesture
into natural language understanding. In Section 3, we describe the dataset on which we
conduct our experiments. In Section 4, we present our model, conditional modality fusion.
We show how gesture salience can be treated as a hidden variable and learned without
explicit annotations. Section 5 includes a description of the textual and gestural features
that we use for our experiments. In Section 6 we present experimental results showing that
our model improves performance on coreference resolution. In Section 7, we show that our
estimates of gesture salience are more general, and can be applied to select useful keyframes
from video. Finally, in Section 8 we discuss implications of this research, and conclude.

2. Related Work
In this section, we describe four general areas of related work that provide background
and context for our efforts. Section 2.1 discusses models of gesture and language from the
psychology and linguistics communities. Section 2.2 describes projects that have employed
gesture in natural language processing. Section 2.3 describes more general modality fusion
techniques, particularly ones that have been used to incorporate prosodic features into NLP.
Finally, Section 2.4 considers models from the machine learning literature that are related
to conditional modality fusion.
2.1 Models of Gesture and Language
Psychology research has explored the problem of modeling gesture and its relation to language. We discuss two frequently-cited models: Kendonâ€™s taxonomy (1980), which focuses
on the kinematic structure of individual gestures; and McNeillâ€™s (1992), which identifies the
ways in which gesture communicates meaning within discourse.
According to Kendon, gestures are constructed from a set of movement phases: prepare, stroke, hold, and retract. The prepare and retract phases initiate and terminate the
gesture, respectively. The stroke is the content-carrying part of the gesture, and a hold
356

Gesture Salience as a Hidden Variable

is a pause that may occur immediately before or after the stroke. These phases provide
an essentially kinematic description of gesture. McNeill focuses on the way gestures communicate meaning, identifying four major types of conversational gestures: deictic, iconic,
metaphoric, and beat. Deictics communicate by reference to spatial locations, iconics and
metaphorics create imagery using the form of the gesture, and beats communicate using
timing and emphasis.5
While these taxonomies have proved useful for psychological and linguistic research,
substantial effort would be required to create a corpus of such annotations for statistical
natural language processing. We circumvent this problem by learning a model of gesture
directly from automatically-extracted visual features. The relationship between gesture and
language semantics is learned in the context of a specific language phenomenon, using annotations only of verbal language semantics. This approach may not capture all meaningful
hand gestures, but it will capture those that a) are relevant to coreference resolution and
b) can be identified using our feature set.
2.2 Multimodal Natural Language Processing
Early computational work on the relationship between language and gesture focused on identifying examples of connections between discourse elements and automatically-recognized
properties of hand gesture (Quek et al., 2000, 2002a). Quek et al. (2002a) show examples
in which similar gestures are used in connection with repetitions of the associated discourse
elements. We exploit this idea by using features that quantify gesture similarity to predict
noun phrase coreference. Follow-up papers attempt to capture the contribution of individual gesture features, such as spatial location (Quek, McNeill, Bryll, & Harper, 2002b)
and symmetric motion (Xiong & Quek, 2006), using a similar methodology. This line of
work provides a helpful framework for understanding the relationship between gesture and
natural language.
On the engineering side, several papers report work on exploiting the relationship between gesture and language. In one line of research, linguistic features are used to improve gesture processing (Poddar, Sethi, Ozyildiz, & Sharma, 1998; Kettebekov, Yeasin,
& Sharma, 2005). These papers evaluate performance on human-human language in the
domain of weather broadcasts, but with the stated goal of developing techniques for gesturebased human-computer interaction. The authors note that in the domain of weather broadcasts, many hand motions are well-described by a relatively small taxonomy of gestures,
which identify points, contours, and regions. Lexical features from ASR transcripts are
shown to improve gesture recognition (Poddar et al., 1998), and prosodic features are used
to identify key gestural segments (Kettebekov et al., 2005).
Similarly, linguistic analysis has been shown to have important consequences for gesture generation in animated agents. Nakano, Reinstein, Stocky, and Cassell (2003) present
an empirical study of human-human interaction, showing a statistical relationship between
hand-coded descriptions of head gestures and the discourse labels for the associated utterances (e.g., â€œacknowledgment,â€ â€œanswer,â€ and â€œassertionâ€). It is then demonstrated that
these findings can be encoded in a model to generate realistic conversational â€œgroundingâ€
5. McNeill notes that these types should not be thought of a mutually exclusive bins, but as features that
may be present in varying degrees.

357

Eisenstein, Barzilay, & Davis

behavior in an animated agent. In addition to this discourse-moderating function, gestures
are also shown to be useful for supplementing the semantic content of verbal explanations.
Kopp, Tepper, Ferriman, and Cassell (2007) describe a system in which animated agents give
navigation directions, using hand gestures to describe the physical properties of landmarks
along the route. While this research describes interesting relationships between gesture
and language that can be exploited for generation, we focus on recognition of multimodal
communication.
Where the research cited above uses linguistic context to supplement gesture generation
and recognition, other work has used gesture features to supplement natural language processing. Much of this research has taken place in the context of spoken language dialogue
systems incorporating pen gestures and automatically recognized speech. An early example of such a system is Quickset (Cohen et al., 1997), in which pen gestures and speech
input are used to plan military missions. Working in this domain, Johnston and Bangalore (2000) describe a multimodal integration algorithm that parses entire utterances and
resolves ambiguity in both the speech and gesture modalities. Chai and Qu (2005) present
an alternative take on a similar problem, showing that speech recognition can be improved
by increasing the salience of entities targeted by gestures. Both research projects differ
from our own in that they assume the ontology of possible referents is known in advance.
In addition, because gestures are performed with a pen rather than the free hand, gesture
segmentation can be inferred from the contact of the pen with the sensing surface. Finally,
the dialogue in both cases is human-computer, rather than human-human, so the language
usage probably differs.
The research most similar to our own involves using gesture features to improve language
processing in spontaneous human-to-human discourse. Gesture is shown to improve the task
of sentence segmentation using automatically recognized features (Chen et al., 2004), and
more successfully with manual gesture annotations (Chen et al., 2006). A hidden Markov
model (HMM) is used to capture the relation between lexical tokens and sentence boundaries. They then train a maximum entropy model using a feature vector of the posterior
probability estimates of the HMM and a set of gesture features based on the KendonMcNeill taxonomies described above. In earlier work, we show that gesture features can
also improve coreference resolution; we describe a system in which a classifier is trained for
coreference, using a joint feature vector of gesture and textual features (Eisenstein & Davis,
2006). In both approaches, gesture and speech are combined in an unstructured way, such
that even irrelevant hand movements may influence classification decisions. The approach
that we present in this paper includes gesture features only when they are likely to be relevant, substantially improving performance above our previous reported results (Eisenstein
& Davis, 2006).
2.3 Model Combination Techniques for NLP
There is a large literature on integrating non-verbal features into NLP, much of it relating
to prosody. For example, Shriberg, Stolcke, Hakkani-Tur, and Tur (2000) explore the use
of prosodic features for sentence and topic segmentation. The first modality combination
technique that they consider trains a single classifier with all modalities combined into a
single feature vector; this is sometimes called early fusion. They also consider training

358

Gesture Salience as a Hidden Variable

separate classifiers and combining their posteriors, either through weighted addition or
multiplication; this is sometimes called late fusion (see also Liu, 2004). Experiments on
multimodal fusion with prosodic features find no conclusive winner among early fusion,
additive late fusion, and multiplicative late fusion (Shriberg et al., 2000; Kim, Schwarm, &
Osterdorf, 2004). These techniques have also been employed for gesture-speech fusion. In
prior work, we employed early fusion for gesture-speech combination (Eisenstein & Davis,
2006); late fusion has also been applied to gesture-speech combination (Chen et al., 2004,
2006).
Toyama and Horvitz (2000) introduce a Bayesian network approach to modality combination for speaker identification. As in late fusion, modality-specific classifiers are trained
independently. However, the Bayesian approach also learns to predict the reliability of each
modality on a given instance, and incorporates this information into the Bayes net. While
more flexible than early or late fusion, training modality-specific classifiers separately is
still suboptimal compared to training them jointly, because independent training of the
modality-specific classifiers forces them to account for data that they cannot possibly explain. For example, if the speakerâ€™s gestures are not relevant to the language processing
task, it is counterproductive to train a gesture-modality classifier on the features at this
instant; doing so can lead to overfitting and poor generalization.
Our approach combines aspects of both early and late fusion. As in early fusion, classifiers for all modalities are trained jointly. But as in Toyama and Horvitzâ€™s Bayesian late
fusion model, modalities can be weighted based on their predictive power for specific instances. In addition, our model is trained to maximize conditional likelihood, rather than
joint likelihood.
2.4 Related Machine Learning Approaches
From a machine learning perspective, our research relates to three general areas: domain
adaptation, co-training, and hidden-variable conditional models.
In domain adaptation, one has a small amount of â€œin-domainâ€ data that is relevant to
the target classification task, and a large amount of â€œout-of-domainâ€ data from a related,
but different task (Blitzer, McDonald, & Pereira, 2006; Chelba & Acero, 2006). The goal is
to use the out-of-domain data to improve performance in the target domain. In one recent
approach, each feature is replicated and separate weights are learned for the general and
domain-specific applications of the feature (DaumeÌ III, 2007). In a sense, the model learns
which features are relevant generally, and which are relevant only in specific domains. Our
task is somewhat similar, in that we are interested in learning when to apply the gesture
features, while simultaneously learning how they predict coreference. However, one key
difference is that in domain adaptation, the data is partitioned into separate domains in
advance, while our model must learn to identify cases in which the gesture is salient.
Co-training is another technique for combining multiple datasets (Blum & Mitchell,
1998). In co-training, a small amount of labeled data is supplemented by a large amount
of unlabeled data. Given sets of features that are each sufficient to predict the desired
label â€“ called â€œviewsâ€ â€“ separate classifiers can be trained such that the predictions of one
classifier provide the labeled data for the other classifier. Such an approach is shown to
yield better performance than using only the labeled data in some applications, such as

359

Eisenstein, Barzilay, & Davis

parsing (Sarkar, 2001). If large amounts of unlabeled data were available, co-training could
be applied here, using the gesture and verbal features for the independent views. In our
research, acquiring data is a greater bottleneck than creating the coreference annotations.
In addition, previous attempts to apply co-training to textual coreference resolution proved
largely unsuccessful (MuÌˆller, Rapp, & Strube, 2002), possibly because the views were not
independently sufficient to predict the label. While further investigation on this topic is
merited, our approach does not make use of any unlabeled data; instead, we treat gestures
salience as a hidden variable within our existing dataset.
From a methodological standpoint, our work is most closely related to the literature
on hidden variables in conditionally trained models. Quattoni, Collins, and Darrell (2004)
improve object recognition through the use of a hidden variable indicating which â€œpartâ€
of the object contains each localized visual feature. Part-based object recognition had
previously been performed in a generative framework, but the conditional approach permits
the use of a broader feature set, without concern for whether the features are mutually
independent. Subsequent work has shown how conditional hidden-variable models can be
used in gesture recognition (Wang, Quattoni, Morency, Demirdjian, & Darrell, 2006) and
language processing (Koo & Collins, 2005; Sutton, McCallum, & Rohanimanesh, 2007).
Wang et al. (2006) employ a model that is similar to HMM-based gesture recognition,
with the hidden variable encoding different phases of the gesture to be recognized; again,
the conditional approach is shown to improve performance. Hidden variables are applied
to statistical parsing by Koo and Collins (2005), assigning lexical items to word clusters
or word senses. Finally, Sutton et al. (2007) use hidden variables to encode intermediate
levels of linguistic structure that are relevant to the overall language-processing task. For
example, in one application, hidden variables encode part-of-speech tags, which are then
used for noun phrase chunking. We continue this line of work, extending hidden-variable
conditional models with a novel, linguistically-motivated hidden-variable architecture for
gesture-speech combination.

3. Dataset
The research described in this paper is based on a corpus of multimodal presentations.
There are a few existing corpora that include visual data, but none are appropriate for our
research. The Ami corpus (Carletta et al., 2005) includes video and audio from meetings,
but participants are usually seated and their hands are often not visible in the video. The
Vace corpus (Chen et al., 2005) also contains recordings of meetings, with tracking beacons
attached to the speakers providing very accurate tracking. This corpus has not been publicly
released at the time of this writing.
Both corpora address seated meeting scenarios; we have observed that gesture is more
frequent when speakers give standing presentations, as in classroom lectures or business
presentations. There are many such video recordings available, but they have typically
been filmed under circumstances that frustrate current techniques for automatic extraction
of visual features, including camera movement, non-static background, poor lighting, and
occlusion of the speaker. Rather than focusing on these substantial challenges for computer
vision, we chose to gather a new multimodal corpus.

360

Gesture Salience as a Hidden Variable

Figure 2: An example pre-printed diagram used in gathering the corpus. The diagram is a
schematic depiction of a candy dispenser.

In gathering our corpus, we aimed to capture conversations in which gesture was frequent and direct, but also natural and unsolicited. We sought a middle ground between
task-oriented dialogues such as Trains (Allen et al., 1995) and completely open-ended
discussions such as Switchboard (Godfrey, Holliman, & McDaniel, 1992). In our work,
participants were given specific topics for discussion (usually the function of mechanical
devices), but were then permitted to converse without outside interference. The speakers
were given pre-printed diagrams to aid their explanations. The interpretation of gestures in
this condition is usually relatively straightforward; many, if not most of the gestures involve
pointing at locations on the diagram. Visual aids such as printed or projected diagrams
are common to important application areas, including business presentations, classroom
lectures, and weather reports. Thus, this restriction does not seem overly limiting to the
applicability of our work. We leave the presumably more challenging problem of understanding the gestures that are produced without visual aids to future work.
Figure 1 shows two still frames from our corpus, with the accompanying text. The
visual aid is shown in more detail in Figure 2. Our corpus includes sixteen short videos
from nine different speakers. A total of 1137 noun phrases were transcribed; this is roughly
half the number found in the MUC6 training set, a text-only dataset that is also used for
coreference resolution (Hirschman & Chinchor, 1998). Building a multimodal corpus is a
time-consuming task requiring substantial manpower, but we hope that this initial work will
lead to larger future corpora that are well-suited for the study of gesture in natural language
processing. Corpus statistics can be found in Appendix C, and the data is available on-line
at: http : //mug.csail.mit.edu/publications/2008/Eisenstein JAIR/
Finally, we draw the readerâ€™s attention to the differences between this corpus and
commonly-used textual corpora in coreference resolution, such as MUC (Hirschman & Chinchor, 1998). Topically, this corpus focuses on description of mechanical devices, rather than
news articles. Consequently, the emphasis is less on disambiguating entities such as people
and organizations, and more on resolving references to physical objects. The corpora also
differ in genre, with our corpus comprised of spontaneous speech, while the MUC corpus
361

Eisenstein, Barzilay, & Davis

includes edited text. Such genre distinctions are known to play an important role in patterns of reference (Strube & MuÌˆller, 2003) and language use generally (Biber, 1988). Four
different mechanical devices were used as topics of discussion: a piston, candy dispenser
(Figure 2), latch box (shown in Appendix B), and pinball machine.
3.1 Data Gathering Protocol
Fifteen pairs of participants joined the study by responding to posters on our university
campus; their ages ranged from 18-32, and all participants were university students or staff.
A subset of nine pairs of participants was selected on the basis of recording quality,6 and
their speech was transcribed and annotated. The corpus is composed of two videos from
each of the nine pairs; audio recording problems forced us to exclude two videos, yielding
16 annotated documents, each between two and three minutes in duration.
One participant was randomly selected from each pair to be the â€œspeaker,â€ and the other
to be the â€œlistener.â€ The speakerâ€™s role was to explain the behavior of a mechanical device
to the listener. The listenerâ€™s role was to understand the speakerâ€™s explanations well enough
to take a quiz later. Prior to each discussion, the speaker privately viewed a simulation of
the operation of the relevant device.
The speaker was limited to two minutes to view the video or object and three minutes to
explain it; the majority of speakers used all of the time allotted. This suggests that we could
have obtained more natural data by not limiting the explanation time. However, we found
in pilot studies that this led to problematic ordering effects, where participants devoted a
long time to the early conditions, and then rushed through later conditions. With these time
constraints, the total running time of the experiment was usually around 45 minutes. The
data used in this study is part of a larger dataset initially described by Adler, Eisenstein,
Oltmans, Guttentag, and Davis (2004).
3.2 Speech Processing
Speech was recorded using headset microphones. An integrated system controlled the synchronization of the microphones and video cameras. Speech was transcribed manually,
and audio was hand-segmented into well-separated chunks with duration not longer than
twenty seconds. The chunks were then force-aligned by the Sphinx-II speech recognition
system (Huang, Alleva, Hwang, & Rosenfeld, 1993).
A wide range of possibilities exist regarding the fidelity and richness of transcribed
speech. Choices include transcription quality, existence of punctuation and capitalization,
the presence of sentence boundaries and syntactic annotations. We assume a perfect transcription of words and sentence boundaries,7 but no additional punctuation. This is similar
to much of the NLP research on the Switchboard corpus, (e.g., Kahn, Lease, Charniak,
Johnson, & Ostendorf, 2005; Li & Roth, 2001), although automatic speech recognition
(ASR) transcripts are also used (e.g., Shriberg et al., 2000). Using ASR may more accurately replicate the situation for an application developer. However, such an approach
would also introduce a certain arbitrariness, as results would depend heavily on the amount
6. Difficulties with the microphones prevented us from getting suitable audio recordings in several cases; in
other cases there were difficulties in synchronizing the two microphones and two video cameras.
7. Sentence boundaries were annotated according to the NIST Rich Transcription Evaluation (NIST, 2003).

362

Gesture Salience as a Hidden Variable

of effort spent tuning the recognizer. In particular, if the recognizer is not well-tuned, this
approach risks overstating the relative contribution of gesture features, because the verbal
features would then be of little value.
Our natural language task of coreference resolution requires noun phrase boundaries as
a preprocessing step, and we provide gold-standard noun phrase annotation. Our goal is to
isolate the contribution of our model for gesture-speech combination on the coreference task,
and thus we did not wish to deliberately introduce noise in the noun phrase boundaries.
Gold standard noun phrase annotations have been used in previous research on coreference
resolution, (e.g., McCallum & Wellner, 2004; Haghighi & Klein, 2007).8 In addition,
automatic noun phrase chunking is now possible with high accuracy. F-measures exceeding
.94 have been reported on textual corpora (Kudo & Matsumoto, 2001; Sha & Pereira, 2003);
on transcripts of the Switchboard corpus, state-of-the-art performance exceeds .91 (Li &
Roth, 2001).9
The annotation of noun phrases followed the MUC task definition for â€œmarkableâ€ NPs
(Hirschman & Chinchor, 1998). Personal pronouns were not annotated, as the discourse
focused on descriptions of mechanical devices. Such pronouns could easily be filtered out
automatically. Annotation attempted to transcribe all other noun phrases. A total of 1137
markable NPs were transcribed. This is roughly half the size of the MUC6 training set,
which includes 2072 markable NPs over 30 documents. The gold standard coreference and
markable annotation was performed by the first author, using both the audio and video
information.
An additional rater performed coreference annotations to help assess validity. The rater
is a native speaker of English and is not an author on this paper. She annotated two documents, comprising a total of 270 noun phrases. Using the interrater agreement methodology
described by Passonneau (1997), a score of .65 is obtained on Krippendorfâ€™s alpha. This is
comparable to some of the results from the MUC textual corpus (Passonneau, 1997), but
higher than the agreement reported on a corpus of multi-party spoken dialogues (MuÌˆller,
2007).
Finally, we assume gold standard sentence boundaries, but no additional punctuation.
3.3 Vision Processing
Video recording was performed using standard digital camcorders. Participants were given
two different colored gloves to facilitate hand tracking. Despite the use of colored gloves, a
post-study questionnaire indicated that only one of the thirty participants guessed that the
study was related to gesture. The study was deliberately designed so that participants had
very little free time to think; when not actually conducting the dialogue, the speaker was
busy viewing the next mechanical system, and the participant was busy being tested on
the previous conversation. We also presented consent forms immediately after the gloves,
which may have diverted attention from the glovesâ€™ purpose.
8. The cited references do not include noun phrase that unless they participate in coreference relations; we
include all noun phrases regardless.
9. This high accuracy on switchboard does not imply good performance on our data, since we do not
have annotated data for noun phrase boundaries. Thus the overall impact of noisy preprocessing on
coreference performance is unknown. In addition, it is possible that noisy noun phrase boundaries may
pose particular problems for our approach, which assesses gesture features over the duration of the NP.

363

Eisenstein, Barzilay, & Davis

An articulated upper-body tracker was used to model the position of the speakerâ€™s torso,
arms, and hands. By building a complete upper-body tracker, rather than simply tracking
the individual hands, we were able to directly model occlusion of the hands and arms. At
each frame, an annealed particle filter is used to search the space of body configurations.
Essentially, the system performs a randomized beam search to simultaneously achieve three
objectives: a) maximize the overlap between the model and pixels judged to be in the
foreground, b) match the known glove color to the color observed at the hypothesized hand
positions, c) respect physiological constraints and temporal continuity. The system was
implemented using the OpenCV library.10
The tracker was inspired largely by the annealed particle filter of Deutscher, Blake,
and Reid (2000); the main differences were that Deutscher et al. did not use color cues
such as gloves, but did use multiple cameras to facilitate 3D tracking. We used only a
single monocular camera and a 2.5D model (with just one degree of freedom in the depth
plane, permitting body rotation). Parameters of the model, such as the body dimensions,
are customized for each speaker. Each speaker provided two different explanations, and
the segmentation of these videos was performed manually. No additional post-processing,
calibration, or â€œcleaningâ€ of the tracker output is performed.
From inspection, the lack of depth information appears the cause of many of our systemâ€™s
errors; bending of the arm joints in the depth dimension caused the arm length to appear
to change in ways that were confusing to our model. Nonetheless, we estimate by manual
examination of the tracking output that both hands were tracked accurately and smoothly
over 90% of the time when not occluded. It is difficult to assess the tracker performance
more precisely, as that would require ground truth data in which the actual hand positions
were annotated manually at each time step.

4. Conditional Modality Fusion for Coreference Resolution
In this section we describe conditional modality fusion. In Section 4.1 we describe how
hidden variables are incorporated in conditional models. Then in Section 4.2, we describe
how various theories of model combination are expressed in this framework. In Section 4.3,
we give details of our implementation.
4.1 Hidden Variables in Conditional Models
Our goal is to learn to use non-verbal features to make predictions when they are helpful,
and ignore them when they are not. We call this approach conditional modality fusion.
More formally, we are trying to predict a label y âˆˆ {âˆ’1, 1}, representing a single binary
coreference decision of whether two noun phrases refer to the same entity.
The hidden variable h describes the salience of the gesture features. The observable
features are written as x, and our model is to learn a set of weights w. Our hidden variable
approach learns to predict y and h jointly, given labeled training data only for y. We use
a conditional model, writing:
10. http://www.intel.com/technology/computing/opencv/

364

Gesture Salience as a Hidden Variable

p(y|x; w) =

X

p(y, h|x; w)

h

=

P
exp(Ïˆ(y, h, x; w))
P h
.
0
y 0 ,h exp(Ïˆ(y , h, x; w))

Here, Ïˆ is a potential function representing the compatibility between the label y, the
hidden variable h, and the observations x; this potential is parameterized by a vector of
weights, w. The numerator expresses the compatibility of the label y and observations x,
summed over all possible values of the hidden variable h. The denominator sums over both
h and all possible labels y 0 , yielding the conditional probability p(y|x; w).
This model can be trained by a gradient-based optimization to maximize the conditional
log-likelihood of the observations. The unregularized log-likelihood and gradient are given
by:
l(w)

=

X

log(p(yi |xi ; w))

(1)

P
exp(Ïˆ(yi , h, xi ; w))
log P h
0
y 0 ,h exp(Ïˆ(y , h, xi ; w))

(2)

i

=

X
i

âˆ‚li
âˆ‚wj

=

X
h

p(h|yi , xi ; w)

X
âˆ‚
âˆ‚
Ïˆ(yi , h, xi ; w) âˆ’
p(h, y 0 |xi ; w)
Ïˆ(y 0 , h, xi ; w)
âˆ‚wj
âˆ‚w
j
0
y ,h

The use of hidden variables in a conditionally-trained model follows Quattoni et al.
(2004). However, while this reference gives the general outline for hidden-variable conditional models, the form of the potential function depends on the role of the hidden variable.
This is problem-specific, and a novel contribution of our research is the exploration of several
different potential functions, permitting different forms of modality fusion.
4.2 Models of Modality Fusion
The form of the potential function Ïˆ is where our intuitions about the role of the hidden
variable are formalized. We consider three alternative forms for Ïˆ, capturing different
theories of gesture-speech integration. The models range from a simple concatenation of
gesture-speech features to a structured fusion model that dynamically assesses the relevance
of gesture features for every noun phrase.
The models we consider are influenced by our goal, which is to determine whether two
noun phrases (NPs) are coreferent. Gesture salience is assessed at each NP, to determine
whether the gestural features should influence our decision about whether the noun phrases
corefer. We set h = hh1 , h2 i, with h1 âˆˆ {1, âˆ’1} representing gesture salience during the
first noun phrase (antecedent), and h2 âˆˆ {1, âˆ’1} representing gesture salience during the
second noun phrase (anaphor).

365

Eisenstein, Barzilay, & Davis

4.2.1 Same-Same model
In the trivial case, we ignore the hidden variable and always include the features from both
gesture and speech. Since the weight vectors for both modalities are unaffected by the
hidden variable, this model is referred to as the â€œsame-sameâ€ model. Note that this is
identical to a standard log-linear conditional model, concatenating all features into a single
vector. This model is thus a type of â€œearly fusion,â€ meaning that the verbal and non-verbal
features are combined prior to training.
T
Ïˆss (y, h, x; w) â‰¡ y(wvT xv + wnv
xnv )

(3)

xv and wv refer to the features and weights for the verbal modality; xnv and wnv refer
to the non-verbal modality.
4.2.2 Same-Zero Model
Next, we consider a model that treats the hidden variable as a gate governing whether the
gesture features are included. This model is called the â€œsame-zeroâ€ model, since the verbal
features are weighted identically regardless of the hidden variable, and the gesture feature
weights go to zero unless h1 = h2 = 1.
(
T x ) + h wT x + h wT x , h = h = 1
y(wvT xv + wnv
1
2
2 h h2
nv
1 h h1
Ïˆsz (y, h, x; w) â‰¡
otherwise.
ywvT xv + h1 whT xh1 + h2 whT xh2 ,

(4)

The features xh and weights wh contribute to the estimation of the hidden variable h.
They may include some or all of the features from xv and xnv , or different features. These
features are assessed independently at each noun phrase, yielding xh1 for the antecedent
and xh2 for the anaphor.
This model reflects the intuition that gesture features (measured by xnv ) are relevant
only when the gestures during both noun phrases are salient. Thus, these features contribute
towards the overall potential only when h1 = h2 = 1.
4.2.3 Different-Zero Model
We may add flexibility to our model by permitting the weights on the verbal features to
change with the hidden variable. This model is called the â€œdifferent-zeroâ€ model, since a
different set of verbal weights (wv,1 or wv,2 ) is used depending on the value of the hidden
variable. Such a model is motivated by empirical research showing language usage is different when used in combination with meaningful non-verbal communication than when it is
used unimodally (Kehler, 2000; Melinger & Levelt, 2004).
The formal definition of the potential function is:
(
T x + wT x ) + h wT x + h wT x , h = h = 1
y(wv,1
v
1 h h1
2 h h2
1
2
nv nv
Ïˆdz (y, h, x; w) â‰¡
T
T
T
ywv,2 xv + h1 wh xh1 + h2 wh xh2 ,
otherwise.

366

(5)

Gesture Salience as a Hidden Variable

4.2.4 Other Models
We have presented three models of increasing complexity; the â€œdifferent-differentâ€ model is
one step more complex, including two pairs of weight vectors for both verbal and gestural
features (see Equation 6). In this model, the distinction between verbal and non-verbal
features (xv and xnv ) evaporates, and there is no reason that the hidden variable h should
actually indicate the relevance of the non-verbal features. In addition, the high degree of
freedom of this model may lead to overfitting.
(
T x + wT x ) + h wT x + h wT x , h = h = 1
y(wv,1
v
1 h h1
2 h h2
1
2
nv,1 nv
Ïˆdd (y, h, x; w) â‰¡
T x + wT x ) + h wT x + h wT x , otherwise.
y(wv,2
v
1 h h1
2 h h2
nv,2 nv

(6)

The models that we have considered assume that the verbal features are always relevant, while the gesture features may sometimes be ignored. In other words, we have not
considered whether it might be necessary to assess the salience of the verbal features. One
might consider alternative potential functions such as a â€œzero-sameâ€ model, in which the
verbal features were sometimes ignored. We did not consider such models, as gesture unaccompanied by speech is extremely rare in our dataset.
4.3 Implementation
The objective function (Equation 1) is optimized using a Java implementation of L-BFGS,
a quasi-Newton numerical optimization technique (Liu & Nocedal, 1989). Standard L2norm regularization is employed to prevent overfitting, with cross-validation to select the
regularization constant. Java source code is available online:
http://rationale.csail.mit.edu/gesture
Although standard logistic regression optimizes a convex objective, the inclusion of the
hidden variable renders our objective non-convex. Thus, convergence to a global optimum
is not guaranteed, and results may differ depending on the initialization. Nonetheless, nonconvexity is encountered with many models in natural language processing and machine
learning generally, such as Baum-Welch training of hidden Markov models (HMMs) (Rabiner, 1989) or hidden-state conditional random fields (Quattoni et al., 2004; Sutton &
McCallum, 2006). Often, results can be shown to be reasonably robust to initialization;
otherwise, multiple restarts can be used to obtain greater stability. We present an empirical
evaluation in Section 6.2 showing that our results are not overly sensitive to initialization. In
all other experiments, weights are initialized to zero, enabling the results to be reproduced
deterministically.

5. Features
Coreference resolution has been studied for over thirty years in the AI community (Sidner, 1979; Kameyama, 1986; Brennan, Friedman, & Pollard, 1987; Lappin & Leass, 1994;
Walker, 1998; Strube & Hahn, 1999; Soon, Ng, & Lim, 2001; Ng & Cardie, 2002). Based
on this large body of work, there is a broad consensus on a core set of useful verbal features. This paper contributes to the literature with the study of gesture features, both for
multimodal coreference resolution and for identifying salient gestures. We describe these
367

Eisenstein, Barzilay, & Davis

feature
edit-distance
exact-match
str-match
nonpro-str

type
similarity
similarity
similarity
similarity

pro-str
j-substring-i
i-substring-j
overlap
np-dist
sent-dist
both-subj
same-verb
number-match

similarity
similarity
similarity
similarity
centering-based
centering-based
centering-based
centering-based
compatibility

pronoun
count
has-modifiers
indef-np
def-np
dem-np
lexical features

centering-based
centering-based
centering-based
centering-based
centering-based
centering-based
centering-based

Pairwise verbal features
description
a numerical measure of the string similarity between the two NPs
true if the two NPs are identical
true if the NPs are identical after removing articles
true if the antecedent i and the anaphor j are not pronouns, and
str-match is true
true if i and j are pronouns, and str-match is true
true if the j is a substring of the i
true if i is a substring of j
true if there are any shared words between i and j
the number of noun phrases between i and j in the document
the number of sentences between i and j in the document
true if both i and j precede the first verb of their sentences
true if the first verb in the sentences for i and j is identical
true if i and j have the same number
Single-phrase verbal features
true if the NP is a pronoun
number of times the NP appears in the document
true if the NP has adjective modifiers
true if the NP is an indefinite NP (e.g., a fish)
true if the NP is a definite NP (e.g., the scooter )
true if the NP begins with this, that, these, or those
lexical features are defined for the most common pronouns: it, that,
this, and they

Table 1: The set of verbal features for multimodal coreference resolution. In this table, i
refers to the antecedent noun phrase and j refers to the anaphor.

features in Sections 5.2 and 5.3, but we begin with a review of the verbal features which we
have selected from the literature.
5.1 Verbal Features
Our selection of verbal features is motivated by the extensive empirical literature on textbased coreference resolution (Soon et al., 2001; Ng & Cardie, 2002; Strube & MuÌˆller, 2003;
DaumeÌ III & Marcu, 2005). The proliferation and variety of features that have been explored
is a consequence of the fact that coreference is a complex discourse phenomenon. Moreover,
realization of coreference is highly dependent on the type of discourse in which it appears;
relevant factors include the modality (e.g., speech vs. language), genre (e.g., meeting vs.
lecture) and topic (e.g., politics vs. scientific subject). Although certain feature types are
application-specific, three classes of features â€“ centering-based, similarity, and compatibility
features â€“ are useful across most coreference applications. These classes form a basis of the
verbal features used by our model. Table 1 provides a brief description of our verbal feature
set. We draw examples from the transcript in Appendix A to provide a more detailed
explanation of these features and motivate their use in our application.

368

Gesture Salience as a Hidden Variable

focus-distance
DTW-agreement
same-cluster*
JS-div*
dist-to-rest
jitter
speed
rest-cluster*
movement-cluster*

Pairwise gesture features
the Euclidean distance in pixels between the average hand position during the two
NPs
a measure of the agreement of the hand-trajectories during the two NPs, computed
using dynamic time warping
true if the hand positions during the two NPs fall in the same cluster
the Jensen-Shannon divergence between the cluster assignment likelihoods
Single-phrase gesture features
distance of the hand from rest position
sum of instantaneous motion across NP
total displacement over NP, divided by duration
true if the hand is usually in the cluster associated with rest position
true if the hand is usually in the cluster associated with movement

Table 2: The set of gesture features for multimodal coreference resolution. Features not
used in prior work on gesture analysis are annotated with an asterisk (*).

â€¢ Centering-related features: This set of features captures the relative prominence
of a discourse entity in a local discourse, and its likelihood to act as a coreferent for
a given phrase. These features are inspired by linguistic analysis formalized in Centering Theory, which links coreferential status of an entity with its discourse prominence (Grosz, Joshi, & Weinstein, 1995; Walker, Joshi, & Prince, 1998; Strube &
Hahn, 1999; Poesio, Stevenson, Eugenio, & Hitzeman, 2004; Kibble & Power, 2004).
This theory hypothesizes that at any point of a coherent discourse, only one entity
is in focus and it characterizes local discourse in terms of focus transitions between
adjacent sentences.
Most of the existing machine-learning based coreference systems do not attempt to
fully implement Centering-style analysis.11 Instead, a number of centering-related features are included. For instance, to identify focus-preserving transitions (i.e., CONTINUE transitions) a feature both-subj is introduced. According to the theory,
such transitions are common in locally-coherent discourse, and therefore coreference
assignments consistent with this principle may be preferable. We also characterize
transitions in terms of their span (np-dist and sent-dist). Transitions that involve
short gaps are preferred over transitions with long gaps.
Another important set of Centering-related features is defined at the level of a single
phrase. The syntactic role of a phrase in a sentence â€“ captured in features such
as pronoun, has-modifiers, indef-np â€“ indicates its discourse prominence and
therefore its likelihood to be a coreference antecedent. For example, consider an
utterance from lines 12 and 13: â€œand this spring is active meaning that its going up
and down.â€ Here, the anaphor â€œitâ€ clearly refers to the antecedent â€œthis spring.â€ The
11. Such an implementation is challenging in several respects: one has to specify the â€œfree parametersâ€ of
the system (Poesio et al., 2004) and to determine ways of combining the effects of various constraints.
Additionally, an implementation of centering depends on obtaining detailed syntactic information, which
is not available in our case.

369

Eisenstein, Barzilay, & Davis

fact that the antecedent is a demonstrative noun phrase (beginning with â€œthisâ€)12
and that the anaphor is a pronoun are also centering-related features that suggest
coreference is likely. In addition to the syntactic status, we also take into account
the frequency of a noun phrase in a monologue (see count). Frequency information
is commonly used to approximate topical salience of an entity in a text (Barzilay &
Lapata, 2005).
â€¢ Similarity features: A simple yet informative set of coreference cues are based on
string-level similarity between noun phrases. For instance, the reference between â€œthis
springâ€ in line 12 and the identical noun phrase in line 5 can be resolved by the exact
match of the surface forms. In general, researchers in text-based coreference resolution
have found that the string match feature is the single most predictive feature because
a discourse entity is commonly described using identical or similar noun phrases (Soon
et al., 2001).
In our system, the similarity information is captured in seven features that quantify
the degree of string overlap. For instance, the feature (exact-match) indicates full
overlap between noun phrases, while the feature (overlap) captures whether two
phrases share any common words. In the context of coreference resolution, noun
phrase match is more informative than pronoun match, so we use distinct features
for matching strings in these syntactic categories (e.g., nonpro-str vs. pro-str),
following (Ng & Cardie, 2002). Surface similarity may also be quantified in terms of
edit-distance (Strube, Rapp, & MuÌˆller, 2002).
â€¢ Compatibility features: An important source of coreference information is compatibility between two noun phrases. For instance, the utterance â€œthe ballâ€ in line 11
can not refer to the preceding noun phrase â€œthese things,â€ since they are incompatible in number. Feature number-match captures this information. Since the topic
of discourse in our corpus relates to mechanical devices, almost all noun phrases are
neuter-gendered. This eliminates the utility of features that measure gender compatibility. Finally, we note that more complex semantic compatibility features have
previously been explored (Harabagiu, Bunescu, & Maiorano, 2001; Strube et al., 2002;
Yang, Zhou, Su, & Tan, 2003; Ji, Westbrook, & Grishman, 2005; DaumeÌ III & Marcu,
2005; Yang, Su, & Tan, 2005).
Some features that are traditionally used in coreference were avoided here. Features
that depend on punctuation seem unlikely to be applicable in an automatic recognition
setting, at least in the near future. In addition, while many systems in the MUC and ACE
coreference corpora use â€œgazetteersâ€ that list the names of nations and business entities,
such features are not relevant to our corpus. Another possibility is to use features identifying
the speaker, to capture individual variation in patterns of reference (Chai, Hong, Zhou, &
Prasov, 2004; Jordan & Walker, 2005). However, we wished to develop an approach that
was speaker-independent.
12. Simple string matching techniques are used to assess phrase types: definite noun phrases are those
beginning with the article â€œtheâ€; indefinite noun phrases begin with â€œaâ€ or â€œanâ€; demonstrative noun
phrases begin with â€œthis.â€ Bare plurals are not marked as indefinites, and proper names do not appear
in the dataset.

370

Gesture Salience as a Hidden Variable

5.2 Non-Verbal Features
Our non-verbal features attempt to capture similarity between the speakerâ€™s hand gestures,
as similar gestures can suggest semantic similarity (McNeill, 1992; Quek et al., 2002a).
For example, two noun phrases may be more likely to corefer if they are accompanied
by identical pointing gestures. In this section, we describe features that quantify various
aspects of gestural similarity.
In general, these features are computed over the duration of each noun phrase, yielding a single feature vector per NP. While it is not universally true that the beginning and
end points of relevant gestures line up exactly with the beginning and end of the associated words, several experiments have demonstrated the close synchrony of gesture and
speech (McNeill, 1992). In future work, we hope to explore whether more sophisticated
gesture segmentation techniques can improve performance.
The most straightforward measure of similarity is the Euclidean distance between the
average hand position during each noun phrase â€“ we call this focus-distance.13 Euclidean
distance captures cases in which the speaker is performing a gestural â€œholdâ€ in roughly the
same location (McNeill, 1992). However, Euclidean distance may not correlate directly
with semantic similarity. For example, when gesturing at a detailed part of a diagram,
very small changes in hand position may be semantically meaningful, while in other regions
positional similarity may be defined more loosely. Ideally, we would compute a semantic
feature capturing the object of the speakerâ€™s reference (e.g., â€œthe red blockâ€), but this is not
possible in general, since a complete taxonomy of all possible objects of reference is usually
unknown.
Instead, we perform a spatio-temporal clustering on hand position and velocity, using a
hidden Markov model (HMM). Hand position and speed are used as observations, and are
assumed to be generated by Gaussians, indexed by the model states. The states themselves
correspond to clusters, and cluster membership can be used as a discretized representation
of positional similarity. Inference of state membership and learning of model parameters are
performed using the traditional forward-backward and Baum-Welch algorithms (Rabiner,
1989).
While a standard hidden Markov model may be suitable, we can increase robustness
and make better use of available training data by reducing the modelâ€™s degrees-of-freedom.
Reducing the number of degrees-of-freedom means that we are learning simpler models,
which are often more general. This is done through parameter tying: requiring some subsets
of model parameters to take the same values (Bishop, 2006). We employ three forms of
parameter tying:
1. Only one state is permitted to have an expected speed greater than zero. This state is
called the â€œmoveâ€ state; all other states are â€œholdâ€ states, and their speed observations
are assumed to be generated by zero-mean Gaussians. Only a single â€œmoveâ€ state is
used because we are most concerned about the location of hold gestures.
2. Transitions between distinct hold states are not permitted. This reflects the commonsense idea that it is not possible to transition between two distinct positions without
moving.
13. In general, features are computed over the duration of individual noun phrases.

371

Eisenstein, Barzilay, & Davis

3. The outgoing transition probabilities from all hold states are assumed to be identical.
Intuitively, this means that the likelihood of remaining within a hold state does not
depend on where that hold is located. While it is possible to imagine scenarios in
which this does not hold, it is a reasonable simplification that dramatically reduces
the number of parameters to be estimated.
Two similarity features are derived from the spatio-temporal clustering. The samecluster feature reports whether the two gestures occupy the same state for the majority
of the durations of the two noun phrases. This is a boolean feature that indicates whether
two gestures are in roughly the same area, without need for an explicit discretization step.
However, two nearby gestures may not be classified as similar by this method, if they are
near the boundary between two states, or if both gestures move between multiple states.
For this reason, we quantify the similarity of the state assignment probabilities using the
Jensen-Shannon divergence, a metric on probability distributions (Lin, 1991). JS-div is a
real-valued feature that provides a more nuanced view of the gesture similarity based on the
HMM clustering. Both same-cluster and JS-div are computed independently for models
comprising five, ten, and fifteen states.
The gesture features described thus far largely capture the similarity between static
gestures; that is, gestures in which the hand position is nearly constant. However, these
features do not capture the similarity between gesture trajectories, which may also be used
to communicate meaning. For example, a description of two identical motions might be
expressed by very similar gesture trajectories. To measure the similarity between such
dynamic gestures, we use dynamic time warping (Huang, Acero, & Hon, 2001); this is
reported in the DTW-distance feature. Dynamic time warping has been used frequently
in recognition of predefined gestures (Darrell & Pentland, 1993).
All features are computed from hand and body pixel coordinates, which are obtained
automatically via computer vision, without manual post-processing of any kind (see Section 3.3). Our feature set currently supports only single-hand gestures, using the hand that
is farthest from the body center. As with the verbal feature set, Wekaâ€™s default supervised
binning class was applied to the continuous-valued features (Fayyad & Irani, 1993).14 This
method identifies â€œcut pointsâ€ that minimize the class-wise impurity of each side of the cut,
measured using average class entropy. A greedy top-down approach is used to recursively
partition the domain of an attribute value. Partitioning is terminated by a criterion based
on minimum description length.
5.3 Meta Features
Meta features are observable properties of the speech and gesture that give clues about
whether the speaker is gesturing in a way that is meaningful for the language language
processing task at hand. We hypothesize that the difference between relevant and irrelevant hand motions is apparent in a range of verbal and visual features. In equations 4-6,
these features are represented by xh1 and xh2 . Unlike the similarity-based features described above, meta features must be computable at a single instant in time, as they encode
properties of individual gestures and their cotemporal NPs.
14. The specific class is weka.filters.supervised.attribute.Discretize.

372

Gesture Salience as a Hidden Variable

Previous research has investigated which types of verbal utterances are likely to be
accompanied by gestural communication (Melinger & Levelt, 2004; Kehler, 2000). However,
this is the first attempt to formalize this relationship in the context of a machine-learning
approach that predicts gesture salience.
5.3.1 Verbal Meta Features
Meaningful gesture has been shown to be more frequent when the associated speech is
ambiguous (Melinger & Levelt, 2004). Kehler (2000) finds that fully-specified noun phrases
are less likely to receive multimodal support. These findings lead us to expect that gestures
should be likely to co-occur with pronouns, and unlikely to co-occur with noun phrases that
begin with the determiner â€œthe,â€ particularly if they include adjectival modifiers. To capture
these intuitions, all single-phrase verbal features (Table 1) are included as meta-features.
5.3.2 Non-verbal Meta Features
Research on gesture has shown that semantically meaningful hand motions usually take
place away from â€œrest position,â€ which is located at the speakerâ€™s lap or sides (McNeill,
1992). Effortful movements away from these default positions can thus be expected to
predict that gesture is being used to communicate. We identify rest position as the center
of the body on the x-axis, and at a fixed, predefined location on the y-axis. The dist-torest feature computes the average Euclidean distance of the hand from the rest position,
over the duration of the NP.
Hand speed may also be related to gesture salience. The speed feature captures the
overall displacement (in pixels) divided by the length of the noun phrase. Writing x for the
hand position and t âˆˆ {1, 2, . . . , T } for the time index, we have speed = T1 ||xT âˆ’ x1 ||2 . The
P
jitter feature captures the average instantaneous speed: jitter = T1 Tt=2 (xt âˆ’xtâˆ’1 )T (xt âˆ’
xtâˆ’1 ). This feature captures periodic or jittery motion, which will not be quantified by the
speed feature if the end position is not far from the original position. Also, high jitter
often indicates that the tracker has lost the hand position, which would be an excellent
reason to ignore the gesture features.
As noted in the previous section, an HMM was used to perform a spatio-temporal
clustering on the hand positions and velocities. The rest-cluster feature takes the value
â€œtrueâ€ iff the most frequently occupied state during the NP is the closest to rest position.
In addition, parameter tying is used in our HMM to ensure that all states but one are
static holds, and this remaining state represents the transition movements between those
holds. Only this last state is permitted to have an expected non-zero speed; if the hand is
most frequently in this state during the NP, then the movement-cluster feature takes
the value â€œtrue.â€

6. Evaluation on Coreference Resolution
In this evaluation, we assess whether gesture features improve coreference resolution, and we
compare conditional modality fusion to other approaches for gesture-speech combination.

373

Eisenstein, Barzilay, & Davis

6.1 Evaluation Setup
We describe our procedure for evaluating the performance of our approach. This includes the
evaluation metric (Section 6.1.1), baselines for comparison (Section 6.1.2), and parameter
tuning (Section 6.1.3). The coreference annotations were described in Section 3.2.
6.1.1 Evaluation Metric
Coreference resolution is often performed in two phases: a binary classification phase, in
which the likelihood of coreference for each pair of noun phrases is assessed; and a global
partitioning phase, in which the clusters of mutually-coreferring NPs are formed. Our model
does not address the global partitioning phase, only the question of whether each pair of
noun phrases in the document corefer. Moving from pairwise noun phrase coreference to
global partitioning requires a clustering step that may obscure performance differences on
the level at which our model operates. Moreover, these results will depend on the choice
of the clustering algorithm and the mechanism for selecting the number of clusters (or,
alternatively, the cut-off value on merging clusters). This parameterization is particularly
challenging for our corpus because we do not have a large dedicated development set. Consequently, the bulk of our evaluation is performed on the binary classification phase. However, for the purpose of comparing with prior work on coreference, we also perform a global
evaluation, which measures the overall results after clustering.
For the binary evaluation, we use the area under the ROC curve (auc) as an error metric (Bradley, 1997). auc evaluates classifier performance without requiring the specification
of a cutoff. This metric penalizes misorderings â€“ cases in which the classifier ranks negative
examples more highly than positive examples. Such ROC analysis is increasingly popular,
and has been used in a variety of NLP tasks, including the detection of action items in
emails (Bennett & Carbonell, 2007) and topic segmentation (Malioutov & Barzilay, 2006).
Although binary evaluation is not typically used for coreference resolution, we believe it is
an appropriate choice here, for the reasons noted above.
The global evaluation uses the constrained entity-alignment f-measure (ceaf) for evaluation (Luo, 2005). This metric avoids well-known problems with the earlier MUC evaluation
metric (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995). The clustering step is
performed using two standard techniques from the literature, which we describe in Section 6.3. In future work we plan to explore techniques that perform coreference in a single
joint step (e.g., DaumeÌ III & Marcu, 2005). Then a global metric would be more appropriate
to measure the contributions of our model directly.
6.1.2 Baselines
Conditional modality fusion (cmf) is compared with traditional approaches to modality
combination for NLP tasks:
â€¢ Early fusion. The early fusion baseline includes all features in a single vector,
ignoring modality. This is equivalent to standard maximum-entropy classification.
Early fusion is implemented with a conditionally-trained log-linear classifier; it uses
the same code as the cmf model, but always includes all features.

374

Gesture Salience as a Hidden Variable

â€¢ Late fusion. The two late fusion baselines train separate classifiers for gesture and
speech, then combine their posteriors. The modality-specific classifiers are conditionallytrained log-linear classifiers, and again use the same code as the cmf model. For
simplicity, a parameter sweep identifies the interpolation weights that maximize performance on the test set. Thus, it is likely that these results somewhat overestimate
the performance of these baseline models. Both additive and multiplicative combination are considered.
â€¢ No fusion. These baselines include the features from only a single modality, and
again build a conditionally-trained log-linear classifier. Implementation uses the same
code as the cmf model, but weights on features outside the target modality are forced
to zero.
An important question is how our results compare with existing state-of-the-art coreference systems. The â€œno fusion, verbal features onlyâ€ baseline provides a reasonable representation of prior work on coreference, by applying a maximum-entropy classifier to a set
of typical textual features. A direct comparison with existing implemented systems would
be ideal, but all such available systems use textual features that are inapplicable to our
spoken-language dataset, such as punctuation, capitalization, and gazetteers.
6.1.3 Parameter Tuning
As the small size of the corpus did not permit dedicated test and training sets, results
are computed using leave-one-out cross-validation, with one fold for each of the sixteen
documents in the corpus. Parameter tuning was performed using cross validation within
each training fold. This includes the selection of the regularization constant, which controls
the trade-off between fitting the training data and learning a model that is simpler (and
thus, potentially more general). In addition, binning of continuous features was performed
within each cross-validation fold, using the method described in Section 5.2. Finally, as
noted above, model weights are initialized to zero, enabling deterministic reproducibility of
the experiments.
6.2 Results
Conditional modality fusion outperforms all other approaches by a statistically significant
margin (Table 4). Compared with early fusion, the different-zero model for conditional
modality fusion offers an absolute improvement of 1.17% in area under the ROC curve (auc)
â€“ compare lines 1 and 4 in the table. A paired t-test shows that this result is statistically
significant (p < .01, t(15) = 3.73). cmf obtains higher performance on fourteen of the
sixteen cross-validation folds. Both additive and multiplicative late fusion perform on par
with early fusion. The p-values of the significance tests for of all pairwise comparisons are
shown in Table 5.
Early fusion with gesture features is superior to unimodal verbal classification by an
absolute improvement of 1.64% auc (p < .01, t(15) = 4.45) â€“ compare lines 4 and 7 in
Table 4. The additional 1.17% auc provided by conditional modality fusion amounts to a
relative 73% increase in the power of the gesture features. The results are relatively robust
to variations in the regularization constant, as shown in Figure 3. This means that the
375

Eisenstein, Barzilay, & Davis

cmf different-different (DD)

cmf different-zero (DZ)

cmf same-zero (SZ)

Early fusion (E)

Late fusion, multiplicative (LM)

Late fusion, additive (LA)

No fusion (VO, GO)

Uses two different sets of weights for both verbal and gestural features, depending on the
hidden variable (equation 6).
Uses different weights on the verbal features
depending on the hidden variable; if the hidden variable indicates non-salience, gesture
weights are set to zero (equation 5).
Uses the same weights on verbal features regardless of gesture salience; if the hidden variable indicates non-salience, gesture weights
are set to zero (equation 4).
Standard log-linear classifier. Uses the same
weights on verbal and gestural features, regardless of hidden variable (equation 3).
Trains separate log-linear classifiers for gesture and verbal features. Combines posteriors
through multiplication.
Trains separate log-linear classifiers for gesture and verbal features. Combines posteriors
through interpolation.
Uses only one modality for classification.

Table 3: Summary of systems compared in this evaluation

model
1. cmf different-zero
2. cmf different-different
3. cmf same-zero
4. Early fusion (same-same)
5. Late fusion, multiplicative
6. Late fusion, additive
7. No fusion (verbal features only)
8. No fusion (gesture features only)

auc
.8226
.8174
.8084
.8109
.8103
.8068
.7945
.6732

Table 4: Coreference performance, in area under the ROC curve (auc). The systems are
described in Table 3

376

Gesture Salience as a Hidden Variable

DD
.01

cmf different-zero (DZ)
cmf different-different (DD)
cmf same-zero (SZ)
Early fusion (E)
Late fusion, multiplicative (LM)
Late fusion, additive (LA)
Verbal features only (VO)
Gesture features only (GO)

SZ
.01
.05

E
.01
ns
ns

LM
.01
ns
ns
ns

LA
.01
.05
ns
ns
ns

VO
.01
.01
.05
.01
.01
.01

GO
.01
.01
.01
.01
.01
.01
.01

Table 5: P-values of the pairwise comparison between models. â€œnsâ€ indicates that the
difference in model performance is not significant at p < .05. The parentheses in
the left column explain the abbreviations in the top line.

Comparison between models

Comparison among CMF models

0.82
area under ROC curve

area under ROC curve

0.82
0.81
0.8
0.79
CMF (diffâˆ’zero)
early fusion
verbalâˆ’only

0.78
0.77

1

2

3
4
5
6
log of regularization constant

7

0.81
0.8
0.79
differentâˆ’zero
differentâˆ’different
sameâˆ’zero

0.78
0.77

8

1

2

3
4
5
6
log of regularization constant

7

8

Figure 3: Results with regularization constant

performance gains obtained by conditional modality fusion are not highly dependent on
finding the optimal regularization constant.
As noted in Section 4.3, conditional modality fusion optimizes a non-convex objective.
We perform an additional evaluation to determine whether performance is sensitive to initialization. Randomizing the weights over five different iterations with our best-performing
system, we observed a standard deviation of 1.09 âˆ— 10âˆ’3 in area under the ROC curve
(auc). In all other experiments the weights were initialized to zero, enabling the results to
be reproduced deterministically.
6.3 Global Metric
Coreference is traditionally evaluated with a global error metric. Our research is directed
specifically at the binary classification of coreference between pairs of noun phrases, so we

377

Eisenstein, Barzilay, & Davis

model
cmf (different-zero)
cmf (different-different)
cmf (same-zero)
Early fusion (same-same)
Late fusion, multiplicative
Late fusion, additive
No fusion (verbal features only)
No fusion (gesture features only)

first-antecedent
55.67
54.71
53.91
54.18
53.74
53.56
53.47
44.68

best-antecedent
56.02
56.20
55.32
55.50
54.44
55.94
55.15
44.85

Table 6: ceaf global evaluation scores, using best clustering threshold
Firstâˆ’antecedent clustering

Bestâˆ’antecedent clustering

0.5

0.5
CEAF

0.55

CEAF

0.55

0.45

0.45

0.4

0.4
CMF (diffâˆ’zero)
late fusion, additive
verbal only

0.35
0.1

0.2

0.3
0.4
0.5
clustering threshold

CMF (diffâˆ’zero)
late fusion, additive
verbal only
0.35
0.1

0.6

0.2

0.3
0.4
0.5
clustering threshold

0.6

Figure 4: Global coreference performance, measured using ceaf scores, plotted against the
threshold on clustering

have focused on evaluating that specific portion of the larger coreference problem. However,
for the purpose of comparing with prior research on coreference, we present results using a
more traditional global metric.
To perform a global evaluation, we must cluster the noun phrases in the document, using
the pairwise coreference likelihoods as a similarity metric. We experiment with two clustering methods that are commonly used in the literature. The first-antecedent technique
resolves NPs to the first antecedent whose similarity is above a predefined threshold (Soon
et al., 2001). The best-antecedent technique resolves each noun phrase to the most compatible prior noun phrase, unless none is above the threshold (Ng & Cardie, 2002).
Figure 4 shows the global scores, plotted against the value of the clustering threshold.
For clarity, only the best performing system from each class is shown: for conditional
378

Gesture Salience as a Hidden Variable

modality fusion, we plot the different-zero model; from the multimodal baselines, we plot the
additive late fusion model (the combination of additive late fusion and the best-antecedent
clustering method is the best performing multimodal baseline); from the unimodal baseline,
we plot the verbal-features only baseline. Table 6 lists the performance of each method at
its optimum clustering threshold. For comparison, Ng reports a ceaf score of 62.3 (Ng,
2007) on the ACE dataset, although the results are not directly comparable due to the
differences in corpora.
As shown in these results, performance is sensitive to both the clustering method and the
clustering threshold. Conditional modality fusion generally achieves the best results, and
best-antecedent clustering generally outperforms the first-antecedent technique. Nonetheless, the advantage of conditional modality fusion is smaller here than with ROC analysis.
We believe that ROC analysis demonstrates the advantage of conditional modality fusion
more directly, while the global metric interposes a clustering step that obscures differences
between the classification techniques. Nonetheless, the global metric may be a better overall measure of the quality of coreference for downstream applications such as search or
summarization. In future work, we hope to investigate whether the conditional modality
fusion approach can be applied to global models of coreference that do not require separate
classification and clustering phases (e.g., DaumeÌ III & Marcu, 2005).
6.4 Feature Analysis
The machine learning approach that we have adopted permits a novel analysis in which we
compare the linguistic contribution of our gesture features in the presence of other verbal
features. Thus we can investigate which gesture features supply unique information over and
above the verbal features. In addition, we analyze which types of verbal features correlate
closely with gesture features, and which are independent. All statistical significance results
are based on two-tailed, paired t-tests.
6.4.1 Gestural Similarity
Figure 5 shows the contribution of three classes of gestural similarity features: focusdistance, DTW-agreement, and the two HMM-based features (same-cluster and JSdiv). The top dotted line in the graph shows performance of the different-zero model with
the complete feature set, and the bottom line shows performance of this model without any
gestural similarity features.15
Each feature group conveys useful information, as performance with any one feature
group is always better than performance without gestural similarity features (p < .01, t(15) =
3.86 for DTW-agreement, the weakest of the three feature groups). The performance using only the focus-distance is significantly better than when only the DTW-agreement
feature is used (p < .05, t(15) = 2.44); other comparisons are not significant. We also find
15. Note that the baseline of â€œno gesture featuresâ€ is higher than the â€œno fusion (verbal features only)â€
baseline from Table 4. Although the feature groups here are identical, the classifiers are different.
The â€œno fusion (verbal features only)â€ baseline uses a standard log-linear classifier, while â€œno gesture
featuresâ€ uses conditional modality fusion, permitting two sets of weights for the verbal features, as
shown in equation 5.

379

Eisenstein, Barzilay, & Davis

0.83
feature absent
all others absent
0.825
all gesture features

feature group
all gesture similarity features
focus-distance
DTW-agreement
HMM-based

AUC

0.82

0.815

0.81

+
.8226
.8200
.8149
.8183

.8054
.8200
.8234
.8198

no gesture features
0.805

0.8

distance

DTW

HMMâˆ’based

Figure 5: An analysis of the contributions of each set of gestural similarity features. The
â€œplusâ€ column on the left of the table shows results when only that feature set
was present; the â€œminusâ€ column shows results when it was removed. As before,
the metric is area under the ROC curve (auc).

evidence of redundancy between the feature groups, as removing any individual feature
group does not significantly impair performance if the other two feature groups remain.
6.4.2 Verbal and Gestural Overlap
Next, we assess the degree of overlap between gesture and verbal information. We hypothesize that gesture is complementary with certain verbal features, and redundant with
others. For example, string match features such as edit-distance and exact-match
seem unlikely to convey the same information as gesture. To see why, consider the cases
in which string match is likely to be helpful: fully-specified noun phrases such as â€œthe red
ball,â€ rather than pronouns. Empirical research suggests that the majority of informative
gestures occur during pronouns and other underspecified utterances, where string match
is unlikely to be helpful (Kehler, 2000). Thus, we expect a low level of overlap between
gesture and string match features.
Distributional features are another source of verbal information. They include the number of intervening sentences or noun phrases between the two candidate NPs, and the
number of times each NP appears in the document. These features establish the context
that may permit the resolution of references that are ambiguous by their surface form alone.
For example, if a noun phrase occurred very recently, or very often, a pronominal reference
may be sufficiently clear. Since gesture may also be used in such cases, we expect some
redundancy between gestural similarity and distributional features.
These intuitions lead us to specific predictions about system performance. The presence
of the gesture similarity features should mitigate the cost of removing the distributional
features, if the gesture features reinforce some of the same information. However, the
presence of the gesture features should have no effect on the cost of removing the string
match features.

380

Gesture Salience as a Hidden Variable

0.01

0

Cost in AUC

âˆ’0.01

feature group

âˆ’0.02

no string match
no distance, count

âˆ’0.03

with gesture similarity features
.7721
.8258

without
.7522
.8018

âˆ’0.04

âˆ’0.05
with gesture
without gesture
âˆ’0.06

string match

distance and count

Figure 6: The contribution of verbal features, with and without gesture similarity features.
The graph shows the loss incurred by removing each verbal feature class, conditioned on the presence of gesture similarity features. The table shows the overall
performance with each combination of feature groups.

These predictions are supported by the data (Figure 6). Removing the distributional
features does not impair performance as long as the gesture features are present, but does
impair performance if the gesture features are also removed â€“ this difference is statistically
significant (p < .01, t(15) = 3.76). This observation is consistent with our hypothesis
that these feature groups convey similar information. In contrast, the cost of removing
the string match features does not vary by a significant margin, regardless of whether the
gesture features are present. This accords with the intuition that these feature groups
convey independent information.

7. Evaluation on Keyframe Extraction
The previous sections describe an application of conditional modality fusion to natural
language processing: by using gesture features only when they are meaningful, their contribution to coreference classification is enhanced. In this section, we show that conditional
modality fusion also predicts which gestures are useful for human viewers. Specifically, we
use the conditional modality fusion estimate of gesture salience to select keyframes from a
video. We demonstrate that the keyframes selected by this method match those selected
by human raters better than the keyframes selected by traditional text and image-based
algorithms.
In Section 7.1, we explain the keyframe-based summarization task. We describe our
basic modeling approach in Section 7.2. The evaluation setup is presented in Section 7.3.
Section 7.4 gives the experimental results.
7.1 Why Keyframe-Based Summarization
Our goal is to produce a â€œcomic bookâ€ summary of a video, in which a transcript is augmented with salient keyframes â€“ still images that clarify the accompanying text. Keyframe381

Eisenstein, Barzilay, & Davis

based summaries allow viewers to quickly review key points of a video presentation, without
requiring the time and hardware necessary to view the actual video (Boreczky, Girgensohn,
Golovchinsky, & Uchihashi, 2000). As we have argued above, textual transcriptions alone do
not capture all relevant information, and a keyframe-based summary may provide the minimal visual information required to understand such a presentation. Appendix B contains
an excerpt from a summary produced by our system.
As noted, gesture supplements speech with unique semantic information. Thus, keyframes
showing salient gestures would be a valuable addition to the transcript text. Ideally, we
would select keyframes that avoid redundancy between the visual and verbal modalities,
while conveying all relevant information.
Existing techniques for keyframe extraction have usually focused on edited videos such
as news broadcasts (e.g., Uchihashi, Foote, Girgensohn, & Boreczky, 1999; Boreczky et al.,
2000; Zhu, Fan, Elmagarmid, & Wu, 2003). Such systems seek to detect large-scale changes
in image features to identify different scenes, and then choose a representative example
from each scene. This approach is poorly suited to unedited videos, such as a recording
of a classroom lecture or business presentation. In such videos, the key visual information
is not the variation in scenes or camera angles, but the visual communication provided by
the gestures of the speaker. Our goal is to capture relevant keyframes by identifying salient
gestures, using the model developed in the previous sections of this paper.
7.2 Modeling Approach
One possible approach is to formulate gesture extraction as a standard supervised learning
task, using a corpus in which salient gestures are annotated. However, such annotation
is expensive, and we prefer to avoid it. Instead we learn salience by bootstrapping from
multimodal coreference resolution, using conditional modality fusion. By learning to predict
the specific instances in which gesture helps, we can obtain a model of gesture salience. For
example, we expect that a pointing gesture in the presence of an anaphoric expression
would be found to be highly salient (as in Figure 1); a more ambiguous hand pose in the
presence of a fully-specified noun phrase would not be salient. This approach will not
identify all salient gestures, but will identify those that occur in the context of the selected
language understanding task. In coreference resolution, only gestures that co-occur with
noun phrases can be selected. As noun phrases are ubiquitous in language, this should still
cover a usefully broad collection of gestures.
Using the model for coreference resolution introduced in Section 4, we obtain the probability distribution for the hidden variable, which controls whether the gesture features are
included for coreference resolution. Our basic hypothesis is that instances in which gesture
features are included with high likelihood are likely to correspond to salient gestures. The
gestures rated salient by this method are used to select keyframes in the summary.
Models of coreference resolution and gesture salience are learned jointly, based on the
â€œsame-zeroâ€ model defined in Equation 4. After training, a set of weights wh is obtained,
allowing the estimation of gesture
We sum over all possible
P salience at each noun phrase.
T
values for y and h2 , obtaining y,h2 Ïˆ(y, h, x; w) = h1 wh xh1 . We find the potential for

382

Gesture Salience as a Hidden Variable

the case when the gesture is salient by setting h1 = 1, yielding whT xh1 .16 Our working
assumption is that this potential is a reasonable proxy for the informativeness of a keyframe
that displays the noun phraseâ€™s accompanying gesture.
The potential provides an ordering on all noun phrases in the document. We select
keyframes from the midpoints of the top n noun phrases, where n is specified in advance
by the annotator. Providing the system with the ground truth number of keyframes follows
common practice from the textual summarization literature â€“ summaries of different lengths
are difficult to compare, as the summary duration is governed partially by the annotatorâ€™s
preference for brevity or completeness (Mani & Maybury, 1999). Each keyframe is given
a caption that includes the relevant noun phrase and accompanying text, up to the noun
phrase in the next keyframe. Portions of the output of the system are shown in Figure 1
and Appendix B.
7.3 Evaluation Setup
Our evaluation methodology is similar to the intrinsic evaluation developed for the Document Understanding Conference.17 We assess the quality of the automatically extracted
keyframes by comparing them to human-annotated ground truth.
7.3.1 Dataset
The dataset again consists of dialogues collected using the procedure described in Section 3.
The same coreference annotations described in Section 3.2 are used. Additionally, nine of
the sixteen videos are annotated for keyframes. Of these, three are used in developing our
system and the baselines, and the remaining six are used for final evaluation (these are
indicated by asterisks in the table in Appendix C). There is no explicit training on the
keyframe annotations, but the development set was used for evaluation as the system was
under construction.
The specification of the ground truth annotation required that the keyframes capture
all static visual information that the annotator deems crucial to understanding the content
of the video. The number of selected frames was left to their discretion; on average, 17.8
keyframes were selected per document, out of an average total of 4296 frames per document.
Annotation was performed by two raters; on a subset of two videos annotated by both raters,
the raw interrater agreement was 86%, yielding a kappa of .52.
One important difference between our dataset and standard sentence extraction datasets
is that many frames may be nearly identical, due to the high frame rate of video. For
this reason, rather than annotating individual frames, the annotators marked regions with
identical visual information. These regions define equivalence classes, such that any frame
from a given region would be equally acceptable. If a single keyframe were selected from
every ground truth region, the result would be the minimal set of keyframes necessary
for a reader to fully understand the discourse. On average, the 17.8 regions selected per
document spanned 568 frames.
16. Note that if we consider the same noun phrase as the anaphor (xh2 ) and sum over all possible values of
h1 , the resulting potential is identical.
17. http://duc.nist.gov

383

Eisenstein, Barzilay, & Davis

Ground truth

1

2

System response

Score

False
Negative

False
Positive

True
Positive

Not
scored

Figure 7: An example of the scoring setup.

7.3.2 Training Coreference Resolution
As described in Section 7.2, our approach to keyframe extraction is based on a model for
gesture salience that is learned from labeled data on coreference resolution. The training
phase is performed as leave-one-out cross-validation: a separate set of weights is learned
for each presentation, using the other fifteen presentations as a training set. The learned
weights are used to obtain the values of the hidden variable indicating gesture salience, as
described in the previous subsection.
7.3.3 Evaluation Metric
Figure 7 illustrates the scoring setup. The top row in the figure represents the ground
truth; the middle row represents the system response, with vertical lines indicating selected
keyframes; the bottom row shows how the response is scored.
For all systems the number of keyframes is fixed to be equal to the number of regions
in the ground truth annotation. If the system response includes a keyframe that is not
within any ground truth region, a false positive is recorded. If the system response fails to
include a keyframe from a region in the ground truth, a false negative is recorded; a true
positive is recorded for the first frame that is selected from a given ground truth region, but
additional frames from the same region are not scored. The system is thus still penalized for
each redundant keyframe, because it has â€œwastedâ€ one of a finite number of keyframes it is
allowed to select. At the same time, such an error seems less grave than a true substitution
error, in which a keyframe not containing relevant visual information is selected. We report
the F-measure, which is the harmonic mean of recall and precision.
7.3.4 Baselines
We compare the performance of our system against three baselines, which we present in
order of increasing competitiveness.
â€¢ Random-keyframe: Our simplest baseline selects n keyframes at random from
throughout the document. This baseline is similar to the â€œrandom sentenceâ€ baselines
that are common in the textual summarization literature (Mani & Maybury, 1999).
The number of keyframes selected in this baseline is equal to the number of regions
in the ground truth. This baseline expresses a lower bound on the performance that
any reasonable system should achieve on this task. Our results report the average of
500 independent runs.

384

Gesture Salience as a Hidden Variable

â€¢ NP-salience: The NP-salience system is based on frequency-based approaches
to identifying salient NPs for the purpose of text summarization (Mani & Maybury,
1999). The salience heuristic prefers the most common representative tokens of the
largest and most homogeneous coreference clusters.18 The largest cluster is the one
containing the most noun phrases; homogeneity is measured by the inverse of the
number of unique surface forms. This provides a total ordering on NPs in the document; we select keyframes at the midpoint of the top n noun phrases, where n is the
number of keyframe regions in the ground truth. In future work we hope to explore
finding the best point within each noun phrase for keyframe selection.
â€¢ Pose-clustering: Our final baseline is based purely on visual features. It employs
clustering to find a representative subset of frames with minimum mutual redundancy.
Uchihashi et al. (1999), in a seminal paper on keyframe selection, perform clustering
on all frames in the video, using the similarity of color histograms as a distance
metric. Representative images from each cluster are then used as keyframes. More
recent video summarization techniques have advanced the clustering algorithms (Liu
& Kender, 2007) and the similarity metric (Zhu et al., 2003), but the basic approach
of forming clusters based on visual similarity and choosing exemplar keyframes from
these clusters is still used in much of the state-of-the-art research on this topic (see
Lew, Sebe, Djeraba, & Jain, 2006, for a survey).
In our dataset, there is a single fixed camera and no change in the video except
for the movements of the speaker; thus, the color histograms are nearly constant
throughout. Instead, we use the tracked coordinates of the speakerâ€™s hands and upperbody, normalize all values, and use the Euclidean distance metric. In this setting,
clusters correspond to typical body poses, and segments correspond to holds in these
poses. Following Uchihashi et al. (1999), the video is divided into segments in which
cluster membership is constant, and keyframes are taken at the midpoints of segments.
We use importance metric from this paper for ranking segments, and choose the top
n, where n is the number of keyframes in the ground truth.
7.4 Results
Table 7 compares the performance of our method (Gesture-salience) with the three
baselines. Using paired t-tests, we find that Gesture-salience significantly outperforms
all alternatives (p < .05 in all cases). The Pose-clustering and NP-salience systems are
statistically equivalent; both are significantly better than the Random-keyframe baseline
(p < .05).
The set of baselines against which our system is compared is necessarily incomplete,
as there are many ways in which keyframes extraction could be performed. For example, prosodic features could be used to identify moments of particular interest in the dialogue (Sundaram & Chang, 2003). In addition, a combination of baselines including visual
and linguistic features may also perform better than any individual baseline. However, developing more complicated baselines is somewhat beside the point. The evaluation demonstrates that a simple yet effective technique for selecting meaningful keyframes is obtained
18. Here, coreference clusters are based on manual annotations.

385

Eisenstein, Barzilay, & Davis

Model
GESTURE-SALIENCE
Pose-clustering
NP-salience
Random-keyframe

F-Measure
.404
.290
.239
.120

Recall
.383
.290
.234
.119

Precision
.427
.290
.245
.121

Table 7: Comparison of performance on keyframe selection task

as a byproduct of conditional modality fusion. This suggests that the estimates of gesture
salience given by our model cohere with human perception.
Error analysis A manual inspection of the system output revealed that in many cases our
system selected a noun phrase that was accompanied by a relevant gesture, but the specific
keyframe was slightly off. Our method always chooses the keyframe at the midpoint of the
accompanying noun phrase; often, the relevant gesture is brief, and does not necessarily
overlap with the middle of the noun phrase. Thus, one promising approach to improving
results would be to â€œlook insideâ€ each noun phrase, using local gesture features to attempt
to identify the specific frame in which the gesture is most salient.
Other errors arise because some key gestures are not related to noun phrases. For
example, suppose the speaker says â€œit shoots the ball up,â€ and accompanies only the word
â€œupâ€ with a gesture indicating the ballâ€™s trajectory. This gesture might be important to
understanding the speakerâ€™s meaning, but since it does not overlap with a noun phrase,
the gesture will not be identified by our system. We believe that our results show that
focusing on noun phrases is a good start for linguistically-motivated keyframe extraction,
and that our unsupervised approach is successful at identifying which noun phrases require
keyframes. As gesture is applied to other language tasks, we hope to model the salience
of gesture at other phrase types, thus increasing the coverage of our approach to keyframe
extraction.

8. Conclusions and Future Work
In summary, this work is motivated by the idea that gestures are best interpreted not
as individual units with self-contained meaning, but in the context of other gestural and
linguistic information. Previous NLP research on gesture has largely focused on building
recognizers for gestures that characterize specific language phenomena: for example, detecting hand gestures that cue sentence boundaries (Chen et al., 2006), or body language
that suggests topic shifts (Nakano et al., 2003). Such approaches treat gesture as a sort of
visual punctuation. In contrast, we are interested in the semantics that gesture carries. We
do not take a recognition-based approach because we believe it unlikely that the space of
possible meaningful gestures could be delineated by any training set. Instead, we start from
the hypothesis that patterns in gesture will correspond to patterns in meaning, so that the
degree of similarity between two gestures predicts the semantic similarity of the associated
speech. This approach is validated by our experimental results, which show substantial
improvement in noun phrase coreference resolution using gesture features. This is one of

386

Gesture Salience as a Hidden Variable

the first results showing that automatically-extracted visual features significantly improve
discourse analysis.
A second key finding is that a structured approach to multimodal integration is crucial
to achieving the full benefits offered by gesture features for language understanding. Rather
than building separate verbal and gesture interpretation units â€“ or simply concatenating
their features â€“ we build a model whose structure encodes the role of each modality. In
particular, the gesture modality supplements speech only intermittently, and therefore we
represent gesture salience explicitly with a hidden variable. This approach, which we call
conditional modality fusion, yields a 73% relative improvement in the contribution of the
gesture features towards coreference resolution. This improvement is attained by modeling
gesture salience with a hidden variable and ignoring gestures that are not salient.
Conditional modality fusion induces an estimate of gesture salience within the context of
a specific linguistic task. To test the generality of the salience model, we transfer the derived
estimates to a completely different task: keyframe extraction. Without any labeled data on
the keyframe task, this simple algorithm outperforms competitive unimodal alternatives.
This suggests that the model of gesture salience learned from coreference coheres with
human perception of gesture salience.
The theme of generality in gesture salience is suggestive for future research. In principle, a general model of gesture salience could be applied to a range of discourse-related
language processing tasks. For example, consider topic segmentation: in text, changes in
the distribution of lexical items is a strong indicator of topic boundaries (Hearst, 1994).
Assuming that salient gestures carry unique semantic content, changes in the distribution
of features of salient gestures could be used in a similar way, supplementing a purely textual
analysis.
Moreover, the combination of multiple language processing tasks in a single joint framework raises the possibility that gesture salience could be modeled more robustly as knowledge is transferred between tasks. We have argued against using an explicit universal
taxonomy of gesture, favoring an approach focused on the relevance of gesture to specific
language processing problems. However, such a joint framework would generalize the notion
of salience in a bottom-up, data-driven way. Such research may be relevant from a purely
linguistic standpoint: for example, investigating which types of language phenomena share
coherent notions of gesture salience, and how gesture salience is expressed in visual and
linguistic features. In this paper we have argued that structured models such as conditional
modality fusion can be used to incorporate linguistic ideas about gesture in a principled
way. We hope that future work will show that such models can also provide a new tool to
study the linguistics of gesture.
Another possibility for future work is to investigate richer models of gesture salience.
The structure we have explored here is minimal â€“ a binary variable to indicate the salience
of a gesture for coreference resolution. We see this as a first step towards more complex
structural representations for gesture salience that may yield greater gains in performance.
For example, it is likely that gesture salience observes some temporal regularity, suggesting
a Markov state model. Other tasks may involve more structured dependencies among
gestures, requiring models such as probabilistic context-free grammars.
Finally, we note that hand gesture is one of several modalities that accompany spoken
language. Prosody has attracted the greatest amount of attention in natural language
387

Eisenstein, Barzilay, & Davis

processing, but other coverbal modalities include facial expressions, body posture, and â€“ in
settings such as lectures or meetings â€“ writing and diagrams. The relationship between these
modalities is poorly understood; future research might explore the mapping of linguistic
functions to modalities, and whether there are sets of modalities that are redundant or
complementary.

Acknowledgments
The authors acknowledge the editor and anonymous reviewers for their helpful comments.
We also thank our colleagues Aaron Adler, S. R. K. Branavan, Emma Brunskill, Sonya
Cates, Erdong Chen, C. Mario Christoudias, Michael Collins, Pawan Deshpande, Lisa Guttentag, Igor Malioutov, Max Van Kleek, Michael Oltmans, Tom Ouyang, Christina Sauper,
Tom Yeh, and Luke Zettlemoyer. The authors acknowledge the support of the National
Science Foundation (Barzilay; CAREER grant IIS-0448168 and grant IIS-0415865) and
the Microsoft Faculty Fellowship. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of
the National Science Foundation or Microsoft.

388

Gesture Salience as a Hidden Variable

Appendix A. Example Transcript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43

ok so [(0) this object right here].
iâ€™m going to attempt to explain what [(0) this] does to you.
[(1) this ball right here] is the only
[(1) this ball]
[(2) this spring]
[(3) this long arm]
and [(4) this] are [(5) the only objects that actually move].
no i take [(6) that] back.
[(7) this] rotates as well.
while [(8) these things] stay fixed.
what happens is [(1) the ball] comes down [(9) here].
and [(2) this spring] is active.
meaning that [(2) itâ€™s] going up and down.
because [(4) this] will come up.
jostle [(3) that].
and then go around.
so [(3) itâ€™ll] as [(4) this] raises [(3) it] up.
[(10) this hand] goes down.
and then [(10) itâ€™ll] spring back up.
[(1) the ball] typically goes up [(11) here].
bounces off [(12) here].
gets caught in like [(13) a groove].
[(7) this] is continually moving around in [(14) a circle]
then [(15) this] happened three times
i watched [(16) a video] and [(15) it] happened [(17) three times]
[(1) the ball] never went through [(18) there] or [(19) over here]
[(1) it] always would get down back to [(20) here]
and then down through [(9) here]
sometimes [(21) this thing] would hit [(1) it] harder
and [(1) it] would go higher up
and sometimes [(1) it] would just kind of loop over
no no [(1) it] only came down through [(9) here]
i have no idea why thereâ€™s [(22) anchors] on [(23) here]
[(24) that] wasnâ€™t really made clear to me
and yeah [(25) thatâ€™s] pretty much [(26) it]
[(1) itâ€™s] essentially [(1) a bouncy ball]
but [(1) it] just pretty much drops like [(27) dead weight]
when [(1) it] hits [(28) something]
and that was [(26) it]
[(16) it] was probably like [(16) a forty five second video] at most
and [(29) it] happened [(17) three times] in [(16) that video]
so [(16) it] moves relatively quickly
not so much lodged as just like [(1) it] would like come down [(13) here]

389

Eisenstein, Barzilay, & Davis

44
45
46
47
48
49
50
51
52
53
54
55
56
57
58

and as [(7) this] is moving [(7) it] would
just kind of like dump [(1) it] into [(20) here]
[(7) itâ€™s] more of something thatâ€™s in [(30) the way]
than actually [(31) a transfer]
because if [(7) this] wasnâ€™t [(32) here]
[(1) it] would still fall down [(20) here] and then get in [(9) here]
thatâ€™s it
iâ€™m not actually sure what [(0) this] does
[(0) it] looks like [(0) it] looks just like
[(0) this] on [(33) the computer screen]
so so um [(0) it] basically looks like
[(34) kind of a so so game of pinball]
[(35) that] was [(36) my understanding of it]
iâ€™m not sure what else [(37) itâ€™s] supposed to do
ok weâ€™re done guys with [(37) this one]

390

Gesture Salience as a Hidden Variable

Appendix B. Example Keyframe Summary
This is an excerpt of a keyframe summary that was generated automatically, as described
in Section 7.

the spring brings this thing back in. and it
latches here. spring right here. this thing i donâ€™t
know what that is. it goes like this.

um and then after this goes below the level here.

1

2

so it goes down.

and it goes out.

3

4

and as soon as it passes this thing.

it comes back.

5

6

391

Eisenstein, Barzilay, & Davis

Appendix C. Dataset Parameters
number
1
2
3*
4
5*
6*
7
8
9*
10*
11
12
13
14*
15
16
total

speaker
1
1
2
2
3
4
4
5
5
6
7
7
8
8
9
9

topic
pinball
candy dispenser
latch
pinball
pinball
candy dispenser
pinball
pinball
piston
pinball
latchbox
pinball
pinball
piston
pinball
candy dispenser

gender
F
F
F
F
F
M
M
M
M
M
M
M
F
F
M
M

duration
3:00
2:27
1:19
2:31
3:00
3:00
3:00
3:00
3:00
3:00
2:20
3:00
2:23
0:47
2:30
2:43
41:00

# words
455
428
104
283
325
404
421
362
313
315
347
221
192
48
378
358
4954

# NPs
95
101
27
65
69
100
109
89
69
71
72
51
47
8
87
77
1137

Corpus statistics for the dataset used in our experiments. Asterisks indicate videos that
were used in the keyframe evaluation.

References
Adler, A., Eisenstein, J., Oltmans, M., Guttentag, L., & Davis, R. (2004). Building the
design studio of the future. In Proceedings of AAAI Workshop on Making Pen-Based
Interaction Intelligent and Natural, pp. 1â€“7.
Allen, J., Schubert, L., Ferguson, G., Heeman, P., Hwang, C., Kato, T., Light, M., Martin,
N., Miller, B., Poesio, M., et al. (1995). The TRAINS project: a case study in building
a conversational planning agent. Journal of Experimental & Theoretical Artificial
Intelligence, 7 (1), 7â€“48.
Barzilay, R., & Lapata, M. (2005). Modeling local coherence: an entity-based approach. In
Proceedings of the ACL, pp. 141â€“148.
Bennett, P., & Carbonell, J. (2007). Combining Probability-Based Rankers for Action-Item
Detection. In Proceedings of HLT-NAACL, pp. 324â€“331.
Biber, D. (1988). Variation Across Speech and Language. Cambridge University Press.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
Blitzer, J., McDonald, R., & Pereira, F. (2006). Domain adaptation with structural correspondence learning. In Proceedings of EMNLP, pp. 120â€“128.
Blum, A., & Mitchell, T. (1998). Combining labeled and unlabeled data with co-training.
In Proceedings of COLT, pp. 92â€“100.
392

Gesture Salience as a Hidden Variable

Boreczky, J., Girgensohn, A., Golovchinsky, G., & Uchihashi, S. (2000). An interactive
comic book presentation for exploring video. In Proceedings of CHI, pp. 185â€“192.
Bradley, A. (1997). The use of the area under the ROC curve in the evaluation of machine
learning algorithms. Pattern Recognition, 30 (7), 1145â€“1159.
Brennan, S. E., Friedman, M. W., & Pollard, C. J. (1987). A centering approach to pronouns.
In Proceedings of the ACL, pp. 155â€“162.
Carletta, J., Ashby, S., Bourban, S., Flynn, M., Guillemot, M., Hain, T., Kadlec, J.,
Karaiskos, V., Kraaij, W., Kronenthal, M., Lathoud, G., Lincoln, M., Lisowska, A.,
McCowan, I., Post, W., Reidsma, D., & Wellner, P. (2005). The ami meeting a corpus: a pre-announcement. In Proceedings of the Workshop on Machine Learning for
Multimodal Interaction, pp. 28â€“39.
Chai, J. Y., Hong, P., Zhou, M. X., & Prasov, Z. (2004). Optimization in multimodal
interpretation. In Proceedings of the ACL, pp. 1â€“8.
Chai, J. Y., & Qu, S. (2005). A salience driven approach to robust input interpretation in
multimodal conversational systems. In Proceedings of HLT-EMNLP, pp. 217â€“224.
Chelba, C., & Acero, A. (2006). Adaptation of maximum entropy capitalizer: Little data
can help a lot. Computer Speech & Language, 20 (4), 382â€“399.
Chen, L., Harper, M., & Huang, Z. (2006). Using maximum entropy (ME) model to incorporate gesture cues for sentence segmentation. In Proceedings of ICMI, pp. 185â€“192.
Chen, L., Liu, Y., Harper, M. P., & Shriberg, E. (2004). Multimodal model integration for
sentence unit detection. In Proceedings of ICMI, pp. 121â€“128.
Chen, L., Rose, R. T., Parrill, F., Han, X., Tu, J., Huang, Z., Harper, M., Quek, F., McNeill,
D., Tuttle, R., & Huang, T. (2005). VACE multimodal meeting corpus. In Proceedings
of the Workshop on Machine Learning for Multimodal Interaction, pp. 40â€“51.
Cohen, P. R., Johnston, M., McGee, D., Oviatt, S., Pittman, J., Smith, I., Chen, L., &
Clow, J. (1997). Quickset: Multimodal interaction for distributed applications. In
Proceedings of ACM Multimedia, pp. 31â€“40.
Darrell, T., & Pentland, A. (1993). Space-time gestures. In Proceedings of CVPR, pp.
335â€“340.
DaumeÌ III, H. (2007). Frustratingly easy domain adaptation. In Proceedings of the ACL,
pp. 256â€“263.
DaumeÌ III, H., & Marcu, D. (2005). A large-scale exploration of effective global features
for a joint entity detection and tracking model. In Proceedings of HLT-EMNLP, pp.
97â€“104.
Deutscher, J., Blake, A., & Reid, I. (2000). Articulated body motion capture by annealed
particle filtering. In Proceedings of CVPR, Vol. 2, pp. 126â€“133.
Eisenstein, J., Barzilay, R., & Davis, R. (2007). Turning lectures into comic books with
linguistically salient gestures. In Proceedings of AAAI, pp. 877â€“882.
Eisenstein, J., & Davis, R. (2006). Gesture improves coreference resolution. In Proceedings
of HLT-NAACL, Companion Volume: Short Papers, pp. 37â€“40.
393

Eisenstein, Barzilay, & Davis

Eisenstein, J., & Davis, R. (2007). Conditional modality fusion for coreference resolution.
In Proceedings of the ACL, pp. 352â€“359.
Fayyad, U. M., & Irani, K. B. (1993). Multi-interval discretization of continuous-valued
attributes for classification learning. In Proceedings of IJCAI, Vol. 2, pp. 1022â€“1027.
Godfrey, J., Holliman, E., & McDaniel, J. (1992). Switchboard: Telephone speech corpus for
research development. In Proceedings of the IEEE Conference on Acoustics, Speech,
and Signal Processing (Vol. 1), pp. 517â€“520.
Goodwin, M., & Goodwin, C. (1986). Gesture and co-participation in the activity of searching for a word. Semiotica, 62, 51â€“75.
Grosz, B., Joshi, A. K., & Weinstein, S. (1995). Centering: A framework for modeling the
local coherence of discourse. Computational Linguistics, 21 (2), 203â€“225.
Haghighi, A., & Klein, D. (2007). Unsupervised coreference resolution in a nonparametric
bayesian model. In Proceedings of the ACL, pp. 848â€“855.
Harabagiu, S. M., Bunescu, R. C., & Maiorano, S. J. (2001). Text and knowledge mining
for coreference resolution. In Proceedings of NAACL, pp. 1â€“8.
Hearst, M. A. (1994). Multi-paragraph segmentation of expository text. In Proceedings of
the ACL.
Hirschman, L., & Chinchor, N. (1998). MUC-7 coreference task definition. In Proceedings
of the Message Understanding Conference.
Huang, X., Acero, A., & Hon, H.-W. (2001). Spoken Language Processing. Prentice Hall.
Huang, X., Alleva, F., Hwang, M.-Y., & Rosenfeld, R. (1993). An overview of the SphinxII speech recognition system. In Proceedings of ARPA Human Language Technology
Workshop, pp. 81â€“86.
Ji, H., Westbrook, D., & Grishman, R. (2005). Using semantic relations to refine coreference
decisions. In Proceedings of HLT-EMNLP, pp. 17â€“24.
Johnston, M., & Bangalore, S. (2000). Finite-state multimodal parsing and understanding,.
In Proceedings of COLING-2000, pp. 369â€“375.
Jordan, P., & Walker, M. (2005). Learning Content Selection Rules for Generating Object
Descriptions in Dialogue. Journal of Artificial Intelligence Research, 24, 157â€“194.
Kahn, J. G., Lease, M., Charniak, E., Johnson, M., & Ostendorf, M. (2005). Effective
use of prosody in parsing conversational speech. In Proceedings of HLT-EMNLP, pp.
233â€“240.
Kameyama, M. (1986). A property-sharing constraint in Centering. In Proceedings of the
ACL, pp. 200â€“206.
Kehler, A. (2000). Cognitive status and form of reference in multimodal human-computer
interaction. In Proceedings of AAAI, pp. 685â€“690.
Kendon, A. (1980). Gesticulation and speech: Two aspects of the process of the utterance.
In Key, M. R. (Ed.), The relation between verbal and non-verbal communication, pp.
207â€“227. Mouton.

394

Gesture Salience as a Hidden Variable

Kettebekov, S., Yeasin, M., & Sharma, R. (2005). Prosody based audiovisual coanalysis for
coverbal gesture recognition. IEEE Transactions on Multimedia, 7 (2), 234â€“242.
Kibble, R., & Power, R. (2004). Optimising referential coherence in text generation. Computational Linguistics, 30 (4), 401â€“416.
Kim, J., Schwarm, S. E., & Osterdorf, M. (2004). Detecting structural metadata with
decision trees and transformation-based learning. In Proceedings of HLT-NAACLâ€™04.
Koo, T., & Collins, M. (2005). Hidden-variable models for discriminative reranking. In
Proceedings of HLT-EMNLP, pp. 507â€“514.
Kopp, S., Tepper, P., Ferriman, K., & Cassell, J. (2007). Trading spaces: How humans and
humanoids use speech and gesture to give directions. In Nishida, T. (Ed.), Conversational Informatics: An Engineering Approach. Wiley.
Kudo, T., & Matsumoto, Y. (2001). Chunking with support vector machines. In Proceedings
of NAACL, pp. 1â€“8.
Lappin, S., & Leass, H. J. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics, 20 (4), 535â€“561.
Lascarides, A., & Stone, M. (2006). Formal semantics for iconic gesture. In Proceedings of
the 10th Workshop on the Semantics and Pragmatics of Dialogue (BRANDIAL), pp.
64â€“71.
Lew, M. S., Sebe, N., Djeraba, C., & Jain, R. (2006). Content-based multimedia information retrieval: State of the art and challenges. ACM Transactions on Multimedia
Computing, Communications and Applications, 2 (1), 1â€“19.
Li, X., & Roth, D. (2001). Exploring evidence for shallow parsing. In Proceedings of CoNLL,
pp. 1â€“7.
Lin, J. (1991). Divergence measures based on the shannon entropy. IEEE Transactions on
Information Theory, 37, 145â€“151.
Liu, D. C., & Nocedal, J. (1989). On the limited memory BFGS method for large scale
optimization. Mathematical Programming, 45, 503â€“528.
Liu, T., & Kender, J. R. (2007). Computational approaches to temporal sampling of video
sequences. ACM Transactions on Multimedia Computing, Communications and Applications, 3 (2), 7.
Liu, Y. (2004). Structural Event Detection for Rich Transcription of Speech. Ph.D. thesis,
Purdue University.
Luo, X. (2005). On coreference resolution performance metrics. In Proceedings of HLTEMNLP, pp. 25â€“32.
Malioutov, I., & Barzilay, R. (2006). Minimum cut model for spoken lecture segmentation.
In Proceedings of the ACL, pp. 25â€“32.
Mani, I., & Maybury, M. T. (Eds.). (1999). Advances in Automatic Text Summarization.
MIT Press, Cambridge, MA, USA.
McCallum, A., & Wellner, B. (2004). Conditional models of identity uncertainty with
application to noun coreference. In Proceedings of NIPS, pp. 905â€“912.
395

Eisenstein, Barzilay, & Davis

McNeill, D. (1992). Hand and Mind. The University of Chicago Press.
Melinger, A., & Levelt, W. J. M. (2004). Gesture and communicative intention of the
speaker. Gesture, 4 (2), 119â€“141.
MuÌˆller, C., Rapp, S., & Strube, M. (2002). Applying Co-Training to reference resolution.
In Proceedings of the ACL, pp. 352â€“359.
MuÌˆller, C. (2007). Resolving it, this, and that in unrestricted multi-party dialog. In Proceedings of the ACL, pp. 816â€“823.
Nakano, Y., Reinstein, G., Stocky, T., & Cassell, J. (2003). Towards a model of face-to-face
grounding. In Proceedings of the ACL, pp. 553â€“561.
Ng, V. (2007). Shallow semantics for coreference resolution. In Proceedings of IJCAI, pp.
1689â€“1694.
Ng, V., & Cardie, C. (2002). Improving machine learning approaches to coreference resolution. In Proceedings of the ACL, pp. 104â€“111.
NIST (2003). The Rich Transcription Fall 2003 (RT-03F) Evaluation plan..
Passonneau, R. J. (1997). Applying reliability metrics to co-reference annotation. Tech.
rep. CUCS-017-97, Columbia University.
Poddar, I., Sethi, Y., Ozyildiz, E., & Sharma, R. (1998). Toward natural gesture/speech
HCI: A case study of weather narration. In Proceedings of Perceptual User Interfaces,
pp. 1â€“6.
Poesio, M., Stevenson, R., Eugenio, B. D., & Hitzeman, J. (2004). Centering: a parametric
theory and its instantiations. Computational Linguistics, 30 (3), 309â€“363.
Quattoni, A., Collins, M., & Darrell, T. (2004). Conditional random fields for object recognition. In Proceedings of NIPS, pp. 1097â€“1104.
Quek, F., McNeill, D., Bryll, R., Duncan, S., Ma, X., Kirbas, C., McCullough, K. E., &
Ansari, R. (2002a). Multimodal human discourse: gesture and speech. ACM Transactions on Computer-Human Interaction, 9:3, 171â€“193.
Quek, F., McNeill, D., Bryll, R., & Harper, M. (2002b). Gestural spatialization in natural discourse segmentation. In Proceedings of International Conference on Spoken
Language Processing, pp. 189â€“192.
Quek, F., McNeill, D., Bryll, R., Kirbas, C., Arslan, H., McCullough, K. E., Furuyama, N.,
& Ansari, R. (2000). Gesture, speech, and gaze cues for discourse segmentation. In
Proceedings of CVPR, Vol. 2, pp. 247â€“254.
Rabiner, L. R. (1989). A tutorial on hidden markov models and selected applications in
speech recognition. Proceedings of the IEEE, 77 (2), 257â€“286.
Sarkar, A. (2001). Applying co-training methods to statistical parsing. In Proceedings of
NAACL, pp. 1â€“8.
Sha, F., & Pereira, F. (2003). Shallow parsing with conditional random fields. In Proceedings
of NAACL, pp. 134â€“141.
Shriberg, E., Stolcke, A., Hakkani-Tur, D., & Tur, G. (2000). Prosody-based automatic
segmentation of speech into sentences and topics. Speech Communication, 32.
396

Gesture Salience as a Hidden Variable

Sidner, C. L. (1979). Towards a computational theory of definite anaphora comprehension
in english discourse. Tech. rep. AITR-537, Massachusetts Institute of Technology.
Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). A machine learning approach to coreference
resolution of noun phrases. Computational Linguistics, 27 (4), 521â€“544.
Strube, M., & Hahn, U. (1999). Functional centering: grounding referential coherence in
information structure. Computational Linguistics, 25 (3), 309â€“344.
Strube, M., Rapp, S., & MuÌˆller, C. (2002). The influence of minimum edit distance on
reference resolution. In Proceedings of EMNLP, pp. 312â€“319.
Strube, M., & MuÌˆller, C. (2003). A machine learning approach to pronoun resolution in
spoken dialogue. In Proceedings of the ACL, pp. 168â€“175.
Sundaram, H., & Chang, S.-F. (2003). Video analysis and summarization at structural and
semantic levels. In D. Feng, W. C. S., & Zhang, H. (Eds.), Multimedia Information
Retrieval and Management: Technological Fundamentals and Applications, pp. 75â€“94.
Springer Verlag.
Sutton, C., & McCallum, A. (2006). An introduction to conditional random fields for
relational learning. In Getoor, L., & Taskar, B. (Eds.), Introduction to Statistical
Relational Learning, pp. 95â€“130. MIT Press.
Sutton, C., McCallum, A., & Rohanimanesh, K. (2007). Dynamic conditional random fields:
Factorized probabilistic models for labeling and segmenting sequence data. Journal
of Machine Learning Research, 8, 693â€“723.
Toyama, K., & Horvitz, E. (2000). Bayesian modality fusion: Probabilistic integration of
multiple vision algorithms for head tracking. In Proceedings of Asian Conference on
Computer Vision (ACCV).
Uchihashi, S., Foote, J., Girgensohn, A., & Boreczky, J. (1999). Video manga: generating
semantically meaningful video summaries. In Proceedings of ACM MULTIMEDIA,
pp. 383â€“392.
Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). A modeltheoretic coreference scoring scheme. In Proceedings of Message Understanding Conference, pp. 45â€“52.
Walker, M., Joshi, A., & Prince, E. (Eds.). (1998). Centering Theory in Discourse. Clarendon Press, Oxford.
Walker, M. A. (1998). Centering, anaphora resolution, and discourse structure. In Marilyn
A. Walker, A. K. J., & Prince, E. F. (Eds.), Centering in Discourse, pp. 401â€“435.
Oxford University Press.
Wang, S., Quattoni, A., Morency, L.-P., Demirdjian, D., & Darrell, T. (2006). Hidden
conditional random fields for gesture recognition. In Proceedings of CVPR, Vol. 02,
pp. 1521â€“1527.
Xiong, Y., & Quek, F. (2006). Hand Motion Gesture Frequency Properties and Multimodal
Discourse Analysis. International Journal of Computer Vision, 69 (3), 353â€“371.
Yang, X., Su, J., & Tan, C. L. (2005). Improving pronoun resolution using statistics-based
semantic compatibility information. In Proceedings of the ACL, pp. 165â€“172.
397

Eisenstein, Barzilay, & Davis

Yang, X., Zhou, G., Su, J., & Tan, C. L. (2003). Coreference resolution using competition
learning approach. In Proceedings of the ACL, pp. 176â€“183.
Zhu, X., Fan, J., Elmagarmid, A., & Wu, X. (2003). Hierarchical video content description
and summarization using unified semantic and visual similarity. Multimedia Systems,
9 (1), 31â€“53.

398

Journal of Artificial Intelligence Research 31 (2008) 497-542

Submitted 08/07; published 03/08

Exploiting Subgraph Structure in
Multi-Robot Path Planning
Malcolm R. K. Ryan

malcolmr@cse.unsw.edu.au

ARC Centre of Excellence for Autonomous Systems
University of New South Wales, Australia

Abstract
Multi-robot path planning is difficult due to the combinatorial explosion of the search
space with every new robot added. Complete search of the combined state-space soon
becomes intractable. In this paper we present a novel form of abstraction that allows
us to plan much more efficiently. The key to this abstraction is the partitioning of the
map into subgraphs of known structure with entry and exit restrictions which we can
represent compactly. Planning then becomes a search in the much smaller space of subgraph
configurations. Once an abstract plan is found, it can be quickly resolved into a correct
(but possibly sub-optimal) concrete plan without the need for further search. We prove
that this technique is sound and complete and demonstrate its practical effectiveness on a
real map.
A contending solution, prioritised planning, is also evaluated and shown to have similar
performance albeit at the cost of completeness. The two approaches are not necessarily
conflicting; we demonstrate how they can be combined into a single algorithm which outperforms either approach alone.

1. Introduction
There are many scenarios which require large groups of robots to navigate around a shared
environment. Examples include: delivery robots in an office (Hada & Takase, 2001), a
warehouse (Everett, Gage, Gilbreth, Laird, & Smurlo, 1994), a shipping yard (Alami, Fleury,
Herrb, Ingrand, & Robert, 1998), or a mine (Alarie & Gamache, 2002); or even virtual
armies in a computer wargame (Buro & Furtak, 2004). In each case we have many robots
with independent goals which must traverse a shared environment without colliding with
one another. When planning a path for just a single robot we can usually consider the
rest of the world to be static, so that the world can be represented by a graph called a
road-map. The path-planning problem then amounts to finding a path in the road-map, for
which reasonably efficient algorithms exist. However, in a multi-robot scenario the world is
not static. We must not only avoid collisions with obstacles, but also with other robots.
Centralised methods (Barraquand & Latombe, 1991), which treat the robots as a single composite entity, scale poorly as the number of robots increases. Decoupled methods
(LaValle & Hutchinson, 1998; Erdmann & Lozano-PeÌrez, 1986), which first plan for each
robot independently then resolve conflicts afterwards, prove to be much faster but are incomplete because many problems require robots to deliberately detour from their optimal
path in order to let another robot pass. Even if a priority ordering is used (van den Berg
& Overmars, 2005), requiring low priority robots to plan to avoid high-priority robots,
problems can be found which cannot be solved with any priority ordering.

c
2008
AI Access Foundation. All rights reserved.

Ryan

In realistic maps there are common structures such as roads, corridors and open spaces
which produce particular topological features in the map which constrain the possible interactions of robots. In a long narrow corridor, for instance, it may be impossible for one robot
to overtake another and so robots must enter and exit in a first-in/first-out order. On the
other hand, a large open space may permit many robots to pass through it simultaneously
without collision.
We can characterise these features as particular kinds of subgraphs occurring in the
road-map. If we can decompose a map into a collection of such simple subgraphs, then we
can build plans hierarchically, first planning the movements from one subgraph to another,
then using special-purpose planners to build paths within each subgraph.
In this paper we propose such an abstraction. We limit ourselves to considering an
homogeneous group of robots navigating using a shared road-map. We identify particular
kinds of subgraphs in this road-map which place known constraints on the ordering of robots
that pass through them. We use these constraints to make efficient planning algorithms for
traversing each kind of subgraph, and we combine these local planners into a hierarchical
planner for solving arbitrary problems.
This abstraction can be used to implement both centralised and prioritised planners,
and we demonstrate both in this paper. Unlike most heuristic abstractions, this method is
sound and complete. That is, when used with a centralised search it is guaranteed to find a
correct plan if and only if one exists. This guarantee cannot be made when prioritised search
is used, however the two-stage planning process means that a prioritised planner with the
abstraction can often find plans that would not be available to it otherwise. Experimental
investigation shows that this approach is most effective in maps with only sparsely connected
graph representations.

2. Problem Formulation
We assume for this work that we are provided with a road-map in the form of a graph
G = (V, E) representing the connectivity of free space for a single robot moving around the
world (e.g. a vertical cell decomposition or a visibility graph, LaValle, 2006). We also have
a set of robots R = {r1 , . . . , rk } which we shall consider to be homogeneous, so a single map
suffices for them all. We shall assume all starting locations and goals lie on this road-map.
Further, we shall assume that the map is constructed so that collisions only occur when
one robot is entering a vertex v at the same time as another robot is occupying, entering or
leaving this vertex. Robots occupying other vertices in the map do not affect this movement.
With appropriate levels of underlying control these assumptions can be satisfied for most
real-world problems.
A simple centralised approach to computing a plan proceeds as follows: First, initialise
every robot at its starting position, then select a robot and move it to a neighbouring vertex,
checking first that no other robot is currently occupying that vertex. Continue in this fashion, selecting and moving one of the robots at each step until each is at its goal. Pseudocode
for this process is shown in Algorithm 1. The code is presented as a non-deterministic algorithm, with choice points indicated by the choose operator, and backtracking required
when the fail command is encountered. In practice, a search algorithm such as depth-first,
breadth-first or A* search is necessary to evaluate all the alternative paths it presents.

498

Exploiting Subgraph Structure in Multi-Robot Path Planning

Algorithm 1 A simple centralised planning algorithm.
1: function Plan(G, a, b)
2:
if a = b then
3:
return hi
4:
end if
5:
choose r âˆˆ R
6:
select vf : a[vf ] = r
7:
choose vt âˆˆ {v | (vf , v) âˆˆ G}
8:
if a[vt ] 6= 2 then
9:
fail
10:
else
11:
a[vf ] â† 2
12:
a[vt ] â† r
13:
return (r, vf , vt ).Plan(G, a, b)
14:
end if
15: end function

. Build a plan from a to b in graph G.
. Nothing to do.
. Choose a robot.
. Find its location.
. Choose an edge.
. The destination is occupied; backtrack.
. Move the robot from vf to vt .
. Recurse.

This algorithm does a complete search of the composite space Gk = G Ã— G Ã— Â· Â· Â· Ã— G,
for k = |R| robots. After eliminating vertices which represent collisions between robots, the
size of the composite graph is given by:




V (Gk ) = n Pk
=

n!
(n âˆ’ k)!




k 
E(G ) = k |E(G)| (nâˆ’2) P(kâˆ’1)
= k |E(G)|

(n âˆ’ 2)!
(n âˆ’ k âˆ’ 1)!

where n = |V (G)| and k = |R|. The running time of this algorithm will depend on the
search algorithm used, but it can be expected to be very long for moderately large values
of n and k.

3. Subgraph Abstraction
Consider the problem shown in Figure 1. This road-map contains 18 vertices and 17 edges,
and there are 3 robots to plan for. So, according to the above formulae, the composite
graph has 18!/15! = 4896 vertices and 3 Ã— 17 Ã— 16!/14! = 12240 edges. A small map has
expanded into a large search problem. But to a human mind it is obvious that a lot of these
arrangements are equivalent. What is important is not the exact positions of the robots,
but their ordering.
Consider the subgraph labeled X. We recognise this subgraph as a stack. That is, robots
can only move in and out of this subgraph in a last-in-first-out (LIFO) order. Robots inside
the stack cannot change their order without exiting and re-entering the stack. So if our
goal is to reverse the order of robots in X, we know immediately that this cannot be done
without moving all the robots out of the stack and then have them re-enter in the opposite
order. Once the robots are in the right order, rearranging them into the right positions is
499

Ryan

y1

x1

x2
a

x3

x4

x5

y2

y3

y4

y5

y6

Y

z2

z3

z4

z5

z6

Z

x6

c

b

X

z1

Figure 1: A planning problem illustrating the use of subgraphs.
trivial. Thus we can make a distinction between the arrangement of the robots (in which
we specify exactly which vertex each robot occupies) and the configuration of the stack (in
which we are only interested in their order).
Now X has 6 vertices, so when there are m robots in the stack, there are 6 Pm =
6!/(6 âˆ’ m)! possible arrangements. So the total number of arrangements is:
6

P3 + 3 Ã— 6 P2 + 3 Ã— 6 P1 + 6 P0 = 120 + 3 Ã— 30 + 3 Ã— 6 + 1
= 229

In terms of deciding whether a robot can leave the stack, however, all we need to know is
their order. So we need only represent 3! + 3 Ã— 2! + 3 Ã— 1! + 1 = 16 different configurations
of the stack.
Subgraphs Y and Z are also stacks. Applying this analysis to all three, we find that
we can represent the abstract state space with only 60 different states, and 144 possible
transitions between states (moving the top-most robot off one stack onto another). This is
dramatically smaller than the composite map space above.
A stack is a very simple kind of subgraph and we will need a larger collection of canonical
subgraphs to represent realistic problems. The key features we are looking for are as follows:
1. Computing transitions to and from the subgraph does not require knowledge of the exact arrangement of robots within the subgraph, only some more abstract configuration
(in this case, their order).
2. If two arrangements of robots share the same configuration, then transforming one
into the other can be done easily without search,
3. Therefore planning need only be done in the configuration space, which is significantly
smaller.
Later we will introduce three more subgraph types â€“ cliques, halls and rings â€“ which also
share these properties and which are readily found in realistic planning problems. But first
we need to formalise the ideas of subgraph planning.

500

Exploiting Subgraph Structure in Multi-Robot Path Planning

4. Definitions
In this section we outline the concepts we will use later in the paper. A complete formal
definition of these terms is provided in the Appendix, along with a proof of soundness and
completeness of the subgraph planning process.
Given a map represented by a graph G we partition it into a set of disjoint subgraphs
S1 , . . . , Sm . These subgraphs are induced, i.e. an edge exists between two vertices in a
subgraph if and only if it also exists in G.
An arrangement a of robots in G is a 1-to-1 partial function a : V (G) â†’ R, which
represents the locations of robots within G. If robot r is in vertex v, we write a(v) = r.
We can also speak of the arrangement of robots within a subgraph S. We will denote
arrangements by the lowercase roman letters a, b
A configuration of a subgraph S is a set of equivalent arrangements of robots within S.
Two arrangements are equivalent if there exists a plan to move robots from one to the other
without any robots leaving the subgraph. We will denote a configuration of subgraph Sx
by cx . The configuration of the whole map can then be represented as a tuple of subgraph
configurations Î³ = (c1 , . . . , cm ).
There are two operators âŠ• and 	 which operate on configurations, representing a robot
entering and leaving the subgraph respectively. When a robot r moves between two subgraphs Sx and Sy their configurations change depending on the identity of the edge (u, v)
on which the robot traveled. We write:
c0x âˆˆ cx 	 (r, u),
c0y âˆˆ cy âŠ• (r, v)
In complex subgraphs it is possible for such a transition to result in several possible configurations, so the operators âŠ• and 	 return sets. It is also possible that a transition is
impossible from a particular configuration, in which case the operation returns the empty
set.
An abstract plan Î  can now be defined as a sequence of transitions Î£ with intermediate
configurations Î“. For every abstract plan between two arrangements there exists at least one
corresponding concrete plan, and vice versa. All the subgraph transitions in the concrete
plan must also exist in the abstract plan. The equivalence of arrangements in a configuration
then guarantees the existence of the intermediate steps. See the Appendix for a complete
proof.

5. Subgraph Planning
We can now construct a planning algorithm which searches the space of abstract plans (Algorithm 2). The procedure is much the same as before. First we compute the configuration
tuple for the initial arrangement. Then we extend the plan one step at a time. Each step
consists of selecting a robot r and moving it from the subgraph it currently occupies Sx to
a neighbouring subgraph Sy in the reduced graph X, along a connecting edge (u, v).
This transition is only possible if the plan-step (s, (u, v)) is applicable. If it is, it may
result in a number of different configurations in the subgraph entered. We need to choose
one to create the configuration tuple for the next step. Both the applicability test and the
selection of the subsequent configurations are performed in lines 10-11 of AbstractPlan.
501

Ryan

The abstract plan is extended step by step in this fashion until it reaches a configuration
tuple which matches the goal arrangement. The resulting abstract plan is then resolved into
a concrete plan. For each transition in the abstract plan we build two short concrete plans
â€“ one to move the robot to the outgoing vertex of the transition, and one to make sure the
incoming vertex is clear and the subgraph is appropriately arranged to create the subsequent
configuration. Since these two plans are on separate subgraphs, they can be combined in
parallel. The final step is to rearrange the robots into the goal arrangement. Again, this
can be done in parallel on each of the subgraphs.
AbstractPlan has been written as a non-deterministic program, including choicepoints. A search algorithm such as breadth-first or depth-first search is needed to examine
each possible set of choices in some ordered fashion. If this search is complete then an
abstract plan is guaranteed to be found, if one exists and so by the theorem above this
planning algorithm is both sound and complete. Note that the resolution phase of the
planner is entirely deterministic, so no further search is needed once an abstract plan is
found.
5.1 Subgraph Methods
The efficiency of this algorithm relies on being able to compute several functions without a
lot of search:
â€¢ Exit To compute c 	 (r, u), testing if it is possible for a robot to exit the subgraph
and determining the resulting configuration(s).
â€¢ Enter To compute c âŠ• (r, v), testing if it is possible for a robot to enter the subgraph
and determining the resulting configuration(s).
â€¢ Terminate To compute b/S âˆˆ c, testing if it is possible for the robots in the subgraph
to move to their terminating positions.
â€¢ ResolveExit To build a plan rearranging robots in a subgraph to allow one to exit.
â€¢ ResolveEnter To build a plan rearranging robots in a subgraph to allow one to
enter.
â€¢ ResolveTerminate To build a plan rearranging robots in a subgraph into their
terminating positions.
The key to efficient subgraph planning is to carefully constrain the allowed structure
of the subgraphs in our partition, so these functions are simple to implement and do not
require expensive search. The advantage of this approach is that each of these functions can
always be computed based only on the arrangement of other robots within that particular
subgraph, not relying on the positions of robots elsewhere.

6. Subgraph Structures
The key to this process is therefore in the selection of subgraph types. These abstractions
need to be chosen such that:
502

Exploiting Subgraph Structure in Multi-Robot Path Planning

v1

v2

v3

v1

vk

v2

(a) A stack

v3

vk

(b) A hall

v1

v2

v1

v2

v4

v3

v4

v3

(c) A clique

(d) A ring

Figure 2: Examples of the four different subgraph structures.

1. They are commonly occurring in real road-maps,
2. They are easy to detect and extract from a road-map,
3. They abstract a large portion of the search space,
4. Computing the legality of transitions is fast, sound and complete,
5. Resolving an abstract plan into a concrete sequence of movements is efficient.
In this paper we present four subgraph types: stacks, halls, cliques and rings, which satisfy
these requirements. In the following analysis, let n be the the number of vertices in the
subgraph and k be the number of robots occupying the subgraph before the action takes
place.
6.1 Stacks
A stack (Figure 2(a)) represents a narrow dead-end corridor in the road-map. It has only
one exit and it is too narrow for robots to pass one another, so robots must enter and leave
in a last-in-first-out order. It is one of the simplest subgraphs and does not occur often
in real maps, but it serves as an easy illustration of the subgraph methods. Formally it
consists of a chain of vertices, each linked only to its predecessor and its successor. Only
the vertex at one end of the chain, called the head, is connected to other subgraphs so all
entrances and exits happen there.
A configuration of a stack corresponds to an ordering of the robots that reside in it, from
the head down. Robots in the stack cannot pass each other, and so the ordering cannot be
changed without the robots exiting and re-entering the stack.

503

Ryan

6.1.1 Enter
A robot can always enter the stack as long as the stack is not full. Only one new configuration is created, adding the robot to the front of the ordering. This computation can be
done in O(1) time.
6.1.2 Exit
A robot can exit the stack only if it is the top robot in the ordering. Only one new
configuration is created, removing the robot from the ordering. This computation can also
be done in O(1) time.
6.1.3 Terminate
To determine whether termination is possible, we need to check if the order of robots in the
current configuration is the same as that in the terminating arrangement. This operation
takes O(k) time.
6.1.4 ResolveEnter
Rearranging robots inside the stack is simple since we know that the ordering is constant.
To vacate the top of the stack (the only possible entrance point) we move robots deeper
into the stack (as necessary). There is guaranteed to be room, since entering a full stack is
not permitted. At worst this takes O(k) time.
6.1.5 ResolveExit
When a robot exits the stack, the abstract planner has already determined that it is the
first robot in the stack with no others between it and the head vertex. It can simply move
up the stack to the head, and then out. No other robots need to be moved. At worst this
takes O(n) time.
6.1.6 ResolveTerminate
Finally, moving robots to their terminating positions can be done in a top-to-bottom order.
If a robot is below its terminating position it can move upwards without interference. If
a robot is above its terminating position, other robots below may need to be moved lower
in order to clear its path. This approach is sound, since the terminating positions of these
robots must be further down the stack (or else the ordering would be different). This process
has an O(nk) total worst-case running time.
6.2 Halls
A hall is a generalisation of a stack (Figure 2(b)). Like a stack, it is a narrow corridor
which does not permit passing, but a hall may have multiple entrances and exits along its
length. Formally it consists of a single chain of vertices, each one joined to its predecessor
and its successor. There must be no other edges between vertices in the hall, but there may
be edges connecting to other subgraphs from any node in the hall. Halls are much more
commonly occurring structures, but still maintain the same property as stacks: the robots

504

Exploiting Subgraph Structure in Multi-Robot Path Planning

j=0
v1

v2

v3

v4

v5
A

v6
B

C

D
j=1
v1

v2

v3

v4

v5
B

A

v6
C

D
j=2
v1
A

v2

v3

v4

B

v5

v6

C

D

Figure 3: Example of entering a hall subgraph, with k = 3, n = 6 and i = 3. Robot D can
enter at three possible sequence positions j = 0, 1 or 2 but not at j = 3.

cannot be reordered without exiting and re-entering. Thus, as with stacks, the configuration
of a hall corresponds to the order of the robots occupying it, from one end of the hall to
the other.
6.2.1 Enter
A robot can enter a hall as long as it is not full. The configurations generated by that
entrance depend on three factors: 1) The size of the hall n, 2) The number of robots
already in the hall k, and 3) The index i of the vertex at which it enters (ranging from 1 to
n).
Figure 3 shows how entering a hall can result in several different configurations. It is
a matter of how the robots already in the hall are arranged, to the left and right of the
entrance, before the entering robot moves in. If there is enough space in the hall on either
side of the entrance vertex, then the new robot can be inserted at any point in the ordering.
But if space is limited (as in the example) then it may not be possible to move all the robots
to one side or another, limiting the possible insertion points.
Given the three variables k, n, i above, we can compute the maximum and minimum
insertion points as:
j â‰¤ min(i âˆ’ 1, k)
j â‰¥ max(0, k âˆ’ (n âˆ’ i))

505

Ryan

Creating a new configuration is then just a matter of inserting the new robot into the
ordering at the appropriate point. Since the list of robots needs to be copied in order to do
this, it takes O(k) time for each new configuration.
6.2.2 Exit
Whether a robot can exit a hall via a given edge again depends on several factors: 1) the
size of the hall n, 2) the number of robots in the hall k, 3) the index i of the vertex from
which it exits (from 1 to k), 3) the index j of the robot in the ordering (from 1 to k). Exit
is possible if:
j â‰¤ i â‰¤ n âˆ’ (k âˆ’ j)
If exit is possible there is one resulting configuration: the previous ordering with the robot
removed. This takes O(k) time to compute.
6.2.3 Terminate
Checking termination is the same for halls as with stacks, we just have to test that the order
of robots in the final arrangement matches the current configuration. This can be done in
O(k) time for k robots in the hall.
6.2.4 ResolveEnter
To resolve an entrance to a hall we need to know which of the subsequent configurations we
are aiming to generate, so we know the proper insertion point for the entering robot. The
robots before the insertion point are shuffled in one direction so that they are on one side
of the entry vertex, and the rest to the other side. At worst this will take O(nk) time.
6.2.5 ResolveExit
Resolving an exit involves moving the robot up or down the hall to the exit vertex, shuffling
any other robots that are in the way. In the worst case, in which all the robots shuffle from
one end of the hall to the other, this takes O(nk) time.
6.2.6 ResolveTerminate
ResolveTerminate for a hall is identical to that for a stack, described above.
6.3 Cliques
A clique (Figure 2(c)) represents a large open area in the map with many exit points
(vertices) around its perimeter. Robots can cross directly from any vertex to another, and
as long as the clique is not full, other robots inside can be shuffled out of the way to allow
this to happen.
Formally a clique is a totally connected subgraph. Cliques have quite different properties
to halls and stacks. As long as there is at least one empty vertex in a clique, it is possible
to rearrange it arbitrarily. So a configuration of a clique, in this circumstance, is just the
set of robots it contains.

506

Exploiting Subgraph Structure in Multi-Robot Path Planning

However there are a special set of configurations in which the clique is locked. This
occurs when the number of robots in the clique equals the number of vertices. Then it
is impossible for the clique to be rearranged. A configuration of a locked clique has to
explicitly record the position of each robot.
6.3.1 Enter
A clique can always be entered so long as it is not full. If the clique has more than one
vacant vertex, then there is a single new configuration with the entering robot added to the
set of occupants. If the clique has only one space remaining, then the entering robot locks
the clique. In theory, at this point it is necessary to make a new configuration for every
possible arrangement of the occupying robots (with the entering robot always in the vertex
it enters).
In practice, it is more efficient to create just a single â€œlockedâ€ configuration which
records the locking robot and its vertex, and leaves the other positions unspecified. Any
permutation of the other robots is possible, so the exact details of the configuration need
not be pinned down until the next action (either Exit or Terminate) requires them to be.
This is a form of least commitment, and it can significantly reduce the branching factor of
our search.
Performing this test and creating the new configuration takes O(k) time for k robots in
the clique.
6.3.2 Exit
If the clique is unlocked then any robot can exit from any vertex and the new configuration
is created by simply removing the robot from the set of occupants.
If the clique is locked then a robot can only exit from the specific vertex that it occupies. The resulting configuration is unlocked and the exact locations of the robots can be
discarded.
In the least-commitment version, the locking robot is constrained to exit from its vertex
and every other robot can exit from any vertex except the one occupied by the locking
robot.
Performing this test and creating the new configuration takes O(k) time for k robots in
the clique.
6.3.3 Terminate
With an unlocked configuration, checking for termination simply consists of making sure
that all (and only) the required occupants are in the clique. For a locked configuration the
robots must all be in their terminating positions (as there is no possibility of rearranging
them). In the least-commitment version just the locking robot must be in its terminating vertex. We can then assume that all the other robots are also in their places (thus
committing to a choice of configuration that we delayed earlier).
Performing this test takes O(k) time for k robots in the clique.

507

Ryan

6.3.4 ResolveEnter
If the entrance vertex is occupied when a robot wishes to enter then we can simply move
the occupant directly to another vacant vertex in the clique, since every vertex is connected
to every other.
If we are using least commitment and the entering robot locks the clique then we need to
look ahead in the plan to see the next action involving this clique. If it is an exit transition
then we need to move the exiting robot to the exit vertex now (before the clique is locked).
If there is no subsequent exit, meaning the robots will be terminating in this clique, then
we need to rearrange them into their terminating positions at this point.
If we amortise the cost of any rearrangements over the subsequent call to ResolveExit
or ResolveTerminate we can treat this operation as taking O(1) time.
6.3.5 ResolveExit
If the clique is full at the time of exit then we can assume that the exiting robot is already
at its exit vertex and nothing needs to be done. On the other hand, if the clique is not full it
may be that the robot is not at its exit vertex. It must be moved there. If the exit vertex is
already occupied by another robot, it can be moved into another unoccupied vertex. Both
these movements can be done directly, as the clique is totally connected. This operation
takes O(1) time.
6.3.6 ResolveTerminate
If the clique is locked then we can assume that the robots have already been appropriately
arranged into their terminal positions and no further work needs to be done. Otherwise the
robots may need to be rearranged. A simple way to do this is to proceed as follows: for each
robot that is out of place, first vacate its terminating position by moving any occupant to
another unoccupied vertex, then move the terminating robot into the vertex. Once a robot
has been moved in this way it will not have to move again, so this process is correct but it
may produce longer plans than necessary. The upside is that it takes only O(n) time.
6.4 Rings
A ring (Figure 2(d)) resembles a hall with its ends connected. Formally, it is a subgraph S
with vertices V (S) = {v1 , . . . , vn } and induced edges E(S) satisfying:
(vi , vj ) âˆˆ E(S) iff |i âˆ’ j| â‰¡ 1 (mod n)
As with a hall, ordering is important in a ring. Robots in the ring cannot pass one another
and so cannot re-order themselves. They can, however, rotate their ordering (provided that
the ring is not full). Thus in a ring of size 4 or more, the sequence hr1 , r2 , r3 i is equivalent
to hr3 , r1 , r2 i but not to hr2 , r1 , r3 i. Equivalent sequences represent the same configuration.
Like cliques, rings are locked when they are full. A locked ring cannot be rotated, so
in a ring of size three the sequences hr1 , r2 , r3 i and hr3 , r1 , r2 i are not equivalent. They
represent two locked configurations with different properties.

508

Exploiting Subgraph Structure in Multi-Robot Path Planning

6.4.1 Enter
A robot may always enter a ring provided that it is not full. If there are k robots already
occupying the ring, then there are k possible configurations that can result (or one if k is
zero), one for each possible insertion point.
If the entering robot locks the ring then we must also record the specific positions of
each robot in the ring. This will still only produce k different configurations because the
robots cannot be arbitrarily rearranged, unlike in cliques.
It is also possible to produce least-commitment versions of Enter for rings as with
cliques. Again, this can significantly reduce the branching factor of the search, but the
details are more involved than we wish to enter into in this paper.
This operation takes O(k) time for each new configuration generated.
6.4.2 Exit
When the ring is locked a robot can only exit from its recorded position, otherwise it can
exit from any vertex. The robot is removed from the sequence to produce the resultant
configuration. The new configuration is unlocked and any position information can be
discarded. This can be done in O(k) time for k robots in the ring.
6.4.3 Terminate
To check if termination is possible we need to see if the order of robots around the ring in
the terminal arrangement matches that of the current configuration. If the configuration is
not locked then rotations are allowed, otherwise the match must be exact. This test can be
done in O(k) time for k robots in the ring.
6.4.4 ResolveEnter
When a robot is about to enter the ring, we need to first rearrange it so that the the entry
vertex is empty and the nearest robots on either side of that vertex provide the correct
insertion point for the subsequent configuration, as selected in Enter above. This may
require shuffling the robots one way or another, in much the same fashion as in a stack or
hall. In the worst case this will take O(nk) operations for k robots in a ring of n vertices.
6.4.5 ResolveExit
If a ring is locked then any robot exiting must already be at its exit position so nothing needs
to be done. Otherwise, in an unlocked ring, the robots may need to be shuffled around the
ring in order to move the robot to its exit. In the worst case this will take O(nk) operations
for k robots in a ring of n vertices.
6.4.6 ResolveTerminate
If a ring is locked then all the robots must already be in their terminating positions; this is
guaranteed by the abstract planner. Otherwise they will need to be rotated into the correct
positions. Once one robot has been moved to its correct vertex, the rest of the ring can be
treated as a stack and the ResolveTerminate method described above can be used, with
O(nk) worst case running time for k robots in a ring of n vertices.
509

Ryan

6.5 Summary
Of these four subgraphs halls and rings are the most powerful. Such subgraphs are not only
common in the structured maps of man-made environments, but can also be found often
in purely random graphs (consider: any shortest path in an unweighted graph is a hall).
Halls, rings and cliques of significant size can be found in many realistic planning problems.
Importantly, these structures are well constrained enough that the six procedures for
planning outlined above can all be implemented efficiently and deterministically, without the
need for any further search. In the cases of the clique and the ring, the resolution methods
we describe sometimes sacrifice path optimality for speed, but this could be improved by
using smarter resolution planners. Since the resolution stage is only done once, this probably
would not have a major effect on the overall running time of the planner.

7. Prioritised Planning
A common solution to the rapid growth of search spaces in multi-robot planning is prioritised
planning (Erdmann & Lozano-PeÌrez, 1986; van den Berg & Overmars, 2005). In this
approach we give the robots a fixed priority ordering before we begin. Planning is performed
in priority ordering: first a plan is built for just the robot with highest priority; then a plan
for the second highest, such that it does not interfere with the first; then the third, and so
on. Each new plan must be constructed so that it does not interfere with the plans before
it. An example implementation is shown in Algorithm 3. Usually there is no backtracking
once a plan has been made. This is signified in the algorithm by the cut operator in line 8
of Plan.
Because of this cut, the search is no longer complete. There are problems with solutions
that a prioritised planner cannot find. Figure 4 is an example. Robots a and b wish to
change positions. To plan for either robot on its own is easy; the plan contains just one
step. But to plan for both robots together requires each of them to move out of its way,
to the right hand side of the map so that the other can pass. A prioritised planner which
committed to a one-step plan for either a or b cannot then construct a plan for the other
robot which does not interfere.
This incompleteness is not just a mistake, however. It is the core of what makes prioritised planning more efficient. The search space has been pruned significantly by eliminating

x1

x2
a

x3

x4

b
y

Figure 4: A simple planning problem that cannot be solved with naive prioritised planning.
The goal is to swap the positions of robots a and b.

510

Exploiting Subgraph Structure in Multi-Robot Path Planning

certain plans from consideration. If there is still a viable solution within this pruned space
(and often there is) then it can be found much more quickly. In the (hopefully few) cases
where it fails, we can always resort to a complete planner as a backup.
7.1 Prioritised Subgraph Planning
Prioritised planning is not strictly a competitor to subgraph planning. In fact, prioritised
search and the subgraph representation are orthogonal ideas, and it is quite possible to use
both together. As in Algorithm 3, a plan is constructed for each robot consecutively, but
rather than building an entire concrete plan, only the abstract version is produced, in the
fashion of Algorithm 2 earlier. Only when compatible abstract plans have been produced
for every robot, are they resolved into a concrete plan.
As well as adding the advantage of abstraction to prioritised planning, the subgraph
representation also allows the planner to cover more of the space of possible plans. By
delaying resolution until the end, we avoid commitment to concrete choices for a high
priority robot which will hamper the planning of later robots.
To illustrate this, letâ€™s return to the example in Figure 4 above. If we partition this
subgraph so that vertices {x1 , x2 , x3 , x4 } are a hall X, then the prioritised subgraph planner
can solve the problem. The abstract plan for the highest priority robot is empty; there is
nothing for it to do as it is already in its goal subgraph. Given this plan, the second highest
priority robot can plan to move from X to y and then back again. This plan can produce
the goal configuration required. Resolving this plan will move the highest priority robot to
x4 and back again as needed, but this plan will be built by the Resolve methods for halls,
and not by search.
Of course there is no such thing as a free lunch and this example only works if we choose
the right partition. If instead we treat {x1 , x2 } as a stack and {x4 , x3 , y} as a separate hall
then the prioritised subgraph planner will not help us. Furthermore there exist problems,
such as the one in Figure 5 which can be solved by standard prioritised planners but will
fail if we introduce the wrong subgraph abstraction. It is difficult to generate more realistic

x1

x2

x3

a

x4
b

y

Figure 5: A simple planning problem that can be solved with naive prioritised planning but
not with the subgraph abstraction. The goal is to swap the positions of robots
a and b. With priority ordering a, b the subgraph planner will choose for robot
a to remain inside the hall. Robot b is then trapped, because a blocks the only
exit to y (note that the edges (x1 , y) and (y, x4 ) are directed).

511

Ryan

cases of this problem with small numbers of robots, but as we will see in Section 9.3 below,
they can occur when the number of robots is large.

8. Search Complexity
Let us consider more carefully where the advantages (if any) of the subgraph decomposition lie. Subgraph transitions act as macro-operators between one abstract state (set of
configurations) to another. There is a long history of planners using macros of one kind
or another, and their advantages and disadvantages are well known (see Section10.1). It is
widely recognised that macros are advantageous when they reduce the depth of the search,
but become a disadvantage when too many macros are created and the branching factor of
the search becomes too large. These guidelines also apply to the use of subgraphs.
A typical search algorithm proceeds as follows: select a plan from the frontier of incomplete plans and create all expansions. Add all the expansions to the frontier and recurse
until a complete plan is found. The time taken to complete this search is determined by
the number of nodes in the search tree, which is in turn determined by three factors:
1. d, the depth of the goal state,
2. b, the average branching factor of the tree, i.e. the number of nodes generated per
node expanded
3. The efficiency of the search.
A perfect search algorithm, which heads directly to the goal, will nevertheless contain O(bd)
nodes as the alternative nodes must still be generated, even if they are never followed. An
uninformed breadth-first search, on the other hand, will generate O(bd ) nodes. This can be
regarded as a sensible upper bound on the efficiency of the search (although it is possible
to do worse).
Macro-operators tend to decrease d at the expense of increasing b, so do very well in
uninformed search when d dominates, but show less advantage when a good heuristic exists,
where b and d are equally important. So it becomes important to consider how to keep the
increases in branching factor to a minimum. In the case of subgraph planning, there are
two main reasons why b increases:
1. The reduced graph may have a larger average degree than the original. Since a
subgraph contains many vertices, it tends to have more out-going edges than a single
vertex. If all these edges connect to different subgraphs, then the branching factor will
be significantly larger. Sparse subgraphs (such as halls) are worse in this regard than
dense subgraphs (such as cliques). The subgraph decomposition needs to be chosen
carefully to avoid this problem.
2. A single subgraph transition may create a large number of possible configurations,
such as when a robot enters a large hall which is already occupied by several robots.
In some cases it may not strictly matter which configuration is generated and where
possible we use least commitment to avoid creating unnecessary alternatives, but if
there is the possibility that different configurations will result in different outcomes

512

Exploiting Subgraph Structure in Multi-Robot Path Planning

further down the track, then they all need to be considered. Halls in particular have
this problem.
As we will see in the experiments that follow, careful choice of the subgraph decomposition is important to avoid these pitfalls, but with an appropriate partition the abstraction
can significantly improve both informed and uninformed search.

9. Experiments
To empirically test the advantages of the subgraph approach, we ran several experiments
on both real and randomly generated problems. Our first experiment demonstrates how the
algorithms scale with changes to the size of the problem, in terms of the number of vertices,
edges and robots, under a standard breadth-first search. The second experiment shows how
these results are affected by using an heuristic to guide search. Both of these experiments
use randomly generated graphs. The final experiment demonstrates the algorithm on a
realistic problem.
In the first two experiments, maps were generated randomly and automatically partitioned into subgraphs. Random generation was done as follows: first a spanning tree was
generated by adding vertices one by one, connecting each to a randomly selected vertex in
the graph. If further edges were required they were generated by randomly selecting two
non-adjacent vertices and creating an edge between them. All edges were undirected.1
Automated partitioning worked as follows:
1. Initially mark all vertices as unused.
2. Select a pair of adjacent unused vertices.
3. Use this pair as the basis for growing a hall, a ring and a clique:
Hall: Randomly add unused vertices adjacent to either end of the hall, provided they
do not violate the hall property. Continue until no further growth is possible.
Ring: Randomly add unused vertices adjacent to either end of the ring until a loop
is created. Discard any vertices not involved in the loop.
Clique: Randomly add unused vertices adjacent to every vertex in the clique. Continue until no further growth is possible.
4. Keep the biggest of the three generated subgraphs. Mark all its vertices as used.
5. Go back to step 2, until no adjacent unused pairs can be found.
6. All remaining unused vertices are singletons.
This is not intended to be an ideal algorithm. Its results are far from optimal but it is fast
and effective. Experience suggests that a partition generated by this approach can contain
about twice as many subgraphs as one crafted by hand, and it makes no effort to minimise
the degree of the reduced graph, but even with these randomly generated partitions the
advantages of the subgraph abstraction are apparent.
1. It should be noted that this algorithm does not generate a uniform distribution over all connected graphs
of a given size, but it is very difficult to generate sparse connected graphs with a uniform distribution.
The bias is not deemed significant.

513

Ryan

4.0
Original
Reduced

30

3.5

degree

# subgraphs

3.0
20

2.5

2.0
10
1.5

0

1.0
10

20

30

40

50

60

70

80

90

100

10

# vertices

20

30

40

50

60

70

80

90

100

# vertices

Figure 6: The results of the automatic partitioning program in Experiment 1a. The left
graph shows the average number of subgraphs generated and the right graph
shows the average degree of the reduced graph.

9.1 Experiment 1: Scaling Problem Size
9.1.1 Scaling |V |
In the first experiment we investigate the effect that scaling the number of vertices in the
graph has on search time. Random graphs were generated with the number of vertices
ranging from 10 to 100. Edges we added so that the average degree d = |E|/|V | was always
equal to 3. (This value seems typical for the realistic maps.) One hundred graphs were
generated of each size, and each one was partitioned using the method described above.
Figure 6 shows the performance of the auto-partitioning. As we can see, the number of
subgraphs increased roughly linearly with the size of the graph, with an average subgraph
size of 4. For small graphs (with fewer than 40 vertices) the reduced graph after partitioning
is sparser than the original, but as the size increases the average degree of the reduced graph
gets larger. These results are presented for informative purposes only. We make no claims
about the quality of this partitioning algorithm, other than that it is indeed reducing the
size of the graph, if only by a small factor.
In each graph, three robots were given randomly selected initial and final locations, and
a plan was generated. Figure 7(a) shows the average run times for each of the four approaches.2 It shows a clear performance hierarchy. The complete planners are significantly
slower than the priority planners, and in both cases the subgraph abstraction shows a significant improvement over the naive alternative. Nevertheless, in every case the combinatorial
growth in runtime is apparent (note that the graph is plotted on a log scale). The linear
relationship between number of vertices and number of subgraphs prevents the subgraph
2. It has been noted that these times are overall rather slow. We acknowledge this and attribute it to our
implementation, which is in Java and which was not heavily optimised to avoid garbage collection. We
are currently working on an implementation with an optimised search engine, but we believe that these
results still provide a valuable comparison between methods.

514

Exploiting Subgraph Structure in Multi-Robot Path Planning

1000000

100000

Time (ms)

10000

1000

100
Naive complete
Naive priority
Subgraph complete
Subgraph priority

10

1
10

20

30

40

50

60

70

80

90

100

# vertices
(a) run times
8
Naive complete
Naive priority
Subgraph complete
Subgraph priority

7

Naive complete
Naive priority
Subgraph complete
Subgraph priority

30

5

path length

branching factor

6

4

20

3
10

2
1
0

0
10

20

30

40

50

60

70

80

90

100

10

# vertices

20

30

40

50

60

70

80

90

100

# vertices

(b) branching factor

(c) goal depth

Figure 7: The results of Experiment 1a. In graph (a) the boxes show the first and third
quartile and whiskers to show the complete range. When an experiment failed to
complete due to time or memory limits or incompleteness of the search, the run
time was treated as infinite. No value is plotted for cases where more than 50%
of experiments failed. In graph (c) the goal depth for the naive complete and
subgraph priority approaches are identical for graphs of 30 to 60 vertices, so the
lines overlap. The naive complete planner could not solve problems with more
than 60 vertices.

515

Ryan

Table 1: The number of planning failures recorded by the two prioritised planning approaches in Experiment 1a.
# Failures
Vertices Naive Subgraph
10
2
0
20 - 70
0
0
80
1
0
90 - 100
0
0

approaches from doing better than this. A better partitioning algorithm should ameliorate
this problem.
To analyse the causes of this variation in run times, we need to consider the search
process more carefully. We can measure the search depth d and average branching factor b
for each experiment. The results are plotted in Figure 7(b) and (c). As we expected, when
the subgraph abstraction is used, the goal depth is decreased and grows more slowly, but
the branching factor is increased. Since we are doing uninformed search, d dominates and
the overall result is an improvement in planning time.
The incompleteness of prioritised planning shows in Table 1. On three occasions the
naive prioritised search failed to find available solutions. However this was not a problem
for the prioritised subgraph search.
9.1.2 Scaling |E|
Next we examine the effect of graph density. Fixing the number of vertices at 30, we
generated random graphs with average degree ranging from 2.0 to 4.0. For each value,
100 graphs were randomly generated and automatically partitioned. Again the planning
problem was to move three robots from between selected initial and goal locations.
The results for this experiment are shown in Figure 8. There does not appear to be much
overall change in the run times of any of the approaches, other than a small improvement
from the naive prioritised planner as the graph gets denser. Figures 8(b) and (c) show
the expected result: increasing the density of the graph increases the branching factor but
decreases the depth. It appears to affect all four approaches similarly.
An interesting difference, however, is shown in Table 2. This records the percentage of
experiments for which each of the prioritised planners was unable to find a solution. For
very sparse graphs, the naive planner failed on as many as 10% of problems, but it improved
quickly as density increased. With the subgraph abstraction added, the planner was able
to solve all but two of the problems. In no case did we find problems which were solved by
the naive planner and not by the subgraph planner.
9.1.3 Scaling |R|
In the last of the scaling experiments, we investigate how each approach performs with
varying numbers of robots. As before, 100 random graphs were generated and partitioned,
each with 30 vertices and average degree of 3, and each one was partitioned using the
516

Exploiting Subgraph Structure in Multi-Robot Path Planning

10000

Time (ms)

1000

100

10
Naive complete
Naive priority
Subgraph complete
Subgraph priority
1
2.0

2.2

2.4

2.6

2.8

3.0

3.2

3.4

3.6

3.8

4.0

degree
(a) run times
8

40

6

Naive complete
Naive priority
Subgraph complete
Subgraph priority

30
path length

branching factor

7

Naive complete
Naive priority
Subgraph complete
Subgraph priority

5
4

20

3
10
2
1
2.0

2.2

2.4

2.6

2.8

3.0

3.2

3.4

3.6

3.8

4.0

0
2.0

2.2

2.4

2.6

2.8

degree

3.0

3.2

degree

(b) branching factor

(c) goal depth

Figure 8: The results for Experiment 1b.

517

3.4

3.6

3.8

4.0

Ryan

100000

Time (ms)

10000

1000

100

Naive complete
Naive priority
Subgraph complete
Subgraph priority

10

1
1

2

3

4

5

6

7

8

9

10

# robots
(a) run times
Naive complete
Naive priority
Subgraph complete
Subgraph priority

7

Naive complete
Naive priority
Subgraph complete
Subgraph priority

1000

5

100
path length

branching factor

6

4

3

10

2

1

1
1

2

3

4

5

6

7

8

9

10

1

2

3

4

# robots

5

6
# robots

(b) branching factor

(c) goal depth

Figure 9: The results for Experiment 1c.

518

7

8

9

10

Exploiting Subgraph Structure in Multi-Robot Path Planning

Table 2: The number of planning failures recorded by the two prioritised planning approaches in Experiment 1b.
# Failures
Degree Naive Subgraph
2.0
10
0
2.2
8
0
2.4
5
0
2.6
1
1
2.8
0
0
3.0
2
0
3.2
1
1
3.4 - 4.0
0
0

Table 3: The number of planning failures recorded by the two prioritised planning approaches in Experiment 1c.
# Failures
# Robots Naive Subgraph
1-3
0
0
4
3
0
5
4
0
6
10
0
7
7
1
8
7
1
9
26
0
10
46
1

automatic partitioning algorithm. Ten planning problems were set in each graph with the
number of robots varying from 1 to 10. In each case initial and goal locations were selected
randomly.
The running times for all four approaches are plotted in Figure 9(a). There is a major
performance difference between the prioritised and non-prioritised planners, with the prioritised planners able to handle twice as many robots. Between the two complete-search
approaches, the subgraph abstraction is an unnecessary overhead for very small problems,
but shows significant advantage as the number of robots increases.
There is less obvious advantage to the subgraph abstraction in the case of prioritised
planning, until we look at the failure rates shown in Table 3. As the number of robots
increases the incompleteness of the naive prioritised algorithm begins to become apparent,
until with 10 robots we see that 46% of the problems could not be solved by this planner.
The advantage of the subgraph abstraction is now apparent: only a total of 3 problems
could not be solved out of 1000 tried.

519

Ryan

Figures 9(b) and (c) plot the average branching factor and goal depth for these problems.
As in previous experiments, the subgraph abstraction is seen to increase the branching
factor but decrease the depth. In the complete search approaches the branching factor
grows rapidly with the number of robots, as each node on the search path contains a choice
of which robot to move. The prioritised approach reverses this trend, as planning is only
ever done for one robot at a time, and the later robots are much more heavily constrained
in the options available to them, providing fewer alternatives in the search tree.
9.1.4 Discussion
To summarise the above experiments, the advantages of the subgraph abstraction are twofold. Firstly, it decreases the necessary search depth of a planning problem by compressing
many robot movements into a single abstract step. Like other macro-based abstractions, it
does this at the expense of increasing the branching factor but the gains seem to outweigh
the losses in practice. Of course, this is dependent to some degree on the use of uninformed
search, which we shall address below.
The other advantage is specific to the prioritised planner. For tightly constrained problems with sparse maps and/or many robots the incompleteness of the naive prioritised
search becomes a very significant issue. With the addition of the subgraph abstraction the
number of such failures is dramatically reduced, without additional search.
9.2 Experiment 2: Heuristic Search
All the experiments so far have involved uninformed breadth-first search without the use of
an heuristic. As such, the runtime of the algorithms is more strongly affected by changes
in search depth than by the branching factor. As we explained above, uninformed search
has an O(bd ) expected running time. However a perfect heuristic can reduce this to O(bd),
making the branching factor a much more significant aspect. A perfect heuristic is, of course,
unavailable, but it it possible to efficiently compute a reasonably good search heuristic for
this task by relaxing the problem. Disregarding collisions we can simply compute the sum
of the shortest path lengths from each robotâ€™s location to its goal. This is an underestimate
of the actual path length, but is accurate for loosely constrained problems (with few robots
and dense graphs).
In this experiment we used a best-first search algorithm guided by this heuristic.3 At
every node in the search tree, we selected the plan which minimised this value. In the case
of the subgraph planner, the actual locations of robots at any time-point are not specified,
just the subgraph they occupy, so the heuristic was calculated using the maximum distances
from any vertex in each robotâ€™s subgraph to its goal. We pre-computed the shortest path
distances between every pair of nodes before running the planner, so the time to do this
computation is not counted in the runtime for the algorithm.
The utility of this heuristic depends largely on how constrained the problem is. If the
graph is dense and there are relatively few robots, the heuristic should direct the planner
quickly to the goal. However if the graph is sparser, then interactions between robots
will become more important, and the heuristic will be less useful. For this reason, we
3. The A* algorithm was not used, as we have no desire to minimise the length of the solution, just to find
a solution as quickly as possible.

520

Exploiting Subgraph Structure in Multi-Robot Path Planning

concentrate our attention in this experiment on how varying the density of the graph affects
the performance of our different approaches.
Random maps of 200 vertices were generated, with average degree ranging from 2 to
3. One hundred graphs were generated of each size and partitioned using the algorithm
described earlier. Figure 10 shows the results. As the original graph gets denser, the
number of subgraphs decreases, mostly because it is possible to create longer halls. This is
good, as fewer subgraphs mean shorter paths, but the consequential increase in degree will
adversely affect the branching factor.
Ten robots were placed randomly in each graph and assigned random goal locations.
All four planning approaches were applied to these problems. The resulting run-times
are plotted in Figure 11(a). The first thing that is apparent from this graph is that the
distinction between the different approaches is greatly reduced. Both the size of the graph
and the number of robots are much larger than in previous experiments, and this has had
a corresponding effect on the goal depth and branching factor (Figure 11(b) and (c)), but
the run-times are much smaller, so clearly the heuristic is effective at guiding the search.
On average the ratio of search nodes expanded to goal depth was very close to 1.0 in all
experiments, with only a slight increase in the more constrained cases, so we can conclude
that this heuristic is close to perfect.
When we compare the four approaches we see three distinct stages. In the most constrained case, at 200 edges, we see both the subgraph approaches outperforming either naive
approach, with a small benefit in prioritised search over complete search. At 220 edges the
pattern has changed. The two prioritised methods are significantly better than the two
complete approaches. As the number of edges increases, both the naive methods continue
to improve, while prioritised subgraph search holds steady and complete subgraph search
gets significantly worse (due to its rapid increase in branching factor). At 300 edges both
the naive approaches are doing significantly better than the subgraph approaches.

All
Singletons
Halls
Cliques
Rings

60

4.5

Original
Reduced

4.0

50

degree

# subgraphs

3.5
40
30

3.0
2.5

20

2.0

10

1.5

0

1.0
200

210

220

230

240

250

260

270

280

290

300

200

# edges

210

220

230

240

250

260

270

280

290

# edges

(a) subgraphs

(b) degree

Figure 10: The results of the auto-partitioner on graphs in Experiment 2.

521

300

Ryan

10000

Time (ms)

1000

100
Naive complete
Naive priority
Subgraph complete
Subgraph priority
10
200

210

220

230

240

250

260

270

280

290

300

edges
(a) run times
120

Naive complete
Naive priority
Subgraph complete
Subgraph priority

400

Naive complete
Naive priority
Subgraph complete
Subgraph priority

300
80

path length

branching factor

100

60

200

40
100
20
0
200

220

240

260

280

300

0
200

220

240

edges

260
edges

(b) branching factor

(c) goal depth

Figure 11: The results for Experiment 2.

522

280

300

Exploiting Subgraph Structure in Multi-Robot Path Planning

Table 4: The number of planning failures recorded by the two prioritised planning approaches in Experiment 2.
# Failures
# Edges Naive Subgraph
200
14
0
210
2
0
220
0
0
230
0
0
240
1
0
250 - 300
0
0

The cause is clearly seen in Figures 11(b) and (c). The branching factors for the subgraph
approaches increase significantly faster than for the naive approaches, and the corresponding
improvement in goal depth is not sufficient to outweigh the cost.
The benefits of the subgraph abstraction in highly constrained cases is also shown in the
failure cases (Table 4). At 200 edges the naive prioritised search was unable to solve 10%
of problems, while prioritised search with subgraphs could solve them all. The number of
failures fell quickly as the density of the graph increased.
9.2.1 Discussion
Once a graph becomes moderately dense and interactions between robots become few,
the total-single-robot-paths measure becomes a near perfect heuristic. This makes the
branching factor a much more critical factor than when using uninformed search. The
auto-partitioning algorithm we use does a very poor job limiting this factor and so the
subgraph approaches perform poorly.
Better results could be achieved with better decomposition, but it is not clear whether
this could be found in a random graph without excessive computation. Certainly partitioning such graphs by hand is no easy task. Realistic graphs, on the other hand, are generally
shaped by natural constraints (e.g. rooms, doors and corridors) which make decomposition
much simpler, as we will see in the following experiment.
9.3 Experiment 3: The Indoor Map
Figure 12 shows the map for our final two experiments, based on the floor-plan of Level 4 of
the K17 building at the University of New South Wales. A road-map of 113 vertices and 308
edges has been drawn (by hand) connecting all the offices and open-plan desk locations.
It is imagined that this might be used as a map for a delivery task involving a team of
medium-sized robots.
The road-map has been partitioned into 47 subgraphs â€“ 11 cliques, 7 halls and 1 ring,
plus 28 remaining â€™singletonâ€™ nodes (subgraphs containing only one vertex). The average

523

Ryan

Figure 12: The map for Experiment 3. Vertices are coloured by subgraph.

524

Exploiting Subgraph Structure in Multi-Robot Path Planning

10000
Naive complete
Naive priority
Subgraph complete
Subgraph priority

Time (ms)

1000

100

10
1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

robots

Figure 13: Comparing run times for Experiment 3.
degree of the reduced graph is 2.1, compared to 2.7 in the original.4 Partitioning was done
by hand with the aid of an interactive GUI which performed some simple graph analysis
and offered recommendations (by indicating nodes which could be added to a hall or clique
the user is creating). The road-map was clearly laid out with partitioning in mind and
deciding on this partitioning was not on the whole difficult. Large open spaces generally
became cliques. Corridors became halls or rings. Only the foyer area (around vertex 94)
caused any particular trouble when finding an ideal partitioning, due to its slightly unusual
topology.5
A series of experiments were run in this world, varying the number of robots from 1
to 20. For each experiment 100 runs were performed in which each robot was placed in
a random office or desk and was required to make a delivery to another random office or
desk (chosen without replacement, so no two robots had the same goal). Plans were built
using both complete and prioritised planners with and without the subgraph abstraction.
All four approaches utilised the total single-robot shortest path heuristic from the previous
experiment. The running times of each algorithm are shown in Figure 13.
We can see that for small numbers of robots (1 or 2) the naive approaches are significantly better than the subgraph approaches. The overhead of doing subgraph search
outweighs its disadvantages in such simple problems. As the number of robots increases
the subgraph methods take over, and for around 9 to 16 robots both subgraph methods are
significant better than either naive approach. At 17 robots the combination of complete
search with subgraphs begins to perform less well and the two prioritised approaches are
the best performers, with a considerable advantage to the subgraph approach.
4. In comparison, the auto-partitioner yielded a partition with fewer subgraphs (avg. 41.8) but higher
degree (avg. 2.25).
5. For the curious, the empty rooms in the centre of the map, near vertex 91, are bathrooms. We did not
consider that the robots would need to make deliveries there.

525

Ryan

Naive complete
Naive priority
Subgraph complete
Subgraph priority

1.8
1.7

expanded / path

1.6
1.5
1.4
1.3
1.2
1.1
1.0
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20
robots

Figure 14: Assessing the quality of the heuristic in Experiment 3. The value plotted is the
ratio of the number of expanded nodes in the search tree and the goal depth. A
perfect heuristic yields a value of 1.0.

Considering search complexity, let us first examine the performance of the heuristic.
Figure 14 plots the ratio or the average number of expanded nodes in the search tree and
the goal depth. For a perfect heuristic, this value is 1.0, as it is in this experiment for up
to 11 robots. With more than 11 robots the heuristic begins to become inaccurate. The
inaccuracy seems to affect the complete planners more badly than the prioritised ones, and
in both cases the subgraph approach is more seriously affected than the naive approach.
To explain this difference, note that the heuristic we are using contains significantly less
information for subgraph search than it does for naive search. As we do not know exactly
where a robot is within a subgraph, we assume that it is in the worst possible position. This
means that the value of a configuration tuple is based solely on the allocation of robots to
subgraphs, and not on the particular configurations of those subgraphs. Hall subgraphs in
particular may have several different configurations for the same set of robots, which will all
be assigned the same heuristic value despite having significantly different real distances to
the goal.This creates a plateau in the heuristic function which broadens the search. For large
numbers of robots these permutations become a significant factor in the search. To improve
the heuristic we need to find a way to distinguish the value of different configurations of a
subgraph. This will probably require an extra method for each specific subgraph structure.
The graphs of branching factor and goal depth (Figure 15) show what we have come to
expect â€“ the branching factor is larger in the complete search than in prioritised search and
the subgraph abstraction makes it worse. Significantly, the branching factor for prioritised
526

Exploiting Subgraph Structure in Multi-Robot Path Planning

Naive complete
Naive priority
Subgraph complete
Subgraph priority

50

Naive complete
Naive priority
Subgraph complete
Subgraph priority

2000

path length

branching factor

40

30

20

1000

10

0

0
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20

1

robots

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20
robots

(a) branching factor

(b) goal depth

Figure 15: The branching factor and goal depth for Experiment 3.
Table 5: The number of planning failures recorded by the two prioritised planning approaches in Experiment 3.
# Failures
Edges Naive Subgraph
1-9
0
0
10 - 19
0
1
20
0
2

search does not increase as more robots are added, because at any step in the plan only
one robot can be moved. The goal depth shows the opposite pattern, complete searches are
shorter than prioritised searches and the subgraph abstraction approximately halves the
search depth in all cases.
Failure rates are recorded in Table 5. The story here is different from that of previous
experiments. The naive prioritised planner was able to solve all the problems at every depth,
but adding the subgraph abstraction caused a small number of failures in more complex
problems. It is not clear what has caused this reversal. The cases involved are very complex
and elude analysis. This problem warrants further investigation.
9.3.1 Discussion
This experiment has shown that in a realistic problem with an appropriately chosen set
of subgraphs the subgraph abstraction is an effective way to reduce the search even when
a good heuristic is available. Why does the subgraph abstraction work so well in this
example, compared to the random graphs in Experiment 2? The answer seems to be found
in the degree of the reduced graph. Automatically partitioning a random graph significantly
increases its degree, as we saw in Figure 10(b). This, in turn, increases the branching factor
and thus the search time.

527

Ryan

In contrast, when we partition the realistic map we decreased the degree of the graph
from 2.7 to 2.1 (by hand) or 2.25 (automatically). The branching factor for the subgraph
methods is still larger (as one transition can still create multiple configurations) but the
effect is reduced enough to be overcome by the decrease in goal depth. The indication is
that a realistic map has more structure that can be exploited by this abstraction. More
investigation is warranted to characterise the features that many this possible.

10. Conclusion
We have demonstrated a new kind of abstract representation for multi-robot path planning
which allows for much faster planning without sacrificing completeness. Decomposing a
road-map into subgraphs is a simple and intuitive way of providing background knowledge
to a planner which can be efficiently exploited. The key is to find subgraph structures which
allow us to treat many arrangements of robots as equivalent configurations and to compute
transitions between these configurations quickly and deterministically. We have described
four such structures in this paper: stacks, halls, cliques and rings. These structures are
simple enough to compute configurations easily but also common enough to be found in
many realistic maps.
We have shown that abstract plans on these subgraphs can be resolved deterministically
into concrete plans without the need for further search. The planner is sound and complete,
although the plans produced are not necessarily optimal. Future work could prove that it
is worth spending more time in the resolution phase to trim unnecessarily wasteful plans,
using, for example, simulated annealing (Sanchez, Ramos, & Frausto, 1999). It may be that
the time saved in abstract planning leaves us space to do more clever resolution.
The conventional solution to the search-space explosion in multi-robot planning is prioritisation. We have shown that not only is subgraph-based planning competitive with
prioritised planning but also that the combination of the two methods is more powerful still
and in some cases, partly alleviates the incompleteness of the prioritised approach.
10.1 Related Work
Abstraction and hierarchical decomposition are standard techniques in planning and other
related search problems. The use of macro-operators dates back as far as Sacerdotiâ€™s early
work on the Abstrips planning system (Sacerdoti, 1974) which introduced abstraction
hierarchies, whereby a problem could first be solved at a high level of abstraction while
ignoring lower-level details. The idea has been re-expressed in many different ways through
the history of planning â€“ far too many to review in detail. This present work was particularly
inspired by the â€˜generic typesâ€™ of Long and Fox (2002) in which they similarly detected
substructures in a task-planning problem and solved them using structure-specific planners.
Hierarchical planning has been applied to path-planning before with abstractions such
as approximate cell decomposition (Barbehenn & Hutchinson, 1995; Conte & Zulli, 1995),
generalised Voronoi graphs (Choset & Burdick, 1995; Choset, 1996) and general ad-hoc
hierarchical maps (Bakker, Zivkovic, & KroÌˆse, 2005; Zivkovic, Bakker, & KroÌˆse, 2005, 2006),
but the structures identified in these examples do not carry over well to the multi-robot
scenario.

528

Exploiting Subgraph Structure in Multi-Robot Path Planning

Other faster solutions to the multi-robot problem are available if we can assume the
existence of â€œgarageâ€ locations for each robot (LaValle & Hutchinson, 1998) or other kinds
of temporary free space (Sharma & Aloimonos, 1992; Fitch, Butler, & Rus, 2003). The
method we present here makes no such assumption and is thus more general in application.
There does not appear to be any previous work which provides a complete abstraction-based
planner for the general multi-robot problem.
The work that bears most similarity to our own is not explicitly in robot path planning,
but in solving the Sokoban puzzle (Botea, MuÌˆller, & Schaeffer, 2003; Junghanns & Schaeffer, 2001). That domain is significantly more constrained than ours (the map is necessarily
an orthogonal grid and the stones can only move when they are pushed by the man) but
the method they employ is similar. Dividing a map up into rooms and tunnels they use
the strongly-connected-component algorithm to identify equivalent arrangements of boulders in each subpart. Equivalent arrangements are then treated as a single abstract state â€“
corresponding to a configuration in our formulation â€“ which is used as the state in a global
search. The particular structures they represent are different, but the general ideas of partitioning into independent local subproblems and identifying abstract states from strongly
connected components, are the same as those employed in this work.
10.2 Future Plans
In the next stage of this project we plan to examine the symmetries provided by the subgraph
representation. Recent work in symbolic task-planning (Porteous, Long, & Fox, 2004)
has shown that recognising and exploiting symmetries and almost-symmetries in planning
problems can eliminate large amounts of search. Subgraph configurations provide a natural
ground for similar work in our problem domain and we expect similar improvements are
possible.
We also plan to further investigate the problem of automatic subgraph partitioning
of maps. Having identified the importance of trading off path depth against branching
factor, we plan to make a partitioning algorithm which chooses subgraphs that optimise this
relationship. Automatically finding an optimal partition could be very hard, but creating
a powerful interactive partitioning tool for a human operator would seem to be a viable
compromise. One approach would be to adapt the auto-partitioner we describe in this
paper so that the seed vertices are selected by the user, who is then allowed to choose from
a number of possible subgraphs based on this selection.
Further subgraph structures can also be identified, and we are currently working on
formalising the properties of tree-structured subgraphs. Another possibility would be to
generalise cliques and rings into a new â€˜ring-with-chordsâ€™ structure, although characterising
such a structure may prove difficult.
There have been many other advances in search technology which may be applicable
to the multi-robot planning problem. We are currently in the process of re-expressing the
entire problem as a constraint satisfaction problem (CSP) in the Gecode constraint engine
(Gecode Team, 2006). We believe that the CSP formulation will be a powerful way to take
advantage of the structural knowledge that subgraph decomposition represents.

Acknowledgments
529

Ryan

Iâ€™d like to thank Jonathan Paxman, Brad Tonkes and Maurice Pagnucco for their help in
developing the ideas in this paper and proofreading the drafts.

Appendix A. Proof of Soundness and Completeness
In this appendix we set up the necessary formal definitions and then prove the soundness
and completeness of the abstract planning process. The main result is a theorem showing
that an abstract plan exists for a given problem if and only if a concrete plan also exists.
A.1 Graphs and Subgraphs
An induced subgraph S âŠ† G is a graph S = (V (S), E(S)) such that
V (S) âŠ† V (G)

E(S) = {(u, v) | u, v âˆˆ V (S), (u, v) âˆˆ E(G)}

Intuitively this describes a subgraph consisting of a subset of vertices with all their connecting edges from the parent graph. Thus an induced subgraph can be specified solely in
terms of its vertices. We shall henceforth assume that all subgraphs we refer to are induced.
A partition P of G is a set {S1 , . . . , Sm } of subgraphs of G satisfying
[
V (G) =
V (Si )
and
V (Si ) âˆ© V (Sj ) = âˆ…, âˆ€i, j : i 6= j
i=1...m

Given a graph G and a partition P we can construct the reduced graph X of G by
contracting each subgraph to a single vertex
V (X) = P
E(X) = {(Si , Sj ) | âˆƒx âˆˆ Si , y âˆˆ Sj : (x, y) âˆˆ G}
A.2 Robots and Arrangements
Let us assume we have a set of robots R. An arrangement a of robots in a graph G is a
1-to-1 partial function a : V (G) â†’ R. An arrangement represents the locations of robots
within G. If a(v) = r, then robot r is at vertex v. We shall use the notation a(v) = 2
to indicate that a is undefined at v, i.e. vertex v is unoccupied. An arrangement may not
necessarily include every robot in R. Two arrangements a and b are said to be disjoint if
range(a) âˆ© range(b) = âˆ…. Let AG represent the set of all arrangements of R in G.
If S is a subgraph of G, and a is an arrangement of R in G then we define a/S, the
induced arrangement of R in S, as
a/S(v) = a(v), âˆ€v âˆˆ V (S)
If S1 and S2 are disjoint subgraphs of G with disjoint arrangements a1 in S1 and a2 in
S2 , then we define the combined arrangement a = a1 âŠ— a2 as an arrangement in S1 âˆª S2
satisfying
(
a1 (v) if v âˆˆ S1
a(v) =
a2 (v) if v âˆˆ S2

530

Exploiting Subgraph Structure in Multi-Robot Path Planning

Lemma 1 If a is an arrangement in G with partition P = {S1 , . . . , Sm } and {a1 , . . . , am }
is the set of induced arrangements ai = a/Si , then the combined arrangement a1 âŠ—Â· Â· Â·âŠ—am =
a.
Given this identity, we can uniquely identify an arrangement a in G as the combination of
its induced arrangements over a partition P.
A.3 Concrete Plans
We now need to define what it means to move robots around a graph. First we will define
two operators âŠ• and 	 which respectively add and remove robots from a given arrangement.
Formally âŠ• : AG Ã— R Ã— V (G) â†’ AG is a mapping which satisfies
G

a âŠ• (r, v) = b
G

where

(
r
b(u) =
a(u)

if u = v
otherwise

Similarly 	 : AG Ã— R â†’ AG is a mapping which satisfies
G

a	r =b
G

where

(
2
b(u) =
a(u)

if a(u) = r
otherwise

We will omit the subscript G when it is clear from the context.
We can now define a plan-step s âˆˆ R Ã— E(G) in G as a robot/edge pair (r, u, v),
representing the movement of r along the edge from u to v, with u 6= v. A plan-step is
applicable to an arrangement a âˆˆ AG iff a(u) = r and a(v) = 2. In this case we can apply
s to a to produce a new arrangement b = s(a) where
s(a) = (a 	 r) âŠ• (r, v)
A concrete plan (or just plan) in G from a âˆˆ AG to b âˆˆ AG is a sequence of plan-steps
hs1 , . . . , sl i such that there exist arrangements a0 , . . . , al âˆˆ AG with si applicable to aiâˆ’1
and
a0 = a
al = b
ai = si (aiâˆ’1 ), âˆ€i : 0 < i â‰¤ l
Lemma 2 If S is a subgraph of G and P is a plan in S then P is also a plan in G.
Lemma 3 If P is a plan in G from a to b and Q is a plan in G from b to c, then the
concatenation of P and Q, written P.Q is a plan in G from a to c.
531

Ryan

Lemma 4 Let P kQ denote the set of all interleavings of sequences P and Q. Let S1 and
S2 be disjoint subgraphs of G, P1 be a plan on S1 from a1 to b1 and P2 be a plan on S2 from
a2 to b2 , such that a1 and a2 are disjoint. Any arbitrary interleaving P âˆˆ P1 kP2 is a plan
on G from a1 âŠ— a2 to b1 âŠ— b2 .
A.4 Configurations
Having defined the machinery for concrete plans, we now introduce abstraction. The key
idea is that of a configuration which is an abstraction of arrangements. If the robots in a
subgraph can be rearranged from one arrangement to another, without any of the robots
having to leave the subgraph during the rearrangement, then those two arrangements can
be treated as equivalent. Configurations represent sets of equivalent arrangements in a
subgraph. So, for example, in a stack subgraph a configuration is the set of all arrangements
which have the same ordering of robots. An arrangement over an entire partitioned graph
can be abstracted as the list of configurations it produces in each of its subgraphs.
Formally, we define a configuration relation âˆ¼ on graph G as an equivalence relation
G

over AG such that a âˆ¼ b iff there exists plans Pab and Pba in G from a to b and from b to a
G

respectively.
A configuration c of G is an equivalence class of âˆ¼. We write c = âˆ¼ (a) to represent
G

G

the equivalence class containing arrangement a. Let CG be the set of all configurations of
G.
Lemma 5 If a âˆ¼ b then range(a) = range(b)
G

Given this identity, we can unambiguously define the range of a configuration c to be
range(c) = range(a), for any a âˆˆ c
We can now extend our definitions of âŠ• and 	 to configurations. If c âˆˆ CG is a
configuration of G, r âˆˆ R and v âˆˆ V (G) then


c âŠ• (r, v) = âˆ¼ (a âŠ• (r, v)) | a âˆˆ c, a(v) = 2
G
G
G


c 	 (r, v) = âˆ¼ (a 	 r) | a âˆˆ c, a(v) = r
G

G

G

Note that âŠ• and 	 map configurations to sets of configurations.6
Given a partition P = {S1 , . . . , Sm } of G and a corresponding set of configuration
relations {âˆ¼ , . . . , âˆ¼ } we define a configuration tuple Î³ of R in G as a tuple (c1 , . . . , cm )
S1

Sm

where âˆ€i : ci âˆˆ CSi , and
[

range(ci ) = R

i=1...m

range(ci ) âˆ© range(cj ) = âˆ…, âˆ€i, j : i 6= j
6. Astute readers will notice that c 	 (r, v) never contains more than one element, although it may be
G

empty.

532

Exploiting Subgraph Structure in Multi-Robot Path Planning

A configuration tuple represents the abstract state of all the robots in the entire graph, in
terms of the configurations of the individual subgraphs in the partition. Given an arrangement a of G we can construct a corresponding configuration tuple Î³(a) = (c1 , . . . , cm ) where
ci = âˆ¼ (a/Si ). Conversely, if a/Si âˆˆ ci for all ci in Î³, then we write a âˆˆ Î³.
Si

Lemma 6 If a and b are arrangements in graph G with partition {S1 , . . . , Sm } and Î³ is a
configuration tuple in G with a, b âˆˆ Î³, then there exists a plan from a to b in G.
Proof
For each i = 1 . . . m, let ai = a/Si and bi = b/Si . Now ai âˆˆ ci and bi âˆˆ ci so
ai âˆ¼ bi . Therefore from the definition of âˆ¼ there exists a plan Pi from ai to bi in Si .
Si

Let P âˆˆ P1 k . . . kPm . Since the Pi â€™s are plans on disjoint subgraphs, P is a plan from
a1 âŠ— Â· Â· Â· âŠ— am = a to b1 âŠ— Â· Â· Â· âŠ— bm = b as required.

A.5 Abstract Plans
With configuration tuples as our abstract state representation, we can now define abstract
plans, as sequences of subgraph transitions â€“ plan steps which move a robot from one
subgraph to another. We will then prove the main result of this section, that an abstract
plan for a problem exists if and only if a corresponding concrete plan exists. This will allow
us later to prove the soundness and completeness of our subgraph planning algorithm.
For the rest of this section we shall assume that our graph G has a partition P =
{S1 , . . . , Sm } with corresponding configuration relations {âˆ¼ , . . . , âˆ¼ }.
S1

Sm

A subgraph transition (or just transition) is a plan-step s = (r, u, v) such that u âˆˆ Sx ,
v âˆˆ Sy and Sx 6= Sy . A transition s = (r, u, v) is applicable to a configuration tuple
Î³ = (c1 , . . . , cm ) of G if
cx 	 (r, u) 6= âˆ…, where u âˆˆ Sx ,
Sx

and cy âŠ• (r, v) 6= âˆ…, where v âˆˆ Sy .
Sy

That is, the robots in Sx can be rearranged so that robot r can leave via u and the robots
in Sy can be rearranged so that v is empty for r to enter.
If transition s = (r, u, v) is applicable to Î³ = (c1 , . . . , cm ) with u âˆˆ Sx and v âˆˆ Sy then
we can apply s to Î³ to compute a set s(Î³) of configuration-tuples
(c01 , . . . c0m ) âˆˆ s(Î³)
if and only if
c0x âˆˆ cx 	 (r, u),
Sx

and

c0y

âˆˆ cy âŠ• (r, v),

c0z

= cz , otherwise.

Sy

Lemma 7 If a is an arrangement in G with partition {S1 , . . . , Sm } and transition s =
(r, u, v) is applicable to a then s is also applicable to Î³(a), with
Î³(s(a)) âˆˆ s(Î³(a))
533

Ryan

Proof Let Sx , Sy be disjoint subgraphs from the partition such that u âˆˆ Sx , v âˆˆ Sy . Let
ax = a/Sx and ay = a/Sy . Let Î³(a) = (c1 , . . . , cm ). Now
ax âˆˆ cx
ax (u) = r
â‡’ cx 	 (r, u) 6= âˆ….
And similarly
ay âˆˆ cy
ay (v) = 2
â‡’ cy âŠ• (r, v) 6= âˆ….
Therefore s is applicable in Î³(a).
Further, let b = s(a) and Î³(b) = (c01 , . . . , c0m ). Now
c0x =âˆ¼ (b/Sx )
Sx

=âˆ¼ (ax 	 r)
Sx

âˆˆ cx 	 (r, u)
and
c0y =âˆ¼ (b/Sy )
Sy

=âˆ¼ (ay âŠ• (r, v))
Sy

âˆˆ cy âŠ• (r, v)
and
c0z = cz .
Therefore Î³(b) âˆˆ s(Î³) as required.



Lemma 8 If s = (r, u, v) with u, v âˆˆ Sx (i.e. s is not a transition) and a is an arrangement in G such that s is applicable in a, then Î³(a) = Î³(s(a)).
Proof
Let b = s(a). Let ai = a/Si and bi = b/Si for all i = 1 . . . m. Let Î³(a) =
(c1 , . . . , cm ) and Î³(b) = (c01 , . . . , c0m ).
Now the plan Px = hsi is a plan from ax to bx in Sx , so ax âˆ¼ bx implying cx = c0x . For
all other z 6= x, we have az = bz so cz = c0z . Therefore Î³(a) = Î³(b) as required.


534

Exploiting Subgraph Structure in Multi-Robot Path Planning

Now we can define an abstract plan Î  from arrangement Î± to Î² in G as a tuple (Î“, Î£)
where Î“ is a sequence of configuration tuples hÎ³0 , . . . , Î³l i and Î£ is a sequence of plan steps
hs1 , . . . , sl i, such that
Î³0 = Î³(Î±),
Î³l = Î³(Î²),
si is applicable in Î³iâˆ’1 ,
and Î³i âˆˆ s(Î³iâˆ’1 ).
Theorem 1 An abstract plan from Î± to Î² in G exists if and only if there exists a corresponding concrete plan P from Î± to Î² in G.
Proof Case (Î  â‡’ P ):
Let Î  = (Î“, Î£) be an abstract plan on G from Î± to Î², with Î“ = hÎ³0 , . . . , Î³l i and
Î£ = hs1 , . . . , sl i. Let Î³i = (ci0 , . . . , cim ).
We shall construct a concrete plan
P = P0 . hs1 i .P1 . Â· Â· Â· .Plâˆ’1 . hsl i .Pl
where each Pi is a concrete plan from ai to bi , satisfying
a0 = Î±,
bl = Î²,
ai , bi âˆˆ Î³i ,
si+1 is applicable in bi ,
and ai+1 = si+1 (bi ), âˆ€i = 0 . . . l âˆ’ 1.
Proposition 1 ai and bi exist satisfying these conditions for all i = 1 . . . l.
Proof by induction:
a0 = Î± therefore a0 exists.
Assume ai exists:
Let si+1 = (r, u, v) with u âˆˆ Sx and v âˆˆ Sy . From the definition of an abstract plan,
si+1 is applicable in Î³i , and Î³i+1 = si+1 (Î³i ). Therefore
ci+1
âˆˆ cix 	 (r, u) 6= âˆ…
x
n
o
i
â‡’ ci+1
âˆˆ
âˆ¼(a
	
(r,
u))
|
a(u)
=
r,
a
âˆˆ
c
x
x 6= âˆ…
â‡’ âˆƒa âˆˆ cix : a(u) = r
Set bix equal to this a. We now have
ci+1
= âˆ¼(bix 	 (r, u))
x
â‡’ bix 	 (r, u) âˆˆ ci+1
x

535

Ryan

Also
ci+1
âˆˆ ciy âŠ• (r, v) 6= âˆ…
y
n
o
i
â‡’ ci+1
âˆˆ
âˆ¼(a
âŠ•
(r,
v))
|
a(v)
=
2,
a
âˆˆ
c
y
y 6= âˆ…
â‡’ âˆƒa âˆˆ ciy : a(v) = 2
Set biy equal to this a. We now have
ci+1
= âˆ¼(biy âŠ• (r, v))
y
â‡’ biy âŠ• (r, v) âˆˆ ci+1
y
Set biz = ai /Sz for all other z âˆˆ
/ {x, y}
bij is now defined for every subgraph Sj in the partition of G. Therefore bi = bi1 âŠ—Â· Â· Â·âŠ—bim
exists and is an arrangement in G.
So if ai exists then bi also exists for all i = 0 . . . l âˆ’ 1.
Now si+1 is applicable in bi since
bi (u) = bix (u) = r
bi (v) = biy (v) = 2
So ai+1 = si+1 (bi ) exists, and
ai+1 /Sx = bix 	 r âˆˆ ci+1
x
ai+1 /Sy = biy âŠ• (r, v) âˆˆ ci+1
y
ai+1 /Sz = biz , âˆ€z âˆˆ
/ {x, y} âˆˆ ciz
âˆˆ ci+1
z
So
ai+1 âˆˆ Î³i+1
By induction, ai âˆˆ Î³i exists for all i = 0 . . . l and bi âˆˆ Î³i exists for all i = 0 . . . l âˆ’ 1.
Furthermore bl = Î² âˆˆ Î³(Î²) = Î³l , so bi exists for all i for all i = 0 . . . l, as required.

Proposition 2 A concrete plan Pi from ai to bi exists, for i = 0, . . . , l
Proof

Since ai , bi âˆˆ Î³i a plan Pi must exist from ai to bi , by Lemma 6 above.



Proposition 3 P is a concrete plan from Î± to Î² in G.
Proof
Pi is a plan from ai to bi for all i = 0, . . . , l. Furthermore ai+1 = si+1 (bi ), so
hsi+1 i is a plan from bi to ai+1 . Therefore by the concatenation of plans
P = P0 . hs1 i . Â· Â· Â· . hsl i .Pl
is a plan in G from a0 = Î± to bl = Î², as required.
536



Exploiting Subgraph Structure in Multi-Robot Path Planning

Case (P â‡’ Î ):
Let P = hs1 , . . . , sL i be a concrete plan from Î± to Î² in G. We wish to construct an
abstract plan Î  = (Î“, Î£) from Î± to Î² in G.
Let T = ht0 , . . . , tl i be an increasing sequence of integers with t0 = 0 and ti = t iff st is
a subgraph transition. (Note: we are using capital L to designate the length of the concrete
plan P and lowercase l to designate the number of transitions in that plan, which will be
the length of the corresponding abstract plan Î .)
Now construct the sequence of arrangements A = hÎ±0 , . . . , Î±L i such that
Î±0 = Î±
Î±i+1 = si+1 (Î±i ), âˆ€i = 0 . . . L âˆ’ 1
and split A into subsequences A0 , . . . , Al such that



Ai = Î±ti , . . . , Î±ti+1 âˆ’1
Define Î³i = Î³(Î±ti ), âˆ€i = 0, . . . , l, Î£ = hÎ³0 , . . . , Î³l i and Î£ = hst1 , . . . , stl i.
Proposition 4 âˆ€a : a âˆˆ Ai â‡’ a âˆˆ Î³i
Proof by induction:
By definition,
Î±ti âˆˆ Î³(Î±ti ) = Î³i
Now assume Î±t âˆˆ Î³i for t = ti + j, j < |Ai | âˆ’ 1. We need to prove Î±t+1 âˆˆ Î³i .
Let st+1 = (r, u, v). Since t + 1 âˆˆ
/ T we must have u, v âˆˆ Sx . So using Lemma 8 above
Î³(Î±t+1 ) = Î³(st+1 (Î±t ))
= Î³(Î±t )
= Î³i .
Therefore, by induction
a âˆˆ Î³i , âˆ€a âˆˆ Ai
as required.



Proposition 5 Î  = (Î“, Î£) is a valid abstract plan from Î± to Î².
Proof
First we check that the initial and final configuration-tuples contain Î± and Î²
respectively:
Î³0 = Î³(Î±0 ) = Î³(Î±).
and
Î² âˆˆ Al
â‡’ Î² âˆˆ Î³l ,
â‡’ Î³l = Î³(Î²).

537

Ryan

Now, for each i = 0 . . . l âˆ’ 1 let bi = Î±ti+1 âˆ’1 (i.e. the final element of Ai ), and let
= bi /Sz for z = 1 . . . m.
Let s = sti+1 = (r, u, v) with u âˆˆ Sx and v âˆˆ Sy . Now s is applicable in bi by the
definition of P . Therefore, by Lemma 7 above, s is applicable in Î³i and

biz

Î³i+1 = Î³(ai+1 )
= Î³(s(bi ))
âˆˆ s(Î³(bi )) = s(Î³i ), as required.

Therefore Î  is a valid abstract plan.



This theorem is significant for our planning problem. It tells us that we do not need to
perform a search of all concrete plans. Instead, we need only search for an abstract plan
and then convert it into a concrete form. Such a search will succeed if and only if a concrete
plan exists.

References
Alami, R., Fleury, S., Herrb, M., Ingrand, F., & Robert, F. (1998). Multi-robot cooperation
in the MARTHA project. Robotics & Automation Magazine, IEEE, 5 (1), 36â€“47.
Alarie, S., & Gamache, M. (2002). Overview of Solution Strategies Used in Truck Dispatching Systems for Open Pit Mines. International Journal of Surface Mining, Reclamation and Environment, 16 (1), 59â€“76.
Bakker, B., Zivkovic, Z., & KroÌˆse, B. (2005). Hierarchical dynamic programming for robot
path planning. Proceedings of IEEE/RSJ International Conference on Intelligent
Robots and Systems, 2756â€“2761.
Barbehenn, M., & Hutchinson, S. (1995). Efficient search and hierarchical motion planning
by dynamically maintaining single-source shortest paths trees. IEEE transactions on
robotics and automation, 11 (2), 198â€“214.
Barraquand, J., & Latombe, J.-C. (1991). Robot motion planning: A distributed representation approach. International Journal of Robotics Research, 10 (6), 628â€“649.
Botea, A., MuÌˆller, M., & Schaeffer, J. (2003). Using abstraction for planning in sokoban. In
Computers and Games: Lecture Notes in Computer Science, Vol. 2883, pp. 360â€“375.
Springer.
Buro, M., & Furtak, T. (2004). RTS games and real-time AI research. Proceedings of the
Behavior Representation in Modeling and Simulation Conference (BRIMS), Arlington
VA 2004, 51â€“58.
Choset, H. (1996). Sensor based motion planning: The hierarchical generalized voronoi
graph. Ph.D. thesis, California Institute of Technology, Pasadena, California.
Choset, H., & Burdick, J. (1995). Sensor based planning. I. The generalized Voronoi graph.
Proceedings of the International Conference on Robotics and utomation, 2.

538

Exploiting Subgraph Structure in Multi-Robot Path Planning

Conte, G., & Zulli, R. (1995). Hierarchical path planning in a multi-robot environment with
a simple navigation function. IEEE Transactions on Systems, Man and Cybernetics,
25 (4), 651â€“654.
Erdmann, M., & Lozano-PeÌrez, T. (1986). On Multiple Moving Objects. Tech. rep. 883,
M.I.T. AI Laboratory.
Everett, H., Gage, D., Gilbreth, G., Laird, R., & Smurlo, R. (1994). Real-world issues
in warehouse navigation. Proceedings of the SPIE Conference on Mobile Robots IX,
2352.
Fitch, R., Butler, Z., & Rus, D. (2003). Reconfiguration planning for heterogeneous selfreconfiguring robots. Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, 3, 2460â€“2467.
Gecode Team (2006). Gecode: Generic constraint development environment,. Available
from http://www.gecode.org.
Hada, Y., & Takase, K. (2001). Multiple mobile robot navigation using the indoor global
positioning system (iGPS). Proceedings of IEEE/RSJ International Conference on
Intelligent Robots and Systems, 2.
Junghanns, A., & Schaeffer, J. (2001). Sokoban: Enhancing general single-agent search
methods using domain knowledge. Artificial Intelligence, 129 (1-2), 219â€“251.
LaValle, S. M. (2006). Planning Algorithms. Cambridge University Press.
LaValle, S. M., & Hutchinson, S. A. (1998). Optimal Motion Planning for Multiple Robots
Having Independent Goals. In IEEE Transactions on Robotics and Automation,
Vol. 14.
Long, D., & Fox, M. (2002). Planning with Generic Types, chap. 4, pp. 103â€“138. Morgan
Kaufmann.
Porteous, J., Long, D., & Fox, M. (2004). The Identification and Exploitation of Almost
Symmetry in Planning Problems. In Brown, K. (Ed.), Proceedings of the 23rd UK
Planning and Scheduling SIG.
Sacerdoti, E. (1974). Planning in a hierarchy of abstraction spaces. Artificial Intelligence,
5 (2), 115â€“135.
Sanchez, G., Ramos, F., & Frausto, J. (1999). Locally-Optimal Path Planning by Using
Probabilistic Road Maps and Simulatead Annealing. Proceedings of IASTED International Conference on Robotics and Applications.
Sharma, R., & Aloimonos, Y. (1992). Coordinated motion planning: the warehousemanâ€™s
problem with constraints on free space. IEEE Transactions on Systems, Man and
Cybernetics, 22 (1), 130â€“141.
van den Berg, J., & Overmars, M. (2005). Prioritized Motion Planning for Multiple Robots.
In Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 430â€“435.
Zivkovic, Z., Bakker, B., & KroÌˆse, B. (2005). Hierarchical map building using visual landmarks and geometric constraints. Proceedings of IEEE/RSJ International Conference
on Intelligent Robots and Systems, 2480â€“2485.
539

Ryan

Zivkovic, Z., Bakker, B., & KroÌˆse, B. (2006). Hierarchical Map Building and Planning based
on Graph Partitioning. IEEE International Conference on Robotics and Automation.

540

Exploiting Subgraph Structure in Multi-Robot Path Planning

Algorithm 2 Planning with subgraph abstraction.
1: function Plan(G, P, R, a, b)
2:
Î± â† Î³(a)
3:
Î² â† Î³(b)
4:
Î  â† AbstractPlan(G, P, R, Î±, Î²)
5:
P â† Resolve(G, P, Î , a, b)
6:
return P
7: end function

. Build a plan from a to b in G using partition P.
. Get the initial configuration.
. Get the final configuration.
. Build the abstract plan.
. Resolve to a concrete plan.

1: function AbstractPlan(G, P, R, Î±, Î²) . Build an abstract plan from Î± to Î² in G using P.
2:
if Î± = Î² then
3:
return (hÎ²i , hi)
. Done.
4:
end if
5:
(c1 , . . . , cm ) = Î±
6:
choose r âˆˆ R
. Choose a robot.
7:
select x : r âˆˆ range(cx )
. Find the subgraph it occupies.
8:
choose Sy âˆˆ P : (Sx , Sy ) âˆˆ X
. Choose a neighbouring subgraph.
9:
choose (u, v) âˆˆ E(G) : u âˆˆ Sx , v âˆˆ Sy
. Choose a connecting edge.
. Choose the resulting configurations of Sx and Sy .
10:
choose c0x âˆˆ cx 	 (r, u)
11:
choose c0y âˆˆ cy âŠ• (r, v)
12:
Î³ â† (c1 , . . . , c0x , . . . , c0y , . . . , cm )
. Construct the new configuration tuple.
13:
(Î“, Î£) â† AbstractPlan(G, P, R, Î³, Î²)
. Recurse.
14:
Î“0 â† Î³.Î“
15:
Î£0 â† (r, u, v).Î£
16:
return (Î“0 , Î£0 )
17: end function
1: function Resolve(G, P, Î , a, b)
. Resolve the abstract plan into a concrete plan.
2:
Î  = (Î“, Î£)
3:
Î“ = hÎ³0 , . . . , Î³l i
4:
Î£ = hs1 , . . . , sl i
5:
P â†hi
6:
a0 â† a
7:
for i = 0 . . . (l âˆ’ 1) do
8:
(r, u, v) = si+1
. The next transition.
9:
(c01 , . . . , c0m ) = Î³i+1
. The target configurations.
10:
find Sx : u âˆˆ Sx
11:
find Sy : v âˆˆ Sy
12:
aiz â† ai /Sz , âˆ€z = 1 . . . m
13:
(Pxi , bix ) â† Sx .ResolveExit(aix , r, u, c0x )
. Rearrange Sx to let robot r exit.
. Rearrange Sy to let robot r enter.
14:
(Pyi , biy ) â† Sy .ResolveEnter(aiy , r, v, c0y )
15:
P â† P.(Pxi ||Pyi )
16:
bi = ai1 âŠ— . . . âŠ— bix âŠ— . . . âŠ— biy âŠ— . . . âŠ— aim
17:
ai+1 â† si+1 (bi )
18:
P â† P.. hsi+1 i
. Add the transition.
19:
end for
20:
for z = 1 . . . m do
21:
Tz â† Sz .ResolveTerminate(al /Sz , b/Sz )
. Rearrange Sz into its final arrangement.
22:
end for
23:
P â† P.(T1 || . . . ||Tm )
24:
return P
25: end function

541

Ryan

Algorithm 3 A simple prioritised planning algorithm.
1: function Plan(G, a, b)
2:
a0 [v] â† 2, âˆ€v âˆˆ G
. a0 is the initial arrangement of robots
0
3:
b [v] â† 2, âˆ€v âˆˆ G
. b0 is the final arrangement of robots
4:
for i = 1 . . . k do
5:
a0 [v] = ri , for v : a[v] = ri
6:
b0 [v] = ri , for v : b[v] = ri
7:
(P, Pi ) â†PlanOne(G, ri , hP1 , . . . , Piâˆ’1 i , h0, . . . , 0i , a0 , b0 )
. Build a plan for
8:
cut
. Do not backtrack once a plan
9:
end for
10:
return P
11: end function

r1 . . . ri .
r1 . . . ri .

r1 . . . ri .
is found

1: function PlanOne(G, ri , hP1 , . . . , Piâˆ’1 i , ht1 , . . . , tiâˆ’1 i , a, b)
2:
if a = b then
3:
return (hi, hi)
. Done.
4:
end if
5:
choose rj âˆˆ R : j â‰¤ i
. Choose a robot to move.
6:
if j = i then
7:
select vf : a[vf ] = ri
8:
choose vt âˆˆ {v | (vf , v) âˆˆ G}
. Choose a new action for ri
9:
else
10:
(r, vf , vt ) â† Pj [tj ]
. Select the old action for rj from Pj
11:
tj â† tj + 1
12:
end if
13:
if a[vt ] 6= 2 then
14:
fail
. Backtrack if the destination is occupied.
15:
end if
16:
a[vf ] â† 2
. Move the robot.
17:
a[vt ] â† r
18:
(P, Pi ) â†PlanOne(G, ri , hP1 , . . . , Piâˆ’1 i , ht1 , . . . , tiâˆ’1 i , a, b)
. Recurse.
19:
P â† (rj , vf , vt ).P
. Add this step to the global plan.
20:
if j = i then
21:
Pi â† (ri , vf , vt ).Pri
. Add this step to ri â€™s plan.
22:
end if
23:
return (P, Pi )
24: end function

542

Journal of Artificial Intelligence Research 31 (2008) 319-351

Submitted 09/07; published 02/08

The Complexity of Planning Problems
With Simple Causal Graphs
Omer GimeÌnez

omer.gimenez@upc.edu

Dept. de Llenguatges i Sistemes InformaÌ€tics
Universitat PoliteÌ€cnica de Catalunya
Jordi Girona, 1-3
08034 Barcelona, Spain

Anders Jonsson

anders.jonsson@upf.edu

Dept. of Information and Communication Technologies
Passeig de CircumvalÂ·lacioÌ, 8
08003 Barcelona, Spain

Abstract
We present three new complexity results for classes of planning problems with simple
causal graphs. First, we describe a polynomial-time algorithm that uses macros to generate plans for the class 3S of planning problems with binary state variables and acyclic
causal graphs. This implies that plan generation may be tractable even when a planning
problem has an exponentially long minimal solution. We also prove that the problem of
plan existence for planning problems with multi-valued variables and chain causal graphs
is NP-hard. Finally, we show that plan existence for planning problems with binary state
variables and polytree causal graphs is NP-complete.

1. Introduction
Planning is an area of research in artificial intelligence that aims to achieve autonomous
control of complex systems. Formally, the planning problem is to obtain a sequence of
transformations for moving a system from an initial state to a goal state, given a description
of possible transformations. Planning algorithms have been successfully used in a variety
of applications, including robotics, process planning, information gathering, autonomous
agents and spacecraft mission control. Research in planning has seen significant progress
during the last ten years, in part due to the establishment of the International Planning
Competition.
An important aspect of research in planning is to classify the complexity of solving
planning problems. Being able to classify a planning problem according to complexity
makes it possible to select the right tool for solving it. Researchers usually distinguish
between two problems: plan generation, the problem of generating a sequence of transformations for achieving the goal, and plan existence, the problem of determining whether
such a sequence exists. If the original STRIPS formalism is used, plan existence is undecidable in the first-order case (Chapman, 1987) and PSPACE-complete in the propositional
case (Bylander, 1994). Using PDDL, the representation language used at the International
Planning Competition, plan existence is EXPSPACE-complete (Erol, Nau, & Subrahmanian, 1995). However, planning problems usually exhibit structure that makes them much
c
Â°2008
AI Access Foundation. All rights reserved.

GimeÌnez & Jonsson

easier to solve. Helmert (2003) showed that many of the benchmark problems used at the
International Planning Competition are in fact in P or NP.
A common type of structure that researchers have used to characterize planning problems is the so called causal graph (Knoblock, 1994). The causal graph of a planning
problem is a graph that captures the degree of independence among the state variables
of the problem, and is easily constructed given a description of the problem transformations. The independence between state variables can be exploited to devise algorithms for
efficiently solving the planning problem. The causal graph has been used as a tool for
describing tractable subclasses of planning problems (Brafman & Domshlak, 2003; Jonsson
& BaÌˆckstroÌˆm, 1998; Williams & Nayak, 1997), for decomposing planning problems into
smaller problems (Brafman & Domshlak, 2006; Jonsson, 2007; Knoblock, 1994), and as the
basis for domain-independent heuristics that guide the search for a valid plan (Helmert,
2006).
In the present work we explore the computational complexity of solving planning problems with simple causal graphs. We present new results for three classes of planning problems studied in the literature: the class 3S (Jonsson & BaÌˆckstroÌˆm, 1998), the class Cn
(Domshlak & Dinitz, 2001), and the class of planning problems with polytree causal graphs
(Brafman & Domshlak, 2003). In brief, we show that plan generation for instances of the
first class can be solved in polynomial time using macros, but that plan existence is not
solvable in polynomial time for the remaining two classes, unless P = NP. This work first
appeared in a conference paper (GimeÌnez & Jonsson, 2007); the current paper provides
more detail and additional insights as well as new sections on plan length and CP-nets.
A planning problem belongs to the class 3S if its causal graph is acyclic and all state
variables are either static, symmetrically reversible or splitting (see Section 3 for a precise definition of these terms). The class 3S was introduced and studied by Jonsson and
BaÌˆckstroÌˆm (1998) as an example of a class for which plan existence is easy (there exists a
polynomial-time algorithm that determines whether or not a particular planning problem
of that class is solvable) but plan generation is hard (there exists no polynomial-time algorithm that generates a valid plan for every planning problem of the class). More precisely,
Jonsson and BaÌˆckstroÌˆm showed that there are planning problems of the class 3S for which
every valid plan is exponentially long. This clearly prevents the existence of an efficient
plan generation algorithm.
Our first contribution is to show that plan generation for 3S is in fact easy if we are
allowed to express a valid plan using macros. A macro is simply a sequence of operators and
other macros. We present a polynomial-time algorithm that produces valid plans of this
form for planning problems of the class 3S. Namely, our algorithm outputs in polynomial
time a system of macros that, when executed, produce the actual valid plan for the planning
problem instance. The algorithm is sound and complete, that is, it generates a valid plan
if and only if one exists. We contrast our algorithm to the incremental algorithm proposed
by Jonsson and BaÌˆckstroÌˆm (1998), which is polynomial in the size of the output.
We also investigate the complexity of the class Cn of planning problems with multivalued state variables and chain causal graphs. In other words, the causal graph is just a
directed path. Domshlak and Dinitz (2001) showed that there are solvable instances of this
class that require exponentially long plans. However, as it is the case with the class 3S,
there could exist an efficient procedure for generating valid plans for Cn instances using
320

Complexity of Planning Problems

macros or some other novel idea. We show that plan existence in Cn is NP-hard, hence
ruling out that such an efficient procedure exists, unless P = NP.
We also prove that plan existence for planning problems whose causal graph is a polytree (i.e., the underlying undirected graph is acyclic) is NP-complete, even if we restrict to
problems with binary variables. This result closes the complexity gap that appears in Brafman and Domshlak (2003) regarding planning problems with binary variables. The authors
show that plan existence is NP-complete for planning problems with singly connected causal
graphs, and that plan generation is polynomial for planning problems with polytree causal
graphs of bounded indegree. We use the same reduction to prove that a similar problem on
polytree CP-nets (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004) is NP-complete.
1.1 Related Work
Several researchers have used the causal graph to devise algorithms for solving planning
problems or to study the complexity of planning problems. Knoblock (1994) used the
causal graph to decompose a planning problem into a hierarchy of increasingly abstract
problems. Under certain conditions, solving the hierarchy of abstract problems is easier than
solving the original problem. Williams and Nayak (1997) introduced several restrictions on
planning problems to ensure tractability, one of which is that the causal graph should be
acyclic. Jonsson and BaÌˆckstroÌˆm (1998) defined the class 3S of planning problems, which
also requires the causal graphs to be acyclic, and showed that plan existence is polynomial
for this class.
Domshlak and Dinitz (2001) analyzed the complexity of several classes of planning
problems with acyclic causal graphs. Brafman and Domshlak (2003) designed a polynomialtime algorithm for solving planning problems with binary state variables and acyclic causal
graph of bounded indegree. Brafman and Domshlak (2006) identified conditions under
which it is possible to factorize a planning problem into several subproblems and solve
the subproblems independently. They claimed that a planning problem is suitable for
factorization if its causal graph has bounded tree-width.
The idea of using macros in planning is almost as old as planning itself (Fikes & Nilsson,
1971). Minton (1985) developed an algorithm that measures the utility of plan fragments
and stores them as macros if they are deemed useful. Korf (1987) showed that macros can
exponentially reduce the search space size of a planning problem if chosen carefully. Vidal
(2004) used relaxed plans generated while computing heuristics to produce macros that
contribute to the solution of planning problems. Macro-FF (Botea, Enzenberger, MuÌˆller,
& Schaeffer, 2005), an algorithm that identifies and caches macros, competed at the fourth
International Planning Competition. The authors showed how macros can help reduce the
search effort necessary to generate a valid plan.
Jonsson (2007) described an algorithm that uses macros to generate plans for planning
problems with tree-reducible causal graphs. There exist planning problems for which the
algorithm can generate exponentially long solutions in polynomial time, just like our algorithm for 3S. Unlike ours, the algorithm can handle multi-valued variables, which enables it
to solve problems such as Towers of Hanoi. However, not all planning problems in 3S have
tree-reducible causal graphs, so the algorithm cannot be used to show that plan generation
for 3S is polynomial.
321

GimeÌnez & Jonsson

1.2 Hardness and Plan Length
A contribution of this paper is to show that plan generation may be polynomial even when
planning problems have exponential length minimal solutions, provided that solutions may
be expressed using a concise notation such as macros. We motivate this result below and
discuss the consequences. Previously, it has been thought that plan generation for planning
problems with exponential length minimal solutions is harder than NP, since it is not
known whether problems in NP are intractable, but it is certain that we cannot generate
exponential length output in polynomial time.
However, for a planning problem with exponential length minimal solution, it is not
clear if plan generation is inherently hard, or if the difficulty just lies in the fact that the
plan is long. Consider the two functional problems
f1 (F ) = w(1, 2|F | ),
f2 (F ) = w(t(F ), 2|F | ),
where F is a 3-CNF formula, |F | is the number of clauses of F , w(Ïƒ, k) is a word containing
k copies of the symbol Ïƒ, and t(F ) is 1 if F is satisfiable (i.e., F is in 3Sat), and 0 if it is
not. In both cases, the problem consists in generating the correct word. Observe that both
f1 and f2 are provably intractable, since their output is exponential in the size of the input.
Nevertheless, it is intuitive to regard problem f1 as easier than problem f2 . One way
to formalize this intuition is to allow programs to produce the output in some succinct
notation. For instance, if we allow programs to write â€œw(Ïƒ,k)â€ instead of a string containing
k copies of the symbol Ïƒ, then problem f1 becomes polynomial, but problem f2 does not
(unless P = NP).
We wanted to investigate the following question: regarding the class 3S, is plan generation intractable because solution plans are long, like f1 , or because the problem is intrinsically hard, like f2 ? The answer is that plan generation for 3S can be solved in polynomial
time, provided that one is allowed to give the solution in terms of macros, where a macro
is a simple substitution scheme: a sequence of operators and/or other macros. To back up
this claim, we present an algorithm that solves plan generation for 3S in polynomial time.
Other researchers have argued intractability using the fact that plans may have exponential length. Domshlak and Dinitz (2001) proved complexity results for several classes of
planning problems with multi-valued state variables and simple causal graphs. They argued
that the class Cn of planning problems with chain causal graphs is intractable since plans
may have exponential length. Brafman and Domshlak (2003) stated that plan generation
for STRIPS planning problems with unary operators and acyclic causal graphs is intractable
using the same reasoning. Our new result puts in question the argument used to prove the
hardness of these problems. For this reason, we analyze the complexity of these problems
and prove that they are hard by showing that the plan existence problem is NP-hard.

2. Notation
Let V be a set of state variables, and let D(v) be the finite domain of state variable v âˆˆ V .
We define a state s as a function on V that maps each state variable v âˆˆ V to a value
s(v) âˆˆ D(v) in its domain. A partial state p is a function on a subset Vp âŠ† V of state
322

Complexity of Planning Problems

variables that maps each state variable v âˆˆ Vp to p(v) âˆˆ D(v). For a subset C âŠ† V of
state variables, p | C is the partial state obtained by restricting the domain of p to Vp âˆ© C.
Sometimes we use the notation (v1 = x1 , . . . , vk = xk ) to denote a partial state p defined by
Vp = {v1 , . . . , vk } and p(vi ) = xi for each vi âˆˆ Vp . We write p(v) =âŠ¥ to denote that v âˆˆ
/ Vp .
Two partial states p and q match, which we denote pâ–½q, if and only if p | Vq = q | Vp ,
i.e., for each v âˆˆ Vp âˆ©Vq , p(v) = q(v). We define a replacement operator âŠ• such that if q and
r are two partial states, p = q âŠ• r is the partial state defined by Vp = Vq âˆª Vr , p(v) = r(v)
for each v âˆˆ Vr , and p(v) = q(v) for each v âˆˆ Vq âˆ’ Vr . Note that, in general, p âŠ• q 6= q âŠ• p.
A partial state p subsumes a partial state q, which we denote p âŠ‘ q, if and only if pâ–½q and
Vp âŠ† Vq . We remark that if p âŠ‘ q and r âŠ‘ s, it follows that p âŠ• r âŠ‘ q âŠ• s. The difference
between two partial states q and r, which we denote q âˆ’ r, is the partial state p defined by
Vp = {v âˆˆ Vq | q(v) 6= r(v)} and p(v) = q(v) for each v âˆˆ Vp .
A planning problem is a tuple P = hV, init, goal, Ai, where V is the set of variables,
init is an initial state, goal is a partial goal state, and A is a set of operators. An operator
a = hpre(a); post(a)i âˆˆ A consists of a partial state pre(a) called the pre-condition and a
partial state post(a) called the post-condition. Operator a is applicable in any state s such
that sâ–½pre(a), and applying operator a in state s results in the new state s âŠ• post(a). A
valid plan Î  for P is a sequence of operators that are sequentially applicable in state init
such that the resulting state sâ€² satisfies sâ€² â–½goal.
The causal graph of a planning problem P is a directed graph (V, E) with state variables
as nodes. There is an edge (u, v) âˆˆ E if and only if u 6= v and there exists an operator
a âˆˆ A such that u âˆˆ Vpre(a) âˆª Vpost(a) and v âˆˆ Vpost(a) .

3. The Class 3S
Jonsson and BaÌˆckstroÌˆm (1998) introduced the class 3S of planning problems to study the
relative complexity of plan existence and plan generation. In this section, we introduce
additional notation needed to describe the class 3S and illustrate some of the properties of
3S planning problems. We begin by defining the class 3S:
Definition 3.1 A planning problem P belongs to the class 3S if its causal graph is acyclic
and each state variable v âˆˆ V is binary and either static, symmetrically reversible, or
splitting.
Below, we provide formal definitions of static, symmetrically reversible and splitting.
Note that the fact that the causal graph is acyclic implies that operators are unary, i.e., for
each operator a âˆˆ A, |Vpost(a) | = 1. Without loss of generality, we assume that 3S planning
problems are in normal form, by which we mean the following:
â€¢ For each state variable v, D(v) = {0, 1} and init(v) = 0.
â€¢ post(a) = (v = x), x âˆˆ {0, 1}, implies that pre(a)(v) = 1 âˆ’ x.
To satisfy the first condition, we can relabel the values of D(v) in the initial and goal
states as well as in the pre- and post-conditions of operators. To satisfy the second condition,
for any operator a with post(a) = (v = x) and pre(a)(v) 6= 1 âˆ’ x, we either remove it if
323

GimeÌnez & Jonsson

v

V0

u
v=0
v

v=0

w=0
w
w=1

w

V*

s

u
v=0
v

t

(a)

v=0

w=0
w
w=1

w

s

V0

t

V1

w

(b)

Figure 1: Causal graph with splitting variable partitions for (a) v, (b) w.
pre(a)(v) = x, or we let pre(a)(v) = 1 âˆ’ x if previously undefined. The resulting planning
problem is in normal form and is equivalent to the original one. This process can be done
in time O(|A||V |).
The following definitions describe the three categories of state variables in 3S:
Definition 3.2 A state variable v âˆˆ V is static if and only if one of the following holds:
1. There does not exist a âˆˆ A such that post(a)(v) = 1,
2. goal(v) = 0 and there does not exist a âˆˆ A such that post(a)(v) = 0.
Definition 3.3 A state variable v âˆˆ V is reversible if and only if for each a âˆˆ A such that
post(a) = (v = x), there exists aâ€² âˆˆ A such that post(aâ€² ) = (v = 1 âˆ’ x). In addition, v is
symmetrically reversible if pre(aâ€² ) | (V âˆ’ {v}) = pre(a) | (V âˆ’ {v}).
From the above definitions it follows that the value of a static state variable cannot or
must not change, whereas the value of a symmetrically reversible state variable can change
freely, as long as it is possible to satisfy the pre-conditions of operators that change its
value. The third category of state variables is splitting. Informally, a splitting state variable
v splits the causal graph into three disjoint subgraphs, one which depends on the value
v = 1, one which depends on v = 0, and one which is independent of v. However, the
precise definition is more involved, so we need some additional notation.
For v âˆˆ V , let Qv0 be the subset of state variables, different from v, whose value is
changed by some operator that has v = 0 as a pre-condition. Formally, Qv0 = {u âˆˆ V âˆ’ {v} |
âˆƒa âˆˆ A s.t. pre(a)(v) = 0 âˆ§ u âˆˆ Vpost(a) }. Define Qv1 in the same way for v = 1. Let
Gv0 = (V, E0v ) be the subgraph of (V, E) whose edges exclude those between v and Qv0 âˆ’ Qv1 .
Formally, E0v = E âˆ’ {(v, w) | w âˆˆ Qv0 âˆ§ w âˆˆ
/ Qv1 }. Finally, let V0v âŠ† V be the subset of state
variables that are weakly connected to some state variable of Qv0 in the graph Gv0 . Define
V1v in the same way for v = 1.
Definition 3.4 A state variable v âˆˆ V is splitting if and only if V0v and V1v are disjoint.
Figure 1 illustrates the causal graph of a planning problem with two splitting state
variables, v and w. The edge label v = 0 indicates that there are operators for changing
the value of u that have v = 0 as a pre-condition. In other words, Qv0 = {u, w}, the graph
Gv0 = (V, E0v ) excludes the two edges labeled v = 0, and V0v includes all state state variables,
324

Complexity of Planning Problems

since v is weakly connected to u and w connects to the remaining state variables. The set
Qv1 is empty since there are no operators for changing the value of a state variable other
than v with v = 1 as a pre-condition. Consequently, V1v is empty as well. Figure 1(a) shows
the resulting partition for v.
w
w
In the case of w, Qw
0 = {s}, G0 = (V, E0 ) excludes the edge labeled w = 0, and
w
V0 = {s}, since no other state variable is connected to s when the edge w = 0 is removed.
Likewise, V1w = {t}. We use Vâˆ—w = V âˆ’ V0w âˆ’ V1w to denote the set of remaining state
variables that belong neither to V0w nor to V1w . Figure 1(b) shows the resulting partition
for w.
Lemma 3.5 For any splitting state variable v, if the two sets V0v and V1v are non-empty,
v belongs neither to V0v nor to V1v .
Proof By contradiction. Assume that v belongs to V0v . Then v is weakly connected to
some state variable of Qv0 in the graph Gv0 = (V, E0v ). But since E0v does not exclude edges
between v and Qv1 , any state variable in Qv1 is weakly connected to the same state variable of
Qv0 in Gv0 . Consequently, state variables in Qv1 belong to both V0v and V1v , which contradicts
that v is splitting. The same reasoning holds to show that v does not belong to V1v .
Lemma 3.6 The value of a splitting state variable never needs to change more than twice
on a valid plan.
Proof Assume Î  is a valid plan that changes the value of a splitting state variable v at
least three times. We show that we can reorder the operators of Î  in such a way that the
value of v does not need to change more than twice. We need to address three cases: v
belongs to V0v (cf. Figure 1(a)), v belongs to V1v , or v belongs to Vâˆ—v (cf. Figure 1(b)).
If v belongs to V0v , it follows from Lemma 3.5 that V1v is empty. Consequently, no
operator in the plan requires v = 1 as a pre-condition. Thus, we can safely remove all
operators in Î  that change the value of v, except possibly the last, which is needed in case
goal(v) = 1. If v belongs to V1v , it follows from Lemma 3.5 that V0v is empty. Thus, no
operator in the plan requires v = 0 as a pre-condition. The first operator in Î  that changes
the value of v is necessary to set v to 1. After that, we can safely remove all operators in Î 
that change the value of v, except the last in case goal(v) = 0. In both cases the resulting
plan contains at most two operators changing the value of v.
If v belongs to Vâˆ—v , then the only edges between V0v , V1v , and Vâˆ—v are those from v âˆˆ Vâˆ—v
to Qv0 âŠ† V0v and Qv1 âŠ† V1v . Let Î 0 , Î 1 , and Î âˆ— be the subsequences of operators in Î  that
affect state variables in V0v , V1v , and Vâˆ—v , respectively. Write Î âˆ— = hÎ â€²âˆ— , av1 , Î â€²â€²âˆ— i, where av1 is
the last operator in Î âˆ— that changes the value of v from 0 to 1. We claim that the reordering
hÎ 0 , Î â€²âˆ— , av1 , Î 1 , Î â€²â€²âˆ— i of plan Î  is still valid. Indeed, the operators of Î 0 only require v = 0,
which holds in the initial state, and the operators of Î 1 only require v = 1, which holds
due to the operator av1 . Note that all operators changing the value of v in Î â€²âˆ— can be safely
removed since the value v = 1 is never needed as a pre-condition to change the value of a
state variable in Vâˆ—v . The result is a valid plan that changes the value of v at most twice
(its value may be reset to 0 by Î â€²â€²âˆ— ).

325

GimeÌnez & Jonsson

Variable
v1
v2
v3
v4
v5
v6
v7
v8

Operators
av11 = h(v1 = 0); (v1 = 1)i
av01 = h(v1 = 1); (v1 = 0)i
av12 = h(v1 = 1, v2 = 0); (v2 = 1)i
av13 = h(v1 = 0, v2 = 1, v3 = 0); (v3 = 1)i
av15
av16
av06
av17
av18

= h(v3
= h(v3
= h(v3
= h(v6
= h(v6

= 0, v4
= 1, v6
= 1, v6
= 1, v7
= 0, v7

= 0, v5 = 0); (v5 = 1)i
= 0); (v6 = 1)i
= 1); (v6 = 0)i
= 0); (v7 = 1)i
= 1, v8 = 0); (v8 = 1)i

V0vi
V

V1vi
V

âˆ…
{v4 , v5 }
V âˆ’ {v4 }
âˆ…
V

V
{v6 , v7 , v8 }
âˆ…
âˆ…
V

âˆ…
âˆ…

V
âˆ…

Table 1: Operators and the sets V0vi and V1vi for the example planning problem.

v4
v1

v5
v7

v3
v6

v2

v8

Figure 2: Causal graph of the example planning problem.
The previous lemma, which holds for splitting state variables in general, provides some
additional insight into how to solve a planning problem with a splitting state variable v.
First, try to achieve the goal state for state variables in V0v while the value of v is 0, as in
the initial state. Then, set the value of v to 1 and try to achieve the goal state for state
variables in V1v . Finally, if goal(v) = 0, reset the value of v to 0.
3.1 Example
We illustrate the class 3S using an example planning problem. The set of state variables
is V = {v1 , . . . , v8 }. Since the planning problem is in normal form, the initial state is
init(vi ) = 0 for each vi âˆˆ V . The goal state is defined by goal = (v5 = 1, v8 = 1), and
the operators in A are listed in Table 1. Figure 2 shows the causal graph (V, E) of the
planning problem. From the operators it is easy to verify that v4 is static and that v1
and v6 are symmetrically reversible. For the planning problem to be in 3S, the remaining
state variables have to be splitting. Table 1 lists the two sets V0vi and V1vi for each state
variable vi âˆˆ V to show that indeed, V0vi âˆ© V1vi = âˆ… for each of the state variables in the set
{v2 , v3 , v5 , v7 , v8 }.
326

Complexity of Planning Problems

4. Plan Generation for 3S
In this section, we present a polynomial-time algorithm for plan generation in 3S. The
algorithm produces a solution to any instance of 3S in the form of a system of macros. The
idea is to construct unary macros that each change the value of a single state variable. The
macros may change the values of other state variables during execution, but always reset
them before terminating. Once the macros have been generated, the goal can be achieved
one state variable at a time. We show that the algorithm generates a valid plan if and only
if one exists.
We begin by defining macros as we use them in the paper. Next, we describe the
algorithm in pseudo-code (Figures 3, 4, and 5) and prove its correctness. To facilitate
reading we have moved a straightforward but involving proof to the appendix. Following
the description of the algorithm we analyze the complexity of all steps involved. In what
follows, we assume that 3S planning problems are in normal form as defined in the previous
section.
4.1 Macros
A macro-operator, or macro for short, is an ordered sequence of operators viewed as a unit.
Each operator in the sequence has to respect the pre-conditions of operators that follow
it, so that no pre-condition of any operator in the sequence is violated. Applying a macro
is equivalent to applying all operators in the sequence in the given order. Semantically,
a macro is equivalent to a standard operator in that it has a pre-condition and a postcondition, unambiguously induced by the pre- and post-conditions of the operators in its
sequence.
Since macros are functionally operators, the operator sequence associated with a macro
can include other macros, as long as this does not create a circular definition. Consequently,
it is possible to create hierarchies of macros in which the operator sequences of macros on
one level include macros on the level below. The solution to a planning problem can itself
be viewed as a macro which sits at the top of the hierarchy.
To define macros we first introduce the concept of induced pre- and post-conditions of
operator sequences. If Î  = ha1 , . . . , ak i is an operator sequence, we write Î i , 1 â‰¤ i â‰¤ k, to
denote the subsequence ha1 , . . . , ai i.
Definition 4.1 An operator sequence Î  = ha1 , . . . , ak i induces a pre-condition pre(Î ) =
pre(ak )âŠ•Â· Â· Â·âŠ•pre(a1 ) and a post-condition post(Î ) = post(a1 )âŠ•Â· Â· Â·âŠ•post(ak ). In addition,
the operator sequence is well-defined if and only if (pre(Î iâˆ’1 )âŠ•post(Î iâˆ’1 ))â–½pre(ai ) for each
1 < i â‰¤ k.
In what follows, we assume that P = (V, init, goal, A) is a planning problem such that
Vpost(a) âŠ† Vpre(a) for each operator a âˆˆ A, and that Î  = ha1 , . . . , ak i is an operator sequence.
Lemma 4.2 For each planning problem P of this type and each Î , Vpost(Î ) âŠ† Vpre(Î ) .
Proof A direct consequence of the definitions Vpre(Î ) = Vpre(a1 ) âˆªÂ· Â· Â·âˆªVpre(ak ) and Vpost(Î ) =
Vpost(a1 ) âˆª Â· Â· Â· âˆª Vpost(ak ) .
327

GimeÌnez & Jonsson

Lemma 4.3 The operator sequence Î  is applicable in state s if and only if Î  is well-defined
and sâ–½pre(Î ). The state sk resulting from the application of Î  to s is sk = s âŠ• post(Î ).
Proof By induction on k. The result clearly holds for k = 1. For k > 1, note that
pre(Î ) = pre(ak ) âŠ• pre(Î kâˆ’1 ), post(Î ) = post(Î kâˆ’1 ) âŠ• post(ak ), and Î  is well-defined if
and only if Î kâˆ’1 is well-defined and (pre(Î kâˆ’1 ) âŠ• post(Î kâˆ’1 ))â–½pre(ak ).
By hypothesis of induction the state skâˆ’1 resulting from the application of Î kâˆ’1 to s is
skâˆ’1 = s âŠ• post(Î kâˆ’1 ). It follows that sk = skâˆ’1 âŠ• post(ak ) = s âŠ• post(Î ).
Assume Î  is applicable in state s. This means that Î kâˆ’1 is applicable in s and that ak
is applicable in skâˆ’1 = s âŠ• post(Î kâˆ’1 ). By hypothesis of induction, the former implies that
sâ–½pre(Î kâˆ’1 ) and Î kâˆ’1 is well-defined, and the latter that (s âŠ• post(Î kâˆ’1 ))â–½pre(ak ). This
last condition implies that (pre(Î kâˆ’1 ) âŠ• post(Î kâˆ’1 ))â–½pre(ak ) if we use that pre(Î kâˆ’1 ) âŠ‘ s,
which is a consequence of sâ–½pre(Î kâˆ’1 ) and s being a total state. Finally, we deduce
sâ–½(pre(ak ) âŠ• pre(Î kâˆ’1 )) from sâ–½pre(Î kâˆ’1 ) and (s âŠ• post(Î kâˆ’1 ))â–½pre(ak ), by using that
Vpost(Î kâˆ’1 ) âŠ† Vpre(Î kâˆ’1 ) . It follows that Î  is well-defined and that sâ–½pre(Î ).
Conversely, assume that Î  is well-defined and sâ–½pre(Î ). This implies that Î kâˆ’1 is
well-defined and sâ–½pre(Î kâˆ’1 ), so by hypothesis of induction, Î kâˆ’1 is applicable in state s.
It remains to show that ak is applicable in state skâˆ’1 , that is, (s âŠ• post(Î kâˆ’1 ))â–½pre(ak ).
From (pre(Î kâˆ’1 ) âŠ• post(Î kâˆ’1 ))â–½pre(ak ) it follows that post(Î kâˆ’1 )â–½pre(ak ). The fact that
sâ–½(pre(ak ) âŠ• pre(Î kâˆ’1 )) and Vpost(Î kâˆ’1 ) âŠ† Vpre(Î kâˆ’1 ) completes the proof.
Since macros have induced pre- and post-conditions, Lemmas 4.2 and 4.3 trivially extend
to the case for which the operator sequence Î  includes macros. Now we are ready to
introduce our definition of macros:
Definition 4.4 A macro m is a sequence Î  = ha1 , . . . , ak i of operators and other macros
that induces a pre-condition pre(m) = pre(Î ) and a post-condition post(m) = post(Î ) âˆ’
pre(Î ). The macro is well-defined if and only if no circular definitions occur and Î  is
well-defined.
To make macros consistent with standard operators, the induced post-condition should
only include state variables whose values are indeed changed by the macro, which is achieved
by computing the difference between post(Î ) and pre(Î ). In particular, it holds that for a
3S planning problem in normal form, derived macros satisfy the second condition of normal
form, namely that post(m) = (v = x), x âˆˆ {0, 1}, implies pre(m)(v) = 1 âˆ’ x.
Definition 4.5 Let Ancv be the set of ancestors of a state variable v in a 3S planning
problem. We define the partial state prev on Vprev = Ancv as
1. prev (u) = 1 if u âˆˆ Ancv is splitting and v âˆˆ V1u ,
2. prev (u) = 0 otherwise.
Definition 4.6 A macro m is a 3S-macro if it is well-defined and, for x âˆˆ {0, 1}, post(m) =
(v = x) and pre(m) âŠ‘ prev âŠ• (v = 1 âˆ’ x).
328

Complexity of Planning Problems

Macro
mv11
mv01
mv12
mv13
mv15
mv16
mv06
mv17
mv18

Sequence

Pre-condition

hav11 i
hav01 i
hmv11 , av12 , mv01 i
hav13 i
hav15 i
hav16 i
hav06 i
hmv16 , av17 , mv06 i
hav18 i

(v1
(v1
(v1
(v1
(v3
(v3
(v3
(v3
(v3

= 0)
= 1)
= 0, v2
= 0, v2
= 0, v4
= 1, v6
= 1, v6
= 1, v6
= 1, v6

= 0)
= 1, v3
= 0, v5
= 0)
= 1)
= 0, v7
= 0, v7

Post-condition

= 0)
= 0)

= 0)
= 1, v8 = 0)

(v1
(v1
(v2
(v3
(v5
(v6
(v6
(v7
(v8

= 1)
= 0)
= 1)
= 1)
= 1)
= 1)
= 0)
= 1)
= 1)

Table 2: Macros generated by the algorithm in the example planning problem.

The algorithm we present only generates 3S-macros. In fact, it generates at most one
macro m = mvx with post(m) = (v = x) for each state variable v and value x âˆˆ {0, 1}. To
illustrate the idea of 3S-macros and give a flavor of the algorithm, Table 2 lists the macros
generated by the algorithm in the example 3S planning problem from the previous section.
We claim that each macro is a 3S-macro. For example, the operator sequence hav16 i
induces a pre-condition (v3 = 1, v6 = 0) and a post-condition (v3 = 1, v6 = 0) âŠ• (v6 = 1) =
(v3 = 1, v6 = 1). Thus, the macro mv16 induces a pre-condition pre(mv16 ) = (v3 = 1, v6 = 0)
and a post-condition post(mv16 ) = (v3 = 1, v6 = 1) âˆ’ (v3 = 1, v6 = 0) = (v6 = 1). Since v2
and v3 are splitting and since v6 âˆˆ V1v2 and v6 âˆˆ V1v3 , it follows that prev6 âŠ• (v6 = 0) =
(v1 = 0, v2 = 1, v3 = 1, v6 = 0), so pre(mv16 ) = (v3 = 1, v6 = 0) âŠ‘ prev6 âŠ• (v6 = 0).
The macros can be combined to produce a solution to the planning problem. The idea
is to identify each state variable v such that goal(v) = 1 and append the macro mv1 to the
solution plan. In the example, this results in the operator sequence hmv15 , mv18 i. However,
the pre-condition of mv18 specifies v3 = 1 and v7 = 1, which makes it necessary to insert mv13
and mv17 before mv18 . In addition, the pre-condition of mv13 specifies v2 = 1, which makes
it necessary to insert mv12 before mv13 , resulting in the final plan hmv15 , mv12 , mv13 , mv17 , mv18 i.
Note that the order of the macros matter; mv15 requires v3 to be 0 while mv18 requires
v3 to be 1. For a splitting state variable v, the goal state should be achieved for state
variables in V0v before the value of v is set to 1. We can expand the solution plan so that
it consists solely of operators in A. In our example, this results in the operator sequence
hav15 , av11 , av12 , av01 , av13 , av16 , av17 , av06 , av18 i. In this case, the algorithm generates an optimal
plan, although this is not true in general.
4.2 Description of the Algorithm
We proceed by providing a detailed description of the algorithm for plan generation in 3S.
We first describe the subroutine for generating a unary macro that sets the value of a state
variable v to x. This algorithm, which we call GenerateMacro, is described in Figure 3.
The algorithm takes as input a planning problem P , a state variable v, a value x (either 0
329

GimeÌnez & Jonsson

1
2
3
4
5
6
7
8
9
10
11
12
13
14

function GenerateMacro(P , v, x, M )
for each a âˆˆ A such that post(a)(v) = x do
S0 â† S1 â† hi
satisf y â† true
U â† {u âˆˆ Vpre(a) âˆ’ {v} | pre(a)(u) = 1}
for each u âˆˆ U in increasing topological order do
if u is static or mu1 âˆˆ
/ M then
satisf y â† false
else if u is not splitting and mu0 âˆˆ M and mu1 âˆˆ M then
S0 â† hS0 , mu0 i
S1 â† hmu1 , S1 i
if satisf y then
return hS1 , a, S0 i
return f ail
Figure 3: Algorithm for generating a macro that sets the value of v to x.

or 1), and a set of macros M for vâ€™s ancestors in the causal graph. Prior to executing the
algorithm, we perform a topological sort of the state variables. We assume that, for each
v âˆˆ V and x âˆˆ {0, 1}, M contains at most one macro mvx such that post(mvx ) = (v = x). In
the algorithm, we use the notation mvx âˆˆ M to test whether or not M contains mvx .
For each operator a âˆˆ A that sets the value of v to x, the algorithm determines whether
it is possible to satisfy its pre-condition pre(a) starting from the initial state. To do this, the
algorithm finds the set U of state variables to which pre(a) assigns 1 (the values of all other
state variables already satisfy pre(a) in the initial state). The algorithm constructs two
sequences of operators, S0 and S1 , by going through the state variables of U in increasing
topological order. If S is an operator sequence, we use hS, oi as shorthand to denote an
operator sequence of length |S| + 1 consisting of all operators of S followed by o, which can
be either an operator or a macro. If it is possible to satisfy the pre-condition pre(a) of some
operator a âˆˆ A, the algorithm returns the macro hS1 , a, S0 i. Otherwise, it returns f ail.
Lemma 4.7 If v is symmetrically reversible and GenerateMacro(P , v, 1, M ) successfully generates a macro, so does GenerateMacro(P , v, 0, M ).
Proof Assume that GenerateMacro(P , v, 1, M ) successfully returns the macro hS1 , a, S0 i
for some operator a âˆˆ A such that post(a) = 1. From the definition of symmetrically
reversible it follows that there exists an operator aâ€² âˆˆ A such that post(aâ€² ) = 0 and
pre(aâ€² ) | V âˆ’ {v} = pre(a) | V âˆ’ {v}. Thus, the set U is identical for a and aâ€² . As
a consequence, the values of S0 , S1 , and satisf y are the same after the loop, which
means that GenerateMacro(P , v, 0, M ) returns the macro hS1 , aâ€² , S0 i for aâ€² . Note
that GenerateMacro(P , v, 0, M ) may return another macro if it goes through the operators of A in a different order; however, it is guaranteed to successfully return a macro.
Theorem 4.8 If the macros in M are 3S-macros and GenerateMacro(P , v, x, M )
generates a macro mvx 6= f ail, then mvx is a 3S-macro.
330

Complexity of Planning Problems

1
2
3
4
5
6
7
8
9
10

function Macro-3S(P )
M â†âˆ…
for each v âˆˆ V in increasing topological order do
mv1 â† GenerateMacro(P , v, 1, M )
mv0 â† GenerateMacro(P , v, 0, M )
if mv1 6= f ail and mv0 6= f ail then
M â† M âˆª {mv1 , mv0 }
else if mv1 6= f ail and goal(v) 6= 0 then
M â† M âˆª {mv1 }
return GeneratePlan(P , V , M )
Figure 4: The algorithm Macro-3S.
The proof of Theorem 4.8 appears in Appendix A.

Next, we describe the algorithm for plan generation in 3S, which we call Macro-3S.
Figure 4 shows pseudocode for Macro-3S. The algorithm goes through the state variables
in increasing topological order and attempts to generate two macros for each state variable
v, mv1 and mv0 . If both macros are successfully generated, they are added to the current
set of macros M . If only mv1 is generated and the goal state does not assign 0 to v, the
algorithm adds mv1 to M . Finally, the algorithm generates a plan using the subroutine
GeneratePlan, which we describe later.
Lemma 4.9 Let P be a 3S planning problem and let v âˆˆ V be a state variable. If there
exists a valid plan for solving P that sets v to 1, Macro-3S(P ) adds the macro mv1 to M .
If, in addition, the plan resets v to 0, Macro-3S(P ) adds mv0 to M .
Proof First note that if mv1 and mv0 are generated, Macro-3S(P ) adds them both to M .
If mv1 is generated but not mv0 , Macro-3S(P ) adds mv1 to M unless goal(v) = 0. However,
goal(v) = 0 contradicts the fact that there is a valid plan for solving P that sets v to 1
without resetting it to 0. It remains to show that GenerateMacro(P , v, 1, M ) always
generates mv1 6= f ail and that GenerateMacro(P , v, 0, M ) always generates mv0 6= f ail
if the plan resets v to 0.
A plan for solving P that sets v to 1 has to contain an operator a âˆˆ A such that
post(a)(v) = 1. If the plan also resets v to 0, it has to contain an operator aâ€² âˆˆ A such
that post(aâ€² )(v) = 0. We show that GenerateMacro(P , v, 1, M ) successfully generates
mv1 6= f ail if a is the operator selected on line 2. Note that the algorithm may return another
macro if it selects another operator before a; however, if it always generates a macro for a,
it is guaranteed to successfully return a macro mv1 6= f ail. The same is true for mv0 and aâ€² .
We prove the lemma by induction on state variables v. If v has no ancestors in the
causal graph, the set U is empty by default. Thus, satisf y is never set to false and
GenerateMacro(P , v, 1, M ) successfully returns the macro mv1 = hai for a. If aâ€² exists,
GenerateMacro(P , v, 0, M ) successfully returns mv0 = haâ€² i for aâ€² .
If v has ancestors in the causal graph, let U = {u âˆˆ Vpre(a) âˆ’ {v} | pre(a)(u) = 1}.
Since the plan contains a it has to set each u âˆˆ U to 1. By hypothesis of induction,
Macro-3S(P ) adds mu1 to M for each u âˆˆ U . As a consequence, satisf y is never set to
331

GimeÌnez & Jonsson

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

function GeneratePlan(P , W , M )
if |W | = 0 then
return hi
v â† first variable in topological order present in W
if v is splitting then
Î v0 â† Generate-Plan(P , W âˆ© (V0v âˆ’ {v}), M )
Î v1 â† Generate-Plan(P , W âˆ© (V1v âˆ’ {v}), M )
Î vâˆ— â† Generate-Plan(P , W âˆ© (V âˆ’ V0v âˆ’ V1v âˆ’ {v}), M )
if Î v0 = f ail or Î v1 = f ail or Î vâˆ— = f ail or (goal(v) = 1 and mv1 âˆˆ
/ M ) then
return f ail
else if mv1 âˆˆ
/ M then return hÎ vâˆ— , Î v0 , Î v1 i
else if goal(v) = 0 then return hÎ vâˆ— , Î v0 , mv1 , Î v1 , mv0 i
else return hÎ vâˆ— , Î v0 , mv1 , Î v1 i
Î  â† Generate-Plan(P , W âˆ’ {v}, M )
if Î  = f ail or (goal(v) = 1 and mv1 âˆˆ
/ M ) then return f ail
else if goal(v) = 1 then return hÎ , mv1 i
else return Î 
Figure 5: Algorithm for generating the final plan

false and thus, GenerateMacro(P , v, 1, M ) successfully returns mv1 for a. If aâ€² exists,
let W = {w âˆˆ Vpre(aâ€² ) âˆ’ {v} | pre(aâ€² )(w) = 1}. If the plan contains aâ€² , it has to set each
w âˆˆ W to 1. By hypothesis of induction, Macro-3S(P ) adds mw
1 to M for each w âˆˆ W
and consequently, GenerateMacro(P , v, 0, M ) successfully returns mv0 for aâ€² .
Finally, we describe the subroutine GeneratePlan(P , W , M ) for generating the final
plan given a planning problem P , a set of state variables W and a set of macros M . If
the set of state variables is empty, GeneratePlan(P , W , M ) returns an empty operator
sequence. Otherwise, it finds the state variable v âˆˆ W that comes first in topological order.
If v is splitting, the algorithm separates W into the three sets described by V0v , V1v , and
Vâˆ—v = V âˆ’ V0v âˆ’ V1v . The algorithm recursively generates plans for the three sets and if
necessary, inserts mv1 between V0v and V1v in the final plan. If this is not the case, the
algorithm recursively generates a plan for W âˆ’ {v}. If goal(v) = 1 and mv1 , the algorithm
appends mv1 to the end of the resulting plan.
Lemma 4.10 Let Î W be the plan generated by GeneratePlan(P , W , M ), let v be the
first state variable in topological order present in W , and let Î V = hÎ a , Î W , Î b i be the final
plan generated by Macro-3S(P ). If mv1 âˆˆ M it follows that (pre(Î a )âŠ•post(Î a ))â–½pre(mv1 ).
Proof We determine the content of the operator sequence Î a that precedes Î W in the final
plan by inspection. Note that the call GeneratePlan(P , W , M ) has to be nested within
a sequence of recursive calls to GeneratePlan starting with GeneratePlan(P , V , M ).
Let Z be the set of state variables such that each u âˆˆ Z was the first state variable in
topological order for some call to GeneratePlan prior to GeneratePlan(P , W , M ).
Each u âˆˆ Z has to correspond to a call to GeneratePlan with some set of state variables
U such that W âŠ‚ U . If u is not splitting, u does not contribute to Î a since the only
332

Complexity of Planning Problems

possible addition of a macro to the plan on line 16 places the macro mu1 at the end of the
plan generated recursively.
Assume that u âˆˆ Z is a splitting state variable. We have three cases: W âŠ† V0u , W âŠ† V1u ,
and W âŠ† Vâˆ—u = V âˆ’ V0u âˆ’ V1u . If W âŠ† Vâˆ—u , u does not contribute to Î a since it never places
macros before Î uâˆ— . If W âŠ† V0u , the plan Î uâˆ— is part of Î a since it precedes Î u0 on lines 11,
12, and 13. If W âŠ† V1u , the plans Î uâˆ— and Î u0 are part of Î a since they both precede Î u1 in
all cases. If mu1 âˆˆ M , the macro mu1 is also part of Î a since it precedes Î u1 on lines 12 and
13. No other macros are part of Î a .
Since the macros in M are unary, the plan generated by GeneratePlan(P , U , M )
only changes the values of state variables in U . For a splitting state variable u, there are
no edges from Vâˆ—u âˆ’ {u} to V0u , from Vâˆ—u âˆ’ {u} to V1u , or from V0u to V1u . It follows that the
plan Î uâˆ— does not change the value of any state variable that appears in the pre-condition
of a macro in Î u0 . The same holds for Î uâˆ— with respect to Î u1 and for Î u0 with respect to Î u1 .
Thus, the only macro in Î a that changes the value of a splitting state variable u âˆˆ Ancv is
mu1 in case W âŠ† V1u .
Recall that prev is defined on Ancv and assigns 1 to u if and only if u is splitting and
v âˆˆ V1u . For all other ancestors of v, the value 0 holds in the initial state and is not
altered by Î a . If u is splitting and v âˆˆ V1u , it follows from the definition of 3S-macros that
pre(mv1 )(u) = 1 or pre(mv1 )(u) =âŠ¥. If pre(mv1 )(u) = 1, it is correct to append mu1 before
mv1 to satisfy pre(mv1 )(u). If mu1 âˆˆ
/ M it follows that u âˆˆ
/ Vpre(mv1 ) , since pre(mv1 )(u) = 1
would have caused GenerateMacro(P , v, 1, M ) to set satisf y to false on line 8. Thus,
the pre-condition pre(mv1 ) of mv1 agrees with pre(Î a ) âŠ• post(Î a ) on the value of each state
variable, which means that the two partial states match.
Lemma 4.11 GeneratePlan(P , V , M ) generates a well-defined plan.
Proof Note that for each state variable v âˆˆ V , GeneratePlan(P , W , M ) is called
precisely once such that v is the first state variable in topological order. From Lemma 4.10
it follows that (pre(Î a ) âŠ• post(Î a ))â–½pre(mv1 ), where Î a is the plan that precedes Î W in
the final plan. Since v is the first state variable in topological order in W , the plans Î v0 ,
Î v1 , Î vâˆ— , and Î , recursively generated by GeneratePlan, do not change the value of any
state variable in pre(mv1 ). It follows that mv1 is applicable following hÎ a , Î vâˆ— , Î v0 i or hÎ a , Î i.
Since mv1 only changes the value of v, mv0 is applicable following hÎ a , Î vâˆ— , Î v0 , mv1 , Î v1 i.
Theorem 4.12 Macro-3S(P ) generates a valid plan for solving a planning problem in 3S
if and only if one exists.
Proof GeneratePlan(P , V , M ) returns f ail if and only if there exists a state variable
v âˆˆ V such that goal(v) = 1 and mv1 âˆˆ
/ M . From Lemma 4.9 it follows that there does
not exist a valid plan for solving P that sets v to 1. Consequently, there does not exist a
plan for solving P . Otherwise, GeneratePlan(P , V , M ) returns a well-defined plan due
to Lemma 4.11. Since the plan sets to 1 each state variable v such that goal(v) = 1 and
resets to 0 each state variable v such that goal(v) = 0, the plan is a valid plan for solving
the planning problem.
333

GimeÌnez & Jonsson

v1

v2

v3

v4

v5

Figure 6: Causal graph of the planning problem P5 .
4.3 Examples
We illustrate the algorithm on an example introduced by Jonsson and BaÌˆckstroÌˆm (1998) to
show that there are instances of 3S with exponentially sized minimal solutions. Let Pn =
hV, init, goal, Ai be a planning problem defined by a natural number n, V = {v1 , . . . , vn },
and a goal state defined by Vgoal = V , goal(vi ) = 0 for each vi âˆˆ {v1 , . . . , vnâˆ’1 }, and
goal(vn ) = 1. For each state variable vi âˆˆ V , there are two operators in A:
av1i = h(v1 = 0, . . . , viâˆ’2 = 0, viâˆ’1 = 1, vi = 0); (vi = 1)i,
av0i = h(v1 = 0, . . . , viâˆ’2 = 0, viâˆ’1 = 1, vi = 1); (vi = 0)i.
In other words, each state variable is symmetrically reversible. The causal graph of the planning problem P5 is shown in Figure 6. Note that for each state variable vi âˆˆ {v1 , . . . , vnâˆ’2 },
v
v
pre(a1i+1 )(vi ) = 1 and pre(a1i+2 )(vi ) = 0, so vi+1 âˆˆ Qv1i and vi+2 âˆˆ Q0vi . Since there is
an edge in the causal graph between vi+1 and vi+2 , no state variable in {v1 , . . . , vnâˆ’2 } is
v
splitting. On the other hand, vnâˆ’1 and vn are splitting since V0 nâˆ’1 = âˆ… and V0vn = V1vn = âˆ….
BaÌˆckstroÌˆm and Nebel (1995) showed that the length of the shortest plan solving Pn is 2n âˆ’1,
i.e., exponential in the number of state variables.
For each state variable vi âˆˆ {v1 , . . . , vnâˆ’1 }, our algorithm generates two macros mv1i and
vi
m0 . There is a single operator, av1i , that changes the value of vi from 0 to 1. pre(av1i )
only assigns 1 to viâˆ’1 , so U = {viâˆ’1 }. Since viâˆ’1 is not splitting, mv1i is defined as mv1i =
v
v
v
v
hm1iâˆ’1 , av1i , m0iâˆ’1 i. Similarly, mv0i is defined as mv0i = hm1iâˆ’1 , av0i , m0iâˆ’1 i. For state variable
vn , U = {vnâˆ’1 }, which is splitting, so mv1n is defined as mv1n = hav1n i.
To generate the final plan, the algorithm goes through the state variables in topological order. For state variables v1 through vnâˆ’2 , the algorithm does nothing, since these
state variables are not splitting and their goal state is not 1. For state variable vnâˆ’1 ,
the algorithm recursively generates the plan for vn , which is hmv1n i since goal(vn ) = 1.
v
Since goal(vnâˆ’1 ) = 0, the algorithm inserts m1nâˆ’1 before mv1n to satisfy its pre-condition
v
vnâˆ’1 = 1 and m0nâˆ’1 after mv1n to achieve the goal state goal(vnâˆ’1 ) = 0. Thus, the final plan
vnâˆ’1
v
vn
is hm1 , m1 , m0nâˆ’1 i. If we expand the plan, we end up with a sequence of 2n âˆ’ 1 operators. However, no individual macro has operator sequence length greater than 3. Together,
the macros recursively specify a complete solution to the planning problem.
We also demonstrate that there are planning problems in 3S with polynomial length
solutions for which our algorithm may generate exponential length solutions. To do this,
we modify the planning problem Pn by letting goal(vi ) = 1 for each vi âˆˆ V . In addition,
for each state variable vi âˆˆ V , we add two operators to A:
bv1i = h(v1 = 1, . . . , viâˆ’1 = 1, vi = 0); (vi = 1)i,
bv0i = h(v1 = 1, . . . , viâˆ’1 = 1, vi = 1); (vi = 0)i.
334

Complexity of Planning Problems

We also add an operator cv1n = h(vnâˆ’1 = 0, vn = 0); (vn = 1)i to A. As a consequence, state variables in {v1 , . . . , vnâˆ’2 } are still symmetrically reversible but not splitting.
vnâˆ’1 is also symmetrically reversible but no longer splitting, since pre(av1n )(vnâˆ’1 ) = 1 and
v
v
pre(cv1n )(vnâˆ’1 ) = 0 implies that vn âˆˆ V0 nâˆ’1 âˆ©V1 nâˆ’1 . vn is still splitting since V0vn = V1vn = âˆ….
Assume that GenerateMacro(P , vi , x, M ) always selects bvxi first. As a consequence, for
each state variable vi âˆˆ V and each x âˆˆ {0, 1}, GenerateMacro(P , vi , x, M ) generates
v
v
the macro mvxi = hm1iâˆ’1 , . . . , mv11 , bvxi , mv01 , . . . , m0iâˆ’1 i.
Let Li be the length of the plan represented by mvxi , x âˆˆ {0, 1}. From the definition of
v
i
mx above we have that Li = 2(L1 + . . . + Liâˆ’1 ) + 1. We show by induction that Li = 3iâˆ’1 .
The length of any macro for v1 is L1 = 1 = 30 . For i > 1,
Li = 2(30 + . . . + 3iâˆ’2 ) + 1 = 2

3iâˆ’1 âˆ’ 1
3iâˆ’1 âˆ’ 1
+1=2
+ 1 = 3iâˆ’1 âˆ’ 1 + 1 = 3iâˆ’1 .
3âˆ’1
2

To generate the final plan the algorithm has to change the value of each state variable
from 0 to 1, so the total length of the plan is L = L1 + . . . + Ln = 30 + . . . + 3nâˆ’1 =
(3n âˆ’ 1)/2. However, there exists a plan of length n that solves the planning problem,
namely hbv11 , . . . , bv1n i.
4.4 Complexity
In this section we prove that the complexity of our algorithm is polynomial. To do this
we analyze each step of the algorithm separately. A summary of the complexity result for
each step of the algorithm is given below. Note that the number of edges |E| in the causal
graph is O(|A||V |), since each operator may introduce O(|V |) edges. The complexity result
O(|V | + |E|) = O(|A||V |) for topological sort follows from Cormen, Leiserson, Rivest, and
Stein (1990).
Constructing the causal graph G = (V, E)
Calculating V1v and V0v for each v âˆˆ V
Performing a topological sort of G
GenerateMacro(P , v, x, M )
GeneratePlan(P , V , M )
Macro-3S(P )

O(|A||V |)
O(|A||V |2 )
O(|A||V |)
O(|A||V |)
O(|V |2 )
O(|A||V |2 )

Lemma 4.13
Lemma 4.14
Lemma 4.15
Lemma 4.16
Theorem 4.17

Lemma 4.13 The complexity of constructing the causal graph G = (V, E) is O(|A||V |).
Proof The causal graph consists of |V | nodes. For each operator a âˆˆ A and each state
variable u âˆˆ Vpre(a) , we should add an edge from u to the unique state variable v âˆˆ Vpost(a) .
In the worst case, |Vpre(a) | = O(|V |), in which case the complexity is O(|A||V |).
Lemma 4.14 The complexity of calculating the sets V0v and V1v for each state variable
v âˆˆ V is O(|A||V |2 ).
Proof For each state variable v âˆˆ V , we have to establish the sets Qv0 and Qv1 , which requires
going through each operator a âˆˆ A in the worst case. Note that we are only interested in
the pre-condition on v and the unique state variable in Vpost(a) , which means that we do not
335

GimeÌnez & Jonsson

need to go through each state variable in Vpre(a) . Next, we have to construct the graph Gv0 .
We can do this by copying the causal graph G, which takes time O(|A||V |), and removing
the edges between v and Qv0 âˆ’ Qv1 , which takes time O(|V |).
Finally, to construct the set V0v we should find each state variable that is weakly connected to some state variable u âˆˆ Qv0 in the graph Gv0 . For each state variable u âˆˆ Qv0 ,
performing an undirected search starting at u takes time O(|A||V |). Once we have performed search starting at u, we only need to search from state variables in Qv0 that were
not reached during the search. This way, the total complexity of the search does not exceed
O(|A||V |). The case for constructing V1v is identical. Since we have to perform the same
procedure for each state variable v âˆˆ V , the total complexity of this step is O(|A||V |2 ).
Lemma 4.15 The complexity of GenerateMacro(P , v, x, M ) is O(|A||V |).
Proof For each operator a âˆˆ A, GenerateMacro(P , v, x, M ) needs to check whether
post(a)(v) = x. In the worst case, |U | = O(|V |), in which case the complexity of the
algorithm is O(|A||V |).
Lemma 4.16 The complexity of GeneratePlan(P , V , M ) is O(|V |2 ).
Proof Note that for each state variable v âˆˆ V , GeneratePlan(P , V , M ) is called recursively exactly once such that v is the first variable in topological order. In other words,
GeneratePlan(P , V , M ) is called exactly |V | times. GeneratePlan(P , V , M ) contains
only constant operations except the intersection and difference between sets on lines 6-8.
Since intersection and set difference can be done in time O(|V |), the total complexity of
GeneratePlan(P , V , M ) is O(|V |2 ).
Theorem 4.17 The complexity of Macro-3S(P ) is O(|A||V |2 ).
Proof Prior to executing Macro-3S(P ), it is necessary to construct the causal graph G,
find the sets V0v and V1v for each state variable v âˆˆ V , and perform a topological sort
of G. We have shown that these steps take time O(|A||V |2 ). For each state variable
v âˆˆ V , Macro-3S(P ) calls GenerateMacro(P , v, x, M ) twice. From Lemma 4.15 it
follows that this step takes time O(2|V ||A||V |) = O(|A||V |2 ). Finally, Macro-3S(P ) calls
GeneratePlan(P , V , M ), which takes time O(|V |2 ) due to Lemma 4.16. It follows that
the complexity of Macro-3S(P ) is O(|A||V |2 ).
We conjecture that it is possible to improve the above complexity result for Macro3S(P ) to O(|A||V |). However, the proof seems somewhat complex, and our main objective
is not to devise an algorithm that is as efficient as possible. Rather, we are interested in
establishing that our algorithm is polynomial, which follows from Theorem 4.17.
4.5 Plan Length
In this section we study the length of the plans generated by the given algorithm. To begin
with, we derive a general bound on the length of such plans. Then, we show how to compute
the actual length of some particular plan without expanding its macros. We also present
an algorithm that uses this computation to efficiently obtain the i-th action of the plan
336

Complexity of Planning Problems

from its macro form. We start by introducing the concept of depth of state variables in the
causal graph.
Definition 4.18 The depth d(v) of a state variable v is the longest path from v to any
other state variable in the causal graph.
Since the causal graph is acyclic for planning problems in 3S, the depth of each state variable
is unique and can be computed in polynomial time. Also, it follows that at least one state
variable has depth 0, i.e., no outgoing edges.
Definition 4.19 The depth d of a planning problem P in 3S equals the largest depth of
any state variable v of P , i.e., d = maxvâˆˆV d(v).
We characterize a planning problem based on the depth of each of its state variables. Let
n = |V | be the number of state variables, and let ci denote the number of state variables
with depth i. If the planning problem has depth d, it follows that c0 + . . . + cd = n. As an
example, consider the planning problem whose causal graph appears in Figure 2. For this
planning problem, n = 8, d = 5, c0 = 2, c1 = 2, c2 = 1, c3 = 1, c4 = 1, and c5 = 1.
Lemma 4.20 Consider the values Li for i âˆˆ {0, . . . , d} defined by Ld = 1, and Li =
2(ci+1 Li+1 + ci+2 Li+2 + . . . + cd Ld ) + 1 when i < d. The values Li are an upper bound on
the length of macros generated by our algorithm for a state variable v with depth i.
Proof We prove it by a decreasing induction on the value of i. Assume v has depth i = d.
It follows from Definition 4.18 that v has no incoming edges. Thus, an operator changing
the value of v has no pre-condition on any state variable other than v, so Ld = 1 is an upper
bound, as stated.
Now, assume v has depth i < d, and that all Li+k for k > 0 are upper bounds on the
length of the corresponding macros. Let a âˆˆ A be an operator that changes the value of v.
From the definition of depth it follows that a cannot have a pre-condition on a state variable
u with depth j â‰¤ i; otherwise there would be an edge from u to v in the causal graph, causing
the depth of u to be greater than i. Thus, in the worst case, a macro for v has to change
the values of all state variables with depths larger than i, change the value of v, and reset
the values of state variables at lower levels. It follows that Li = 2(ci+1 Li+1 + . . . + cd Ld ) + 1
is an upper bound.
Theorem 4.21 The upper bounds Li of Lemma 4.20 satisfy Li = Î dj=i+1 (1 + 2cj ).
Proof Note that
Li = 2(ci+1 Li+1 + ci+2 Li+2 + . . . + cd Ld ) + 1 =
= 2ci+1 Li+1 + 2(ci+2 Li+2 + . . . + cd Ld ) + 1 =
= 2ci+1 Li+1 + Li+1 = (2ci+1 + 1)Li+1 .
The result easily follows by induction.
337

GimeÌnez & Jonsson

Now we can obtain an upper bound L on the total length of the plan. In the worst
case, the goal state assigns a different value to each state variable than the initial state,
i.e., goal(v) 6= init(v) for each v âˆˆ V . To achieve the goal state the algorithm applies one
macro per state variable. Hence
L = c0 L0 + c1 L1 + . . . + cd Ld = c0 L0 +

d
L0 âˆ’ 1
(1 + 2c0 )L0 âˆ’ 1
1Y
1
=
=
(1 + 2cj ) âˆ’ .
2
2
2
2
j=0

The previous bound depends on the distribution of the variables on depths according
to the causal graph. To obtain a general bound that does not depend on the depths of the
variables we first find which distribution maximizes the upper bound L.
Q
Lemma 4.22 The upper bound L = 21 dj=0 (1+2cj )âˆ’ 12 on planning problems on n variables
and depth d is maximized when all ci are equal, that is, ci = n/(d + 1).
Proof Note that ci > 0 for all i, and that c0 + Â· Â· Â· + cd = n. The result follows from a direct
application of the well known AM-GM (arithmetic mean-geometric mean) inequality, which
states that the arithmetic mean of positive values xi is greater or equal than its geometric
mean, with equality only when all xi are the same.
This implies that the product of positive
P
factors xi = (1 + 2ci ) with fixed sum A = dj=0 xj = 2n + d is maximized when all are
equal, that is, ci = n/(d + 1).
Theorem 4.23 The length of a plan generated by the algorithm for a planning problem in
3S with n state variables and depth d is at most ((1 + 2n/(d + 1))d+1 âˆ’ 1)/2.
Proof This is a direct consequence of Lemma 4.22. Since c0 , . . . , cd are discrete, it may not
be possible to set c0 = . . . = cd = n/(d + 1). Nevertheless, ((1 + 2n/(d + 1))d+1 âˆ’ 1)/2 is an
upper bound on L in this case.
Observe that the bound established in Theorem 4.23 is an increasing function of d. This
implies that for a given d, the bound also applies to planning problems in 3S with depth
smaller than d. As a consequence, if the depth of a planning problem in 3S is bounded
from above by d, our algorithm generates a solution plan for the planning problem with
polynomial length O(nd+1 ). Since the complexity of executing a plan is proportional to
the plan length, we can use the depth d to define tractable complexity classes of planning
problems in 3S with respect to plan execution.
Theorem 4.24 The length of a plan generated by the algorithm for a planning problem in
3S with n state variables is at most (3n âˆ’ 1)/2.
Proof In the worst case, the depth d of a planning problem is nâˆ’1. It follows from Theorem
4.23 that the length of a plan is at most ((1 + 2n/n)n âˆ’ 1)/2 = (3n âˆ’ 1)/2.
Note that the bound established in Theorem 4.24 is tight; in the second example in Section
4.3, we showed that our algorithm generates a plan whose length is (3n âˆ’ 1)/2.
338

Complexity of Planning Problems

1
2
3
4
5
6
7
8
9

function Operator(S, i)
o â† first operator in S
while length(o) < i do
i â† i âˆ’ length(o)
o â† next operator in S
if primitive(o) then
return o
else
return Operator(o, i)
Figure 7: An algorithm for determining the i-th operator in a sequence

Lemma 4.25 The complexity of computing the total length of any plan generated by our
algorithm is O(|V |2 ).
Proof The algorithm generates at most 2|V | = O(|V |) macros, 2 for each state variable. The
operator sequence of each macro consists of one operator and at most 2(|V | âˆ’ 1) = O(|V |)
other macros. We can use dynamic programming to avoid computing the length of a macro
more than once. In the worst case, we have to compute the length of O(|V |) macros, each
of which is a sum of O(|V |) terms, resulting in a total complexity of O(|V |2 ).
Lemma 4.26 Given a solution plan of length l and an integer 1 â‰¤ i â‰¤ l, the complexity of
determining the i-th operator of the plan is O(|V |2 ).
Proof We prove the lemma by providing an algorithm for determining the i-th operator,
which appears in Figure 7. Since operator sequences S consist of operators and macros,
the variable o represents either an operator in A or a macro generated by Macro-3S. The
function primitive(o) returns true if o is an operator and f alse if o is a macro. The function
length(o) returns the length of o if o is a macro, and 1 otherwise. We assume that the length
of macros have been pre-computed, which we know from Lemma 4.25 takes time O(|V |2 ).
The algorithm simply finds the operator or macro at the i-th position of the sequence,
taking into account the length of macros in the sequence. If the i-th position is part of
a macro, the algorithm recursively finds the operator at the appropriate position in the
operator sequence represented by the macro. In the worst case, the algorithm has to go
through O(|V |) operators in the sequence S and call Operator recursively O(|V |) times,
resulting in a total complexity of O(|V |2 ).
4.6 Discussion
The general view of plan generation is that an output should consist in a valid sequence of
grounded operators that solves a planning problem. In contrast, our algorithm generates a
solution plan in the form of a system of macros. One might argue that to truly solve the
plan generation problem, our algorithm should expand the system of macros to arrive at the
sequence of underlying operators. In this case, the algorithm would no longer be polynomial,
since the solution plan of a planning problem in 3S may have exponential length. In fact, if
the only objective is to execute the solution plan once, our algorithm offers only marginal
benefit over the incremental algorithm proposed by Jonsson and BaÌˆckstroÌˆm (1998).
339

GimeÌnez & Jonsson

On the other hand, there are several reasons to view the system of macros generated by
our algorithm as a complete solution to a planning problem in 3S. The macros collectively
specify all the steps necessary to reach the goal. The solution plan can be generated and
verified in polynomial time, and the plan can be stored and reused using polynomial memory.
It is even possible to compute the length of the resulting plan and determine the i-th
operator of the plan in polynomial time as shown in Lemmas 4.25 and 4.26. Thus, for all
practical purposes the system of macros represents a complete solution. Even if the only
objective is to execute the solution plan once, our algorithm should be faster than that of
Jonsson and BaÌˆckstroÌˆm (1998). All that is necessary to execute a plan generated by our
algorithm is to maintain a stack of currently executing macros and select the next operator
to execute, whereas the algorithm of Jonsson and BaÌˆckstroÌˆm has to perform several steps
for each operator output.
Jonsson and BaÌˆckstroÌˆm (1998) proved that the bounded plan existence problem for 3S
is NP-hard. The bounded plan existence problem is the problem of determining whether or
not there exists a valid solution plan of length at most k. As a consequence, the optimal
plan generation problem for 3S is NP-hard as well; otherwise, it would be possible to
solve the bounded plan existence problem by generating an optimal plan and comparing
the length of the resulting plan to k. In our examples we have seen that our algorithm
does not generate an optimal plan in general. In fact, our algorithm is just as bad as the
incremental algorithm of Jonsson and BaÌˆckstroÌˆm, in the sense that both algorithms may
generate exponential length plans even though there exists a solution of polynomial length.
Since our algorithm makes it possible to compute the total length of a valid solution
in polynomial time, it can be used to generate heuristics for other planners. Specifically,
Katz and Domshlak (2007) proposed projecting planning problems onto provably tractable
fragments and use the solution to these fragments as heuristics for the original problem. We
have shown that 3S is such a tractable fragment. Unfortunately, because optimal planning
for 3S is NP-hard, there is no hope of generating an admissible heuristic. However, the
heuristic may still be informative in guiding the search towards a solution of the original
problem. In addition, for planning problems with exponential length optimal solutions, a
standard planner has no hope of generating a heuristic in polynomial time, making our
macro-based approach (and that of Jonsson, 2007) the only (current) viable option.

5. The Class Cn
Domshlak and Dinitz (2001) defined the class Cn of planning problems with multi-valued
state variables and chain causal graphs. Since chain causal graphs are acyclic, it follows that
operators are unary. Moreover, let vi be the i-th state variable in the chain. If i > 1, for
each operator a such that Vpost(a) âŠ† {vi } it holds that Vpre(a) = {viâˆ’1 , vi }. In other words,
each operator that changes the value of a state variable vi may only have pre-conditions on
viâˆ’1 and vi .
The authors showed that there are instances of Cn with exponentially sized minimal
solutions, and therefore argued that the class is intractable. In light of the previous section,
this argument on the length of the solutions does not discard the possibility that instances
of the class can be solved in polynomial time using macros. We show that this is not the
case, unless P = NP.
340

Complexity of Planning Problems

v1

vk

w

Figure 8: Causal graph of P (F ).
C1

C1, Câ€™1

0,1
Cn,Câ€™n
Cn

Câ€™1

0,1
0

S

S

0,1

S

1

C1, Câ€™1
0,1

Cn,Câ€™n

Câ€™n

Figure 9: Domain transition graph for vi .
We define the decision problem Plan-Existence-Cn as follows. A valid input of PlanExistence-Cn is a planning instance P of Cn . The input P belongs to Plan-ExistenceCn if and only if P is solvable. We show in this section that the problem Plan-ExistenceCn is NP-hard. This implies that, unless P = NP, solving instances of Cn is a truly
intractable problem, namely, no polynomial-time algorithm can distinguish between solvable
and unsolvable instances of Cn . In particular, no polynomial-time algorithm can solve Cn
instances by using macros or any other kind of output format.1
We prove that Plan-Existence-Cn is NP-hard by a reduction from Cnf-Sat, that is,
the problem of determining whether a CNF formula F is satisfiable. Let C1 , . . . , Cn be the
clauses of the CNF formula F , and let v1 , . . . , vk be the variables that appear in F . We
briefly describe the intuition behind the reduction. The planning problem we create from
the formula F has a state variable for each variable appearing in F , and plans are forced
to commit a value (either 0 or 1) to these state variables before actually using them. Then,
to satisfy the goal of the problem, these variables are used to pass messages. However, the
operators for doing this are defined in such a way that a plan can only succeed when the
state variable values it has committed to are a satisfying assignment of F .
We proceed to describe the reduction. First ,we define a planning problem P (F ) =
hV, init, goal, Ai as follows. The set of state variables is V = {v1 , . . . , vk , w}, where D(vi ) =
{S, 0, 1, C1 , C1â€² , . . . , Cn , Cnâ€² } for each vi and D(w) = {S, 1, . . . , n}. The initial state defines
init(v) = S for each v âˆˆ V and the goal state defines goal(w) = n. Figure 8 shows the
causal graph of P (F ).
The domain transition graph for each state variable vi is shown in Figure 9. Each node
represents a value in D(vi ), and an edge from x to y means that there exists an operator
a such that pre(a)(vi ) = x and post(a)(vi ) = y. Edge labels represent the pre-condition of
such operators on state variable viâˆ’1 , and multiple labels indicate that several operators
are associated with an edge. We enumerate the operators acting on vi using the notation
a = hpre(a); post(a)i (when i = 1 any mention of viâˆ’1 is understood to be void):
1. A valid output format is one that enables efficient distinction between an output representing a valid
plan and an output representing the fact that no solution was found.

341

GimeÌnez & Jonsson

S

C1, Câ€™1

nâˆ’1

1

Cn,Câ€™n

n

Figure 10: Domain transition graph for w.
(1) Two operators hviâˆ’1 = S, vi = S; vi = 0i and hviâˆ’1 = S, vi = S; vi = 1i that allow vi
to move from S to either 0 or 1.
(2) Only when i > 1. For each clause Cj and each X âˆˆ {Cj , Cjâ€² }, two operators
hviâˆ’1 = X, vi = 0; vi = Cj i and hviâˆ’1 = X, vi = 1; vi = Cjâ€² i. These operators allow vi to move to Cj or Cjâ€² if viâˆ’1 has done so.
(3) For each clause Cj and each X âˆˆ {0, 1}, an operator hviâˆ’1 = X, vi = 0; vi = Cj i if v i
occurs in clause Cj , and an operator hviâˆ’1 = X, vi = 1; vi = Cjâ€² i if vi occurs in clause
Cj . These operators allow vi to move to Cj or Cjâ€² even if viâˆ’1 has not done so.
(4) For each clause Cj and each X = {0, 1}, two operators hviâˆ’1 = X, vi = Cj ; vi = 0i
and hviâˆ’1 = X, vi = Cjâ€² ; vi = 1i. These operators allow vi to move back to 0 or 1.
The domain transition graph for state variable w is shown in Figure 10. For every clause
Cj the only two operators acting on w are hvk = X, w = j âˆ’ 1; w = ji, where X âˆˆ {Cj , Cjâ€² }
(if j = 1, the pre-condition w = j âˆ’ 1 is replaced by w = S).
Proposition 5.1 A CNF formula F is satisfiable if and only if the planning instance P (F )
is solvable.
Proof The proof follows from a relatively straightforward interpretation of the variables
and values of the planning instance P (F ). For every state variable vi , we must use an
operator of (1) to commit to either 0 or 1. Note that, once this choice is made, variable vi
cannot be set to the other value. The reason we need two values Cj and Cjâ€² for each clause
is to enforce this commitment (Cj corresponds to vi = 0, while Cjâ€² corresponds to vi = 1).
To reach the goal the state variable w has to advance step by step along the values 1, . . . , n.
Clearly, for every clause Cj there must exist some variable vi that is first set to values Cj
or Cjâ€² using an operator of (3). Then, this â€œmessageâ€ can be propagated along variables
vi+1 , . . . , vk using operators of (2). Note that the existence of an operator of (3) acting on
vi implies that the initial choice of 0 or 1 for state variable vi , when applied to the formula
variable vi , makes the clause Cj true. Hence, if Î  is a plan solving P (F ), we can use the
initial choices of Î  on state variables vi to define a (partial) assignment Ïƒ that satisfies all
clauses of F .
Conversely, if Ïƒ is some assignment that satisfies F , we show how to obtain a plan Î 
that solves P (F ). First, we set every state variable vi to value Ïƒ(vi ). For every one of the
clauses Cj , we choose a variable vi among those that make Cj true using assignment Ïƒ.
Then, in increasing order of j, we set the state variable vi corresponding to clause Cj to a
value Cj or Cjâ€² (depending on Ïƒ(vi )), and we pass this message along vi+1 , . . . , vk up to w.
Theorem 5.2 Plan-Existence-Cn is NP-hard.
342

Complexity of Planning Problems

vx
vC

vC

vC

vC

vC

vC

1

2

3

vx

vy

vy

vz

vz

1

2

v1

v2

v3

v4

v5

3

Figure 11: Causal graph of PF when F = C1 âˆ§ C2 âˆ§ C3 on three variables x, y, z.
Proof Producing a planning instance P (F ) from a CNF formula F can be easily done in
polynomial time, so we have a polynomial-time reduction Cnf-Sat â‰¤p Plan-ExistenceCn .

6. Polytree Causal Graphs
In this section, we study the class of planning problems with binary state variables and
polytree causal graphs. Brafman and Domshlak (2003) presented an algorithm that finds
plans for problems of this class in time O(n2Îº ), where n is the number of variables and
Îº is the maximum indegree of the polytree causal graph. Brafman and Domshlak (2006)
also showed how to solve in time roughly O(nÏ‰Î´ ) planning domains with local depth Î´ and
causal graphs of tree-width Ï‰. It is interesting to observe that both algorithms fail to solve
polytree planning domains in polynomial time for different reasons: the first one fails when
the tree is too broad (unbounded indegree), the second one fails when the tree is too deep
(unbounded local depth, since the tree-width Ï‰ of a polytree is 1).
In this section we prove that the problem of plan existence for polytree causal graphs
with binary variables is NP-hard. Our proof is a reduction from 3Sat to this class of
planning problems. As an example of the reduction, Figure 11 shows the causal graph of
the planning problem PF that corresponds to a formula F with three variables and three
clauses (the precise definition of PF is given in Proposition 6.2). Finally, at the end of this
section we remark that the same reduction solves a problem expressed in terms of CP-nets
(Boutilier et al., 2004), namely, that dominance testing for polytree CP-nets with binary
variables and partially specified CPTs is NP-complete.
Let us describe briefly the idea behind the reduction. The planning problem PF has two
â€² , . . . , and v ) depends on
different parts. The first part (state variables vx , vx , . . . , vC1 , vC
1
1
the formula F and has the property that a plan may change the value of v1 from 0 to 1 as
many times as the number of clauses of F that a truth assignment can satisfy. However, this
condition on v1 cannot be stated as a planning problem goal. We overcome this difficulty
by introducing a second part (state variables v1 , v2 , . . . , vt ) that translates it to a regular
planning problem goal.
We first describe the second part. Let P be the planning problem hV, init, goal, Ai
where V is the set of state variables {v1 , . . . , v2kâˆ’1 } and A is the set of 4k âˆ’ 2 operators
{Î±1 , . . . , Î±2kâˆ’1 , Î²1 , . . . , Î²2kâˆ’1 }. For i = 1, the operators are defined as Î±1 = hv1 = 1; v1 = 0i
343

GimeÌnez & Jonsson

and Î²1 = hv1 = 0; v1 = 1i. For i > 1, the operators are Î±i = hviâˆ’1 = 0, vi = 1; vi = 0i and
Î²i = hviâˆ’1 = 1, vi = 0; vi = 1i. The initial state is init(vi ) = 0 for all i, and the goal state
is goal(vi ) = 0 if i is even and goal(vi ) = 1 if odd.
Lemma 6.1 Any valid plan for planning problem P changes state variable v1 from 0 to 1
at least k times. There is a valid plan that achieves this minimum.
Proof Let Ai and Bi be, respectively, the sequences of operators hÎ±1 , . . . , Î±i i and hÎ²1 , . . . , Î²i i.
It is easy to verify that the plan hB2kâˆ’1 , A2kâˆ’2 , B2kâˆ’3 , . . . , B3 , A2 , B1 i solves the planning
problem P . Indeed, after applying the operators of Ai (respectively, the operators of Bi ),
variables v1 , . . . , vi become 0 (respectively, 1). In particular, variable vi attains its goal
state (0 if i is even, 1 if i is odd). Subsequent operators in the plan do not modify vi , so
the variable remains in its goal state until the end. The operator Î²1 appears k times in the
plan (one for each sequence of type Bi ), thus the value of v1 changes k times from 0 to 1.
We proceed to show that k is the minimum. Consider some plan Î  that solves the
planning problem P , and let Î»i be the number of operators Î±i and Î²i appearing in Î  (in
other words, Î»i is the number of times that the value of vi changes, either from 0 to 1 or
from 1 to 0). Note that the number of times operator Î²i appears is equal to or precisely one
more than the number of occurrences of Î±i . We will show that Î»iâˆ’1 > Î»i . Since Î»2kâˆ’1 â‰¤ 1,
this implies that Î»1 â‰¥ 2k âˆ’ 1, so that plan Î  has, at least, k occurrences of Î²1 , completing
the proof.
We show that Î»iâˆ’1 > Î»i . Let Si be the subsequence of operators Î±i and Î²i in plan Î .
Clearly, Si starts with Î²i (since the initial state is vi = 0), and the same operator cannot
appear twice consecutively in Si , so Si = Î²i , Î±i , Î²i , Î±i , etc. Also note that, for i > 1, Î²i has
viâˆ’1 = 1 as a pre-condition, and Î±i has viâˆ’1 = 0, hence there must be at least one operator
Î±iâˆ’1 in plan Î  betweeen any two operators Î²i and Î±i . For the same reason we must have
at least one operator Î²iâˆ’1 between any two operators Î±i and Î²i , and one operator Î²iâˆ’1
before the first operator Î²i . This shows that Î»iâˆ’1 â‰¥ Î»i . On the other hand, variables vi and
viâˆ’1 have different values in the goal state, so subsequences Si and Siâˆ’1 must have different
lengths, that is, Î»iâˆ’1 6= Î»i . Together, this implies Î»iâˆ’1 > Î»i , as desired.
Proposition 6.2 3Sat reduces to plan existence for planning problems with binary variables and polytree causal graphs.
Proof Let F be a CNF formula with k clauses and n variables. We produce a planning
problem PF with 2n + 4k âˆ’ 1 state variables and 2n + 14k âˆ’ 3 operators. The planning
problem has two state variables vx and vx for every variable x in F , two state variables vC
â€² for every clause C in F , and 2k âˆ’ 1 additional variables v , . . . , v
and vC
1
2kâˆ’1 . All variables
are 0 in the initial state. The (partial) goal state is defined by Vgoal = {v1 , . . . , v2kâˆ’1 },
goal(vi ) = 0 when i is even, and goal(vi ) = 1 when i is odd, like in problem P of Lemma
6.1. The operators are:
(1) Operators hvx = 0; vx = 1i and hvx = 0; vx = 1i for every variable x of F .
â€² = 0; v â€² = 1i, hv â€² = 0, v = 0; v = 1i and hv â€² = 1, v = 1; v = 0i
(2) Operators hvC
C
C
C
C
C
C
C
for every clause C of F .

344

Complexity of Planning Problems

(3) Seven operators for every clause C, one for each partial assignment that satisfies C.
Without loss of generality, let x, y, and z be the three variables that appear in clause C.
Then for each operator a among these seven, Vpre(a) = {vx , vx , vy , vy , vz , vz , vC , v1 },
Vpost(a) = {v1 }, pre(a)(vC ) = 1, pre(a)(v1 ) = 0, and post(a)(v1 ) = 1. The precondition on state variables vx , vx , vy , vy , vz , vz depends on the corresponding satisfying partial assignment. For example, the operator corresponding to the partial
assignment {x = 0, y = 0, z = 1} of the clause C = x âˆ¨ y âˆ¨ z has the pre-condition
(vx = 0, vx = 1, vy = 0, vy = 1, vz = 1, vz = 0).
(4) An operator h(âˆ€C, vC = 0), v1 = 1; v1 = 0i.
(5) Operators Î±i = hviâˆ’1 = 0, vi = 1; vi = 0i and Î²i = hviâˆ’1 = 1, vi = 0; vi = 1i for
2 â‰¤ i â‰¤ 2k âˆ’ 1 (the same operators as in problem P except for Î±1 and Î²1 ).
We note some simple facts about problem PF . For any variable x, state variables vx and
vx in PF start at 0, and by applying the operators in (1) they can change into 1 but not
back to 0. In particular, a plan Î  cannot reach both of the partial states hvx = 1, vx = 0i
and hvx = 0, vx = 1i during the course of its execution.
Similarly, if C is a clause of F , state variable vC can change from 0 to 1 and, by first
â€² into 1, v can change back to 0. No further changes are possible, since no
changing vC
C
â€² to 0.
operator brings back vC
Now we interpret operators in (3) and (4), which are the only operators that affect v1 .
To change v1 from 0 to 1 we need to apply one of the operators in (3), thus we require
vC = 1 for a clause C. But the only way to bring back v1 to 0 is applying the operator in
(4) which has as pre-condition that vC = 0. We deduce that every time that v1 changes its
value from 0 to 1 and then back to 0 in plan Î , at least one of the k state variables vC is
used up, in the sense that vC has been brought from 0 to 1 and then back to 0, and cannot
be used again for the same purpose.
We show that F is in 3Sat if and only if there is a valid plan for problem PF . Assume
F is in 3Sat, and let Ïƒ be a truth assignment that satisfies F . Consider the following plan
Î â€² . First, we set vx = Ïƒ(x) and vx = 1 âˆ’ Ïƒ(x) for all variables x using the operators of (1).
Then, for a clause C in F , we set vC = 1, we apply the operator of (3) that corresponds to
Ïƒ restricted to the variables of clause C (at this point, v1 changes from 0 to 1), then we set
â€² = 1 and v = 0, and we apply the operator of (4) (at this point, v change from 1 to
vC
1
C
0). By repeating this process for every clause C of F we are switching the state variable v1
exactly k times from 0 to 1. Now, following the proof of Lemma 6.1, we can easily extend
this plan Î â€² to a plan Î  that sets all variables vi to their goal values.
We show the converse, namely, that the existence of a valid plan Î  in PF implies that F
is satisfiable. Define an assignment Ïƒ by setting Ïƒ(x) = 1 if the partial state {vx = 1, vx = 0}
appears during the execution of Î , and Ïƒ(x) = 0 otherwise. (Recall that at most one of the
partial states {vx = 1, vx = 0} and {vx = 0, vx = 1} can appear during the execution of any
plan). By Lemma 6.1, Î  must be such that state variable v1 changes from 0 to 1 at least k
times. This implies that k operators of (3), all of them corresponding to different clauses,
have been used to move v1 from 0 to 1. But to apply such an operator, the values of state
variables {vx , vx } must satisfy the corresponding clause. Thus the assignment Ïƒ satisfies all
the k clauses of F .
345

GimeÌnez & Jonsson

Theorem 6.3 Plan existence for planning problems with binary variables and polytree
causal graph is NP-complete.
Proof Due to Proposition 6.2 we only need to show that the problem is in NP. But
Brafman and Domshlak (2003) showed that this holds in the more general setting of planning
problems with causal graphs where each component is directed-path singly connected (that
is, there is at most one directed path between any pair of nodes). Their proof exploits a
non-trivial auxiliary result: solvable planning problems on binary variables with a directedpath singly connected causal graph have plans of polynomial length (the same is not true
for non-binary variables, or unrestricted causal graphs).
6.1 CP-nets
Boutilier et al. (2004) introduced the notion of a CP-net as a graphical representation of
user preferences. In brief, a CP-net is a network of dependences on a set of variables: the
preferences the user has for a variable depend on the values of some of the others, under the
ceteris paribus (all else being equal) assumption, that is, the user preferences on the variable
are completely independent of the values of the variables not mentioned. The preferences
for a variable given its parent variables in the network are stored in conditional preference
tables, or CPTs.
Boutilier et al. (2004) showed that the dominance query problem in acyclic CP-nets,
that is, the problem of deciding if one variable outcome is preferable to another, can be
expressed in terms of a planning problem. The network of dependences of the CP-net
becomes the causal graph of the planning problem.
However, under certain conditions, we can perform the opposite process: transform
a planning problem into a CP-net and a dominance query problem, such that answering
the query amounts to solving the planning problem. This is possible under the following
conditions on planning problems with acyclic causal graph and binary variables:
1. Two operators that modify the same variable in opposing directions must have nonmatching prevail conditions (the prevail condition of an operator a is the partial state
pre(a) | V âˆ’ Vpost(a) ).
2. We must allow partially specified CPTs in the CP-net description.
The first condition guarantees that we obtain consistent CPTs from the planning instance
operators. The second condition ensures that the reduction is polynomial-size preserving,
since fully specified CPTs are exponential in the maximum node indegree of the CP-net.
In particular, the planning instance PF we reduced F to satisfies the first condition.
(Note that this is not true for the planning problem P of Lemma 6.1, but we drop the
reversing operators Î±1 and Î²1 when constructing PF in Proposition 6.2.) As a consequence,
we can claim the following:
Theorem 6.4 Dominance testing for polytree CP-nets with binary variables and partially
specified CPTs is NP-complete.
346

Complexity of Planning Problems

7. Conclusion
We have presented three new complexity results for planning problems with simple causal
graphs. First, we provided a polynomial-time algorithm that uses macros to generate solution plans for the class 3S. Although the solutions are generally suboptimal, the algorithm
can generate representations of exponentially long plans in polynomial time. This has several implications for theoretical work in planning, since it has been generally accepted that
exponentially sized minimal solutions imply that plan generation is intractable. Our work
shows that this is not always the case, provided that one is allowed to express the solution
in a succinct notation such as macros. We also showed that plan existence for the class Cn
is NP-hard, and that plan existence for the class of planning problems with binary variables
and polytree causal graph is NP-complete.
Jonsson and BaÌˆckstroÌˆm (1998) investigated whether plan generation is significantly
harder than plan existence. Using the class 3S, they demonstrated that plan existence
can be solved in polynomial time, while plan generation is intractable in the sense that
solution plans may have exponential length. Our work casts new light on this result: even
though solution plans have exponential length, it is possible to generate a representation
of the solution in polynomial time. Thus, it appears as if for the class 3S, plan generation
is not inherently harder than plan existence. We are not aware of any other work that
determines the relative complexity of plan existence and plan generation, so the question
of whether plan generation is harder that plan existence remains open.
A potential criticism of our algorithm is that a solution in the form of macros is not
standard, and that it is intractable to expand the system of macros to arrive at the possibly
exponentially long sequence of underlying operators. Although this is true, we have shown
that the system of macros share several characteristics with a proper solution. It is possible
to generate and validate the solution in polynomial time, and the solution can be stored
using polynomial memory. We also showed that it is possible to compute the total length
of the solution in polynomial time, as well as determine which is the i-th operator in the
underlying sequence.
Since they are relatively simple, the class Cn and the class of planning problems with
binary state variables and polytree causal graphs could be seen as promising candidates for
proving the relative complexity of plan existence and plan generation. However, we have
shown that plan existence for Cn is NP-hard, and that plan existence for planning problems
with polytree causal graphs is NP-complete. Consequently, these classes cannot be used
to show that plan generation is harder than plan existence, since plan existence is already
difficult. Our work also closes the complexity gaps that appear in the literature regarding
these two classes.
It is however possible that there exist subsets of planning problems in these classes
for which plan existence can be solved in polynomial time. In fact, for polytree causal
graphs in binary variables we know that this is the case, due to the algorithms of Brafman
and Domshlak (2003, 2006) mentioned in Section 6. Hence the plan generation problem
is polynomial if we restrict to polytree causal graphs with either bounded indegree Îº or
bounded local depth Î´. Consequently, our reduction from 3Sat exhibits both unbounded
indegree and unbounded local depth.
347

GimeÌnez & Jonsson

Similarly, one may ask if the class Cn of planning problems has some parameter that,
when bounded, would yield a tractable subclass. The state variables in our reduction have
domains whose size depends on the number of clauses of the corresponding CNF formula,
so the domain size appears as an interesting candidate. Planning problems of Cn with
binary variables are tractable due to the work of Brafman and Domshlak (2003), but the
ideas they use do not extend to domain sizes other than 2. Hence it would be interesting
to investigate whether the problem of plan existence for the class Cn is easier if the size of
the state variable domains is bounded by a constant.

Appendix A. Proof of Theorem 4.8
Assume that GenerateMacro(P , v, x, M ) successfully returns the macro mvx = hS1 , a, S0 i.
Let U = {u âˆˆ Vpre(a) âˆ’ {v} | pre(a)(u) = 1} and let W = {w1 , . . . , wk } âŠ† U be the set
wi
i
of state variables in U such that wi is not splitting, {mw
0 , m1 } âˆˆ M , and wi comes before wj in topological order if and only if i < j. It follows that no u âˆˆ U is static, that
wk
w1
w1
k
S1 = hmw
1 , . . . , m1 i and that S0 = hm0 , . . . , m0 i. Since each state variable wi âˆˆ W is
not splitting, it has to be symmetrically reversible.
Lemma A.1 For each wi âˆˆ W , prewi âŠ‘ prev .
Proof Since wi âˆˆ Vpre(a) and v âˆˆ Vpost(a) , there is an edge from wi to v in the causal graph.
Thus, any ancestor of wi is also an ancestor of v, so Ancwi âŠ‚ Ancv . For a state variable
u âˆˆ Ancwi , prewi (u) = 1 if and only if u is splitting and wi âˆˆ V1u . The graph Gu1 = (V, E1u )
includes the edge from wi to v, which means that v âˆˆ V1u if and only if wi âˆˆ V1u . It follows
that prewi (u) = 1 if and only if prev (u) = 1, and as a consequence, prewi âŠ‘ prev .
i
Let Î  = hS0 , a, S1 i. For each wi âˆˆ W and y âˆˆ {0, 1}, let Î w
y be the sequence preceding
wiâˆ’1
w
w
w
w
i+1
w
i
1
i
k
i.
the macro my i in Î , that is, Î 1 = hm1 , . . . , m1 i and Î 0 = hS0 , a, mw
0 , . . . , m0
a
a
Further, let Î  be the sequence appearing before a, that is, Î  = hS0 i.

wi
a
i
Lemma A.2 For each 1 â‰¤ i â‰¤ k, the post-conditions of sequences Î w
1 , Î  , and Î 0 are
i
â€¢ post(Î w
1 ) = (wi+1 = 1, . . . , wk = 1),

â€¢ post(Î a ) = (w1 = 1, . . . , wk = 1),
i
â€¢ post(Î w
0 ) = (w1 = 0, . . . , wiâˆ’1 = 0, wi = 1, . . . , wk = 1, v = x).
i
Proof A direct consequence of post(ha1 , . . . , ak i) = post(a1 )âŠ•Â· Â· Â·âŠ•post(ak ) and post(mw
y )=
(wi = y), post(a) = (v = x).

wi
a
i
Lemma A.3 For each 1 â‰¤ i â‰¤ k, the pre-conditions of sequences Î w
1 , Î  , Î 0 , and Î 
wi
v
a
i
satisfy pre(Î w
1 ) âŠ‘ pre(Î  ) âŠ‘ pre(Î 0 ) âŠ‘ pre(Î ) âŠ‘ pre âŠ• (v = 1 âˆ’ x).
a
i
Proof Since pre(ha1 , . . . , ak i) = pre(ak )âŠ•Â· Â· Â·âŠ•pre(a1 ), it follows that pre(Î w
1 ) âŠ‘ pre(Î  ) âŠ‘
wi
v
pre(Î 0 ) âŠ‘ pre(Î ). We prove that pre(Î ) âŠ‘ pre âŠ• (v = 1 âˆ’ x). For a state variable u
such that pre(Î )(u) 6=âŠ¥, let mu be the first operator in hS0 , a, S1 i such that u âˆˆ Vpre(mu ) ,
so that pre(Î )(u) = pre(mu )(u).

348

Complexity of Planning Problems

u
wi âŠ• (w = 0) âŠ‘ prev , where we have
i
If mu = mw
i
1 , then it follows that pre(m ) âŠ‘ pre
wi
used that m1 is a 3S-macro, wi is symmetrically reversible, and that prewi âŠ‘ prev due to
Lemma A.1. In particular, pre(mu )(u) = prev (u).
Since we assume that planning problems are in normal form, u = wi implies that
wi
u
i
u âˆˆ Vpre(mwi ) . It follows that if mu 6= mw
1 for all i, then u 6= wi for all i. If m = m0
1
we have that pre(mu ) âŠ‘ prewi âŠ• (wi = 1), but due to u 6= wi , we deduce pre(mu )(u) =
prewi (u) = prev (u).
Finally, consider the case mu = a. If u = v then pre(mu )(u) = 1 âˆ’ x, as desired. If
u 6= v is splitting, then either v belongs to V0u and pre(mu )(u) = 0, or v belongs to V1u and
pre(mu )(u) = 1. That is, pre(mu )(u) = prev (u). If u 6= v is symmetrically reversible it
follows that pre(mu )(u) = 0, since the case pre(mu )(u) = 1 would have forced the algorithm
to either fail or include u in W . If u 6= v is static, pre(mu )(u) = 0, else the algorithm would
have failed.

Lemma A.4 Let p, pâ€² , q and r be partial states. If p âŠ‘ pâ€² and (pâ€² âŠ• q)â–½r, then (p âŠ• q)â–½r.
Proof A direct consequence of p âŠ• q âŠ‘ pâ€² âŠ• q.
Lemma A.5 The macro mvx generated by the algorithm is well-defined.
Proof Since Î  only includes macros for the ancestors of v in the causal graph, and since
the causal graph is acyclic, no cyclic definitions occur. It remains to show that, for a macro
m in Î  and a sequence Î m preceding m in Î , it holds that (pre(Î m ) âŠ• post(Î m ))â–½pre(m).
Note that due to Lemmas A.3 and A.4 it is enough to show that
wi
i
(a) (prev âŠ• (v = 1 âˆ’ x) âŠ• post(Î w
1 ))â–½pre(m1 ),

(b) (prev âŠ• (v = 1 âˆ’ x) âŠ• post(Î a ))â–½pre(a),
wi
i
(c) (prev âŠ• (v = 1 âˆ’ x) âŠ• post(Î w
0 ))â–½pre(m0 ).
wi
i
Case (a) follows easily since Vpost(Î wi ) âˆ©Vpre(mwi ) = âˆ… and pre(mw
1 ) = pre âŠ•(wi = 0) âŠ‘
1
1
w
prev . Case (c) is similar, although this time we must use that post(Î 0 i )(wi ) = 1 and
wi
wi âŠ• (w = 1). Finally, case (b)
i
post(Î w
i
0 )(wj ) = 0 for j < i, as required by pre(m0 ) = pre
holds because a variable u âˆˆ Vpre(a) can be either u = v, which is covered by (v = 1 âˆ’ x),
splitting or static, which is covered by prev , or symmetrically reversible, which is covered
by prev (u) = 0 if pre(a)(u) = 0, and by post(Î a )(u) = 1 if pre(a)(u) = 1.

In remains to show that mvx is a 3S-macro. It follows from Lemmas A.3 and A.5 that it
is well-defined and it satisfies pre(mvx ) = pre(Î ) âŠ‘ prev âŠ• (v = 1 âˆ’ x). Finally, post(mvx ) =
post(Î )âˆ’pre(Î ) = (v = x) is a direct consequence of post(Î ) = (w1 = 0, . . . , wk = 0, v = x)
from Lemma A.2, and pre(Î )(wi ) = 0, pre(Î )(v) = 1 âˆ’ x from the proof of Lemma A.3.

Acknowledgments
This work was partially funded by MEC grants TIN2006-15387-C03-03 and TIN2004-07925C03-01 (GRAMMARS).
349

GimeÌnez & Jonsson

References
BaÌˆckstroÌˆm, C., & Nebel, B. (1995). Complexity Results for SAS+ Planning. Computational
Intelligence, 11 (4), 625â€“655.
Botea, A., Enzenberger, M., MuÌˆller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI
Planning with Automatically Learned Macro-Operators. Journal of Artificial Intelligence Research, 24, 581â€“621.
Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: A Tool for
Representing and Reasoning with Conditional Ceteris Paribus Preference Statements.
Journal of Artificial Intelligence Research, 21, 135â€“191.
Brafman, R., & Domshlak, C. (2003). Structure and Complexity in Planning with Unary
Operators. Journal of Artificial Intelligence Research, 18, 315â€“349.
Brafman, R., & Domshlak, C. (2006). Factored Planning: How, When, and When Not. In
Proceedings of the 21st National Conference on Artificial Intelligence.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning.
Artificial Intelligence, 69, 165â€“204.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 32(3), 333â€“377.
Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (1990). Introduction to Algorithms. MIT
Press and McGraw Hill.
Domshlak, C., & Dinitz, Y. (2001). Multi-Agent Off-line Coordination: Structure and Complexity. In Proceedings of the 6th European Conference on Planning, pp. 277â€“288.
Erol, K., Nau, D., & Subrahmanian, V. (1995). Complexity, decidability and undecidability
results for domain-independent planning. Artificial Intelligence, 76(1-2), 75â€“88.
Fikes, R., & Nilsson, N. (1971). STRIPS: A new approach to the application of theorem
proving to problem solving. Artificial Intelligence, 5 (2), 189â€“208.
GimeÌnez, O., & Jonsson, A. (2007). On the Hardness of Planning Problems With Simple
Causal Graphs. In Proceedings of the 17th International Conference on Automated
Planning and Scheduling, pp. 152â€“159.
Helmert, M. (2003). Complexity results for standard benchmark domains in planning.
Artificial Intelligence, 143(2), 219â€“262.
Helmert, M. (2006). The Fast Downward Planning System. Journal of Artificial Intelligence
Research, 26, 191â€“246.
Jonsson, A. (2007). The Role of Macros in Tractable Planning Over Causal Graphs. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence, pp.
1936â€“1941.
Jonsson, P., & BaÌˆckstroÌˆm, C. (1998). Tractable plan existence does not imply tractable
plan generation. Annals of Mathematics and Artificial Intelligence, 22(3-4), 281â€“296.
Katz, M., & Domshlak, C. (2007). Structural Patterns Heuristics: Basic Idea and Concrete
Instance. In Workshop on Heuristics for Domain-independent Planning: Progress,
Ideas, Limitations, Challenges (ICAPS-07).
350

Complexity of Planning Problems

Knoblock, C. (1994). Automatically generating abstractions for planning. Artificial Intelligence, 68(2), 243â€“302.
Korf, R. (1987). Planning as search: A quantitative approach. Artificial Intelligence, 33(1),
65â€“88.
Minton, S. (1985). Selectively generalizing plans for problem-solving. In Proceedings of the
9th International Joint Conference on Artificial Intelligence, pp. 596â€“599.
Vidal, V. (2004). A Lookahead Strategy for Heuristic Search Planning. In Proceedings of the
14th International Conference on Automated Planning and Scheduling, pp. 150â€“159.
Williams, B., & Nayak, P. (1997). A reactive planner for a model-based executive. In
Proceedings of the 15th International Joint Conference on Artificial Intelligence, pp.
1178â€“1185.

351

Journal of Artificial Intelligence Research 31 (2008) 217-257

Submitted 09/07; published 02/08

Loosely Coupled Formulations for Automated Planning: An
Integer Programming Perspective
Menkes H.L. van den Briel

menkes@asu.edu

Department of Industrial Engineering
Arizona State University, Tempe, AZ 85281 USA

Thomas Vossen

vossen@colorado.edu

Leeds School of Business
University of Colorado at Boulder, Boulder CO, 80309 USA

Subbarao Kambhampati

rao@asu.edu

Department of Computer Science and Engineering
Arizona State University, Tempe, AZ 85281 USA

Abstract
We represent planning as a set of loosely coupled network flow problems, where each
network corresponds to one of the state variables in the planning domain. The network
nodes correspond to the state variable values and the network arcs correspond to the value
transitions. The planning problem is to find a path (a sequence of actions) in each network
such that, when merged, they constitute a feasible plan. In this paper we present a number of integer programming formulations that model these loosely coupled networks with
varying degrees of flexibility. Since merging may introduce exponentially many ordering
constraints we implement a so-called branch-and-cut algorithm, in which these constraints
are dynamically generated and added to the formulation when needed. Our results are very
promising, they improve upon previous planning as integer programming approaches and
lay the foundation for integer programming approaches for cost optimal planning.

1. Introduction
While integer programming1 approaches for automated planning have not been able to
scale well against other compilation approaches (i.e. satisfiability and constraint satisfaction), they have been extremely successful in the solution of many real-world large scale
optimization problems. Given that the integer programming framework has the potential
to incorporate several important aspects of real-world automated planning problems (for
example, numeric quantities and objective functions involving costs and utilities), there is
significant motivation to investigate more effective integer programming formulations for
classical planning as they could lay the groundwork for large scale optimization (in terms
of cost and resources) in automated planning. In this paper, we study a novel decomposition based approach for automated planning that yields very effective integer programming
formulations.
1. We use the term integer programming to refer to integer linear programming unless stated otherwise.
c
2008
AI Access Foundation. All rights reserved.

Van den Briel, Vossen & Kambhampati

Decomposition is a general approach to solving problems more efficiently. It involves
breaking a problem up into several smaller subproblems and solving each of the subproblems separately. In this paper we use decomposition to break up a planning problem into
several interacting (i.e. loosely coupled) components. In such a decomposition, the planning
problem involves both finding solutions to the individual components and trying to merge
them into a feasible plan. This general approach, however, prompts the following questions:
(1) what are the components, (2) what are the component solutions, and (3) how hard is it
to merge the individual component solutions into a feasible plan?
1.1 The Components
We let the components represent the state variables of the planning problem. Figure 1
illustrates this idea using a small logistics example, with one truck and a package that
needs to be moved from location 1 to location 2. There are a total of five components in
this example, one for each state variable. We represent the components by an appropriately
defined network, where the network nodes correspond to the values of the state variable
(for atoms this is T = true and F = false), and the network arcs correspond to the value
transitions. The source node in each network, represented by a small in-arc, corresponds
to the initial value of the state variable. The sink node(s), represented by double circles,
correspond to the goal value(s) of the state variable. Note that the effects of an action
can trigger value transitions in the state variables. For example, loading the package at
location 1 makes the atom pack-in-truck true and pack-at-loc1 false. In addition, loading
the package at location 1 requires that the atom truck-at-loc1 is true.
While the idea of components representing the state variables of the planning problem
can be used with any state variable representation, it is particularly synergistic with multivalued state variables. Multi-valued state variables provide a more compact representation
of the planning problem than their binary-valued counterparts. Therefore, by making the
conversion to multi-valued state variables we can reduce the number of components and
create a better partitioning of the constraints. Figure 2 illustrates the use of multi-valued
state variables on our small logistics example. There are two multi-valued state variables
in this problem, one to characterize the location of the truck and one to characterize the
location of the package. In our network representation, the nodes correspond to the state
variable values (1 = at-loc1, 2 = at-loc2, and t = in-truck), and the arcs correspond to the
value transitions.
1.2 The Component Solutions
We let the component solutions represent a path of value transitions in the state variables.
In the networks, nodes and arcs appear in layers. Each layer represents a plan period
in which, depending on the structure of the network, one or more value transitions can
occur. The networks in Figures 1 and 2 each have three layers (i.e. plan periods) and their
structure allows values to persist or change exactly once per period. The layers are used to
solve the planning problem incrementally. That is, we start with one layer in each network
and try to solve the planning problem. If no plan is found, all networks are extended by
one extra layer and a new attempt is made to solve the planning problem. This process is
repeated until a plan is found or a time limit is reached. In Figures 1 and 2, a path (i.e.
218

Loosely Coupled Formulations for Automated Planning

loc1

truck-at-loc1

loc2

T

Load at loc1

F
truck-at-loc2

T

T

-

T

T

Drive loc1â†’loc2

-

T

F

T

T

-

T

T

Unload at loc2

-

F

T

T
F

-

T
F

Unload at loc2

F

T

T
F

F

F
Load at loc1

-

F
-

F

F
pack-in-truck

T

T
F

F
Load at loc1

F
pack-at-loc2

Drive loc1â†’loc2

F

F
pack-at-loc1

T

T
F

Unload at loc2

F

T
F

Figure 1: Logistics example broken up into five components (binary-valued state variables)
that are represented by network flow problems.

truck-location

1

Load at loc1

2
pack-location

1

1

Drive loc1â†’loc2

2
Load at loc1

1

1

Unload at loc2

2
-

1

1
2

Unload at loc2

1

2

2

2

2

t

t

t

t

Figure 2: Logistics example broken up into two components (multi-valued state variables)
that are represented by network flow problems.

a solution) from the source node to one of the sink nodes is highlighted in each network.
Since the execution of an action triggers value transitions in the state variables, each path
in a network corresponds to a sequence of actions. Consequently, the planning problem
can be thought of as a collection of network flow problems where the problem is to find a
path (i.e. a sequence of actions) in each of the networks. However, interactions between
219

Van den Briel, Vossen & Kambhampati

the networks impose side constraints on the network flow problems, which complicate the
solution process.
1.3 The Merging Process
We solve these loosely coupled networks using integer programming formulations. One
design choice we make is that we expand all networks (i.e. components) together, so the
cost of finding solutions for the individual networks as well as merging them depends on the
difficulty of solving the integer programming formulation. This, in turn, typically depends
on the size of the integer programming formulation, which is partly determined by the
number of layers in each of the networks. The simplest idea is to have the number of
layers of the networks equal the length of the plan, just as in sequential planning where the
plan length equals the number of actions in the plan. In this case, there will be as many
transitions in the networks as there are actions in the plan, with the only difference that a
sequence of actions corresponding to a path in a network could contain no-op actions.
An idea to reduce the required number of layers is by allowing multiple actions to be
executed in the same plan period. This is exactly what is done in Graphplan (Blum & Furst,
1995) and in other planners that have adopted the Graphplan-style definition of parallelism.
That is, two actions can be executed in parallel (i.e. in the same plan period) as long as
they are non-interfering. In our formulations we adopt more general notions of parallelism.
In particular, we relax the strict relation between the number of layers in the networks
and the length of the plan by changing the network representation of the state variables.
For example, by allowing multiple transitions in each network per plan period we permit
interfering actions to be executed in the same plan period. This, however, raises issues
about how solutions to the individual networks are searched and how they are combined.
When the network representations for the state variables allow multiple transitions in each
network per plan period, and thus become more flexible, it becomes harder to merge the
solutions into a feasible plan. Therefore, to evaluate the tradeoffs in allowing such flexible
representations, we look at a variety of integer programming formulations.
We refer to the integer programming formulation that uses the network representation
shown in Figures 1 and 2 as the one state change model, because it allows at most one
transition (i.e. state change) per plan period in each state variable. Note that in this network
representation a plan period mimics the Graphplan-style parallelism. That is, two actions
can be executed in the same plan period if one action does not delete the precondition or
add-effect of the other action. A more flexible representation in which values can change at
most once and persist before and after each change we refer to as the generalized one state
change model. Clearly, we can increase the number of changes that we allow in each plan
period. The representations in which values can change at most twice or k times, we refer
to as the generalized two state change and the generalized k state change model respectively.
One disadvantage with the generalized k state change model is that it creates one variable
for each way to do k value changes, and thus introduces exponentially many variables per
plan period. Therefore, another network representation that we consider allows a path of
value transitions in which each value can be visited at most once per plan period. This
way, we can limit the number of variables, but may introduce cycles in our networks. The
220

Loosely Coupled Formulations for Automated Planning

integer programming formulation that uses this representation is referred to as the state
change path model.
In general, by allowing multiple transitions in each network per plan period (i.e. layer),
the more complex the merging process becomes. In particular, the merging process checks
whether the actions in the solutions of the individual networks can be linearized into a
feasible plan. In our integer programming formulations, ordering constraints ensure feasible
linearizations. There may, however, be exponentially many ordering constraints when we
generalize the Graphplan-style parallelism. Rather than inserting all these constraints in the
integer programming formulation up front, we add them as needed using a branch-and-cut
algorithm. A branch-and-cut algorithm is a branch-and-bound algorithm in which certain
constraints are generated dynamically throughout the branch-and-bound tree.
We show that the performance of our integer programming (IP) formulations show new
potential and are competitive with SATPLAN04 (Kautz, 2004). This is a significant result
because it forms a basis for other more sophisticated IP-based planning systems capable of
handling numeric constraints and non-uniform action costs. In particular, the new potential
of our IP formulations has led to their successful use in solving partial satisfaction planning
problems (Do, Benton, van den Briel, & Kambhampati, 2007). Moreover, it has initiated a
new line of work in which integer and linear programming are used in heuristic state-space
search for automated planning (Benton, van den Briel, & Kambhampati, 2007; van den
Briel, Benton, Kambhampati, & Vossen, 2007).
The remainder of this paper is organized as follows. In Section 2 we provide a brief
background on integer programming and discuss some approaches that have used integer
programming to solve planning problems. In Section 3 we present a series of integer programming formulations that each adopt a different network representation. We describe how
we set up these loosely coupled networks, provide the corresponding integer programming
formulation, and discuss the different variables and constraints. In Section 4 we describe
the branch-and-cut algorithm that is used for solving these formulations. We provide a
general background on the branch-and-cut concept and show how we apply it to our formulations by means of an example. Section 5 provides experimental results to determine
which characteristics in our approach have the greatest impact on performance. Related
work is discussed in Section 6 and some conclusions are given in Section 7.

2. Background
Since our formulations are based on integer programming, we briefly review this technique
and discuss its use in planning. A mixed integer program is represented by a linear objective
function and a set of linear inequalities:
min{cx : Ax â‰¥ b, x1 , ..., xp â‰¥ 0 and integer, xp+1 , ..., xn â‰¥ 0},
where A is an (m Ã— n) matrix, c is an n-dimensional row vector, b is an m-dimensional
column vector, and x an n-dimensional column vector of variables. If all variables are
continuous (p = 0) we have a linear program, if all variables are integer (p = n) we have
an integer program, and if x1 , ..., xp âˆˆ {0, 1} we have a mixed 0-1 program. The set S =
{x1 , ..., xp â‰¥ 0 and integer, xp+1 , ..., xn â‰¥ 0 : Ax â‰¥ b} is called the feasible region, and an
n-dimensional column vector x is called a feasible solution if x âˆˆ S. Moreover, the function
221

Van den Briel, Vossen & Kambhampati

cx is called the objective function, and the feasible solution xâˆ— is called an optimal solution
if the objective function is as small as possible, that is, cxâˆ— = min{cx : x âˆˆ S}
Mixed integer programming provides a rich modeling formalism that is more general than
propositional logic. Any propositional clause can be represented by one linear inequality in
0-1 variables, but a single linear inequality in 0-1 variables may require exponentially many
clauses (Hooker, 1988).
The most widely used method for solving (mixed) integer programs is by applying a
branch-and-bound algorithm to the linear programming relaxation, which is much easier
to solve2 . The linear programming (LP) relaxation is a linear program obtained from the
original (mixed) integer program by relaxing the integrality constraints:
min{cx : Ax â‰¥ b, x1 , ..., xn â‰¥ 0}
Generally, the LP relaxation is solved at every node in the branch-and-bound tree, until
(1) the LP relaxation gives an integer solution, (2) the LP relaxation value is inferior to the
current best feasible solution, or (3) the LP relaxation is infeasible, which implies that the
corresponding (mixed) integer program is infeasible.
An ideal formulation of an integer program is one for which the solution of the linear programming relaxation is integral. Even though every integer program has an ideal
formulation (Wolsey, 1998), in practice it is very hard to characterize the ideal formulation as it may require an exponential number of inequalities. In problems where the ideal
formulation cannot be determined, it is often desirable to find a strong formulation of
the integer program. Suppose that the feasible regions P1 = {x âˆˆ Rn : A1 x â‰¥ b1 } and
P2 = {x âˆˆ Rn : A2 x â‰¥ b2 } describe the linear programming relaxations of two IP formulations of a problem. Then we say that formulation for P1 is stronger than formulation for P2
if P1 âŠ‚ P2 . That is, the feasible region P1 is subsumed by the feasible region P2 . In other
words P1 improves the quality of the linear relaxation of P2 by removing fractional extreme
points.
There exist numerous powerful software packages that solve mixed integer programs. In
our experiments we make use of the commercial solver CPLEX 10.0 (Inc., 2002), which is
currently one of the best LP/IP solvers.
The use of integer programming techniques to solve artificial intelligence planning problems has an intuitive appeal, especially given the success IP has had in solving similar types
of problems. For example, IP has been used extensively for solving problems in transportation, logistics, and manufacturing. Examples include crew scheduling, vehicle routing, and
production planning problems (Johnson, Nemhauser, & Savelsbergh, 2000). One potential
advantage is that IP techniques can provide a natural way to incorporate several important
aspects of real-world planning problems, such as numeric constraints and objective functions
involving costs and utilities.
Planning as integer programming has, nevertheless, received only limited attention. One
of the first approaches is described by Bylander (1997), who proposes an LP heuristic for
partial order planning algorithms. While the LP heuristic helps to reduce the number of
expanded nodes, the evaluation is rather time-consuming. In general, the performance of
2. While the integer programming problem is N P -complete (Garey & Johnson, 1979) the linear programming problem is polynomially solvable (Karmarkar, 1984).

222

Loosely Coupled Formulations for Automated Planning

IP often depends on the structure of the problem and on how the problem is formulated.
The importance of developing strong IP formulations is discussed by Vossen et al. (1999),
who compare two formulations for classical planning: (1) a straightforward formulation
based on the conversion of the propositional representation by SATPLAN which yields
only mediocre results, and (2) a less intuitive formulation based on the representation of
state transitions which leads to considerable performance improvements. Several ideas that
further improve formulation based on the representation of state transitions are described by
Dimopoulos (2001). Some of these ideas are implemented in the IP-based planner Optiplan
(van den Briel & Kambhampati, 2005). Approaches that rely on domain-specific knowledge
are proposed by Bockmayr and Dimopoulos (1998, 1999). By exploiting the structure of
the planning problem these IP formulations often provide encouraging results. The use of
LP and IP has also been explored for non-classical planning. Dimopoulos and Gerevini
(2002) describe an IP formulation for temporal planning and Wolfman and Weld (1999)
use LP formulations in combination with a satisfiability-based planner to solve resource
planning problems. Kautz and Walser (1999) also solve resource planning problems, but
use domain-specific IP formulations.

3. Formulations
This section describes four IP formulations that model the planning problem as a collection
of loosely coupled network flow problems. Each network represents a state variable, in which
the nodes correspond to the state variable values, and the arcs correspond to the value
transitions. The state variables are based on the SAS+ planning formalism (BaÌˆckstroÌˆm &
Nebel, 1995), which is a planning formalism that uses multi-valued state variables instead
of binary-valued atoms. An action in SAS+ is modeled by its pre-, post- and prevailconditions. The pre- and post-conditions express which state variables are changed and
what values they must have before and after the execution of the action, and the prevailconditions specify which of the unchanged variables must have some specific value before
and during the execution of an action. A SAS+ planning problem is described by a tuple
Î  = hC, A, s0 , sâˆ— i where:
â€¢ C = {c1 , ..., cn } is a finite set of state variables, where each state variable c âˆˆ C has an
associated domain Vc and an implicitly defined extended domain Vc+ = Vc âˆª{u}, where
u denotes the undefined value. For each state variable c âˆˆ C, s[c] denotes the value of
c in state s. The value of c is said to be defined in state s if and only if s[c] 6= u. The
total state space S = Vc1 Ã— ... Ã— Vcn and the partial state space S + = Vc+1 Ã— ... Ã— Vc+n
are implicitly defined.
â€¢ A is a finite set of actions of the form hpre, post, previ, where pre denotes the preconditions, post denotes the post-conditions, and prev denotes the prevail-conditions.
For each action a âˆˆ A, pre[c], post[c] and prev[c] denotes the respective conditions on
state variable c. The following two restrictions are imposed on all actions: (1) Once
the value of a state variable is defined, it can never become undefined. Hence, for all
c âˆˆ C, if pre[c] 6= u then pre[c] 6= post[c] 6= u; (2) A prevail- and post-condition of
an action can never define a value on the same state variable. Hence, for all c âˆˆ C,
either post[c] = u or prev[c] = u or both.
223

Van den Briel, Vossen & Kambhampati

â€¢ s0 âˆˆ S denotes the initial state and sâˆ— âˆˆ S + denotes the goal state. While SAS+
planning allows the initial state and goal state to be both partial states, we assume
that s0 is a total state and sâˆ— is a partial state. We say that state s is satisfied by
state t if and only if for all c âˆˆ C we have s[c] = u or s[c] = t[c]. This implies that if
sâˆ— [c] = u for state variable c, then any defined value f âˆˆ Vc satisfies the goal for c.
To obtain a SAS+ description of the planning problem we use the translator component
of the Fast Downward planner (Helmert, 2006). The translator is a stand-alone component
that contains a general purpose algorithm which transforms a propositional description
of the planning problem into a SAS+ description. The algorithm provides an efficient
grounding that minimizes the state description length and is based on the preprocessing
algorithm of the MIPS planner (Edelkamp & Helmert, 1999).
In the remainder of this section we introduce some notation and describe our IP formulations. The formulations are presented in such a way that they progressively generalize the
Graphplan-style parallelism through the incorporation of more flexible network representations. For each formulation we will describe the underlying network, and define the variables
and constraints. We will not concentrate on the objective function as much because the
constraints will tolerate only feasible plans.
3.1 Notation
For the formulations that are described in this paper we assume that the following information is given:
â€¢ C: a set of state variables;
â€¢ Vc : a set of possible values (i.e. domain) for each state variable c âˆˆ C;
â€¢ Ec : a set of possible value transitions for each state variable c âˆˆ C;
â€¢ Gc = (Vc , Ec ) : a directed domain transition graph for every c âˆˆ C;
State variables can be represented by a domain transition graph, where the nodes correspond
to the possible values, and the arcs correspond to the possible value transitions. An example
of the domain transition graph of a variable is given in Figure 3. While the example depicts
a complete graph, a domain transition graph does not need to be a complete graph.
Furthermore, we assume as given:
â€¢ Eca âŠ† Ec represents the effect of action a in c;
â€¢ Vca âŠ† Vc represents the prevail condition of action a in c;
a
E
â€¢ AE
c := {a âˆˆ A : |Ec | > 0} represents the actions that have an effect in c, and Ac (e)
represents the actions that have the effect e in c;

â€¢ AVc := {a âˆˆ A : |Vca | > 0} represents the actions that have a prevail condition in c,
and AVc (f ) represents the actions that have the prevail condition f in c;
V
â€¢ C a := {c âˆˆ C : a âˆˆ AE
c âˆª Ac } represents the state variables on which action a has an
effect or a prevail condition.

224

Loosely Coupled Formulations for Automated Planning

f

g

h
Figure 3: An example of a domain transition graph, where Vc = {f, g, h} are the possible
values (states) of c and Ec = {(f, g), (f, h), (g, f ), (g, h), (h, f ), (h, g)} are the
possible value transitions in c.

Hence, each action is defined by its effects (i.e. pre- and post-conditions) and its prevail
conditions. In SAS+ planning, actions can have at most one effect or prevail condition in
each state variable. In other words, for each a âˆˆ A and c âˆˆ C, we have that Eca and Vca are
empty or |Eca | + |Vca | â‰¤ 1. An example of how the effects and prevail conditions affect one
or more domain transition graphs is given in Figure 4.

f

f

f

g

g

g

h

h

h

Figure 4: An example of how action effects and prevail conditions are represented in a
domain transition graph. Action a has implications on three state variables C a =
{c1 , c2 , c3 }. The effects of a are represented by Eca1 = {(f, g)} and Eca2 = {(h, f )},
and the prevail condition of a is represented by Vca3 = {h}.
In addition, we use the following notation:
â€¢ Vc+ (f ): to denote the in-arcs of node f in the domain transition graph Gc ;
â€¢ Vcâˆ’ (f ): to denote the out-arcs of node f in the domain transition graph Gc ;
+
â€¢ Pc,k
(f ): to denote paths of length k in the domain transition graph Gc that end at
+
node f . Note that Pc,1
(f ) = Vc+ (f ).
âˆ’
â€¢ Pc,k
(f ): to denote paths of length k in the domain transition graph Gc that start at
âˆ’
node f . Note that Pc,1
(f ) = Vcâˆ’ (f ).

225

Van den Briel, Vossen & Kambhampati

âˆ¼ (f ): to denote paths of length k in the domain transition graph G that visit node
â€¢ Pc,k
c
f , but that do not start or end at f .

3.2 One State Change (1SC) Formulation
Our first IP formulation incorporates the network representation that we have seen in
Figures 1 and 2. The name one state change relates to the number of transitions that we
allow in each state variable per plan period. The restriction of allowing only one value
transition in each network also restricts which actions we can execute in the same plan
period. It happens to be the case that the network representation of the 1SC formulation
incorporates the standard notion of action parallelism which is used in Graphplan (Blum
& Furst, 1995). The idea is that actions can be executed in the same plan period as long
as they do not delete the precondition or add-effect of another action. In terms of value
transitions in state variables, this is saying that actions can be executed in the same plan
period as long as they do not change the same state variable (i.e. there is only one value
change or value persistence in each state variable).
3.2.1 State Change Network
Figure 5 shows a single layer (i.e. period) of the network which underlies the 1SC formulation. If we set up the IP formulation with T plan periods, then there will be T + 1 layers
of nodes and T layers of arcs in the network (the zeroth layer of nodes is for the initial
state and the remaining T layers of nodes and arcs are for the successive plan periods). For
each possible state transition there is an arc in the state change network. The horizontal
arcs correspond to the persistence of a value, and the diagonal arcs correspond to the value
changes. A solution path to an individual network follows the arcs whose transitions are
supported by the action effect and prevail conditions that appear in the solution plan.
1SC network
f

f

g

g

h

h

Period t

Figure 5: One state change (1SC) network.

3.2.2 Variables
We have two types of variables in this formulation: action variables to represent the execution of an action, and arc flow variables to represent the state transitions in each network.
226

Loosely Coupled Formulations for Automated Planning

We use separate variables for changes in a state variable (the diagonal arcs in the 1SC
network) and for the persistence of a value in a state variable (the horizontal arcs in the
1SC network). The variables are defined as follows:
â€¢ xat âˆˆ {0, 1}, for a âˆˆ A, 1 â‰¤ t â‰¤ T ; xat is equal to 1 if action a is executed at plan period
t, and 0 otherwise.
â€¢ yÌ„c,f,t âˆˆ {0, 1}, for c âˆˆ C, f âˆˆ Vc , 1 â‰¤ t â‰¤ T ; yÌ„c,f,t is equal to 1 if the value f of state
variable c persists at period t, and 0 otherwise.
â€¢ yc,e,t âˆˆ {0, 1}, for c âˆˆ C, e âˆˆ Ec , 1 â‰¤ t â‰¤ T ; yc,e,t is equal to 1 if the transition e âˆˆ Ec
in state variable c is executed at period t, and 0 otherwise.

3.2.3 Constraints
There are two classes of constraints. We have constraints for the network flows in each
state variable network and constraints for the action effects that determine the interactions
between these networks. The 1SC integer programming formulation is:
â€¢ State change flows for all c âˆˆ C, f âˆˆ Vc

X
1 if f = s0 [c]
yc,e,1 + yÌ„c,f,1 =
0 otherwise.
âˆ’

(1)

eâˆˆVc (f )

X

X

yc,e,t+1 + yÌ„c,f,t+1 =

X

yc,e,t + yÌ„c,f,t

for 1 â‰¤ t â‰¤ T âˆ’ 1

(2)

eâˆˆVc+ (f )

eâˆˆVcâˆ’ (f )

yc,e,T + yÌ„c,f,T

= 1

if f = sâˆ— [c]

(3)

eâˆˆVc+ (f )

â€¢ Action implications for all c âˆˆ C, 1 â‰¤ t â‰¤ T
X
xat = yc,e,t for e âˆˆ Ec

(4)

aâˆˆA:eâˆˆEca

xat â‰¤ yÌ„c,f,t

for a âˆˆ A, f âˆˆ Vca

(5)

Constraints (1), (2), and (3) are the network flow constraints for state variable c âˆˆ C.
Constraint (1) ensures that the path of state transitions begins in the initial state of the
state variable and constraint (3) ensures that, if a goal exists, the path ends in the goal
state of the state variable. Note that, if the goal value for state variable c is undefined
(i.e. sâˆ— [c] = u) then the path of state transitions may end in any of the values f âˆˆ Vc .
Hence, we do not need a goal constraint for the state variables whose goal states sâˆ— [c] are
undefined. Constraint (2) is the flow conservation equation and enforces the continuity of
the constructed path.
Actions may introduce interactions between the state variables. For instance, the effects
of the load action in our logistics example affect two different state variables. Actions link
state variables to each other and these interactions are represented by the action implication
227

Van den Briel, Vossen & Kambhampati

constraints. For each transition e âˆˆ Ec , constraints (4) link the action execution variables
that have e as an effect (i.e. e âˆˆ Eca ) to the arc flow variables. For example, if an action
xat with effect e âˆˆ Eca is executed, then the path in state variable c must follow the arc
represented by yc,e,t. Likewise, if we choose to follow the arc represented by yc,e,t, then
exactly one action xat with e âˆˆ Eca must be executed. The summation on the left hand side
prevents two or more actions from interfering with each other, hence only one action may
cause the state change e in state variable c at period t.
Prevail conditions of an action link state variables in a similar way as the action effects
do. Specifically, constraint (5) states that if action a is executed at period t (xat = 1), then
the prevail condition f âˆˆ Vca is required in state variable c at period t (yÌ„c,f,t = 1).
3.3 Generalized One State Change (G1SC) Formulation
In our second formulation we incorporate the same network representation as in the 1SC
formulation, but adopt a more general interpretation of the value transitions, which leads
to an unconventional notion of action parallelism. For the G1SC formulation we relax the
condition that parallel actions can be arranged in any order by requiring a weaker condition.
We allow actions to be executed in the same plan period as long as there exists some ordering
that is feasible. More specifically, within a plan period a set of actions is feasible if (1) there
exists an ordering of the actions such that all preconditions are satisfied, and (2) there is
at most one state change in each of the state variables. This generalization of conditions
is similar to what Rintanen, Heljanko and NiemelaÌˆ (2006) refer to as the âˆƒ-step semantics
semantics.
To illustrate the basic concept, let us again examine our small logistics example introduced in Figure 1. The solution to this problem is to load the package at location 1, drive the
truck from location 1 to location 2, and unload the package at location 2. Clearly, this plan
would require three plan periods under Graphplan-style parallelism as these three actions
interfere with each other. If, however, we allow the load at loc1 and the drive loc1 â†’ loc2
action to be executed in the same plan period, then there exists some ordering between
these two actions that is feasible, namely load the package at the location 1 before driving
the truck to location 2. The key idea behind this example should be clear: while it may
not be possible to find a set of actions that can be linearized in any order, there may nevertheless exist some ordering of the actions that is viable. The question is, of course, how
to incorporate this idea into an IP formulation.

truck-location

1

Load at loc1
Drive loc1â†’loc2

2
pack-location

1

1

Unload at loc2

2
Load at loc1

1

1
2

Unload at loc2

1

2

2

2

t

t

t

Figure 6: Logistics example represented by network flow problems with generalized arcs.
228

Loosely Coupled Formulations for Automated Planning

This example illustrates that we are looking for a set of constraints that allow sets of
actions for which: (1) all action preconditions are met, (2) there exists an ordering of the
actions at each plan period that is feasible, and (3) within each state variable, the value is
changed at most once. The incorporation of these ideas only requires minor modifications
to the 1SC formulation. Specifically, we need to change the action implication constraints
for the prevail conditions and add a new set of constraints which we call the ordering
implication constraints.
3.3.1 State Change Network
The minor modifications are revealed in the G1SC network. While the network itself is
identical to the 1SC network, the interpretation of the transition arcs is somewhat different.
To incorporate the new set of conditions, we implicitly allow values to persist (the dashed
horizontal arcs in the G1SC network) at the tail and head of each transition arc. The
interpretation of these implicit arcs is that in each plan period a value may be required as
a prevail condition, then the value may change, and the new value may also be required as
a prevail condition as shown in Figure 7.
G1SC network

Generalized state change arc

f

f

f

f

g

g

g

g

h

h

h

h

Period t

Period t

Figure 7: Generalized one state change (G1SC) network.

3.3.2 Variables
Since the G1SC network is similar to the 1SC network the same variables are used, thus,
action variables to represent the execution of an action, and arc flow variables to represent
the flow through each network. The difference in the interpretation of the state change arcs
is dealt with in the constraints of the G1SC formulation, and therefore does not introduce
any new variables. For the variable definitions, we refer to Section 3.2.2.
3.3.3 Constraints
We now have three classes of constraints, that is, constraints for the network flows in each
state variable network, constraints for linking the flows with the action effects and prevail
conditions, and ordering constraints to ensure that the actions in the plan can be linearized
into a feasible ordering.
229

Van den Briel, Vossen & Kambhampati

The network flow constraints for the G1SC formulation are identical to those in the 1SC
formulation given by (1)-(3). Moreover, the constraints that link the flows with the action
effects are equal to the action effect constraints in the 1SC formulation given by (4). The
G1SC formulation differs from the 1SC formulation in that it relaxes the condition that
parallel actions can be arranged in any order by requiring a weaker condition. This weaker
condition affects the constraints that link the flows with the action prevail conditions, and
introduces a new set of ordering constraints. These constraints of the G1SC formulation
are given as follows:
â€¢ Action implications for all c âˆˆ C, 1 â‰¤ t â‰¤ T
X
X
xat â‰¤ yÌ„c,f,t +
yc,e,t +
eâˆˆVc+ (f )

â€¢ Ordering implications
X

yc,e,t

for a âˆˆ A, f âˆˆ Vca

(6)

eâˆˆVcâˆ’ (f )

xat â‰¤ |V (âˆ†)| âˆ’ 1 for all cycles âˆ† âˆˆ Gprec

(7)

aâˆˆV (âˆ†)

Constraint (6) incorporates this new set of conditions for which actions can be executed
in the same plan period. In particular, we need to ensure that for each state variable c, the
value f âˆˆ Vc holds if it is required by the prevail condition of action a at plan period t. There
are three possibilities: (1) The value f holds for c throughout the period. (2) The value f
holds initially for c, but the value is changed to a value other than f by another action. (3)
The value f does not hold initially for c, but the value is changed to f by another action.
In either of the three cases the value f holds at some point in period t so that the prevail
condition for action a can be satisfied. In words, the value f may prevail implicitly as long
as there is a state change that includes f . As before, the prevail implication constraints
link the action prevail conditions to the corresponding network arcs.
The action implication constraints ensure that the preconditions of the actions in the
plan are satisfied. This, however, does not guarantee that the actions can be linearized
into a feasible order. Figure 7 indicates that there are implied orderings between actions.
Actions that require the value f as a prevail condition must be executed before the action
that changes f into g. Likewise, an action that changes f into g must be executed before
actions that require the value g as a prevail condition. The state change flow and action
implication constraints outlined above indicate that there is an ordering between the actions,
but this ordering could be cyclic and therefore infeasible. To make sure that an ordering
is acyclic we start by creating a directed implied precedence graph Gprec = (V prec , E prec ).
In this graph the nodes a âˆˆ V prec correspond to the actions, that is, V prec = A, and we
create a directed arc (i.e. an ordering) between two nodes (a, b) âˆˆ E prec if action a has to be
executed before action b in time period t, or if b has to be executed after a. In particular,
we have
[
[
E prec =
(a, b) âˆª
(a, b)
(a,b)âˆˆAÃ—A,câˆˆC,f âˆˆVca ,eâˆˆEcb :
âˆ’
eâˆˆVc,f

230

(a,b)âˆˆAÃ—A,câˆˆC,gâˆˆVcb ,eâˆˆEca :
+
eâˆˆVc,g

Loosely Coupled Formulations for Automated Planning

The implied orderings become immediately clear from Figure 8. The figure on the left
depicts the first set of orderings in the expression of E prec . It says that the ordering between
two actions a and b that are executed in the same plan period is implied if action a requires
a value to prevail that action b deletes. Similarly, the figure on the right depicts second set
of orderings in the expression of E prec . That is, an ordering is implied if action a adds the
prevail condition of b.
f

a

f

f

b

f

a

g

g

g

h

h

h

b

g

h

Figure 8: Implied orderings for the G1SC formulation.
The ordering implication constraints ensure that the actions in the final solution can be
linearized. They basically involve putting an n-ary mutex relation between the actions that
are involved in each cycle. Unfortunately, the number of ordering implication constraints
grows exponentially in the number of actions. As a result, it will be impossible to solve
the resulting formulation using standard approaches. We address this complication by
implementing a branch-and-cut approach in which the ordering implication constraints are
added dynamically to the formulation. This approach is discussed in Section 4.
3.4 Generalized k State Change (GkSC) Formulation
In the G1SC formulation actions can be executed in the same plan period if (1) there exists
an ordering of the actions such that all preconditions are satisfied, and (2) there occurs at
most one value change in each of the state variables. One obvious generalization of this
would be to relax the second condition and allow at most kc value changes in each state
variable c, where kc â‰¤ |Vc | âˆ’ 1. By allowing multiple value changes in a state variable per
plan period we, in fact, permit a series of value changes. Specifically, the GkSC model
allows series of value changes.
Obviously, there is a tradeoff between loosening the networks versus the amount of
work it takes to merge the individual plans. While we have not implemented the GkSC
formulation, we provide some insight in this tradeoff by describing and evaluating the GkSC
formulation with kc = 2 for all c âˆˆ C We will refer to this special case as the generalized
two state change (G2SC) formulation. One reason we restrict ourselves to this special case
is that the general case of k state changes would introduce exponentially many variables
in the formulation. There are IP techniques, however, that deal with exponentially many
variables (Desaulniers, Desrosiers, & Solomon, 2005), but we will not discuss them here.
3.4.1 State Change Network
The network that underlies the G2SC formulation is equivalent to G1SC, but spans an extra
layer of nodes and arcs. This extra layer allows us to have a series of two transitions per plan
231

Van den Briel, Vossen & Kambhampati

period. All transitions are generalized and implicitly allow values to persist just as in the
G1SC network. Figure 9 displays the network corresponding to the G2SC formulation. In
the G2SC network there are generalized one and two state change arcs. For example, there
is a generalized one state change arc for the transition (f, g), and there is a generalized two
state changes arc for the transitions {(f, g), (g, h)}. Since all arcs are generalized, each value
that is visited can also be persisted. We also allow cyclic transitions, such as, {(f, g), (g, f )}
if f is not the prevail condition of some action. If we were to allow cyclic transitions in
which f is a prevail condition of an action, then the action ordering in a plan period can not
be implied anymore (i.e. the prevail condition on f would either have to occur before the
value transitions to g, or after it transitions back to f ). Thus if there is no prevail condition
on f then we can safely allow the cyclic transition {(f, g), (g, f )}.
1 state change arcs

2 state changes arcs

f

f

f

f
f

f

g

g

g

g
g

g

h

h

h

h
h

h

Period t

Period t

Figure 9: Generalized two state change (G2SC) network. On the left the subnetwork that
consists of generalized one state change arcs and no-op arcs, on the right the subnetwork that consists of the generalized two state change arcs. The subnetwork
for the two state change arcs may include cyclic transitions, such as, {(f, g), (g, f )}
as long as f is not the prevail condition of some action.

3.4.2 Variables
As before we have variables representing the execution of an action, and variables representing the flows over one state change (diagonal arcs) or persistence (horizontal arcs). In
addition, we have variables representing paths over two consecutive state changes. Hence,
we have variables for each pair of state changes (f, g, h) such that (f, g) âˆˆ Ec and (g, h) âˆˆ Ec .
We will restrict these paths to visit unique values only, that is, f 6= g, g 6= h, and h 6= f ,
or if f is not a prevail condition of any action then we also allow paths where f = h. The
variables from the G1SC formulation are also used in G2SC formulation. There is, however,
an additional variable to represent the arcs that allow for two state changes:
â€¢ yc,e1,e2 ,t âˆˆ {0, 1}, for c âˆˆ C, (e1 , e2 ) âˆˆ Pc,2 , 1 â‰¤ t â‰¤ T ; yc,e1,e2 ,t is equal to 1 if
there exists a value f âˆˆ Vc and transitions e1 , e2 âˆˆ Ec , such that e1 âˆˆ Vc+ (f ) and
e2 âˆˆ Vcâˆ’ (f ), in state variable c are executed at period t, and 0 otherwise.
232

Loosely Coupled Formulations for Automated Planning

3.4.3 Constraints
We again have our three classes of constraints, which are given as follows:
â€¢ State change flows for all c âˆˆ C, f âˆˆ Vc
X

yc,e1,e2 ,1 +

âˆ’
(e1 ,e2 )âˆˆPc,2
(f )

X

X

yc,e,1 + yÌ„c,f,1 =

eâˆˆVcâˆ’ (f )

yc,e1,e2 ,t+1 +

âˆ’
(e1 ,e2 )âˆˆPc,2
(f )

X



1
0

if f = s0 [c]
otherwise.

(8)

for 1 â‰¤ t â‰¤ T âˆ’ 1

(9)

yc,e,t+1 + yÌ„c,f,t+1 =

eâˆˆVcâˆ’ (f )

X

+
(e1 ,e2 )âˆˆPc,2
(f )

X

X

yc,e1,e2 ,t +

yc,e,t + yÌ„c,f,t

eâˆˆVc+ (f )

yc,e1,e2 ,T +

+
(e1 ,e2 )âˆˆPc,2
(f )

X

yc,e,T + yÌ„c,f,T

= 1 if {f âˆˆ sâˆ— [c]}

(10)

eâˆˆVc+ (f )

â€¢ Action implications for all c âˆˆ C, 1 â‰¤ t â‰¤ T
X
X
xat = yc,e,t +
aâˆˆA:eâˆˆEca

yc,e1,e2 ,t

for e âˆˆ Ec

X

yc,e1,e2 ,t +

(11)

(e1 ,e2 )âˆˆPc,2 :e1 =eâˆ¨e2 =e

xat â‰¤ yÌ„c,f,t +

X

eâˆˆVc+ (f )

X

X

yc,e,t +

eâˆˆVcâˆ’ (f )

X

yc,e1,e2 ,t +

+
(e1 ,e2 )âˆˆPc,2
(f )

â€¢ Ordering implications
X

yc,e,t +

âˆ¼ (f )
(e1 ,e2 )âˆˆPc,2

yc,e1,e2 ,t

for a âˆˆ A, f âˆˆ Vca

(12)

âˆ’
(e1 ,e2 )âˆˆPc,2
(f )

xat â‰¤ |V (âˆ†)| âˆ’ 1 for all cycles âˆ† âˆˆ Gprec

(13)

aâˆˆV (âˆ†)

Constraints (8), (9), and (10) represent the flow constraints for the G2SC network. Constraints (11) and (12) link the action effects and prevail conditions with the corresponding
flows, and constraint 13 ensures that the actions can be linearized into some feasible ordering.
3.5 State Change Path (PathSC) Formulation
There are several ways to generalize the network representation of the G1SC formulation
and loosen the interaction between the networks. The GkSC formulation presented one
generalization that allows up to k transitions in each state variable per plan period. Since
it uses exponentially many variables another way to generalize the network representation
of the G1SC formulation is by requiring that each value can be true at most once per plan
period. To illustrate this idea we consider our logistics example again, but we now use
233

Van den Briel, Vossen & Kambhampati

truck-location

1

Load at loc1
Drive loc1â†’loc2
Unload at loc2

2

pack-location

1

1
2

Load at loc1
Unload at loc2
-

1

2

2

t

t

Figure 10: Logistics example represented by network flow problems that allow a path of
value transitions per plan period such that each value can be true at most once.

a network representation that allows a path of transitions per plan period as depicted in
Figure 10.
Recall that the solution to the logistics example consists of three actions: first load the
package at location 1, then drive the truck from location 1 to location 2, and last unload
the package at location 2. Clearly, this solution would not be allowed within a single plan
period under Graphplan-style parallelism. Moreover, it would also not be allowed within
a single period in the G1SC formulation. The reason for this is that the number of value
changes in the package-location state variable is two. First, it changes from pack-at-loc1 to
pack-in-truck, and then it changes from pack-in-truck to pack-at-loc2. As before, however,
there does exists an ordering of the three actions that is feasible. The key idea behind this
example is to show that we can allow multiple value changes in a single period. If we limit
the value changes in a state variable to simple paths, that is, in one period each value is
visited at most once, then we can still use implied precedences to determine the ordering
restrictions.
3.5.1 State Change Network
In this formulation each value can be true at most once in each plan period, hence the
number of value transitions for each plan period is limited to kc where kc = |Vc | âˆ’ 1 for each
c âˆˆ C. In the PathSC network, nodes appear in layers and correspond to the values of the
state variable. However, each layer now consists of twice as many nodes. If we set up an
IP encoding with a maximum number of plan periods T then there will be T layers. Arcs
within a layer correspond to transitions or to value persistence, and arcs between layers
ensure that all plan periods are connected to each other.
Figure 11 displays a network corresponding to the state variable c with domain Vc =
{f, g, h} that allows multiple transitions per plan period. The arcs pointing rightwards
correspond to the persistence of a value, while the arcs pointing leftwards correspond to the
value changes. If more than one plan period is needed the curved arcs pointing rightwards
234

Loosely Coupled Formulations for Automated Planning

link the layers between two consecutive plan periods. Note that with unit capacity on the
arcs, any path in the network can visit each node at most once.
PathSC network
f

f

g

g

h

h

Period t

Figure 11: Path state change (PathSC) network.
3.5.2 Variables
We now have action execution variables and arc flow variables (as defined in the previous
formulations), and linking variables that connect the networks between two consecutive
time periods. These variables are defined as follows:
â€¢ zc,f,t âˆˆ {0, 1}, for c âˆˆ C, f âˆˆ Vc , 0 â‰¤ t â‰¤ T ; zc,f,t is equal to 1 if the value f of state
variable c is the end value at period t, and 0 otherwise.
3.5.3 Constraints
As in the previous formulations, we have state change flow constraints, action implication
constraints, and ordering implication constraints. The main difference is the underlying
network. The PathSC integer programming formulation is given as follows:
â€¢ State change flows for all c âˆˆ C, f âˆˆ Vc

1 if f = s0 [c]
zc,f,0 =
0 otherwise.
X
yc,e,t + zc,f,tâˆ’1 = yÌ„c,f,t

(14)
(15)

eâˆˆVc+ (f )

yÌ„c,f,t =

X

yc,e,t + zc,f,t

for 1 â‰¤ t â‰¤ T âˆ’ 1

(16)

eâˆˆVcâˆ’ (f )

zc,f,T

= 1 if f âˆˆ sâˆ— [c]

â€¢ Action implications for all c âˆˆ C, 1 â‰¤ t â‰¤ T
X
xat = yc,e,t

(17)

for e âˆˆ Ec

(18)

for f âˆˆ Vca

(19)

aâˆˆA:eâˆˆEca

xat â‰¤ yÌ„c,f,t
235

Van den Briel, Vossen & Kambhampati

â€¢ Ordering implications
X

xat â‰¤ |V (âˆ†)| âˆ’ 1 for all cycles âˆ† âˆˆ Gprec

â€²

(20)

aâˆˆV (âˆ†)

Constraints (14)-(17) are the network flow constraints. For each node, except for the initial
and goal state nodes, they ensure a balance of flow (i.e. flow-in must equal flow-out). The
initial state node has a supply of one unit of flow and the goal state node has a demand of
one unit of flow, which are given by constraints (14) and (17) respectively. The interactions
that actions impose upon different state variables are represented by the action implication
constraints (18) and (19), which have been discussed earlier.
â€²
â€²
â€²
The implied precedence graph for this formulation is given by Gprec = (V prec , E prec ).
It has an extra set of arcs to incorporate the implied precedences that are introduced when
â€²
two actions imply a state change in the same class c âˆˆ C. The nodes a âˆˆ V prec again
â€²
correspond to actions, and there is an arc (a, b) âˆˆ E prec if action a has to be executed
before action b in the same time period, or if b has to be executed after a. More specifically,
we have
E prec

â€²

[

= E prec âˆª

(a, b)

(a,b)âˆˆAÃ—A,câˆˆC,f âˆˆVc ,eâˆˆEca ,eâ€² âˆˆEcb :
eâˆˆVc+ (f )âˆ§eâ€² âˆˆVcâˆ’ (f )

As before, the ordering implication constraints (20) ensure that the actions in the solution plan can be linearized into a feasible ordering.

4. Branch-and-Cut Algorithm
IP problems are usually solved with an LP-based branch-and-bound algorithm. The basic
structure of this technique involves a binary enumeration tree in which branches are pruned
according to bounds provided by the LP relaxation. The root node in the enumeration tree
represents the LP relaxation of the original IP problem and each other node represents a
subproblem that has the same objective function and constraints as the root node except
for some additional bound constraints. Most IP solvers use an LP-based branch-and-bound
algorithm in combination with various preprocessing and probing techniques. In the last
few years there has been significant improvement in the performance of these solvers (Bixby,
2002).
In an LP-based branch-and-bound algorithm, the LP relaxation of the original IP problem (the solution to the root node) will rarely be integer. When some integer variable x
has a fractional solution v we branch to create two new subproblems, such that the bound
constraint x â‰¤ âŒŠvâŒ‹ is added to the left-child node, and x â‰¥ âŒˆvâŒ‰ is added to the right-child
node. This branching process is carried out recursively to expand those subproblems whose
solution remains fractional. Eventually, after enough bounds are placed on the variables, an
integer solution is found. The value of the best integer solution found so far, Z âˆ— , is referred
to as the incumbent and is used for pruning.
236

Loosely Coupled Formulations for Automated Planning

In a minimization problem, branches emanating from nodes whose solution value ZLP is
greater than the current incumbent, Z âˆ— , can never give rise to a better integer solution as
each child node has a smaller feasible region than its parent. Hence, we can safely eliminate
such nodes from further consideration and prune them. Nodes whose feasible region have
been reduced to the empty set, because too many bounds are placed on the variables, can
be pruned as well.
When solving an IP problem with an LP-based branch-and-bound algorithm we must
consider the following two decisions. If several integer variables have a fractional solution,
which variable should we branch on next, and if the branch we are currently working on
is pruned, which subproblem should we solve next? Basic rules include use the â€œmost
fractional variableâ€ rule for branching variable selection and the â€œbest objective valueâ€ rule
for node selection.
For our formulations a standard LP-based branch-and-bound algorithm approach is very
ineffective due to the large number (potentially exponentially many) ordering implication
constraints in the G1SC, G2SC, and PathSC formulations. While it is possible to reduce
the number of constraints by introducing additional variables (Martin, 1991), the resulting
formulations would still be intractable for all but the smallest problem instances. Therefore,
we solve the IP formulations with a so-called branch-and-cut algorithm, which considers the
ordering implication constraints implicitly. A branch-and-cut algorithm is a branch-andbound algorithm in which certain constraints are generated dynamically throughout the
branch-and-bound tree. A flowchart of our branch-and-cut algorithm is given in Figure 12.
If, after solving the LP relaxation, we are unable to prune the node on the basis of the
LP solution, the branch-and-cut algorithm tries to find a violated cut, that is, a constraint
that is valid but not satisfied by the current solution. This is also known as the separation
problem. If one or more violated cuts are found, the constraints are added to the formulation
and the LP is solved again. If none are found, the algorithm creates a branch in the
enumeration tree (if the solution to the current subproblem is fractional) or generates a
feasible solution (if the solution to the current subproblem is integral).
The basic idea of branch-and-cut is to leave out constraints from the LP relaxation
of which there are too many to handle efficiently, and add them to the formulation only
when they become binding at the solution to the current LP. Branch-and-cut algorithms
have successfully been applied in solving hard large-scale optimization problems in a wide
variety of applications including scheduling, routing, graph partitioning, network design,
and facility location problems (Caprara & Fischetti, 1997).
In our branch-and-cut algorithm we can stop as soon as we find the first feasible solution,
or we can implicitly enumerate all nodes (through pruning) and find the optimal solution
for a given objective function. Note that our formulations can only be used to find bounded
length optimal plans. That is, find the optimal plan given a plan period (i.e. a bounded
length). In our experimental results, however, we focus on finding feasible solutions.
4.1 Constraint Generation
At any point during runtime that the cut generator is called we have a solution to the
current LP problem, which consists of the LP relaxation of the original IP problem plus
any added bound constraints and added cuts. In our implementation of the branch-and-cut
237

Van den Briel, Vossen & Kambhampati

START

STOP

Initialize LP
no
yes

LP solver

Feasible?

no

Prune

Nodes found?

Node selection

yes
ZLP > Z*?

yes

no
Cut generator
yes

Cuts found?
no
Integer?

no

Branching

yes
Optimize?

yes

no

Figure 12: Flowchart of our branch-and-cut algorithm. For finding any feasible solution (i.e.
optimize = no) the algorithm stops as soon as the first feasible integer solution
is found. When searching for the optimal solution (i.e. optimize = yes) for the
given formulation we continue until no open nodes are left.

238

Loosely Coupled Formulations for Automated Planning

algorithm, we start with an LP relaxation in which the ordering implication constraints are
omitted. So given a solution to the current LP relaxation, which could be fractional, the
separation problem is to determine whether the solution violates one of the omitted ordering
implication constraints. If so, we identify the violated ordering implication constraints, add
them to the formulation, and resolve the new problem.
4.1.1 Cycle Identification
In the G1SC, G2SC, and PathSC formulations an ordering implication constraint is violated if there is a cycle in the implied precedence graph. Separation problems involving
cycles occur in numerous applications. Probably the best known of its kind is the traveling salesman problem in which subtours (i.e. cycles) are identified and subtour elimination
constraints are added to the current LP. Our algorithm for separating cycles is based on
the one described by Padberg and Rinaldi (1991). We are interested in finding the shortest
cycle in the implied precedence graph, as the shortest cycle cuts off more fractional extreme
points. The general idea behind this approach is as follows:
1. Given a solution to the LP relaxation, determine the subgraph Gt for plan period t
consisting of all the nodes a for which xat > 0.
2. For all the arcs (a, b) âˆˆ Gt , define the weights wa,b := xat + xbt âˆ’ 1.
3. Determine the shortest path distance da,b for all pairs ((a, b) âˆˆ Gt ) based on arc
weights wÌ„a,b := 1 âˆ’ wa,b (for example, using the Floyd-Warshall all-pairs shortest path
algorithm).
4. If da,b âˆ’ wb,a < 0 for some arc (a, b) âˆˆ Gt , there exists a violated cycle constraint.
While the general principles behind branch-and-cut algorithms are rather straightforward, there are a number of algorithmic and implementation issues that may have a significant impact on overall performance. At the heart of these issues is the trade-off between
computation time spent at each node in the enumeration tree and the number of nodes
that are explored. One issue, for example, is to decide when to generate violated cuts.
Another issue is which of the generated cuts (if any) should be added to the LP relaxation,
and whether and when to delete constraints that were added to the LP before. In our
implementation, we have only addressed these issues in a straightforward manner: cuts are
generated at every node in the enumeration tree, the first cut found by the algorithm is
added, and constraints are never deleted from the LP relaxation. However, given the potential of more advanced strategies that has been observed in other applications, we believe
there still may be considerable room for improvement.
4.1.2 Example
In this section we will show the workings of our branch-and-cut algorithm on the G1SC
formulation using a small hypothetical example involving two state variables c1 and c2 , five
actions A1, A2, A3, A4, and A5, and one plan period. In particular we will show how the
cycle detection procedure works and how an ordering implication constraint is generated.
239

Van den Briel, Vossen & Kambhampati

Figure 13 depicts a solution to the current LP of the planning problem. For state variable
c1 we have that actions A1 and A2 have a prevail condition on g, A4 has a prevail condition
on h, and action A3 has an effect that changes g into h. Likewise, for state variable c2 we
have that action A4 has an effect that changes g into f , action A5 changes g into h, and
action A1 has a prevail condition on f . Note that the given solution is fractional. Therefore
some of the action variables have fractional values. In particular, we have xA1 = xA4 = 0.8,
xA5 = 0.2, and xA2 = xA3 = 1. In other words, actions A2 and A3 are fully executed while
actions A1, A4 and A5 are only fractionally executed. Clearly, in automated planning the
fractional execution of an action has no meaning whatsoever, but it is very common that
the LP relaxation of an IP formulation gives a fractional solution. We simply try to show
that we can find a violated cut even when we have a fractional solution. Also, note that the
actions A4 and A5 have interfering effects in c2 . While this would generally be infeasible,
the actions are executed only fractionally, so this is actually a feasible solution to the LP
relaxation of the IP formulation.
State variable 1

State variable 2
A1

f

f

f

f
A4

A1,A2
g

g

g

h

h

g

A3
A4
h

A5

A1 = A4 = 0.8, A2 = A3 = 1

h
A1 = A4 = 0.8, A5 = 0.2

Figure 13: Solution to a small hypothetical planning example. The solution to the current
LP has flows over the indicated paths and executes actions A1, A2, A3, A4, and
A5.
In order to determine whether the actions can be linearized into a feasible ordering we first create the implied precedence graph Gprec = (V prec , E prec ), where we have
V prec = {A1, A2, A3, A4, A5} and E prec = {(A1, A3),(A2, A3),(A3, A4),(A4, A1)}. The ordering (A1, A3), for example, is established by the effects of these actions in state variable
c1 . A1 has a prevail condition g in c1 while A3 changes g to h in c1 , which implies that
A1 must be executed before A3. The other orderings are established in a similar way. The
complete implied precedence graph for this example is given in Figure 14.
The cycle detection algorithm gets the implied precedence graph and the solution to the
current LP as input. Weights for each arc (a, b) âˆˆ E prec are determined by the values of the
action variables in the current solution. We have the LP solution that is given in Figure
13, so in this example we have wA1,A3 = wA3,A4 = 0.8, wA2,A3 = 1, and wA4,A1 = 0.6. The
length of the shortest path from A1 to A4 using weights wÌ„a,b is equal to 0.4 (0.2+0.2). Hence,
we have dA1,A4 = 0.4 and wA4,A1 = 0.6. Since dA1,A4 âˆ’ wA4,A1 < 0, we have a violated cycle
(i.e. violated ordering implication) that includes all actions that are on the shortest path
from A1 to A4 (i.e. A1, A3, and A4, which can be retrieved by the shortest path algorithm).
240

Loosely Coupled Formulations for Automated Planning

A3
A4
This generates the following ordering implication constraint xA1
1 + x1 + x1 â‰¤ 2, which will
be added to the current LP. Note that this ordering constraint is violated by the current
A3
A4
LP solution, as xA1
1 + x1 + x1 = 0.8 + 1 + 0.8 = 2.6. Once the constraint is added to the
LP, the next solution will select a set of actions that does not violate the newly added cut.
This procedure continues until no cuts are violated and the solution is integer.

A1

Implied precedence graph
(0.6,0.4)

(0.8,0.2)

A4

(0.8,0.2)
A3

(1,0)
A2

A5

Figure 14: Implied precedence graph for this example, where the labels show (wa,b , wÌ„a,b ).

5. Experimental Results
The described formulations are based on two key ideas. The first idea is to decompose the
planning problem into several loosely coupled components and represent these components
by an appropriately defined network. The second idea is to reduce the number of plan
periods by adopting different notions of parallelism and use a branch-and-cut algorithm
to dynamically add constraints to the formulation in order to deal with the exponentially
many action ordering constraints in an efficient manner.
To evaluate the tradeoffs of allowing more flexible network representations we compare
the performance of the one state change (1SC) formulation, the generalized one state change
formulation (G1SC), the generalized two state change (G2SC) formulation, and the state
change path (PathSC) formulation. For easy reference, an overview of these formulations
is given in Figure 15.
In our experiments we focus on finding feasible solutions. Note, however, that our
formulations can be used to do bounded length optimal planning. That is, given a plan
period (i.e. a bounded length), find the optimal solution.
5.1 Experimental Setup
To compare and analyze our formulations we use the STRIPS domains from the second
and third international planning competitions (IPC2 and IPC3 respectively). That is,
Blocksworld, Logistics, Miconic, Freecell from IPC2 and Depots, Driverlog, Zenotravel,
Rovers, Satellite, and Freecell from IPC3. We do not compare our formulations on the
STRIPS domains from IPC4 and IPC5 mainly because of a peripheral limitation of the
current implementation of the G2SC and PathSC formulations. In particular, the G2SC
formulation cannot handle operators that change a state variable from an undefined value
to a defined value, and the PathSC formulation cannot handle such operators if the domain
241

Van den Briel, Vossen & Kambhampati

1SC
Each state variable can change or
prevail a value at most once per
plan period.

G1SC
Each state variable can change (and
prevail a value before and after each
change) at most once per plan period.

f

f

f

f

g

g

g

g

h

h

h

h

G2SC
Each state variable can change (and
prevail a value before and after each
change) at most twice per plan
period. Cyclic changes (f, g, f ) are
allowed only if f is not the
prevail condition of some action

PathSC
The state variable can change any
number of times, but each value
can be true at most once per plan
period.

f

f
f

f

f

f

g

g
g

g

g

g

h

h
h

h

h

h

Figure 15: Overview of the 1SC, G1SC, G2SC, and PathSC formulations.

size of the state variable is larger than two. Because of these limitations we could not test
the G2SC formulation on the Miconic, Satellite and Rovers domains, and we could not test
the PathSC formulation on the Satellite domain.
In order to setup our formulations we translate a STRIPS planning problem into a
multi-valued state description using the translator of the Fast Downward planner (Helmert,
2006). Each formulation uses its own network representation and starts by setting the
number of plan periods T equal to one. We try to solve this initial formulation and if no
plan is found, T is increased by one, and then try to solve this new formulation. Hence,
the IP formulation is solved repeatedly until the first feasible plan is found or a 30 minute
time limit (the same time limit that is used in the international planning competitions) is
reached. We use CPLEX 10.0 (ILOG Inc., 2002), a commercial LP/IP solver, for solving
the IP formulations on a 2.67GHz Linux machine with 1GB of memory.
We set up our experiments as follows. First, in Section 5.2 we provide a brief overview of
our main results by looking at aggregated results from IPC2 and IPC3. Second, in Section
5.3, we give a more detailed analysis on our loosely coupled encodings for planning and
242

Loosely Coupled Formulations for Automated Planning

focus on the tradeoffs of reducing the number of plan periods to solve a planning problem
versus the increased difficulty in merging the solutions to the different components. Third,
in Section 5.4 we briefly touch upon how different state variable representations of the same
planning problem can influence performance.
5.2 Results Overview
In this general overview we compare our formulations to the following planning systems:
Optiplan (van den Briel & Kambhampati, 2005), SATPLAN04 (Kautz, 2004), SATPLAN06
(Kautz & Selman, 2006), and Satplanner (Rintanen et al., 2006)3 .
Optiplan is an integer programming based planner that participated in the optimal track
of the fourth international planning competition4 . Like our formulations, Optiplan models
state transitions but it does not use a factored representation of the planning domain.
In particular, Optiplan represents state transitions in the atoms of the planning domain,
whereas our formulations use multi-valued state variables. Apart from this, Optiplan is
very similar to the 1SC formulation as they both adopt the Graphplan-style parallelism.
SATPLAN04, SATPLAN06, and Satplanner are satisfiability based planners. SATPLAN04 and SATPLAN06 are versions of the well known system SATPLAN (Kautz &
Selman, 1992), which has a long track record in the international planning competitions.
Satplanner has not received that much attention, but is among the state-of-the-art in planning as satisfiability. Like our formulations Satplanner generalizes the Graphplan-style
parallelism to improve planning efficiency.
The main results are summarized by Figure 16. It displays aggregate results from IPC2
and IPC3, where the number of instances solved (y-axis) is drawn as a function of log time
(x-axis). We must note that the graph with the IPC2 results favors the PathSC formulation
over all other planners. However, as we will see in Section 5.3, this is mainly a reflection
of its exceptional performance in the Miconic domain rather than its overall performance
in IPC2. Morever, the graph with the IPC3 results does not include the Satellite domain.
We decided to remove this domain, because we could not run it on the public versions of
SATPLAN04 and SATPLAN06 nor the G2SC and PathSC formulations. While the results
in Figure 16 provide a rather coarse overview, they sum up the following main findings.
â€¢ Factored planning using loosely coupled formulations helps improve performance. Note
that all integer programming formulations that use factored representations, that is
1SC, G1SC, G2SC, and PathSC (except the G2SC formulation which could not be
3. We note that that SATPLAN04, SATPLAN06, Optiplan, and the 1SC formulation are â€œstep-optimalâ€
while the G1SC, G2SC, and PathSC formulations are not. There is, however, considerable controversy
in the planning community as to whether the step-optimality guaranteed by Graphplan-style planners
has any connection to plan quality metrics that users would be interested in. We refer the reader to
Kambhampati (2006) for a longer discussion of this issue both by us and several prominent researchers
in the planning community. Given this background, we believe it is quite reasonable to compare our formulations to step-optimal approaches, especially since our main aim here is to show that IP formulations
have come a long way and that they can be made competitive with respect to SAT-based encodings.
This in turn makes it worthwhile to consider exploiting other features of IP formulations, such as their
amenability to a variety of optimization objectives as we have done in our recent work (van den Briel
et al., 2007).
4. A list of participating planners and their results is available at http://ipc04.icaps-conference.org/

243

Van den Briel, Vossen & Kambhampati

tested on all domains), are able to solve more problem instances in a given amount
of time than Optiplan, which does not use a factored representation. Especially, the
difference between 1SC and Optiplan is remarkable as they both adopt the Graphplanstyle parallelism. In Section 5.3, however, we will see that Optiplan does perform well
in domains that are either serial by design or have a significant serial component.
â€¢ Decreasing the encoding size by relaxing the Graphplan-style parallelism helps improve
performance. This is not too surprising, Dimopoulos et al. (1997) already note that a
reduction in the number of plan periods helps improve planning performance. However, this does not always hold because of the tradeoff between reducing the number
plan periods versus the increased difficulty in merging the solutions to the different
components. In Section 5.3 we will see that different relaxations of Graphplan-style
parallelism lead to different results. For example, the PathSC formulation shows superior performance in Miconic and Driverlog, but does poorly in Blocksworld, Freecell,
and Zenotravel. Likewise, the G2SC formulation does well in Freecell, but it does not
seem to excel in any other domain.

200

90

180

80

160

Solved intstances (IPC3)

Solved intstances (IPC2)

â€¢ Planning as integer programming shows new potential. The conventional wisdom in
the planning community has been that planning as integer programming cannot compete with planning as satisfiability or constraint satisfaction. In Figure 16, however,
we see that the 1SC, G1SC and PathSC formulation can compete quite well with
SATPLAN04. While SATPLAN04 is not state-of-the-art in planning as satisfiability anymore, it does show that planning as integer programming has come a long
way. The fact that IP is competitive allows us to exploit its other virtues such as
optimization (Do et al., 2007; Benton et al., 2007; van den Briel et al., 2007).

140
120
100
80
60
40
Satplanner
SAT04
G1SC
PathSC

20

SAT06
1SC
G2SC
Optiplan

10

100

60
50
40
30
20
10
0

0
1

70

1000

1

10

100

1000

Solution time (sec)

Solution time (sec)

Figure 16: Aggregate results of the second and third international planning competitions.

5.3 Comparing Loosely Coupled Formulations for Planning
In this section we compare our IP formulations and try to evaluate the benefits of allowing
more flexible network representations. Specifically, we are interested in the effects of reducing the number of plan periods required to solve the planning problem versus dealing with
244

Loosely Coupled Formulations for Automated Planning

merging solutions to the different components. Reducing the number of plan periods can
lead to smaller encodings, which can lead to improved performance. However, it also makes
the merging of the loosely coupled components harder, which could worsen performance.
In order to compare our formulations we will analyze the following two things. First, we
examine the performance of our formulations by comparing their solution times on problem
instances from IPC2 and IPC3. In this comparison we will include results from Optiplan
as it gives us an idea of the differences between a formulation based on Graphplan and
formulations based on loosely coupled components. Moreover, it will also show us the
improvements in IP based approaches for planning. Second, we examine the number of
plan periods that each formulation needs to solve each problem instance. Also, we will look
at the tradeoffs between reducing the number of plan periods and the increased difficulty
in merging the solutions of the loosely coupled components. In this comparison we will
include results from Satplanner because, just like our formulations, it adopts a generalized
notion of the Graphplan-style parallelism.
We use the following figures and table. Figure 17 shows the total solution time (y-axis)
needed to solve the problem instances (x-axis), Figure 18 shows the number of plan periods
(y-axis) to solve the problem instances (x-axis), and Table 1 shows the number of ordering
constraints that were added during the solution process, which can be seen as an indicator
of the merging effort. The selected problem instances in Table 1 represent the five largest
instances that could be solved by all of our formulations (in some domains, however, not
all formulations could solve at least five problem instances).
The label GP steps in Figure 18 represents the number of plan steps that SATPLAN06,
a state-of-the-art Graphplan-based planner, would use. In the Satellite domain, however,
we use the results from the 1SC formulation as we were unable to run the public version
of SATPLAN06 in this domain. We like to point out that Figure 18 is not intended to
favor one formulation over the other, it simply shows that it is possible to generate encodings for automated planning that use drastically fewer plan periods than Graphplan-based
encodings.
5.3.1 Results: Planning Performance
Blocksworld is the only domain in which Optiplan solves more problems than our formulations. In Zenotravel and Satellite, Optiplan is generally outperformed with respect to
solution time, and in Rovers and Freecell, Optiplan is generally outperformed with respect
to the number of problems solved. As for the other IP formulations, the G1SC provides
the overall best performance and the performance of the PathSC formulation is somewhat
irregular. For example, in Miconic, Driverlog and Rovers the PathSC formulation does very
well, but in Depots and Freecell it does rather poorly.
In the Logistics domain all formulations that generalize the Graphplan-style parallelism
(i.e. G1SC, G2SC, and PathSC) scale better than the 1SC formulation and Optiplan, which
adopt the Graphplan-style parallelism. Among G1SC, G2SC, and PathSC formulations
there is no clear best performer, but in the larger Logistics problems the G1SC formulation
seems to do slightly better. The Logistics domain provides a great example of the tradeoff
between flexibility and merging. By allowing more actions to be executed in each plan
period, generally shorter plans (in terms of number of plan periods) are needed to solve
245

Van den Briel, Vossen & Kambhampati

the planning problem (see Figure 18), but at the same time merging the solutions to the
individual components will be harder as one has to respect more ordering constraints (see
Table 1).
Optiplan versus 1SC. If we compare the 1SC formulation with Optiplan, we note
that Optiplan fares well in domains that are either serial by design (Blocksworld) or in
domains that have a significant serial aspect (Depots). We think that Optiplanâ€™s advantage
over the 1SC formulation in these domains is due to the following two possibilities. First,
our intuition is that in serial domains the reachability and relevance analysis in Graphplan is
stronger in detecting infeasible action choices (due to mutex propagation) than the network
flow restrictions in the 1SC formulation. Second, it appears that the state variables in these
domains are more tightly coupled (i.e. the actions have more effects, thus transitions in one
state variable are coupled with several transitions in other state variables) than in most
other domains, which may negatively affect the performance of the 1SC formulation.
1SC versus G1SC. When comparing the 1SC formulation with the G1SC formulation
we can see that in all domains, except in Blocksworld and Miconic, the G1SC formulation
solves at least as many problems as the 1SC formulation. The results in Blocksworld are
not too surprising and can be attributed to semantics of this domain. Each operator in
Blocksworld requires one state change in the state variable of the arm (stack and putdown
change the status of the arm to arm âˆ’ empty, and unstack and pickup change the status
of the arm to holding âˆ’ x where x is the block being lifted). Since, the 1SC and the
G1SC formulations both allow at most one state change in each state variable, there is no
possibility for the G1SC formulation to allow more than one action to be executed in the
same plan period. Given this, one may think that the 1SC and G1SC formulations should
solve at least the same number of problems, but in this case the prevail constraints (5) of
the 1SC formulation are stronger than the prevail constraints (6) of the G1SC formulation.
That is, the right-hand side of (6) subsumes (i.e. allows for a larger feasible region in the LP
relaxation) than the right-hand side of (5). In Figure 17 we can see this slight advantage
of 1SC over G1SC in the Blocksworld domain.
The results in the Miconic domain are, on the other hand, not very intuitive. We
would have expected the G1SC formulation to solve at least as many problems as the 1SC
formulation, but this did not turn out to be the case. One thing we noticed is that in this
domain the G1SC formulation required a lot more time to determine that there is no plan
for a given number of plan periods.
G1SC versus G2SC and PathSC. Table 1 only shows the five largest problems in
each domain that were solved by the formulations, yet it is representative for the whole set
of problems. The table indicates that when Graphplan-style parallelism is generalized, more
ordering constraints are needed to ensure a feasible plan. On average, the G2SC formulation
includes more ordering constraints than the G1SC formulation, and the PathSC formulation
in its turn includes more ordering constraints than the G2SC formulation. The performance
of these formulations as shown by Figure 17 varies per planning domain. The PathSC
formulation does well in Miconic and Driverlog, the G2SC formulation does well in Freecell,
and the G1SC does well in Zenotravel. Because of these performance differences, we believe
that the ideal amount of flexibility in the generalization of Graphplan-style parallelism is
different for each planning domain.
246

Loosely Coupled Formulations for Automated Planning

10000
Optiplan
1SC
G1SC
G2SC
PathSC

1000
100

Solution time (sec.)

Solution time (sec.)

10000

10
1
0.1

Optiplan
1SC
G1SC
G2SC
PathSC

1000
100
10
1
0.1
0.01

0.01
1

2

3

4

5

6

7

8

1

9 10 11 12 13 14 15 16 17

3

5

7

9

11

13

10000

1000

1000

100
10
Optiplan
1SC
G1SC
G2SC
PathSC

1
0.1
0.01
3

5

7

9

11

13

15

17

19

21

Solution time (sec.)

Solution time (sec.)

10000

1

0.1

23

Optiplan
1SC
G1SC
G2SC
PathSC

1
0.1
0.01
8

Solution time (sec.)

Solution time (sec.)

10

7

Optiplan
1SC
G1SC
G2SC
PathSC

100
10
1
0.1
0.01

9 10 11 12 13 14 15 16 17

1

2

3

4

5

6

Depots
10000

Optiplan
1SC
G1SC
G2SC
PathSC

1000
100
10
1
0.1
0.01

8

9

10 11 12 13 14 15

Optiplan
1SC
G1SC
PathSC

1000
100
10
1
0.1
0.01

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16

1

2

3

4

5

6

Zenotravel
10000

10000

1000

1000

100
10
1
Optiplan
1SC
G1SC

0.1
0.01
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18
Rovers

7

8

9

10

11

Solution time (sec.)

Solution time (sec.)

7

Driverlog

Solution time (sec.)

Solution time (sec.)

10000

27

Miconic

100

6

25

1 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145

1000

5

23

Optiplan
1SC
G1SC
G2SC
PathSC

0.01

1000

4

21

1

10000

3

19

10

10000

2

17

100

Freecell (IPC2)

1

15

Logistics

Blocksworld

100
10

Optiplan
1SC
G1SC
G2SC
PathSC

1
0.1
0.01
1

Satellite

2

3

4

5

Freecell (IPC3)

Figure 17: Solution times in the planning domains of the second and third international
planning competition.

247

Van den Briel, Vossen & Kambhampati

60

#Plan periods

40

#Plan periods

GPsteps
Satplanner
G1SC
G2SC
PathSC

50

30
20
10
0
1

3

5

7

18
16
14
12
10
8
6
4
2
0

9 11 13 15 17 19 21 23 25 27 29 31 33 35

GPsteps
Satplanner
G1SC
G2SC
PathSC

1

3

5

7

9

11

13

Blocksworld
14

8
6
4

23

25

27

GPsteps
Satplanner
G1SC
PathSC

20
15
10

0

0
1

3

5

7

9

11

13

15

17

19

21

1

23

10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145
Miconic

Freecell (IPC2)

GPsteps
Satplanner
G1SC
G2SC
PathSC

25
20
15
10

#Plan periods

30

#Plan periods

21

5

2

5
0

18
16
14
12
10
8
6
4
2
0

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

GPsteps
Satplanner
G1SC
G2SC
PathSC

1

2

3

4

5

6

7

8

Depots
10

16

GPsteps
Satplanner
G1SC
PathSC

14
#Plan periods

6

9 10 11 12 13 14 15 16 17 18
Driverlog

GPsteps
Satplanner
G1SC
G2SC
PathSC

8
#Plan periods

19

25
#Plan periods

#Plan periods

10

17

30

GPsteps
Satplanner
G1SC
G2SC
PathSC

12

15

Logistics

4
2

12
10
8
6
4
2

0

0
1

2

3

4

5

6

7

8

9

1

10 11 12 13 14 15 16

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20
Rovers

14

GPsteps
Satplanner
G1SC

#Plan periods

12
10
8
6
4
2
0
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19

#Plan periods

Zenotravel
18
16
14
12
10
8
6
4
2
0

GPsteps
Satplanner
G1SC
G2SC
PathSC

1

2

3

4

5

6

Freecell (IPC3)

Satellite

Figure 18: Number of plan periods required for each formulation to solve the planning
problems in the second and third international planning competition.

248

Loosely Coupled Formulations for Automated Planning

Problem
Blocksworld
5-1
5-2
6-0
6-1
8-2
Logistics
10-1
11-0
11-1
12-0
14-0
Freecell
2-1
2-2
2-3
2-4
5-5
Miconic
6-4
7-0
7-2
7-3
9-4

G1SC

G2SC

PathSC

0
0
0
0
0

0
0
0
0
0

16
62
5
5
62

0
0
0
0
0

7
0
0
16
7

11
10
49
9
110

0
0
0
0
0

0
0
0
2
3

0
0
84
0
*

0
0
0
0
0

-

0
0
2
4
5

Problem
Depots
1
2
10
13
17
Driverlog
7
8
9
10
11
Zenotravel
5
6
10
11
12
Rovers
14
15
16
17
18
Satellite
5
6
7
9
11
Freecell
1
2
3
4
5

G1SC

G2SC

PathSC

0
0
0
0
0

0
0
2
0
0

7
2
*
30
*

1
32
58
5
6

16
62
80
5
30

2
108
32
69
11

0
0
0
0
0

4
5
0
0
60

485
6
214
586
6259

0
12
1
1
1

-

13
11
92
4
192

2
6
8
14
0

-

-

0
0
0
*
*

0
0
1
1
0

3
2480
1989
*
*

Table 1: Number of ordering constraints, or cuts, that were added dynamically through the
solution process to problems in IPC2 (left) and IPC3 (right). A dash â€˜-â€™ indicates
that the IP formulation could not be tested on the domain and a star â€˜*â€™ indicates
that the formulation could not solve the problem instance within 30 minutes.

249

Van den Briel, Vossen & Kambhampati

5.3.2 Results: Number of Plan Periods
In Figure 18, we see that in all domains the flexible network representation of the G1SC
formulation is slightly more general than the 1-linearization semantics that is used by Satplanner. That is, the number of plan periods required by the G1SC formulation is always
less than or equal to the number of plan periods used by Satplanner. Moreover, the flexible
network representation of the G2SC and PathSC formulations are both more general than
the one used by the G1SC formulation. One may think that the network representation
of the PathSC formulation should provide the most general interpretation of action parallelism, but since the G2SC network representations allows some values to change back to
their original value in the same plan period this is not always the case.
In the domains of Logistics, Freecell, Miconic, and Driverlog, the PathSC never required
more than two plan periods to solve the problem instances. For the Miconic domain this
is very easy to understand. In Miconic there is an elevator that needs to bring travelers
from one floor to another. The state variables representation of this domain has one state
variable for the elevator and two for each traveler (one to represent whether the traveler has
boarded the elevator and one to represent whether the traveler has been serviced). Clearly,
one can devise a plan such that each value of the state variable is visited at most twice. The
elevator simply could visit all floors and pickup all the travelers, and then visit all floors
again to bring them to their destination floor.
5.4 Comparing Different State Variable Representations
An interesting question is to find out whether different state variable representations lead to
different performance benefits. In our loosely coupled formulations we have components that
represent multi-valued state variables. However, the idea of modeling value transitions as
flows in an appropriately defined network can be applied to any binary or multi-valued state
variable representation. In this section we concentrate on the efficiency tradeoffs between
binary and multi-valued state descriptions. As there are generally fewer multi-valued state
variables than binary atoms needed to describe a planning problem, we can expect our
formulations to be more compact when they use a multi-valued state description. For this
comparison we only concentrate on the G1SC formulation as it showed the overall best
performance among our formulations. In our recent work (van den Briel, Kambhampati, &
Vossen, 2007) we analyze different state variable representations in more detail.
Table 2 compares the encoding size for the G1SC formulation on a set of problems
using either a binary or multi-valued state description. The table clearly shows that the
encoding size becomes significantly smaller (both before and after CPLEX presolve) when
a multi-valued state description is used. The encoding size before presolve gives an idea of
the impact of using a more compact multi-valued state description, whereas the encoding
size after presolve shows how much preprocessing can be done by removing redundancies
and substituting out variables.
Figure 19 shows the total solution time (y-axis) needed to solve the problem instances
(x-axis). Since we did not make any changes to the G1SC formulation, the performance
differences are the result of using different state descriptions. In several domains the multivalued state description shows a clear advantage over the binary state description when
using the G1SC formulation, but there are also domains in which the multi-valued state
250

Loosely Coupled Formulations for Automated Planning

description does not provide too much of an advantage. In general, however, the G1SC
formulation using a multi-valued state description leads to the same or better performance
than using a binary state description. In all our tests, we encountered only one problem
instance (Rovers pfile10) in which the binary state description notably outperformed the
multi-valued state description.

6. Related Work
There are only few integer programming-based planning systems. Bylander (1997) considers
an IP formulation based on converting the propositional representation given by Satplan
(Kautz & Selman, 1992) to an IP formulation with variables that take the value 1 if a
certain proposition is true, and 0 otherwise. The LP relaxation of this formulation is
used as a heuristic for partial order planning, but tends to be rather time-consuming. A
different IP formulation is given by Vossen et al. (1999). They consider an IP formulation
in which the original propositional variables are replaced by state change variables. State
change variables take the value 1 if a certain proposition is added, deleted, or persisted,
and 0 otherwise. Vossen et al. show that the formulation based on state change variables
outperforms a formulation based on converting the propositional representation. Van den
Briel and Kambhampati (2005) extend the work by Vossen et al. by incorporating some of
the improvements described by Dimopoulos (2001). Other integer programming approaches
for planning rely on domain-specific knowledge (Bockmayr & Dimopoulos, 1998, 1999) or
explore non-classical planning problems (Dimopoulos & Gerevini, 2002; Kautz & Walser,
1999).
In our formulations we model the transitions of each state variable as a separate flow
problem, with the individual problems being connected through action constraints. The
Graphplan planner introduced the idea of viewing planning as a network flow problem, but
it did not decompose the domain into several loosely coupled components. The encodings
that we described are related to the loosely-coupled modular planning architecture by Srivastava, Kambhampati, and Do (2001), as well as factored planning approaches by Amir
and Engelhardt (2003), and Brafman and Domshlak (2006). The work by Brafman and
Domshlak, for example, proposes setting up a separate CSP problem for handling each factor. These individual factor plans are then combined through a global CSP. In this way, it
has some similarities to our work (with our individual state variable flows corresponding to
encodings for the factor plans). Although Brafman and Domshlak do not provide empirical
evaluation of their factored planning framework, they do provide some analysis on when
factored planning is expected to do best. It would be interesting to adapt their minimal
tree-width based analysis to our scenario.
The branch-and-cut concept was introduced by GroÌˆtschel, RuÌˆnger, and Reinelt (1984)
and Padberg and Rinaldi (1991), and has been successfully applied in the solution of
many hard large-scale optimization problems (Caprara & Fischetti, 1997). In planning,
approaches that use dynamic constraint generation during search include RealPlan (Srivastava et al., 2001) and LPSAT (Wolfman & Weld, 1999).
Relaxed definitions for Graphplan-style parallelism have been investigated by several
other researchers. Dimopoulos et al. (1997) were the first to point out that it is not necessary
to require two actions to be independent in order to execute them in the same plan period.
251

Van den Briel, Vossen & Kambhampati

Problem
Blocksworld
6-2
7-0
8-0
Logistics
14-1
15-0
15-1
Miconic
6-4
7-0
7-2
Freecell(IPC2)
3-3
3-4
3-5
Depots
7
10
13
Driverlog
8
10
11
Zenotravel
12
13
14
Rovers
16
17
18
Satellite
6
7
11
Freecell(IPC3)
1
2
3

Binary
Before presolve
After presolve
#va
#co
#va
#co

Multi
Before presolve After presolve
#va
#co
#va
#co

7645
10166
11743

12561
16881
19657

5784
7384
9947

9564
12318
16773

5125
6806
7855

7281
9741
11305

3716
4761
6438

5409
6967
9479

16464
16465
14115

16801
16801
14401

7052
7044
4625

7386
7385
4935

10843
10844
9297

11180
11180
9583

2693
2696
1771

3007
3009
2133

2220
2842
2527

3403
4474
3977

1776
2295
1999

2843
3764
3287

1905
2473
2199

3088
4105
3649

428
503
431

1495
1972
1719

128636
129392
128636

399869
401486
399869

27928
28234
27947

79369
79577
79444

25267
23734
23342

62588
61601
61083

7123
6346
6237

15588
15101
14931

21845
30436
36006

36181
50785
59425

11572
13727
14729

23233
27570
29712

17250
24120
27900

15381
21713
25297

4122
4643
4372

5592
6731
6806

3431
4328
8457

3673
4645
9101

2245
2159
5907

2506
2333
6404

2595
3551
6997

2513
3292
6471

1146
1409
3558

1102
1171
3073

9656
13738
40332

15589
21649
70021

4294
7779
17815

7046
12449
32959

2858
4466
9282

5821
8417
24121

1051
1882
3367

2398
4174
10619

8631
25794
20895

8093
23906
20241

5424
19549
12056

5297
18384
12144

7367
22889
18351

6637
20700
17377

4394
16652
10081

4155
15257
9988

4471
5433
16758

4945
5833
21537

3584
4294
13643

3774
4267
16713

4087
5013
15578

4561
5413
20357

2288
2974
7108

2478
2925
10118

7332
28214
39638

19185
76343
105995

2965
16218
19603

7339
43427
50819

1624
4873
7029

3265
11383
16003

624
2604
3394

1339
6416
8055

Table 2: Formulation size for binary and multi-valued state description of problem instances
from the IPC2 and IPC3 in number of variables (#va), number of constraints
(#co), and number of ordering constraints, or cuts, (#cu) that were added dynamically through the solution process.

252

Loosely Coupled Formulations for Automated Planning

10000

binary

1000

Solution time (sec.)

Solution time (sec.)

10000
multi

100
10
1
0.1
0.01

binary

1000

multi

100
10
1
0.1
0.01

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15

1

3

5

7

9

11

13

Blocksworld
10000
binary

Solution time (sec.)

Solution time (sec.)

10000
1000

multi

100
10
1
0.1

17

19

21

23

25

27

binary

1000

multi

100
10
1
0.1
0.01

0.01
1 2 3 4 5

1

6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

3

5

7

9 11 13 15 17 19 21 23 25 27 29 31 33
Miconic

Freecell (IPC2)

10000

10000

1000

1000

Solution time (sec.)

Solution time (sec.)

15

Logistics

100
10
1
binary

0.1

binary
multi

100
10
1
0.1

multi
0.01

0.01
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17

1

2

3

4

5

Depots
10000

binary
Solution time (sec.)

Solution time (sec.)

10000
1000

multi

100
10
1
0.1
0.01

7

8

9

10

11

binary

1000

multi

100
10
1
0.1
0.01

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16

1

2

3

4

Zenotravel
10000

6

7

8

9 10 11 12 13 14 15 16 17 18

10000

binary

1000

5

Rovers

Solution time (sec.)

Solution time (sec.)

6
Driverlog

multi

100
10
1
0.1

1000

binary
multi

100
10
1
0.1
0.01

0.01
1

2

3

4

5

6

7

8

9

10

1

11

2

3

Freecell (IPC3)

Satellite

Figure 19: Comparing binary state descriptions with multi-valued state descriptions using
the G1SC formulation.

253

Van den Briel, Vossen & Kambhampati

In their work they introduce the property of post-serializability of a set of actions. A set
of actions Aâ€² âŠ† A is said to be post-serializable if (1) the union of their preconditions
is consistent, (2) the union of their effects is consistent, and (3) the preconditions-effects
graph is acyclic. Where the preconditions-effects graph is a directed graph that contains
a node for each action in Aâ€² , and an arc (a, b) for a, b âˆˆ Aâ€² if the preconditions of a are
inconsistent with the effects of a. For certain planning problems Dimopoulos et al. (1997)
show that their modifications reduce the number of plan periods and improve performance.
Rintanen (1998) provides a constraint-based implementation of their idea and shows that
the improvements hold over a broad range of planning domains.
Cayrol et al. (2001) introduce the notion of authorized linearizations, which implies an
order for the execution of two actions. In particular, an action a âˆˆ A authorizes an action
b âˆˆ A implies that if a is executed before b, then the preconditions of b will not be deleted
by a and the effects of a will not be deleted by b. The notion of authorized linearizations
is very similar to the property of post-serializability. If we were to adopt these ideas in
our network-based representations it would compare to the G1SC network in which the
generalized state change arcs (see Figure 7) only allows values to prevail after, but not
before, each of the transition arcs.
A more recent discussion on the definitions of parallel plans is given by Rintanen, Heljanko and NiemelaÌˆ (2006). Their work introduces the idea of âˆƒ-step semantics, which says
that it is not necessary that all parallel actions are non-interfering as long as they can be
executed in at least one order. âˆƒ-step semantics provide a more general interpretation of
parallel plans than the notion of authorized linearizations used by LCGP (Cayrol et al.,
2001). The current implementation of âˆƒ-step semantics in Satplanner is, however, somewhat restricted. While the semantics allow actions to have conflicting effects, the current
implementation of Satplanner does not.

7. Conclusions
This work makes two contributions: (1) it improves state of the art in modeling planning as
integer programming, and (2) it develops novel decomposition methods for solving bounded
length (in terms of number of plan periods) planning problems.
We presented a series of IP formulations that represent the planning problem as a set
of loosely coupled network flow problems, where each network flow problem corresponds
to one of the state variables in the planning domain. We incorporated different notions
of action parallelism in order to reduce the number of plan periods needed to find a plan
and to improve planning efficiency. The IP formulations described in this paper have led
to their successful use in solving partial satisfaction planning problems (Do et al., 2007).
Moreover, they have initiated a new line of work in which integer and linear programming
are used in heuristic state-space search for automated planning (Benton et al., 2007; van den
Briel et al., 2007). It would be interesting to see how our approach in the context of IP
formulations applies to formulations based on satisfiability and constraint satisfaction.

254

Loosely Coupled Formulations for Automated Planning

Acknowledgments
This research is supported in part by the NSF grant IIS308139, the ONR grant N000140610058,
and by the Lockheed Martin subcontract TT0687680 to Arizona State University as part
of the DARPA integrated learning program. We thank Derek Long for his valuable input,
and we especially thank the anonymous reviewers whose attentive comments and helpful
suggestions have greatly improved this paper.

References
Amir, E., & Engelhardt, B. (2003). Factored planning. In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-2003), pp. 929â€“935.
BaÌˆckstroÌˆm, C., & Nebel, B. (1995). Complexity results for SAS+ planning. Computational
Intelligence, 11 (4), 625â€“655.
Benton, J., van den Briel, M., & Kambhampati, S. (2007). A hybrid linear programming
and relaxed plan heuristic for partial satisfaction planning problems. In Proceedings of
the International Conference on Automated Planning and Scheduling (ICAPS-2007),
pp. 34â€“41.
Bixby, R. E. (2002). Solving real-world linear programs: a decade and more of progress.
Operations Research, 50 (1), 3â€“15.
Blum, A., & Furst, M. (1995). Fast planning through planning graph analysis. In Proceedings
of the 14th International Joint Conference on Artificial Intelligence (IJCAI-1995), pp.
1636â€“1642.
Bockmayr, A., & Dimopoulos, Y. (1998). Mixed integer programming models for planning problems. In Working notes of the CP-98 Constraint Problem Reformulation
Workshop.
Bockmayr, A., & Dimopoulos, Y. (1999). Integer programs and valid inequalities for planning problems. In Proceedings of the European Conference on Planning (ECP-1999),
pp. 239â€“251.
Brafman, R., & Domshlak, C. (2006). Factored planning: How, when, and when not. In
Proceedings of the 21st National Conference on Artificial Intelligence (AAAI-2006),
pp. 809â€“814.
Bylander, T. (1997). A linear programming heuristic for optimal planning. In Proceedings
of the 14th National Conference on Artificial Intelligence (AAAI-1997), pp. 694â€“699.
Caprara, A., & Fischetti, M. (1997). Annotated Bibliographies in Combinatorial Optimization, chap. Branch and Cut Algorithms, pp. 45â€“63. John Wiley and Sons.
Cayrol, M., ReÌgnier, P., & Vidal, V. (2001). Least commitment in graphplan. Artificial
Intelligence, 130 (1), 85â€“118.
255

Van den Briel, Vossen & Kambhampati

Desaulniers, G., Desrosiers, J., & Solomon, M. (Eds.). (2005). Column Generation. Springer.
Dimopoulos, Y. (2001). Improved integer programming models and heuristic search for AI
planning. In Proceedings of the European Conference on Planning (ECP-2001), pp.
301â€“313.
Dimopoulos, Y., & Gerevini, A. (2002). Temporal planning through mixed integer programming. In Proceedings of the Workshop on Planning for Temporal Domains (AIPS2002), pp. 2â€“8.
Dimopoulos, Y., Nebel, B., & Koehler, J. (1997). Encoding planning problems in nonmonotic logic programs. In Proceedings of the 4th European Conference on Planning
(ECP-1997), pp. 167â€“181.
Do, M., Benton, J., van den Briel, M., & Kambhampati, S. (2007). Planning with goal
utility dependencies. In Proceedings of the 20th International Joint Conference on
Artificial Intelligence (IJCAI-2007), pp. 1872â€“1878.
Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge in planning problems to minimize state encoding length. In Proceedings of the European Conference on Planning
(ECP-1999), pp. 135â€“147.
Garey, M., & Johnson, D. (1979). Computers and Intractability: a Guide to the Theory of
NP-Completeness. Freeman and Company, N.Y.
GroÌˆtschel, M., JuÌˆnger, M., & Reinelt, G. (1984). A cutting plane algorithm for the linear
ordering problem. Operations Research, 32, 1195â€“1220.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artifical Intelligence
Research, 26, 191â€“246.
Hooker, J. (1988). A quantitative approach to logical inference. Decision Support Systems,
4, 45â€“69.
ILOG Inc., Mountain View, CA (2002). ILOG CPLEX 8.0 userâ€™s manual.
Johnson, E., Nemhauser, G., & Savelsbergh, M. (2000). Progress in linear programming
based branch-and-bound algorithms: An exposition. INFORMS Journal on Computing, 12, 2â€“23.
Kambhampati, S., & commentary from other planning researchers (2006).
On
the suboptimality of optimal planning track at ipc 2006.
http://raosruminations.blogspot.com/2006/07/on-suboptimality-of-optimal-planning.html.
Karmarkar, N. (1984). A new polynomial time algorithm for linear programming. Combinatorica, 4 (4), 373â€“395.
Kautz, H. (2004). SATPLAN04: Planning as satisfiability. In Working Notes on the Fourth
International Planning Competition (IPC-2004), pp. 44â€“45.
256

Loosely Coupled Formulations for Automated Planning

Kautz, H., & Selman, B. (1992). Planning as satisfiability. In Proceedings of the European
Conference on Artificial Intelligence (ECAI-1992).
Kautz, H., & Selman, B. (2006). SATPLAN04: Planning as satisfiability. In Working Notes
on the Fifth International Planning Competition (IPC-2006), pp. 45â€“46.
Kautz, H., & Walser, J. (1999). State-space planning by integer optimization. In Proceedings
of the 16th National Conference on Artificial Intelligence (AAAI-1999), pp. 526â€“533.
Martin, K. (1991). Using separation algorithms to generate mixed integer model reformulations. Operations Research Letters, 10, 119â€“128.
Padberg, M., & Rinaldi, G. (1991). A branch-and-cut algorithm for the resolution of largescale symmetric traveling salesman problems. SIAM Review, 33, 60â€“100.
Rintanen, J. (1998). A planning algorithm not based on directional search. In Proceedings
of the Sixth International Conference on Principles of Knowledge Representation and
Reasoning (KR-1998), pp. 617â€“624.
Rintanen, J., Heljanko, K., & NiemelaÌˆ, I. (2006). Planning as satisfiability: parallel plans
and algorithms for plan search. Artificial Intelligence, 170 (12), 1031â€“1080.
Srivastava, B., Kambhampati, S., & Do, M. (2001). Planning the project management way:
Efficient planning by effective integration of causal and resource reasoning in realplan.
Artificial Intelligence, 131 (1-2), 73â€“134.
van den Briel, M., Benton, J., Kambhampati, S., & Vossen, T. (2007). An LP-based heuristic
for optimal planning. In Proceedings of the International Conference of Principles and
Practice of Constraint Programming (CP-2007), pp. 651â€“665.
van den Briel, M., & Kambhampati, S. (2005). Optiplan: Unifying IP-based and graphbased planning. Journal of Artificial Intelligence Research, 24, 623â€“635.
van den Briel, M., Kambhampati, S., & Vossen, T. (2007). Fluent merging: A general technique to improve reachability heuristics and factored planning. In Proceedings of the
Workshop Heuristics for Domain-Independent Planning: Progress, Ideas, Limitations,
Challenges (ICAPS-2007).
Vossen, T., Ball, M., Lotem, A., & Nau, D. (1999). On the use of integer programming
models in AI planning. In Proceedings of the 18th International Joint Conference on
Artificial Intelligence (IJCAI-1999), pp. 304â€“309.
Wolfman, S., & Weld, D. (1999). The LPSAT engine and its application to resource planning. In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-1999), pp. 310â€“317.
Wolsey, L. (1998). Integer Programming. John Wiley and Sons.

257

Journal of Artificial Intelligence Research 31 (2008) 431-472

Submitted 11/2007; published 3/2008

First Order Decision Diagrams for Relational MDPs
Chenggang Wang
Saket Joshi
Roni Khardon

cwan@cs.tufts.edu
sjoshi01@cs.tufts.edu
roni@cs.tufts.edu

Department of Computer Science, Tufts University
161 College Avenue, Medford, MA 02155, USA

Abstract
Markov decision processes capture sequential decision making under uncertainty, where
an agent must choose actions so as to optimize long term reward. The paper studies efficient reasoning mechanisms for Relational Markov Decision Processes (RMDP) where
world states have an internal relational structure that can be naturally described in terms
of objects and relations among them. Two contributions are presented. First, the paper
develops First Order Decision Diagrams (FODD), a new compact representation for functions over relational structures, together with a set of operators to combine FODDs, and
novel reduction techniques to keep the representation small. Second, the paper shows how
FODDs can be used to develop solutions for RMDPs, where reasoning is performed at the
abstract level and the resulting optimal policy is independent of domain size (number of
objects) or instantiation. In particular, a variant of the value iteration algorithm is developed by using special operations over FODDs, and the algorithm is shown to converge to
the optimal policy.

1. Introduction
Many real-world problems can be cast as sequential decision making under uncertainty.
Consider a simple example in a logistics domain where an agent delivers boxes. The agent
can take three types of actions: to load a box on a truck, to unload a box from a truck, and
to drive a truck to a city. However the effects of actions may not be perfectly predictable.
For example its gripper may be slippery so load actions may not succeed, or its navigation
module may not be reliable and it may end up in a wrong location. This uncertainty
compounds the already complex problem of planning a course of action to achieve some
goals or maximize rewards.
Markov Decision Processes (MDP) have become the standard model for sequential decision making under uncertainty (Boutilier, Dean, & Hanks, 1999). These models also provide
a general framework for artificial intelligence (AI) planning, where an agent has to achieve
or maintain a well-defined goal. MDPs model an agent interacting with the world. The
agent can fully observe the state of the world and takes actions so as to change the state.
In doing that, the agent tries to optimize a measure of the long term reward it can obtain
using such actions.
The classical representation and algorithms for MDPs (Puterman, 1994) require enumeration of the state space. For more complex situations we can specify the state space
in terms of a set of propositional variables called state attributes. These state attributes
together determine the world state. Consider a very simple logistics problem that has only
c
2008
AI Access Foundation. All rights reserved.

Wang, Joshi, & Khardon

one box and one truck. Then we can have state attributes such as truck in Paris (TP), box
in Paris (BP), box in Boston (BB), etc. If we let the state space be represented by n binary
state attributes then the total number of states would be 2n . For some problems, however,
the domain dynamics and resulting solutions have a simple structure that can be described
compactly using the state attributes, and previous work known as the propositionally factored approach has developed a suite of algorithms that take advantage of such structure
and avoid state enumeration. For example, one can use dynamic Bayesian networks, decision trees, and algebraic decision diagrams to concisely represent the MDP model. This
line of work showed substantial speedup for propositionally factored domains (Boutilier,
Dearden, & Goldszmidt, 1995; Boutilier, Dean, & Goldszmidt, 2000; Hoey, St-Aubin, Hu,
& Boutilier, 1999).
The logistics example presented above is very small. Any realistic problem will have
a large number of objects and corresponding relations among them. Consider a problem
with four trucks, three boxes, and where the goal is to have a box in Paris, but it does not
matter which box is in Paris. With the propositionally factored approach, we need to have
one propositional variable for every possible instantiation of the relations in the domain,
e.g., box 1 in Paris, box 2 in Paris, box 1 on truck 1, box 2 on truck 1, and so on, and
the action space expands in the same way. The goal becomes a ground disjunction over
different instances stating â€œbox 1 in Paris, or box 2 in Paris, or box 3 in Paris, or box 4 in
Parisâ€. Thus we get a very large MDP and at the same time we lose the structure implicit
in the relations and the potential benefits of this structure in terms of computation.
This is the main motivation behind relational or first order MDPs (RMDP). 1 A first
order representation of MDPs can describe domain objects and relations among them, and
can use quantification in specifying objectives. In the logistics example, we can introduce three predicates to capture the relations among domain objects, i.e., Bin(Box, City),
T in(T ruck, City), and On(Box, T ruck) with their obvious meaning. We have three parameterized actions, i.e., load(Box, T ruck), unload(Box, T ruck), and drive(T ruck, City). Now
domain dynamics, reward, and solutions can be described compactly and abstractly using
the relational notation. For example, we can define the goal using existential quantification,
i.e., âˆƒb, Bin(b, P aris). Using this goal one can identify an abstract policy, which is optimal
for every possible instance of the domain. Intuitively when there are 0 steps to go, the
agent will be rewarded if there is any box in Paris. When there is one step to go and there
is no box in Paris yet, the agent can take one action to help achieve the goal. If there is a
box (say b1 ) on a truck (say t1 ) and the truck is in Paris, then the agent can execute the
action unload(b1 , t1 ), which may make Bin(b1 , P aris) true, thus the goal will be achieved.
When there are two steps to go, if there is a box on a truck that is in Paris, the agent
can take the unload action twice (to increase the probability of successful unloading of the
box), or if there is a box on a truck that is not in Paris, the agent can first take the action
drive followed by unload. The preferred plan will depend on the success probability of the
different actions. The goal of this paper is to develop efficient solutions for such problems
using a relational approach, which performs general reasoning in solving problems and does
not propositionalize the domain. As a result the complexity of our algorithms does not
1. Sanner and Boutilier (2005) make a distinction between first order MDPs that can utilize the full power
of first order logic to describe a problem and relational MDPs that are less expressive. We follow this in
calling our language RMDP.

432

First Order Decision Diagrams for Relational MDPs

change when the number of domain objects changes. Also the solutions obtained are good
for any domain of any size (even infinite ones) simultaneously. Such an abstraction is not
possible within the propositional approach.
Several approaches for solving RMDPs were developed over the last few years. Much
of this work was devoted to developing techniques to approximate RMDP solutions using
different representation languages and algorithms (Guestrin, Koller, Gearhart, & Kanodia,
2003a; Fern, Yoon, & Givan, 2003; Gretton & Thiebaux, 2004; Sanner & Boutilier, 2005,
2006). For example, Dzeroski, De Raedt, and Driessens (2001) and Driessens, Ramon, and
GaÌˆrtner (2006) use reinforcement learning techniques with relational representations. Fern,
Yoon, and Givan (2006) and Gretton and Thiebaux (2004) use inductive learning methods
to learn a value map or policy from solutions or simulations of small instances. Sanner and
Boutilier (2005, 2006) develop an approach to approximate value iteration that does not need
to propositionalize the domain. They represent value functions as a linear combination of
first order basis functions and obtain the weights by lifting the propositional approximate
linear programming techniques (Schuurmans & Patrascu, 2001; Guestrin, Koller, Par, &
Venktaraman, 2003b) to handle the first order case.
There has also been work on exact solutions such as symbolic dynamic programming
(SDP) (Boutilier, Reiter, & Price, 2001), the relational Bellman algorithm (ReBel) (Kersting, Otterlo, & De Raedt, 2004), and first order value iteration (FOVIA) (GroÃŸmann,
HoÌˆlldobler, & Skvortsova, 2002; HoÌˆolldobler, Karabaev, & Skvortsova, 2006). There is no
working implementation of SDP because it is hard to keep the state formulas consistent and
of manageable size in the context of the situation calculus. Compared with SDP, ReBel and
FOVIA provide more practical solutions. They both use restricted languages to represent
RMDPs, so that reasoning over formulas is easier to perform. In this paper we develop a
representation that combines the strong points of these approaches.
Our work is inspired by the successful application of Algebraic Decision Diagrams (ADD)
(Bryant, 1986; McMillan, 1993; Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi,
1993) in solving propositionally factored MDPs and POMDPs (Hoey et al., 1999; St-Aubin,
Hoey, & Boutilier, 2000; Hansen & Feng, 2000; Feng & Hansen, 2002). The intuition
behind this idea is that the ADD representation allows information sharing, e.g., sharing
the value of all states that belong to an â€œabstract stateâ€, so that algorithms can consider
many states together and do not need to resort to state enumeration. If there is sufficient
regularity in the model, ADDs can be very compact, allowing problems to be represented
and solved efficiently. We provide a generalization of this approach by lifting ADDs to
handle relational structure and adapting the MDP algorithms. The main difficulty in lifting
the propositional solution, is that in relational domains the transition function specifies a
set of schemas for conditional probabilities. The propositional solution uses the concrete
conditional probability to calculate the regression function. But this is not possible with
schemas. One way around this problem is to first ground the domain and problem at hand
and only then perform the reasoning (see for example Sanghai, Domingos, & Weld, 2005).
However this does not allow for solutions abstracting over domains and problems. Like
SDP, ReBel, and FOVIA, our constructions do perform general reasoning.
First order decision trees and even decision diagrams have already been considered in
the literature (Blockeel & De Raedt, 1998; Groote & Tveretina, 2003) and several semantics
for such diagrams are possible. Blockeel and De Raedt (1998) lift propositional decision
433

Wang, Joshi, & Khardon

trees to handle relational structure in the context of learning from relational datasets.
Groote and Tveretina (2003) provide a notation for first order Binary Decision Diagrams
(BDD) that can capture formulas in Skolemized conjunctive normal form and then provide
a theorem proving algorithm based on this representation. The paper investigates both
approaches and identifies the approach of Groote and Tveretina (2003) as better suited
for the operations of the value iteration algorithm. Therefore we adapt and extend their
approach to handle RMDPs. In particular, our First Order Decision Diagrams (FODD) are
defined by modifying first order BDDs to capture existential quantification as well as realvalued functions through the use of an aggregation over different valuations for a diagram.
This allows us to capture MDP value functions using algebraic diagrams in a natural way.
We also provide additional reduction transformations for algebraic diagrams that help keep
their size small, and allow the use of background knowledge in reductions. We then develop
appropriate representations and algorithms showing how value iteration can be performed
using FODDs. At the core of this algorithm we introduce a novel diagram-based algorithm
for goal regression where, given a diagram representing the current value function, each
node in this diagram is replaced with a small diagram capturing its truth value before the
action. This offers a modular and efficient form of regression that accounts for all potential
effects of an action simultaneously. We show that our version of abstract value iteration is
correct and hence it converges to optimal value function and policy.
To summarize, the contributions of the paper are as follows. The paper identifies the
multiple path semantics (extending Groote & Tveretina, 2003) as a useful representation for
RMDPs and contrasts it with the single path semantics of Blockeel and De Raedt (1998).
The paper develops FODDs and algorithms to manipulate them in general and in the
context of RMDPs. The paper also develops novel weak reduction operations for first order
decision diagrams and shows their relevance to solving relational MDPs. Finally the paper
presents a version of the relational value iteration algorithm using FODDs and shows that
it is correct and thus converges to the optimal value function and policy. While relational
value iteration was developed and specified in previous work (Boutilier et al., 2001), to our
knowledge this is the first detailed proof of correctness and convergence for the algorithm.
This section has briefly summarized the research background, motivation, and our approach. The rest of the paper is organized as follows. Section 2 provides background on
MDPs and RMDPs. Section 3 introduces the syntax and the semantics of First Order Decision Diagrams (FODD), and Section 4 develops reduction operators for FODDs. Sections
5 and 6 present a representation of RMDPs using FODDs, the relational value iteration
algorithm, and its proof of correctness and convergence. The last two sections conclude the
paper with a discussion of the results and future work.

2. Relational Markov Decision Processes
We assume familiarity with standard notions of MDPs and value iteration (see for example
Bellman, 1957; Puterman, 1994). In the following we introduce some of the notions. We
also introduce relational MDPs and discuss some of the previous work on solving them.
Markov Decision Processes (MDPs) provide a mathematical model of sequential optimization problems with stochastic actions. A MDP can be characterized by a state space
S, an action space A, a state transition function P r(sj |si , a) denoting the probability of
434

First Order Decision Diagrams for Relational MDPs

transition to state sj given state si and action a, and an immediate reward function r(s),
specifying the immediate utility of being in state s. A solution to a MDP is an optimal
policy that maximizes expected discounted total reward as defined by the Bellman equation:
V âˆ— (s) = maxaâˆˆA [r(s) + Î³

X

P r(s0 |s, a)V âˆ— (s0 )]

s0 âˆˆS

where V âˆ— represents the optimal state-value function. The value iteration algorithm (VI)
uses the Bellman equation to iteratively refine an estimate of the value function:
Vn+1 (s) = maxaâˆˆA [r(s) + Î³

X

P r(s0 |s, a)Vn (s0 )]

(1)

s0 âˆˆS

where Vn (s) represents our current estimate of the value function and Vn+1 (s) is the next
estimate. If we initialize this process with V0 as the reward function, Vn captures the optimal
value function when we have n steps to go. As discussed further below the algorithm is
known to converge to the optimal value function.
Boutilier et al. (2001) used the situation calculus to formalize first order MDPs and a
structured form of the value iteration algorithm. One of the useful restrictions introduced
in their work is that stochastic actions are specified as a randomized choice among deterministic alternatives. For example, action unload in the logistics example can succeed or
fail. Therefore there are two alternatives for this action: unloadS (unload success) and
unloadF (unload failure). The formulation and algorithms support any number of action
alternatives. The randomness in the domain is captured by a random choice specifying
which action alternative (unloadS or unloadF ) gets executed when the agent attempts an
action (unload). The choice is determined by a state-dependent probability distribution
characterizing the dynamics of the world. In this way one can separate the regression over
effects of action alternatives, which is now deterministic, from the probabilistic choice of
action. This considerably simplifies the reasoning required since there is no need to perform
probabilistic goal regression directly. Most of the work on RMDPs has used this assumption, and we use this assumption as well. Sanner and Boutilier (2007) investigate a model
going beyond this assumption.
Thus relational MDPs are specified by the set of predicates in the domain, the set of
probabilistic actions in the domain, and the reward function. For each probabilistic action,
we specify the deterministic action alternatives and their effects, and the probabilistic choice
among these alternatives. A relational MDP captures a family of MDPs that is generated
by choosing an instantiation of the state space. Thus the logistics example corresponds to
all possible instantiations with 2 boxes or with 3 boxes and so on. We only get a concrete
MDP by choosing such an instantiation.2 Yet our algorithms will attempt to solve the entire
MDP family simultaneously.
Boutilier et al. (2001) introduce the case notation to represent probabilities and rewards
compactly. The expression t = case[Ï†1 , t1 ; Â· Â· Â· ; Ï†n , tn ], where Ï†i is a logical formula, is
equivalent to (Ï†1 âˆ§ (t = t1 )) âˆ¨ Â· Â· Â· âˆ¨ (Ï†n âˆ§ (t = tn )). In other words, t equals ti when Ï†i is
2. One could define a single MDP including all possible instances at the same time, e.g. it will include some
states with 2 boxes, some states with 3 boxes and some with an infinite number of boxes. But obviously
subsets of these states form separate MDPs that are disjoint. We thus prefer the view of a RMDP as a
family of MDPs.

435

Wang, Joshi, & Khardon

true. In general, the Ï†i â€™s are not constrained but some steps in the VI algorithm require
that the Ï†i â€™s are disjoint and partition the state space. In this case, exactly one Ï†i is
true in any state. Each Ï†i denotes an abstract state whose member states have the same
value for that probability or reward. For example, the reward function for the logistics
domain, discussed above and illustrated on the right side of Figure 1, can be captured as
case[âˆƒb, Bin(b, P aris), 10; Â¬âˆƒb, Bin(b, P aris), 0]. We also have the following notation for
operations over function defined by case expressions. The operators âŠ• and âŠ— are defined
by taking a cross product of the partitions and adding or multiplying the case values.
case[Ï†i , ti : i â‰¤ n] âŠ• case[Ïˆj , vj : j â‰¤ m] = case[Ï†i âˆ§ Ïˆj , ti + vj : i â‰¤ n, j â‰¤ m]
case[Ï†i , ti : i â‰¤ n] âŠ— case[Ïˆj , vj : j â‰¤ m] = case[Ï†i âˆ§ Ïˆj , ti Â· vj : i â‰¤ n, j â‰¤ m].
In each iteration of the VI algorithm, the value of a stochastic action A(~x) parameterized
with free variables ~x is determined in the following manner:
QA(~x) (s) = rCase(s) âŠ• [Î³ âŠ— âŠ•j (pCase(nj (~x), s) âŠ— Regr(nj (~x), vCase(do(nj (~x), s))))] (2)
where rCase(s) and vCase(s) denote reward and value functions in case notation, n j (~x)
denotes the possible outcomes of the action A(~x), and pCase(nj (~x), s) the choice probabilities for nj (~x). Note that we can replace a sum over possible next states s0 in the standard
value iteration (Equation 1) with a finite sum over the action alternatives j (reflected in âŠ• j
in Equation 2), since different next states arise only through different action alternatives.
Regr, capturing goal regression, determines what states one must be in before an action
in order to reach a particular state after the action. Figure 1 illustrates the regression of
âˆƒb, Bin(b, P aris) in the reward function R through the action alternative unloadS(b âˆ— , tâˆ— ).
âˆƒb, Bin(b, P aris) will be true after the action unloadS(bâˆ— , tâˆ— ) if it was true before or box
bâˆ— was on truck tâˆ— and truck tâˆ— was in Paris. Notice how the reward function R partitions
the state space into two regions or abstract states, each of which may include an infinite
number of complete world states (e.g., when we have an infinite number of domain objects).
Also notice how we get another set of abstract states after the regression step. In this
way first order regression ensures that we can work on abstract states and never need to
propositionalize the domain.
After the regression, we get a parameterized Q-function which accounts for all possible
instances of the action. We need to maximize over the action parameters of the Q-function
to get the maximum value that could be achieved by using an instance of this action. To
illustrate this step, consider the logistics example where we have two boxes b 1 and b2 , and
b1 is on truck t1 , which is in Paris (that is, On(b1 , t1 ) and T in(t1 , P aris)), while b2 is in
Boston (Bin(b2 , Boston)). For the action schema unload(bâˆ— , tâˆ— ), we can instantiate bâˆ— and
tâˆ— with b1 and t1 respectively, which will help us achieve the goal; or we can instantiate bâˆ—
and tâˆ— with b2 and t1 respectively, which will have no effect. Therefore we need to perform
maximization over action parameters to get the best instance of an action. Yet, we must
perform this maximization generically, without knowledge of the actual state. In SDP, this
is done in several steps. First, we add existential quantifiers over action parameters (which
leads to non disjoint partitions). Then we sort the abstract states in Q A(~x) by the value in
decreasing order and include the negated conditions for the first n abstract states in the
formula for the (n + 1)th , ensuring mutual exclusion. Notice how this step leads to complex
436

First Order Decision Diagrams for Relational MDPs

R
âˆƒ b , Bin ( b , Paris )

âˆƒ b , Bin ( b , Paris )

10

Â¬âˆƒ b , Bin ( b , Paris )
0

On ( b *, t *)
âˆ§ Tin ( t *, Paris )

Figure 1: An example illustrating regression over the action alternative unloadS(b âˆ— , tâˆ— ).

description of the resulting state partitions in SDP. This process is performed for every
action separately. We call this step object maximization and denote it with obj-max(Q A(~x) ).
Finally, to get the next value function we maximize over the Q-functions of different
actions. These three steps provide one iteration of the VI algorithm which repeats the
update until convergence.
The solutions of ReBel (Kersting et al., 2004) and FOVIA (GroÃŸmann et al., 2002;
HoÌˆolldobler et al., 2006) follow the same outline but use a simpler logical language for representing RMDPs. An abstract state in ReBel is captured using an existentially quantified
conjunction. FOVIA (GroÃŸmann et al., 2002; HoÌˆolldobler et al., 2006) has a more complex
representation allowing a conjunction that must hold in a state and a set of conjunctions
that must be violated. An important feature in ReBel is the use of decision list (Rivest,
1987) style representations for value functions and policies. The decision list gives us an
implicit maximization operator since rules higher on the list are evaluated first. As a result
the object maximization step is very simple in ReBel. Each state partition is represented
implicitly by the negation of all rules above it, and explicitly by the conjunction in the rule.
On the other hand, regression in ReBel requires that one enumerate all possible matches
between a subset of a conjunctive goal (or state partition) and action effects, and reason
about each of these separately. So this step can potentially be improved.
In the following section we introduce a new representation â€“ First Order Decision Diagrams (FODD). FODDs allow for sharing of parts of partitions, leading to space and time
saving. More importantly the value iteration algorithm based on FODDs has both simple
regression and simple object maximization.
437

Wang, Joshi, & Khardon

3. First Order Decision Diagrams
A decision diagram is a graphical representation for functions over propositional (Boolean)
variables. The function is represented as a labeled rooted directed acyclic graph where each
non-leaf node is labeled with a propositional variable and has exactly two children. The
outgoing edges are marked with values true and false. Leaves are labeled with numerical
values. Given an assignment of truth values to the propositional variables, we can traverse
the graph where in each node we follow the outgoing edge corresponding to its truth value.
This gives a mapping from any assignment to a leaf of the diagram and in turn to its
value. If the leaves are marked with values in {0, 1} then we can interpret the graph as
representing a Boolean function over the propositional variables. Equivalently, the graph
can be seen as representing a logical expression which is satisfied if and only if the 1 leaf is
reached. The case with {0, 1} leaves is known as Binary Decision Diagrams (BDDs) and the
case with numerical leaves (or more general algebraic expressions) is known as Algebraic
Decision Diagrams (ADDs). Decision Diagrams are particularly interesting if we impose
an order over propositional variables and require that node labels respect this order on
every path in the diagram; this case is known as Ordered Decision Diagrams (ODD). In
this case every function has a unique canonical representation that serves as a normal form
for the function. This property means that propositional theorem proving is easy for ODD
representations. For example, if a formula is contradictory then this fact is evident when
we represent it as a BDD, since the normal form for a contradiction is a single leaf valued
0. This property together with efficient manipulation algorithms for ODD representations
have led to successful applications, e.g., in VLSI design and verification (Bryant, 1992;
McMillan, 1993; Bahar et al., 1993) as well as MDPs (Hoey et al., 1999; St-Aubin et al.,
2000). In the following we generalize this representation for relational problems.
3.1 Syntax of First Order Decision Diagrams
There are various ways to generalize ADDs to capture relational structure. One could
use closed or open formulas in the nodes, and in the latter case we must interpret the
quantification over the variables. In the process of developing the ideas in this paper we
have considered several possibilities including explicit quantifiers but these did not lead to
useful solutions. We therefore focus on the following syntactic definition which does not
have any explicit quantifiers.
For this representation, we assume a fixed set of predicates and constant symbols, and
an enumerable set of variables. We also allow using an equality between any pair of terms
(constants or variables).
Definition 1 First Order Decision Diagram
1. A First Order Decision Diagram (FODD) is a labeled rooted directed acyclic graph,
where each non-leaf node has exactly two children. The outgoing edges are marked
with values true and false.
2. Each non-leaf node is labeled with: an atom P (t1 , . . . , tn ) or an equality t1 = t2 where
each ti is a variable or a constant.
3. Leaves are labeled with numerical values.
438

First Order Decision Diagrams for Relational MDPs

p (x)
q (x)
1

h (y)

0 1

0

Figure 2: A simple FODD.

Figure 2 shows a FODD with binary leaves. Left going edges represent true branches.
To simplify diagrams in the paper we draw multiple copies of the leaves 0 and 1 (and
occasionally other values or small sub-diagrams) but they represent the same node in the
FODD.
We use the following notation: for a node n, nâ†“t denotes the true branch of n, and nâ†“f
the false branch of n; nâ†“a is an outgoing edge from n, where a can be true or false. For
an edge e, source(e) is the node that edge e issues from, and target(e) is the node that edge e
points to. Let e1 and e2 be two edges, we have e1 = sibling(e2 ) iff source(e1 ) = source(e2 ).
In the following we will slightly abuse the notation and let nâ†“a mean either an edge or
the sub-FODD this edge points to. We will also use nâ†“a and target(e1 ) interchangeably
where n = source(e1 ) and a can be true or false depending on whether e1 lies in the
true or false branch of n.
3.2 Semantics of First Order Decision Diagrams
We use a FODD to represent a function that assigns values to states in a relational MDP.
For example, in the logistics domain, we might want to assign values to different states in
such a way that if there is a box in Paris, then the state is assigned a value of 19; if there is
no box in Paris but there is a box on a truck that is in Paris and it is raining, this state is
assigned a value of 6.3, and so on.3 The question is how to define the semantics of FODDs
in order to have the intended meaning.
The semantics of first order formulas are given relative to interpretations. An interpretation has a domain of elements, a mapping of constants to domain elements and, for
each predicate, a relation over the domain elements which specifies when the predicate is
true. In the MDP context, a state can be captured by an interpretation. For example in
the logistics domain, a state includes objects such as boxes, trucks, and cities, and relations
among them, such as box 1 on truck 1 (On(b1 , t1 )), box 2 in Paris (Bin(b2 , P aris)) and so
on. There is more than one way to define the meaning of FODD B on interpretation I. In
the following we discuss two possibilities.
3.2.1 Semantics Based on a Single Path
A semantics for relational decision trees is given by Blockeel and De Raedt (1998) and it can
be adapted to FODDs. The semantics define a unique path that is followed when traversing
3. This is a result of regression in the logistics domain cf. Figure 19(l).

439

Wang, Joshi, & Khardon

B relative to I. All variables are existential and a node is evaluated relative to the path
leading to it.
In particular, when we reach a node some of its variables have been seen before on the
path and some are new. Consider a node n with label l(n) and the path leading to it from
the root, and let C be the conjunction of all labels of nodes that are exited on the true
branch on the path. Then in the node n we evaluate âˆƒ~x, C âˆ§ l(n), where ~x includes all the
variables in C and l(n). If this formula is satisfied in I then we follow the true branch.
Otherwise we follow the false branch. This process defines a unique path from the root
to a leaf and its value.
For example, if we evaluate the diagram in Figure 2 on the interpretation I 1 with
domain {1, 2, 3} and where the only true atoms are {p(1), q(2), h(3)} then we follow the
true branch at the root since âˆƒx, p(x) is satisfied, but we follow the false branch at q(x)
since âˆƒx, p(x) âˆ§ q(x) is not satisfied. Since the leaf is labeled with 0 we say that B does not
satisfy I. This is an attractive approach, because it partitions the set of interpretations into
mutually exclusive sets and this can be used to create abstract state partitions in the MDP
context. However, for reasons we discuss later, this semantics leads to various complications
for the value iteration algorithm, and it is therefore not used in the paper.
3.2.2 Semantics Based on Multiple Paths
The second alternative builds on work by Groote and Tveretina (2003) who defined semantics based on multiple paths. Following this work, we define the semantics first relative to a
variable valuation Î¶. Given a FODD B over variables ~x and an interpretation I, a valuation
Î¶ maps each variable in ~x to a domain element in I. Once this is done, each node predicate
evaluates either to true or false and we can traverse a single path to a leaf. The value
of this leaf is denoted by MAPB (I, Î¶).
Different valuations may give different values; but recall that we use FODDs to represent
a function over states, and each state must be assigned a single value. Therefore, we next
define
MAPB (I) = aggregateÎ¶ {MAPB (I, Î¶)}
for some aggregation function. That is, we consider all possible valuations Î¶, and for each
valuation we calculate MAPB (I, Î¶). We then aggregate over all these values. In the special
case of Groote and Tveretina (2003) leaf labels are in {0, 1} and variables are universally
quantified; this is easily captured in our formulation by using minimum as the aggregation
function. In this paper we use maximum as the aggregation function. This corresponds
to existential quantification in the binary case (if there is a valuation leading to value 1,
then the value assigned will be 1) and gives useful maximization for value functions in the
general case. We therefore define:
MAPB (I) = max{MAPB (I, Î¶)}.
Î¶

Using this definition B assigns every I a unique value v = MAPB (I) so B defines a function
from interpretations to real values. We later refer to this function as the map of B.
Consider evaluating the diagram in Figure 2 on the interpretation I1 given above where
the only true atoms are {p(1), q(2), h(3)}. The valuation where x is mapped to 2 and y is
440

First Order Decision Diagrams for Relational MDPs

mapped to 3 denoted {x/2, y/3} leads to a leaf with value 1 so the maximum is 1. When leaf
labels are in {0,1}, we can interpret the diagram as a logical formula. When MAP B (I) = 1,
as in our example, we say that I satisfies B and when MAPB (I) = 0 we say that I falsifies
B.
We define node formulas (NF) and edge formulas (EF) recursively as follows. For a node
n labeled l(n) with incoming edges e1 , . . . , ek , the node formula NF(n) = (âˆ¨i EF(ei )). The
edge formula for the true outgoing edge of n is EF(nâ†“t ) = NF(n) âˆ§ l(n). The edge formula
for the false outgoing edge of n is EF(nâ†“f ) = NF(n) âˆ§ Â¬l(n). These formulas, where all
variables are existentially quantified, capture the conditions under which a node or edge are
reached.
3.3 Basic Reduction of FODDs
Groote and Tveretina (2003) define several operators that reduce a diagram into normal
form. A total order over node labels is assumed. We describe these operators briefly and
give their main properties.
(R1) Neglect operator: if both children of a node p in the FODD lead to the same node q
then we remove p and link all parents of p to q directly.
(R2) Join operator: if two nodes p, q have the same label and point to the same two
children then we can join p and q (remove q and link qâ€™s parents to p).
(R3) Merge operator: if a node and its child have the same label then the parent can point
directly to the grandchild.
(R4) Sort operator: If a node p is a parent of q but the label ordering is violated (l(p) >
l(q)) then we can reorder the nodes locally using two copies of p and q such that labels
of the nodes do not violate the ordering.
Define a FODD to be reduced if none of the four operators can be applied. We have the
following:
Theorem 1 (Groote & Tveretina, 2003)
(1) Let O âˆˆ {Neglect, Join, Merge, Sort} be an operator and O(B) the result of applying O
to FODD B, then for any B, I, and Î¶, MAPB (I, Î¶) = MAPO(B) (I, Î¶).
(2) If B1 , B2 are reduced and satisfy âˆ€Î¶, MAPB1 (I, Î¶) = MAPB2 (I, Î¶) then they are identical.
Property (1) gives soundness, and property (2) shows that reducing a FODD gives a normal
form. However, this only holds if the maps are identical for every Î¶ and this condition is
stronger than normal equivalence. This normal form suffices for Groote and Tveretina
(2003) who use it to provide a theorem prover for first order logic, but it is not strong
enough for our purposes. Figure 3 shows two pairs of reduced FODDs (with respect to R1R4) such that MAPB1 (I) = MAPB2 (I) but âˆƒÎ¶, MAPB1 (I, Î¶) 6= MAPB2 (I, Î¶). In this case
although the maps are the same the FODDs are not reduced to the same form. Consider
first the pair in part (a) of the figure. An interpretation where p(a) is false but p(b) is
true and a substitution {x/a, y/b} leads to value of 0 in B1 while B2 always evaluates to
1. But the diagrams are equivalent. For any interpretation, if p(c) is true for any object
441

Wang, Joshi, & Khardon

B1

B2

p (x)

(a)

1

1

p (y)
0

1

p (x, y)
(b)

p (y, z)
1

p (x, y)

0

p (z, x)

0

1

0

0

Figure 3: Examples illustrating weakness of normal form.

c then MAPB1 (I) = 1 through the substitution {x/c}; if p(c) is false for any object c
then MAPB1 (I) = 1 through the substitution {x/c, y/c}. Thus the map is always 1 for
B1 as well. In Section 4.2 we show that with the additional reduction operators we have
developed, B1 in the first pair is reduced to 1. Thus the diagrams in (a) have the same form
after reduction. However, our reductions do not resolve the second pair given in part (b)
of the figure. Notice that both functions capture a path of two edges labeled p in a graph
(we just change the order of two nodes and rename variables) so the diagrams evaluate to
1 if and only if the interpretation has such a path. Even though B1 and B2 are logically
equivalent, they cannot be reduced to the same form using R1-R4 or our new operators. To
identify a unique minimal syntactic form one may have to consider all possible renamings
of variables and the sorted diagrams they produce, but this is an expensive operation. A
discussion of normal form for conjunctions that uses such an operation is given by Garriga,
Khardon, and De Raedt (2007).
3.4 Combining FODDs
Given two algebraic diagrams we may need to add the corresponding functions, take the
maximum or use any other binary operation, op, over the values represented by the functions. Here we adopt the solution from the propositional case (Bryant, 1986) in the form
of the procedure Apply(B1 ,B2 ,op) where B1 and B2 are algebraic diagrams. Let p and q
be the roots of B1 and B2 respectively. This procedure chooses a new root label (the lower
among labels of p, q) and recursively combines the corresponding sub-diagrams, according
to the relation between the two labels (â‰º, =, or ). In order to make sure the result is
reduced in the propositional sense one can use dynamic programming to avoid generating
nodes for which either neglect or join operators ((R1) and (R2) above) would be applicable.
Figure 4 illustrates this process. In this example, we assume predicate ordering as
p1 â‰º p2 , and parameter ordering x1 â‰º x2 . Non-leaf nodes are annotated with numbers and
numerical leaves are underlined for identification during the execution trace. For example,
442

First Order Decision Diagrams for Relational MDPs

1
p1 (x1)
2
p2 (x1)
10

âŠ•

3
p2 (x2)
9

0

0

1+3
p1 (x1)
=

2+3
p2 (x1)

0+3

10+3
p2 (x2)
19

10

p2 (x2)
9

0

Figure 4: A simple example of adding two FODDs.

the top level call adds the functions corresponding to nodes 1 and 3. Since p1 (x1 ) is the
smaller label it is picked as the label for the root of the result. Then we must add both
left and right child of node 1 to node 3. These calls are performed recursively. It is easy
to see that the size of the result may be the product of sizes of input diagrams. However,
much pruning will occur with shared variables and further pruning is made possible by weak
reductions presented later.
Since for any interpretation I and any fixed valuation Î¶ the FODD is propositional, we
have the following lemma. We later refer to this property as the correctness of Apply.
Lemma 1 Let C = Apply(A, B, op), then for any I and Î¶, MAPA (I, Î¶) op MAPB (I, Î¶) =
MAPC (I, Î¶).
Proof: First we introduce some terminology. Let #nodes(X) refer to the set of all nodes
in a FODD X. Let the root nodes of A and B be Aroot and Broot respectively. Let the
FODDs rooted at Arootâ†“t , Arootâ†“f , Brootâ†“t , Brootâ†“f , Crootâ†“t , and Crootâ†“f be Al , Ar , B l , B r ,
C l and C r respectively.
The proof is by induction on n = |#nodes(A)| + |#nodes(B)|. The lemma is true for
n = 2, because in this case both Aroot and Broot have to be single leaves and an operation
on them is the same as an operation on two real numbers. For the inductive step we need
to consider two cases.
Case 1: Aroot = Broot . Since the root nodes are equal, if a valuation Î¶ reaches Al ,
then it will also reach B l and if Î¶ reaches Ar , then it will also reach B r . Also, by the
definition of Apply, in this case C l = Apply(Al , B l , op) and C r = Apply(Ar , B r , op). Therefore the statement of the lemma is true if MAPAl (I, Î¶) op MAPB l (I, Î¶) = MAPC l (I, Î¶) and
MAPAr (I, Î¶) op MAPB r (I, Î¶) = MAPC r (I, Î¶) for any Î¶ and I. Now, since |#nodes(Al ) +
#nodes(B l )| < n and |#nodes(Ar ) + #nodes(B r )| < n, this is guaranteed by the induction
hypothesis.
Case 2: Aroot 6= Broot . Without loss of generality let us assume that Aroot â‰º Broot .
By the definition of Apply, C l = Apply(Al , B, op) and C r = Apply(Ar , B, op). Therefore
the statement of the lemma is true if MAPAl (I, Î¶) op MAPB (I, Î¶) = MAPC l (I, Î¶) and
MAPAr (I, Î¶) op MAPB (I, Î¶) = MAPC r (I, Î¶) for any Î¶ and I. Again this is guaranteed by
the induction hypothesis.
2
443

Wang, Joshi, & Khardon

3.5 Order of Labels
The syntax of FODDs allows for two â€œtypesâ€ of objects: constants and variables. Any
argument of a predicate can be a constant or a variable. We assume a complete ordering
on predicates, constants, and variables. The ordering â‰º between two labels is given by the
following rules.
1. P (x1 , ..., xn ) â‰º P 0 (x01 , ..., x0m ) if P â‰º P 0
2. P (x1 , ..., xn ) â‰º P (x01 , ..., x0n ) if there exists i such that xj = x0j for all j < i, and
type(xi ) â‰º type(x0i ) (where â€œtypeâ€ can be constant or variable) or type(xi ) = type(x0i )
and xi â‰º x0i .
While the predicate order can be set arbitrarily it appears useful to assign the equality
predicate as the first in the predicate ordering so that equalities are at the top of the
diagrams. During reductions we often encounter situations where one side of the equality
can be completely removed leading to substantial space savings. It may also be useful to
order the argument types so that constant â‰º variables. This ordering may be helpful for
reductions. Intuitively, a variable appearing lower in the diagram can be bound to the
value of a constant that appears above it. These are only heuristic guidelines and the best
ordering may well be problem dependent. We later introduce other forms of arguments:
predicate parameters and action parameters. The ordering for these is discussed in Section 6.

4. Additional Reduction Operators
In our context, especially for algebraic FODDs, we may want to reduce the diagrams further.
We distinguish strong reductions that preserve MAPB (I, Î¶) for all Î¶ and weak reductions
that only preserve MAPB (I). Theorem 1 shows that R1-R4 given above are strong reductions. The details of our relational VI algorithm do not directly depend on the reductions
used. Readers more interested in RMDP details can skip to Section 5 which can be read
independently (except where reductions are illustrated in examples).
All the reduction operators below can incorporate existing knowledge on relationships
between predicates in the domain. We denote this background knowledge by B. For example
in the Blocks World we may know that if there is a block on block y then it is not clear:
âˆ€x, y, [on(x, y) â†’ Â¬clear(y)].
In the following when we define conditions for reduction operators, there are two types
of conditions: the reachability condition and the value condition. We name reachability
conditions by starting with P (for Path Condition) and the reduction operator number. We
name conditions on values by starting with V and the reduction operator number.
4.1 (R5) Strong Reduction for Implied Branches
Consider any node n such that whenever n is reached then the true branch is followed. In
this case we can remove n and connect its parents directly to the true branch. We first
present the condition, followed by the lemma regarding this operator.
(P5) : B |= âˆ€~x, [NF(n) â†’ l(n)] where ~x are the variables in EF(nâ†“t ).
444

First Order Decision Diagrams for Relational MDPs

Let R5(n) denote the operator that removes node n and connects its parents directly
to the true branch. Notice that this is a generalization of R3. It is easy to see that the
following lemma is true:
Lemma 2 Let B be a FODD, n a node for which condition P5 holds, and B 0 the result
of R5(n). Then for any interpretation I and any valuation Î¶ we have MAP B (I, Î¶) =
MAPB 0 (I, Î¶).
A similar reduction can be formulated for the false branch, i.e., if B |= âˆ€~x, [NF(n) â†’
Â¬l(n)] then whenever node n is reached then the false branch is followed. In this case we
can remove n and connect its parents directly to the false branch.
Implied branches may simply be a result of equalities along a path. For example (x =
y) âˆ§ p(x) â†’ p(y) so we may prune p(y) if (x = y) and p(x) are known to be true. Implied
branches may also be a result of background knowledge. For example in the Blocks World
if on(x, y) is guaranteed to be true when we reach a node labeled clear(y) then we can
remove clear(y) and connect its parent to clear(y)â†“f .
4.2 (R7) Weak Reduction Removing Dominated Edges
Consider any two edges e1 and e2 in a FODD whose formulas satisfy that if we can follow
e2 using some valuation then we can also follow e1 using a possibly different valuation. If
e1 gives better value than e2 then intuitively e2 never determines the value of the diagram
and is therefore redundant. We formalize this as reduction operator R7. 4
Let p = source(e1 ), q = source(e2 ), e1 = pâ†“a , and e2 = qâ†“b , where a and b can be true
or false. We first present all the conditions for the operator and then follow with the
definition of the operator.
(P7.1) : B |= [âˆƒ~x, EF(e2 )] â†’ [âˆƒ~y , EF(e1 )] where ~x are the variables in EF(e2 ) and ~y the
variables in EF(e1 ).
(P7.2) : B |= âˆ€~u, [[âˆƒw,
~ EF(e2 )] â†’ [âˆƒ~v , EF(e1 )]] where ~u are the variables that appear in
both target(e1 ) and target(e2 ), ~v the variables that appear in EF(e1 ) but are not in ~u, and
w
~ the variables that appear in EF(e2 ) but are not in ~u. This condition requires that for
every valuation Î¶1 that reaches e2 there is a valuation Î¶2 that reaches e1 such that Î¶1 and
Î¶2 agree on all variables that appear in both target(e1 ) and target(e2 ).
(P7.3) : B |= âˆ€~r, [[âˆƒ~s, EF(e2 )] â†’ [âˆƒ~t, EF(e1 )]] where ~r are the variables that appear in both
target(e1 ) and target(sibling(e2 )), ~t the variables that appear in EF(e1 ) but are not in ~r,
and ~s the variables that appear in EF(e2 ) but are not in ~r. This condition requires that for
every valuation Î¶1 that reaches e2 there is a valuation Î¶2 that reaches e1 such that Î¶1 and
Î¶2 agree on all variables that appear in both target(e1 ) and target(sibling(e2 )).
(V7.1) : min(target(e1 )) â‰¥ max(target(e2 )) where min(target(e1 )) is the minimum leaf
value in target(e1 ), and max(target(e2 )) the maximum leaf value in target(e2 ). In this case
regardless of the valuation we know that it is better to follow e1 and not e2 .
(V7.2) : min(target(e1 )) â‰¥ max(target(sibling(e2 ))).
(V7.3) : all leaves in D = target(e1 ) 	 target(e2 ) have non-negative values, denoted as
D â‰¥ 0. In this case for any fixed valuation it is better to follow e1 instead of e2 .
4. We use R7 and skip the notation R6 for consistency with earlier versions of this paper. See further
discussion in Section 4.2.1.

445

Wang, Joshi, & Khardon

(V7.4) : all leaves in G = target(e1 ) 	 target(sibling(e2 )) have non-negative values.
We define the operators R7-replace(b, e1 , e2 ) as replacing target(e2 ) with a constant b
that is between 0 and min(target(e1 )) (we may write it as R7-replace(e1 , e2 ) if b = 0),
and R7-drop(e1 , e2 ) as dropping the node q = source(e2 ) and connecting its parents to
target(sibling(e2 )).
We need one more â€œsafetyâ€ condition to guarantee that the reduction is correct:
(S1) : NF(source(e1 )) and the sub-FODD of target(e1 ) remain the same before and after
R7-replace and R7-drop. This condition says that we must not harm the value promised
by target(e1 ). In other words, we must guarantee that p = source(e1 ) is reachable just as
before and the sub-FODD of target(e1 ) is not modified after replacing a branch with 0. The
condition is violated if q is in the sub-FODD of pâ†“a , or if p is in the sub-FODD of qâ†“b . But
it holds in all other cases, that is when p and q are unrelated (one is not the descendant of
the other), or q is in the sub-FODD of pâ†“a , or p is in the sub-FODD of qâ†“b , where a, b are
the negations of a, b.
Lemma 3 Let B be a FODD, e1 and e2 edges for which conditions P7.1, V7.1, and S1
hold, and B 0 the result of R7-replace(b, e1 , e2 ), where 0 â‰¤ b â‰¤ min(target(e1 )), then for any
interpretation I we have MAPB (I) = MAPB 0 (I).
Proof: Consider any valuation Î¶1 that reaches target(e2 ). Then according to P7.1,
there is another valuation reaching target(e1 ) and by V7.1 it gives a higher value. Therefore, MAPB (I) will never be determined by target(e2 ) so we can replace target(e2 ) with a
constant between 0 and min(target(e1 )) without changing the map.
2
Lemma 4 Let B be a FODD, e1 and e2 edges for which conditions P7.2, V7.3, and S1
hold, and B 0 the result of R7-replace(b, e1 , e2 ), where 0 â‰¤ b â‰¤ min(target(e1 )), then for any
interpretation I we have MAPB (I) = MAPB 0 (I).
Proof: Consider any valuation Î¶1 that reaches target(e2 ). By P7.2 there is another
valuation Î¶2 reaching target(e1 ) and Î¶1 and Î¶2 agree on all variables that appear in both
target(e1 ) and target(e2 ). Therefore, by V7.3 it achieves a higher value (otherwise, there
must be a branch in D = target(e1 )	target(e2 ) with a negative value). Therefore according
to maximum aggregation the value of MAPB (I) will never be determined by target(e2 ), and
we can replace it with a constant as described above.
2
Note that the conditions in the previous two lemmas are not comparable since P7.2
â†’ P7.1 and V7.1 â†’ V7.3. Intuitively when we relax the conditions on values, we need
to strengthen the conditions on reachability. The subtraction operation D = target(e 1 ) 	
target(e2 ) is propositional, so the test in V7.3 implicitly assumes that the common variables in the operands are the same and P7.1 does not check this. Figure 5 illustrates
that the reachability condition P7.1 together with V7.3, i.e., combining the weaker portions of conditions from Lemma 3 and Lemma 4, cannot guarantee that we can replace
a branch with a constant. Consider an interpretation I with domain {1, 2, 3, 4} and relations {h(1, 2), q(3, 4), p(2)}. In addition assume domain knowledge B = [âˆƒx, y, h(x, y) â†’
âˆƒz, w, q(z, w)]. So P7.1 and V7.3 hold for e1 = [q(x, y)]â†“t and e2 = [h(z, y)â†“t ]. We have
MAPB1 (I) = 3 and MAPB2 (I) = 0. It is therefore not possible to replace h(z, y)â†“t with 0.
446

First Order Decision Diagrams for Relational MDPs

q(x,y)
p(y)

q(x,y)

h(z,y)
0 p(y) 0

5

3

3
B1

0

p(y)
5

0

0
B2

Figure 5: An example illustrating the subtraction condition in R7.

10

B1

B2

p(x)

p(x)

q(y)
7

10

p(y)

20

h(y)

9 20

h(y)
0

0

Figure 6: An example illustrating the condition for removing a node in R7.

Sometimes we can drop the node q completely with R7-drop. Intuitively, when we
remove a node, we must guarantee that we do not gain extra value. The conditions for
R7-replace can only guarantee that we will not lose any value. But if we remove the node
q, a valuation that was supposed to reach e2 may reach a better value in e2 â€™s sibling. This
would change the map, as illustrated in Figure 6. Notice that the conditions P7.1 and
V7.1 hold for e1 = [p(x)]â†“t and e2 = [p(y)]â†“t so we can replace [p(y)]â†“t with a constant.
Consider an interpretation I with domain {1, 2} and relations {q(1), p(2), h(2)}. We have
MAPB1 (I) = 10 via valuation {x/2} and MAPB2 (I) = 20 via valuation {x/1, y/2}. Thus
removing p(y) is not correct.
Therefore we need the additional condition to guarantee that we will not gain extra value
with node dropping. This condition can be stated as: for any valuation Î¶1 that reaches e2
and thus will be redirected to reach a value v1 in sibling(e2 ) when q is removed, there is a
valuation Î¶2 that reaches a leaf with value v2 â‰¥ v1 . However, this condition is too complex
to test in practice. In the following we identify two stronger conditions.
Lemma 5 Let B be a FODD, e1 and e2 edges for which condition V7.2 hold in addition to
the conditions for replacing target(e2 ) with a constant, and B 0 the result of R7-drop(e1 , e2 ),
then for any interpretation I we have MAPB (I) = MAPB 0 (I).
Proof: Consider any valuation reaching target(e2 ). As above its true value is dominated
by another valuation reaching target(e1 ). When we remove q = source(e2 ) the valuation
will reach target(sibling(e2 )) and by V7.2 the value produced is smaller than the value from
target(e1 ). So again the map is preserved.
2
447

Wang, Joshi, & Khardon

Lemma 6 Let B be a FODD, e1 and e2 edges for which P7.3 and V7.4 hold in addition
to conditions for replacing target(e2 ) with a constant, and B 0 the result of R7-drop(e1 , e2 ),
then for any interpretation I we have MAPB (I) = MAPB 0 (I).
Proof: Consider any valuation Î¶1 reaching target(e2 ). As above its value is dominated
by another valuation reaching target(e1 ). When we remove q = source(e2 ) the valuation
will reach target(sibling(e2 )) and by the conditions P7.3 and V7.4, the valuation Î¶2 will
reach leaf of greater value in target(e1 )(otherwise there will be a branch in G leading to a
negative value). So under maximum aggregation the map is not changed.
2
To summarize if P7.1 and V7.1 and S1 hold or P7.2 and V7.3 and S1 hold then we can
replace target(e2 ) with a constant. If we can replace and V7.2 or both P7.3 and V7.4 hold
then we can drop q = source(e2 ) completely.
In the following we provide a more detailed analysis of applicability and variants of R7.
4.2.1 R6: A Special Case of R7
We have a special case of R7 when p = q, i.e., e1 and e2 are siblings. In this context R7
can be considered to focus on a single node n instead of two edges. Assuming that e 1 = nâ†“t
and e2 = nâ†“f , we can rewrite the conditions in R7 as follows.
(P7.1) : B |= [âˆƒ~x, NF(n)] â†’ [âˆƒ~x, ~y , EF(nâ†“t )]. This condition requires that if n is reachable
then nâ†“t is reachable.
(P7.2) : B |= âˆ€~r, [âˆƒ~v , NF(n)] â†’ [âˆƒ~v , w,
~ EF(nâ†“t )] where ~r are the variables that appear in
both nâ†“t and nâ†“f , ~v the variables that appear in NF(n) but not in ~r, and w
~ the variables
in l(n) and not in ~r or ~v .
(P7.3) : B |= âˆ€~u, [âˆƒ~v , NF(n)] â†’ [âˆƒ~v , w,
~ EF(nâ†“t )] where ~u are the variables that appear in
nâ†“t (since sibling(e2 ) = e1 ), ~v the variables that appear in NF(n) but not in ~u, and w
~ the
variables in l(n) and not in ~u or ~v .
(V7.1) : min(nâ†“t ) â‰¥ max(nâ†“f ).
(V7.2) : nâ†“t is a constant.
(V7.3) : all leaves in the diagram D = nâ†“t 	 nâ†“f have non-negative values.
Conditions S1 and V7.4 are always true. We have previously analyzed this special case
as a separate reduction operator named R6 (Wang, Joshi, & Khardon, 2007). While this is
a special case, it may still be useful to check for it separately before applying the generalized
case of R7, as it provides large reductions and seems to occur frequently in example domains.
An important special case of R6 occurs when l(n) is an equality t1 = y where y is a
variable that does not occur in the FODD above node n. In this case, the condition P7.1
holds since we can choose the value of y. We can also enforce the equality in the subdiagram of nâ†“t . Therefore if V7.1 holds we can remove the node n connecting its parents to
nâ†“t and substituting t1 for y in the diagram nâ†“t . (Note that we may need to make copies of
nodes when doing this.) In Section 4.4 we introduce a more elaborate reduction to handle
equalities by taking a maximum over the left and the right children.
4.2.2 Application Order
In some cases several instances of R7 are applicable. It turns out that the order in which
we apply them is important. In the following, the first example shows that the order affects
448

First Order Decision Diagrams for Relational MDPs

p(x1,y1)
q(x3)

p(x1,y1)
q(x3)
10

p(x2,y2)

q(x2)
6

0 5
(a)

p(x1,y1)

10

0

q(x2)
6

q(x2) 0

q(x3)
10

0

(b)

0

q(x3)

p(x2,y2)
0 q(x2)
5
(d)

(c)

p(x1,y1)

p(x1,y1)
10

0

0

0

q(x3)
10

p(x2,y2)
0

0

0

(e)

Figure 7: An example illustrating the effect of application order for R7.

the number of steps needed to reduce the diagram. The second example shows that the
order affects the final result.
Consider the FODD in Figure 7(a). R7 is applicable to edges e1 = [p(x1 , y1 )]â†“t and
e2 = [p(x2 , y2 )]â†“t , and e01 = [q(x3 )]â†“t and e02 = [q(x2 )]â†“t . If we reduce in a top down
manner, i.e., first apply R7 on the pair [p(x1 , y1 )]â†“t and [p(x2 , y2 )]â†“t , we will get the FODD
in Figure 7(b), and then we apply R7 again on [q(x3 )]â†“t and [q(x2 )]â†“t , and we will get the
FODD in Figure 7(c). However, if we apply R7 first on [q(x3 )]â†“t and [q(x2 )]â†“t thus getting
Figure 7(d), R7 cannot be applied to [p(x1 , y1 )]â†“t and [p(x2 , y2 )]â†“t because [p(x1 , y1 )]â†“t 	
[p(x2 , y2 )]â†“t will have negative leaves. In this case, the diagram can still be reduced. We can
reduce by comparing [q(x3 )]â†“t and [q(x2 )]â†“t that is in the right part of FODD. We can first
remove q(x2 ) and get a FODD shown in Figure 7(e), and then use the neglect operator to
remove p(x2 , y2 ). As we see in this example applying one instance of R7 may render other
instances not applicable or may introduce more possibilities for reductions so in general
we must apply the reductions sequentially. Wang (2007) develops conditions under which
several instances of R7 can be applied simultaneously.
One might hope that repeated application of R7 will lead to a unique reduced result but
this is not true. In fact, the final result depends on the choice of operators and the order of
application. Consider Figure 8(a). R7 is applicable to edges e1 = [p(x)]â†“t and e2 = [p(y)]â†“t ,
and e01 = [q(x)]â†“t and e02 = [q(y)]â†“t . If we reduce in a top down manner, i.e., first apply
R7 on the pair [p(x)]â†“t and [p(y)]â†“t , we will get the FODD in Figure 8(b), which cannot be
reduced using existing reduction operators (including the operator R8 introduced below).
However, if we apply R7 first on [q(x)]â†“t and [q(y)]â†“t we will get Figure 8(c). Then we can
apply R7 again on e1 = [p(x)]â†“t and e2 = [p(y)]â†“t and get the final result Figure 8(d), which
is clearly more compact than Figure 8(b). It is interesting that the first example seems to
449

Wang, Joshi, & Khardon

p(x)
10

p(x)
10

p(y)

10 q(x)
10

10 q(y)
1

q(y)
1

0

0

(a)

(b)

p(x)
10

q(x)

p(x)
10 q(x)

p(y)

10 0

10 q(x)
10 0

(d)

(c)

Figure 8: An example illustrating that the final result of R7 reductions is order dependent.
suggest applying R7 in a top down manner (since it takes fewer steps), while the second
seems to suggest the opposite (since the final result is more compact). More research is
needed to develop useful heuristics to guide the choice of reductions and the application
order and in general develop a more complete set of reductions.
Note that we could also consider generalizing R7. In Figure 8(b), if we can reach [q(y)] â†“t
then clearly we can reach [p(x)]â†“t or [q(x)]â†“t . Since both [p(x)]â†“t and [q(x)]â†“t give better values, we can safely replace [q(y)]â†“t with 0, thus obtaining the final result Figure 8(d). In theory we can generalize P7.1 as B |= [âˆƒ~x, EF(e2 )] â†’ [âˆƒy~1 , EF(e11 )] âˆ¨ Â· Â· Â· âˆ¨ [âˆƒy~n , EF(e1n )] where
~x are the variables in EF(e2 ) and y~i the variables in EF(e1i ) where 1 â‰¤ i â‰¤ n, and generalize
the corresponding value condition V7.1 as âˆ€i âˆˆ [1, n], min(target(e1i )) â‰¥ max(target(e2 )).
We can generalize other reachability and value conditions similarly. However the resulting
conditions are too expensive to test in practice.
4.2.3 Relaxation of Reachability Conditions
The conditions P7.2 and P7.3 are sufficient, but not necessary to guarantee correct reductions. Sometimes valuations just need to agree on a smaller set of variables than the
intersection of variables. To see this, consider the example as shown in Figure 9, where
A 	 B > 0 and the intersection is {x, y, z}. However, to guarantee A 	 B > 0 we just need
to agree on either {x, y} or {x, z}. Intuitively we have to agree on the variable x to avoid
the situation when two paths p(x, y) âˆ§ Â¬q(x) and p(x, y) âˆ§ q(x) âˆ§ h(z) can co-exist. In order
to prevent the co-existence of two paths Â¬p(x, y) âˆ§ Â¬h(z) and p(x, y) âˆ§ q(x) âˆ§ h(z), either y
or z has to be the same as well. Now if we change this example a little bit and replace each
450

First Order Decision Diagrams for Relational MDPs

h(z) with h(z, v), then we have two minimal sets of variables of different size, one is {x, y},
and the other is {x, z, v}. As a result we cannot identify a minimum set of variables for the
subtraction and must either choose the intersection or heuristically identify a minimal set,
for example, using a greedy procedure.

A

B

p(x, y)

p(x, y)

q(x)
3

h(z)
2 3

q(x)
2

1 2

h(z)
3

h(z)
1

1

Figure 9: An example illustrating that the minimal set of variables for subtraction is not
unique.
4.3 (R8) Weak Reduction by Unification
Consider a FODD B. Let ~v denote its variables, and let ~x and ~y be disjoint subsets of ~v ,
which are of the same cardinality. We define the operator R8(B, ~x, ~y ) as replacing variables
in ~x by the corresponding variables in ~y . We denote the resulting FODD by B{~x/~y } so the
result has variables in ~v \~x. We have the following condition for the correctness of R8:
(V8) : all leaves in B{~x/~y } 	 B are non negative.
Lemma 7 Let B be a FODD, B 0 the result of R8(B, ~x, ~y ) for which V8 holds, then for any
interpretation I we have MAPB (I) = MAPB 0 (I).
Proof: Consider any valuation Î¶1 to ~v in B. By V8, B{~x/~y } gives a better value on the
same valuation. Therefore we do not lose any value by this operator. We also do not gain
any extra value. Consider any valuation Î¶2 to variables in B 0 reaching a leaf node with value
v, we can construct a valuation Î¶3 to ~v in B with all variables in ~x taking the corresponding
value in ~y , and it will reach a leaf node in B with the same value. Therefore the map will
not be changed by unification.
2
Figure 10 illustrates that in some cases R8 is applicable where R7 is not. We can apply
R8 with {x1 /x2 } to get a FODD as shown in Figure 10(b). Since (b) 	 (a) â‰¥ 0, (b) becomes
the result after reduction. Note that if we unify in the other way, i.e.,{x2 /x1 }, we will get
Figure 10(c), it is isomorphic to Figure 10(b), but we cannot reduce the original FODD to
this result, because (c)	(a) 6â‰¥ 0. This phenomenon happens since the subtraction operation
(implemented by Apply) used in the reductions is propositional and therefore sensitive to
variable names.
4.4 (R9) Equality Reduction
Consider a FODD B with an equality node n labeled t = x. Sometimes we can drop n and
connect its parents to a sub-FODD that is the result of taking the maximum of the left and
451

Wang, Joshi, & Khardon

p(x2)
p(x1)
p(x2)

0

x1 / x2

q(x2)
10

q(x2) 0
10
(a)

0

0

0
(b)

x2/ x1

p(x1)
q(x1)
10

0

0
(c)

Figure 10: An example illustrating R8.

the right children of n. For this reduction to be applicable B has to satisfy the following
condition.
(E9.1) : For an equality node n labeled t = x at least one of t and x is a variable and it
appears neither in nâ†“f nor in the node formula for n. To simplify the description of the
reduction procedure below, we assume that x is that variable.
Additionally we make the following assumption about the domain.
(D9.1) : The domain contains more than one object.
The above assumption guarantees that valuations reaching the right child of equality
nodes exist. This fact is needed in proving correctness of the Equality reduction operator.
First we describe the reduction procedure for R9(n). Let Bn denote the FODD rooted at
node n in FODD B. We extract a copy of Bnâ†“t (and name it Bnâ†“t -copy), and a copy of
Bnâ†“f (Bnâ†“f -copy) from B. In Bnâ†“t -copy, we rename the variable x to t to produce diagram
Bn0 â†“t -copy. Let Bn0 = Apply(Bn0 â†“t -copy, Bnâ†“f -copy, max). Finally we drop the node n in B
and connect its parents to the root of Bn0 to obtain the final result B 0 . An example is shown
in Figure 11.
Informally, we are extracting the parts of the FODD rooted at node n, one where x = t
(and renaming x to t in that part) and one where x 6= t. The condition E9.1 and the
assumption D9.1 guarantee that regardless of the value of t, we have valuations reaching
both parts. Since by the definition of MAP, we maximize over the valuations, in this case
we can maximize over the diagram structure itself. We do this by calculating the function
which is the maximum of the two functions corresponding to the two children of n (using
Apply) and replacing the old sub-diagram rooted at node n by the new combined diagram.
Theorem 9 proves that this does not affect the map of B.
One concern for implementation is that we simply replace the old sub-diagram by the
new sub-diagram, which may result in a diagram where strong reductions are applicable.
While this is not a problem semantically, we can avoid the need for strong reductions by
using Apply that implicitly performs strong reductions R1(neglect) and R2(join) as follows.
452

First Order Decision Diagrams for Relational MDPs

Let Ba denote the FODD resulting from replacing node n in B with 0, and Bb the
FODD resulting from replacing node n with 1 and all leaves other than node n by 0, we
have the final result B 0 = Ba âŠ• Bb0 where Bb0 = Bb âŠ— Bn0 . By correctness of Apply the two
forms of calculating B 0 give the same map.

b=x
0

p(y)
q(x)

x=y
p(y)
5

q(x)

10

q(x)

q(x)
10

p(x)
0

10

(b)

0

(a)

(c)
b=x

q(x)
5

0

0
(d)

0

p(x)
q(x)

10

q(x)
5

0

(e)

Figure 11: An example of the equality reduction. (a) The FODD before reduction. The
node x = y satisfies condition E9.1 for variable y. (b) Bnâ†“t -copy (nâ†“t extracted).
(c) Bnâ†“t -copy renamed to produce Bn0 â†“t -copy. (d) Bnâ†“f -copy. (e) Final result
with node n replaced by apply(Bn0 â†“t -copy, Bnâ†“f -copy, max)
In the following we prove that for any node n where equality condition E9.1 holds in B
we can perform the equality reduction R9 without changing the map for any interpretation
satisfying D9.1. We start with properties of FODDs defined above, e.g., B a , Bb , and Bb0 . Let
Î“n denote the set of all valuations reaching node n and let Î“m denote the set of all valuations
not reaching node n in B. From the basic definition of MAP we have the following:
Claim
(a) âˆ€ Î¶
(b) âˆ€ Î¶
(c) âˆ€ Î¶
(d) âˆ€ Î¶

1 For any interpretation I,
âˆˆ Î“m , MAPBa (I, Î¶) = MAPB (I, Î¶).
âˆˆ Î“n , MAPBa (I, Î¶) = 0.
âˆˆ Î“m , MAPBb (I, Î¶) = 0.
âˆˆ Î“n , MAPBb (I, Î¶) = 1.

From Claim 1 and the definition of MAP, we have,
Claim 2 For any interpretation I,
(a) âˆ€ Î¶ âˆˆ Î“m , MAPBb0 (I, Î¶) = 0.
(b) âˆ€ Î¶ âˆˆ Î“n , MAPBb0 (I, Î¶) = MAPBn0 (I, Î¶).
From Claim 1, Claim 2, and the definition of MAP we have,

453

Wang, Joshi, & Khardon

Claim 3 For any interpretation I,
(a) âˆ€ Î¶ âˆˆ Î“m , MAPB 0 (I, Î¶) = MAPB (I, Î¶).
(b) âˆ€ Î¶ âˆˆ Î“n , MAPB 0 (I, Î¶) = MAPBn0 (I, Î¶).
Next we prove the main property of this reduction stating that for all valuations reaching
node n in B, the old sub-FODD rooted at n and the new (combined) sub-FODD produce
the same map.
Lemma 8 Let Î“n be the set of valuations reaching node n in FODD B. For any interpretation I satisfying D9.1, maxÎ¶âˆˆÎ“n MAPBn (I, Î¶) = maxÎ¶âˆˆÎ“n MAPBn0 (I, Î¶).
Proof: By condition E9.1, the variable x does not appear in N F (n) and hence its value
in Î¶ âˆˆ Î“n is not constrained. We can therefore partition the valuations in Î“n into disjoint
sets, Î“n = {Î“âˆ† | âˆ† is a valuation to variables other than x}, where in Î“âˆ† variables other
than x are fixed to their value in âˆ† and x can take any value in the domain of I. Assumption
D9.1 guarantees that every Î“âˆ† contains at least one valuation reaching Bnâ†“t and at least one
valuation reaching Bnâ†“f in B. Note that if a valuation Î¶ reaches Bnâ†“t then t = x is satisfied
by Î¶ thus MAPBnâ†“t (I, Î¶) = MAPBn0 -copy (I, Î¶). Since x does not appear in Bnâ†“f we also
â†“t
have that MAPBn0 -copy (I, Î¶) is constant for all Î¶ âˆˆ Î“âˆ† . Therefore by the correctness of
â†“f
Apply we have maxÎ¶âˆˆÎ“âˆ† MAPBn (I, Î¶) = maxÎ¶âˆˆÎ“âˆ† MAPBn0 (I, Î¶).
Finally, by the definition of MAP, maxÎ¶âˆˆÎ“n MAPBn (I, Î¶) = maxâˆ† maxÎ¶âˆˆÎ“âˆ† MAPBn (I, Î¶)
= maxâˆ† maxÎ¶âˆˆÎ“âˆ† MAPBn0 (I, Î¶) = maxÎ¶âˆˆÎ“n MAPBn (I, Î¶).
2
Lemma 9 Let B be a FODD, n a node for which condition E9.1 holds, and B 0 be the result
of R9(n), then for any interpretation I satisfying D9.1, MAP B (I) = MAPB 0 (I).
Proof: Let X = maxÎ¶âˆˆÎ“m MAPB 0 (I, Î¶) and Y = maxÎ¶âˆˆÎ“n MAPB 0 (I, Î¶). By the definition of MAP, MAPB 0 (I) = max(X, Y ). However, by Claim 3, X = maxÎ¶âˆˆÎ“m MAPB (I, Î¶)
and by Claim 3 and Lemma 8, Y = maxÎ¶âˆˆÎ“n MAPBn0 (I, Î¶) = maxÎ¶âˆˆÎ“n MAPBn (I, Î¶). Thus
2
max(X, Y ) = MAPB (I) = MAPB 0 (I).
While Lemma 9 guarantees correctness, when applying it in practice it may be important
to avoid violations of the sorting order (which would require expensive re-sorting of the
diagram). If both x and t are variables we can sometimes replace both with a new variable
name so the resulting diagram is sorted. However this is not always possible. When such a
violation is unavoidable, there is a tradeoff between performing the reduction and sorting
the diagram and ignoring the potential reduction.
To summarize, this section introduced several new reductions that can compress diagrams significantly. The first (R5) is a generic strong reduction that removes implied
branches in a diagram. The other three (R7, R8, R9) are weak reductions that do not alter
the overall map of the diagram but do alter the map for specific valuations. The three
reductions are complementary since they capture different opportunities for space saving.

5. Decision Diagrams for MDPs
In this section we show how FODDs can be used to capture a RMDP. We therefore use
FODDs to represent the domain dynamics of deterministic action alternatives, the probabilistic choice of action alternatives, the reward function, and value functions.
454

First Order Decision Diagrams for Relational MDPs

5.1 Example Domain
We first give a concrete formulation of the logistics problem discussed in the introduction. This example follows exactly the details given by Boutilier et al. (2001), and is used
to illustrate our constructions for MDPs. The domain includes boxes, trucks and cities,
and predicates are Bin(Box, City), T in(T ruck, City), and On(Box, T ruck). Following
Boutilier et al. (2001), we assume that On(b, t) and Bin(b, c) are mutually exclusive, so a
box on a truck is not in a city and vice versa. That is, our background knowledge includes
statements âˆ€b, c, t, On(b, t) â†’ Â¬Bin(b, c) and âˆ€b, c, t, Bin(b, c) â†’ Â¬On(b, t). The reward
function, capturing a planning goal, awards a reward of 10 if the formula âˆƒb, Bin(b, P aris)
is true, that is if there is any box in Paris. Thus the reward is allowed to include constants
but need not be completely ground.
The domain includes 3 actions load, unload, and drive. Actions have no effect if their
preconditions are not met. Actions can also fail with some probability. When attempting
load, a successful version loadS is executed with probability 0.99, and an unsuccessful version loadF (effectively a no-operation) with probability 0.01. The drive action is executed
deterministically. When attempting unload, the probabilities depend on whether it is raining or not. If it is not raining then a successful version unloadS is executed with probability
0.9, and unloadF with probability 0.1. If it is raining unloadS is executed with probability
0.7, and unloadF with probability 0.3.
5.2 The Domain Dynamics
We follow Boutilier et al. (2001) and specify stochastic actions as a randomized choice
among deterministic alternatives. The domain dynamics are defined by truth value diagrams (TVDs). For every action schema A(~a) and each predicate schema p(~x) the TVD
T (A(~a), p(~x)) is a FODD with {0, 1} leaves. The TVD gives the truth value of p(~x) in
the next state when A(~a) has been performed in the current state. We call ~a action parameters, and ~x predicate parameters. No other variables are allowed in the TVD; the
reasoning behind this restriction is explained in Section 6.2. The restriction can be sometimes sidestepped by introducing more action parameters instead of the variables.
The truth value of a TVD is valid when we fix a valuation of the parameters. The
TVD simultaneously captures the truth values of all instances of p(~x) in the next state.
Notice that TVDs for different predicates are separate. This can be safely done even if an
action has coordinated effects (not conditionally independent) since the action alternatives
are deterministic.
Since we allow both action parameters and predicate parameters, the effects of an action
are not restricted to predicates over action arguments so TVD are more expressive than
simple STRIPS based schemas. For example, TVDs can easily express universal effects of
an action. To see this note that if p(~x) is true for all ~x after action A(~a) then the TVD
T (A(~a), p(~x)) can be captured by a leaf valued 1. Other universal conditional effects can be
captured similarly. On the other hand, since we do not have explicit universal quantifiers,
TVDs cannot capture universal preconditions.
For any domain, a TVD for predicate p(~x) can be defined generically as in Figure 12.
The idea is that the predicate is true if it was true before and is not â€œundoneâ€ by the action
or was false before and is â€œbrought aboutâ€ by the action. TVDs for the logistics domain
455

Wang, Joshi, & Khardon

p( x )
bring
about

undo
0

0

1

Figure 12: A template for the TVD

Bin (B, C)
1

On (B, T)

On (B, t*)

B= b*

T= t*
0

Tin (t*, C)
1

0

B= b*

B= b*

Bin (B, C)
0

1

C= c*
1

0
(b)

Bin (B, c*)
1

Tin (T, c*)

(c)

C c*
0

(d)

T= t*
C= c*

1
(e)

1

0

1

Tin (T, C)
T= t*

B= b*
T= t*

Tin( t*, C)

0
(a)

On (B, T)

0

rain
0.7

Bin (b, Paris)

0.9

10

(f)

0
(g)

Figure 13: FODDs for logistics domain: TVDs, action choice, and reward function. (a)(b) The TVDs for Bin(B, C) and On(B, T ) under action choice
unloadS(bâˆ— , tâˆ— ). (c)(d) The TVDs for Bin(B, C) and On(B, T ) under action
choice loadS(bâˆ— , tâˆ— , câˆ— ). Note that câˆ— must be an action parameter so that (d)
is a valid TVD. (e) The TVD for T in(T, C) under action choice driveS(tâˆ— , câˆ— ).
(f) The probability FODD for the action choice unloadS(bâˆ— , tâˆ— ). (g) The reward
function.

456

First Order Decision Diagrams for Relational MDPs

in our running example are given in Figure 13. All the TVDs omitted in the figure are
trivial in the sense that the predicate is not affected by the action. In order to simplify the
presentation we give the TVDs in their generic form and did not sort the diagrams using
the order proposed in Section 3.5; the TVDs are consistent with the ordering Bin â‰º â€œ=â€
â‰º On â‰º T in â‰º rain. Notice that the TVDs capture the implicit assumption usually taken
in such planning-based domains that if the preconditions of the action are not satisfied then
the action has no effect.
Notice how we utilize the multiple path semantics with maximum aggregation. A predicate is true if it is true according to one of the paths specified so we get a disjunction
over the conditions for free. If we use the single path semantics of Blockeel and De Raedt
(1998) the corresponding notion of TVD is significantly more complicated since a single
path must capture all possibilities for a predicate to become true. To capture that, we must
test sequentially for different conditions and then take a union of the substitutions from
different tests and in turn this requires additional annotation on FODDs with appropriate
semantics. Similarly an OR operation would require union of substitutions, thus complicating the representation. We explain these issues in more detail in Section 6.3 after we
introduce the first order value iteration algorithm.
5.3 Probabilistic Action Choice
One can consider modeling arbitrary conditions described by formulas over the state to
control natureâ€™s probabilistic choice of action. Here the multiple path semantics makes it
hard to specify mutually exclusive conditions using existentially quantified variables and in
this way specify a distribution. We therefore restrict the conditions to be either propositional
or depend directly on the action parameters. Under this condition any interpretation follows
exactly one path (since there are no variables and thus only the empty valuation) thus the
aggregation function does not interact with the probabilities assigned. A diagram showing
action choice for unloadS in our logistics example is given in Figure 13. In this example,
the condition is propositional. The condition can also depend on action parameters, for
example, if we assume that the result is also affected by whether the box is big or not, we
can have a diagram as in Figure 14 specifying the action choice probability.
Big(b*)
rain

0.9

0.7 0.9

Figure 14: An example showing that the choice probability can depend on action parameters.
Note that a probability usually depends on the current state. It can depend on arbitrary properties of the state (with the restriction stated as above), e.g., rain and big(b âˆ— ),
as shown in Figure 14. We allow arbitrary conditions that depend on predicates with arguments restricted to action parameters so the dependence can be complex. However, we
do not allow any free variables in the probability choice diagram. For example, we cannot
model a probabilistic choice of unloadS(bâˆ— , tâˆ— ) that depends on other boxes on the truck tâˆ— ,
457

Wang, Joshi, & Khardon

e.g., âˆƒb, On(b, tâˆ— ) âˆ§ b 6= bâˆ— : 0.2; otherwise, 0.7. While we can write a FODD to capture this
condition, the semantics of FODD means that a path to 0.7 will be selected by max aggregation so the distribution cannot be modeled in this way. While this is clearly a restriction,
the conditions based on action arguments still give a substantial modeling power.
5.4 Reward and Value Functions
Reward and value functions can be represented directly using algebraic FODDs. The reward
function for our logistics domain example is given in Figure 13.

6. Value Iteration with FODDs
Following Boutilier et al. (2001) we define the first order value iteration algorithm as follows:
given the reward function R and the action model as input, we set V0 = R, n = 0 and repeat
the procedure Rel-greedy until termination:
Procedure 1 Rel-greedy
1. For each action type A(~x), compute:
A(~
x)

QV n

= R âŠ• [Î³ âŠ— âŠ•j (prob(Aj (~x)) âŠ— Regr(Vn , Aj (~x)))]

(3)

A(~
x)

2. QA
Vn = obj-max(QVn ).
3. Vn+1 = maxA QA
Vn .
The notation and steps of this procedure were discussed in Section 2 except that now âŠ—
and âŠ• work on FODDs instead of case statements. Note that since the reward function does
not depend on actions, we can move the object maximization step forward before adding
the reward function. I.e., we first have
A(~
x)

TV n

= âŠ•j (prob(Aj (~x)) âŠ— Regr(Vn , Aj (~x))),

followed by
A(~
x)

QA
Vn = R âŠ• Î³ âŠ— obj-max(TVn ).
Later we will see that the object maximization step makes more reductions possible; therefore by moving this step forward we get some savings in computation. We compute the
updated value function in this way in the comprehensive example of value iteration given
later in Section 6.8.
(Puterman, 1994). In our case we
Value iteration terminates when kVi+1 âˆ’ Vi k â‰¤ Îµ(1âˆ’Î³)
2Î³
need to test that the values achieved by the two diagrams is within Îµ(1âˆ’Î³)
2Î³ .
Some formulations of goal based planning problems use an absorbing state with zero
additional reward once the goal is reached. We can handle this formulation when there is
only one non-zero leaf in R. In this case, we can replace Equation 3 with
A(~
x)

QV n

= max(R, Î³ âŠ— âŠ•j (prob(Aj (~x)) âŠ— Regr(Vn , Aj (~x))).

To see why this is correct, note that due to discounting the max value is always â‰¤ R. If R
is satisfied in a state we do not care about the action (max would be R) and if R is 0 in a
state we get the value of the discounted future reward.
458

First Order Decision Diagrams for Relational MDPs

Note that we can only do this in goal based domains, i.e., there is only one non-zero
leaf. This does not mean that we cannot have disjunctive goals, but it means that we must
value each goal condition equally.
6.1 Regressing Deterministic Action Alternatives
We first describe the calculation of Regr(Vn , Aj (~x)) using a simple idea we call block replacement. We then proceed to discuss how to obtain the result efficiently.
Consider Vn and the nodes in its FODD. For each such node take a copy of the corresponding TVD, where predicate parameters are renamed so that they correspond to the
nodeâ€™s arguments and action parameters are unmodified. BR-regress(V n , A(~x)) is the FODD
resulting from replacing each node in Vn with the corresponding TVD, with outgoing edges
connected to the 0, 1 leaves of the TVD.
Recall that a RMDP represents a family of concrete MDPs each generated by choosing a
concrete instantiation of the state space (typically represented by the number of objects and
their types). The formal properties of our algorithms hold for any concrete instantiation.
Fix any concrete instantiation of the state space. Let s denote a state resulting from
executing an action A(~x) in state sÌ‚. Notice that Vn and BR-regress(Vn , A(~x)) have exactly
the same variables. We have the following lemma:
Lemma 10 Let Î¶ be any valuation to the variables of Vn (and thus also the variables of
BR-regress(Vn , A(~x))). Then MAPVn (s, Î¶) = MAPBRâˆ’regress(Vn ,A(~x)) (sÌ‚, Î¶).
Proof: Consider the paths P, PÌ‚ followed under the valuation Î¶ in the two diagrams. By the
definition of TVDs, the sub-paths of PÌ‚ applied to sÌ‚ guarantee that the corresponding nodes
in P take the same truth values in s. So P, PÌ‚ reach the same leaf and the same value is
obtained.
2
A naive implementation of block replacement may not be efficient. If we use block
replacement for regression then the resulting FODD is not necessarily reduced and moreover,
since the different blocks are sorted to start with the result is not even sorted. Reducing
and sorting the results may be an expensive operation. Instead we calculate the result as
follows. For any FODD Vn we traverse BR-regress(Vn , A(~x)) using postorder traversal in
terms of blocks and combine the blocks. At any step we have to combine up to 3 FODDs
such that the parent block has not yet been processed (so it is a TVD with binary leaves)
and the two children have been processed (so they are general FODDs). If we call the parent
Bn , the true branch child Bt and the false branch child Bf then we can represent their
combination as [Bn âŠ— Bt ] âŠ• [(1 	 Bn ) âŠ— Bf ].
Lemma 11 Let B be a FODD where Bt and Bf are FODDs, and Bn is a FODD with {0, 1}
leaves. Let BÌ‚ be the result of using Apply to calculate the diagram [Bn âŠ—Bt ]âŠ•[(1	Bn )âŠ—Bf ].
Then for any interpretation I and valuation Î¶ we have MAPB (I, Î¶) = MAPBÌ‚ (I, Î¶).
Proof: This is true since by fixing the valuation we effectively ground the FODD and all
paths are mutually exclusive. In other words the FODD becomes propositional and clearly
the combination using propositional Apply is correct.
2
A high-level description of the algorithm to calculate BR-regress(V n , A(~x)) by block
combination is as follows:
459

Wang, Joshi, & Khardon

Procedure 2 Block Combination for BR-regress(Vn , A(~x))
1. Perform a topological sort on Vn nodes (see for example Cormen, Leiserson, Rivest,
& Stein, 2001).
2. In reverse order, for each non-leaf node n (its children Bt and Bf have already been
processed), let Bn be a copy of the corresponding TVD, calculate [Bn âŠ— Bt ] âŠ• [(1 	
Bn ) âŠ— Bf ].
3. Return the FODD corresponding to the root.
Notice that different blocks share variables so we cannot perform weak reductions during
this process. However, we can perform strong reductions in intermediate steps since they
do not change the map for any valuation. After the process is completed we can perform
any combination of weak and strong reductions since this does not change the map of the
regressed value function.
Blue (b)

On (B, T)
1

Big(t)
On(b,t)
0

0

B= b*

Big(t)
On (b, t)

T= t*

1
(a)

Blue (b)

0

Bin (B, c)
Tin (T, c)

0

b= b*
t= t*

0

1
(b)

Bin (b, c)
Tin (t, c)
1

0
(c)

Figure 15: An example illustrating why variables are not allowed in TVDs.
We can now explain why we cannot have variables in TVDs through an example illustrated in Figure 15. Suppose we have a value function as defined in Figure 15(a), saying
that if there is a blue block and a big truck such that the block is not on the truck then
value 1 is assigned. Figure 15(b) gives the TVD for On(B, T ) under action loadS, in
which c is a variable instead of an action parameter. Figure 15(c) gives the result after
block replacement. Consider an interpretation sÌ‚ with domain {b1 , t1 , c1 , c2 } and relations
{Blue(b1 ), Big(t1 ), Bin(b1 , c1 ), T in(t1 , c1 )}. After the action loadS(b1 , t1 ) we will reach the
state s = {Blue(b1 ), Big(t1 ), On(b1 , t1 ), T in(t1 , c1 )}, which gives us a value of 0. But Figure 15(c) with bâˆ— = b1 , tâˆ— = t1 evaluated in sÌ‚ gives value of 1 by valuation {b/b1 , c/c2 , t/t1 }.
Here the choice c/c2 makes sure the precondition is violated. By making c an action parameter, applying the action must explicitly choose a valuation and this leads to a correct
value function. Object maximization turns action parameters into variables and allows us
to choose the argument so as to maximize the value.
460

First Order Decision Diagrams for Relational MDPs

6.2 Regressing Probabilistic Actions
To regress a probabilistic action we must regress all its deterministic alternatives and combine each with its choice probability as in Equation 3. As discussed in Section 2, due to
the restriction in the RMDP model that explicitly specifies a finite number of deterministic
action alternatives, we can replace the potentially infinite sum of Equation 1 with the finite
sum of Equation 3. If this is done correctly for every state then the result of Equation 3 is
correct. In the following we specify how this can be done with FODDs.
Recall that prob(Aj (~x)) is restricted to include only action parameters and cannot include variables. We can therefore calculate prob(Aj (~x))âŠ—Regr(Vn , Aj (~x)) in step (1) directly
using Apply. However, the different regression results are independent functions so that in
the sum âŠ•j (prob(Aj (~x)) âŠ— Regr(Vn , Aj (~x))) we must standardize apart the different regression results before adding the functions (note that action parameters are still considered
constants at this stage). The same holds for the addition of the reward function. The need
to standardize apart complicates the diagrams and often introduces structure that can be
reduced. When performing these operations we first use the propositional Apply procedure
and then follow with weak and strong reductions.

V0

ASucc(x*)
q (x)

p (x)
10

p (A)
5

1

A=x*

0

q (A)
1

(a)

0
(b)
q (x2)

q (x1)
p (x1) 2.5
x1= x*

q (x2)
+

p (x2) 2.5
5

q (x1)
5

0

â€¦

q (x1)
p (x1)

0

x1= x*
q (x1)

0
(c)

7.5

Figure 16: An example illustrating the need to standardize apart.
Figure 16 illustrates why we need to standardize apart different action outcomes. Action
A can succeed (denoted as ASucc) or fail (denoted as AF ail, effectively a no-operation),
and each is chosen with probability 0.5. Part (a) gives the value function V 0 . Part (b) gives
the TVD for P (A) under the action choice ASucc(xâˆ— ). All other TVDs are trivial. Part
(c) shows part of the result of adding the two outcomes for A after standardizing apart
(to simplify the presentation the diagrams are not sorted). Consider an interpretation with
domain {1, 2} and relations {q(1), p(2)}. As can be seen from (c), by choosing x âˆ— = 1, i.e.
461

Wang, Joshi, & Khardon

action A(1), the valuation x1 = 1, x2 = 2 gives a value of 7.5 after the action (without
considering the discount factor). Obviously if we do not standardize apart (i.e x 1 = x2 ),
there is no leaf with value 7.5 and we get a wrong value. Intuitively the contribution of
ASucc to the value comes from the â€œbring aboutâ€ portion of the diagram and AF ailâ€™s
contribution uses bindings from the â€œnot undoâ€ portion and the two portions can refer to
different objects. Standardizing apart allows us to capture both simultaneously.
From Lemma 10 and 11 and the discussion so far we have:
Lemma 12 Consider any concrete instantiation of a RMDP. Let Vn be a value function
for the corresponding MDP, and let A(~x) be a probabilistic action in the domain. Then
A(~
x)
QVn as calculated by Equation 3 is correct. That is, for any state s, MAPQA(~x) (s) is the
Vn

expected value of executing A(~x) in s and then receiving the terminal value V n .
6.3 Observations for Single Path Semantics

Section 5.2 suggested that the single path semantics of Blockeel and De Raedt (1998) does
not support value iteration as well as the multiple path semantics. Now with the explanation
of regression, we can use an example to illustrate this. Suppose we have a value function
as defined in Figure 17(a), saying that if we have a red block in a big city then value 1 is
assigned. Figure 17(b) gives the result after block replacement under action unloadS(b âˆ— , tâˆ— ).
However this is not correct. Consider an interpretation sÌ‚ with domain {b 1 , b2 , t1 , c1 } and
relations {Red(b2 ), Blue(b1 ), Big(c1 ), Bin(b1 , c1 ), T in(t1 , c1 ), On(b2 , t1 )}. Note that we use
the single path semantics. We follow the true branch at the root since âˆƒb, c, Bin(b, c) is true
with {b/b1 , c/c1 }. But we follow the false branch at Red(b) since âˆƒb, c, Bin(b, c) âˆ§ Red(b)
is not satisfied. Therefore we get a value of 0. Clearly, we should get a value of 1 instead
with {b/b2 , c/c1 }, but it is impossible to achieve this value in Figure 17(b) with the single
path semantics. The reason block replacement fails is that the top node decides on the true
branch based on one instance of the predicate but we really need all true instances of the
predicate to filter into the true leaf of the TVD.
To correct the problem, we want to capture all instances that were true before and
not undone and all instances that are made true on one path. Figure 17(c) gives one
possible way to do it. Here â† means variable renaming, and âˆª stands for union operator,
which takes a union of all substitutions. Both can be treated as edge operations. Note
that âˆª is a coordinated operation, i.e., instead of taking the union of the substitutions for
b0 and b00 , c0 and c00 separately we need to take the union of the substitutions for (b0 , c0 )
and (b00 , c00 ). This approach may be possible but it clearly leads to complicated diagrams.
Similar complications arise in the context of object maximization. Finally if we are to use
this representation then all our procedures will need to handle edge marking and unions of
substitutions so this approach does not look promising.
6.4 Object Maximization
Notice that since we are handling different probabilistic alternatives of the same action
separately we must keep action parameters fixed during the regression process and until
they are added in step 1 of the algorithm. In step 2 we maximize over the choice of action
parameters. As mentioned above we get this maximization for free. We simply rename
462

First Order Decision Diagrams for Relational MDPs

Bin(b ,c )

Bin(b , c )

Bin(b, c)

b =b*

Red(b)

Bin(b ,c )

On(b , t*)

b =b*

Tin(t*,c )

Big(c)
0

1
(a)

Red(b )
Big(c )
1

Red(b )

On(b ,t*)
0

1

0

On(b ,t*)
Tin(t*,c )

Tin(t*,c ) (b,c)
(b ,c )
(b,c)
(b ,c ) âˆª
(b ,c )

Big(c )
0

b =b*

(b,c)
(b ,c )

0

Red(b)
Big(c)

(b)

1

0

(c)

Figure 17: An example illustrating union or.

the action parameters using new variable names (to avoid repetition between iterations)
and consider them as variables. The aggregation semantics provides the maximization and
by definition this selects the best instance of the action. Since constants are turned into
variables additional reduction is typically possible at this stage. Any combination of weak
and strong reductions can be used. From the discussion we have the following lemma:
Lemma 13 Consider any concrete instantiation of a RMDP. Let Vn be a value function
for the corresponding MDP, and let A(~x) be a probabilistic action in the domain. Then
QA
Vn as calculated by object maximization in step 2 of the algorithm is correct. That is, for
any state s, MAPQA (s) is the maximum over expected values achievable by executing an
Vn
instance of A(~x) in s and then receiving the terminal value Vn .
A potential criticism of our object maximization is that we are essentially adding more
variables to the diagram and thus future evaluation of the diagram in any state becomes
more expensive (since more substitutions need to be considered). However, this is only true
if the diagram remains unchanged after object maximization. In fact, as illustrated in the
example given below, these variables may be pruned from the diagram in the process of
reduction. Thus as long as the final value function is compact the evaluation is efficient and
there is no such hidden cost.
6.5 Maximizing Over Actions
The maximization Vn+1 = maxA QA
n+1 in step (3) combines independent functions. Therefore as above we must first standardize apart the different diagrams, then we can follow
with the propositional Apply procedure and finally follow with weak and strong reductions.
This clearly maintains correctness for any concrete instantiation of the state space.
463

Wang, Joshi, & Khardon

6.6 Order Over Argument Types
We can now resume the discussion of ordering of argument types and extend it to predicate
and action parameters. As above, some structure is suggested by the operations of the
algorithm. Section 3.5 already suggested that we order constants before variables.
Action parameters are â€œspecial constantsâ€ before object maximization but they become
variables during object maximization. Thus their position should allow them to behave as
variables. We should therefore also order constants before action parameters.
Note that predicate parameters only exist inside TVDs, and will be replaced with domain
constants or variables during regression. Thus we only need to decide on the relative
order between predicate parameters and action parameters. If we put action parameters
before predicate parameters and the latter is replaced with a constant then we get an order
violation, so this order is not useful. On the other hand, if we put predicate parameters
before action parameters then both instantiations of predicate parameters are possible.
Notice that when substituting a predicate parameter with a variable, action parameters
still need to be larger than the variable (as they were in the TVD). Therefore, we also order
action parameters after variables.
To summarize, the ordering: constants â‰º variables (predicate parameters in case of
TVDs) â‰º action parameters, is suggested by heuristic considerations for orders that maximize the potential for reductions, and avoid the need for re-sorting diagrams.
Finally, note that if we want to maintain the diagram sorted at all times, we need
to maintain variant versions of each TVD capturing possible ordering of replacements of
predicate parameters. Consider a TVD in Figure 18(a). If we rename predicate parameters
X and Y to be x2 and x1 respectively, and if x1 â‰º x2 , then the resulting sub-FODD as
shown in Figure 18(b) violates the order. To solve this problem we have to define another
TVD corresponding to the case where the substitution of X  the substitution of Y , as
shown in Figure 18(c). In the case of replacing X with x2 and Y with x1 , we use the TVD
in Figure 18(c) instead of the one in Figure 18(a).

On(X, Y)

On(x2, x1)

On(X, Y)

p(X)

p(x2)

p(Y)

p(x1)

p(Y)
1

0
(a)

1

p(X)
0

(b)

1

0
(c)

Figure 18: An example illustrating the necessity to maintain multiple TVDs.

6.7 Convergence and Complexity
Since each step of Procedure 1 is correct we have the following theorem:

464

First Order Decision Diagrams for Relational MDPs

Theorem 2 Consider any concrete instantiation of a RMDP. Let Vn be the value function
for the corresponding MDP when there are n steps to go. Then the value of Vn+1 calculated
by Procedure 1 correctly captures the value function when there are n + 1 steps to go. That
is, for any state s, MAPVn+1 (s) is the maximum expected value achievable in s in n + 1
steps.
Note that for RMDPs some problems require an infinite number of state partitions.
Thus we cannot converge to V âˆ— in a finite number of steps. However, since our algorithm
implements VI exactly, standard results about approximating optimal value functions and
policies still hold. In particular the following standard result (Puterman, 1994) holds for
our algorithm, and our stopping criterion guarantees approximating optimal value functions
and policies.
Theorem 3 Let V âˆ— be the optimal value function and let Vk be the value function calculated
by the relational VI algorithm.
(1) If r(s) â‰¤ M for all s then kVn âˆ’ V âˆ— k â‰¤ Îµ for n â‰¥
(2) If kVn+1 âˆ’ Vn k â‰¤

Îµ(1âˆ’Î³)
2Î³

2M
)
log( Îµ(1âˆ’Î³)

log Î³1

.

then kVn+1 âˆ’ V âˆ— k â‰¤ Îµ.

While the algorithm maintains compact diagrams, reduction of diagrams is not guaranteed for all domains. Therefore we can only provide trivial upper bounds in terms of
worst case time complexity. Notice first that every time we use the Apply procedure the
size of the output diagram may be as large as the product of the size of its inputs. We
must also consider the size of the FODD giving the regressed value function. While Block
replacement is O(N ) where N is the size of the current value function, it is not sorted
and sorting may require both exponential time and space in the worst case. For example,
Bryant (1986) illustrates how ordering may affect the size of a diagram. For a function of
2n arguments, the function x1 Â· x2 + x3 Â· x4 + Â· Â· Â· + x2nâˆ’1 Â· x2n only requires a diagram of
2n + 2 nodes, while the function x1 Â· xn+1 + x2 Â· xn+2 + Â· Â· Â· + xn Â· x2n requires 2n+1 nodes.
Notice that these two functions only differ by a permutation of their arguments. Now if
x1 Â· x2 + x3 Â· x4 + Â· Â· Â· + x2nâˆ’1 Â· x2n is the result of block replacement then clearly sorting
requires exponential time and space. The same is true for our block combination procedure
or any other method of calculating the result, simply because the output is of exponential
size. In such a case heuristics that change variable ordering, as in propositional ADDs
(Bryant, 1992), would probably be very useful.
Assuming TVDs, reward function, and probabilities all have size â‰¤ C, each action
has â‰¤ M action alternatives, the current value function Vn has N nodes, and worst case
space expansion for regression and all Apply operations, the overall size of the result and
2
the time complexity for one iteration are O(C M (N +1) ). However note that this is the
worst case analysis and does not take reductions into account. While our method is not
guaranteed to always work efficiently, the alternative of grounding the MDP will have an
unmanageable number of states to deal with, so despite the high worst case complexity our
method provides a potential improvement. As the next example illustrates, reductions can
substantially decrease diagram size and therefore save considerable time in computation.
465

Wang, Joshi, & Khardon

6.8 A Comprehensive Example of Value Iteration
Figure 19 traces steps in the application of value iteration to the logistics domain. The
TVDs, action choice probabilities, and reward function for this domain are given in Figure 13. To simplify the presentation, we continue using the predicate ordering Bin â‰º â€œ=â€
â‰º On â‰º T in â‰º rain introduced earlier.5
Given V0 = R as shown in Figure 19(a), Figure 19(b) gives the result of regression of
V0 through unloadS(bâˆ— , tâˆ— ) by block replacement, denoted as Regr(V0 , unloadS(bâˆ— , tâˆ— )).
Figure 19(c) gives the result of multiplying Regr(V0 , unloadS(bâˆ— , tâˆ— )) with the choice
probability of unloadS P r(unloadS(bâˆ— , tâˆ— )).
Figure 19(d) gives the result of P r(unloadF (bâˆ— , tâˆ— )) âŠ— Regr(V0 , unloadF (bâˆ— , tâˆ— )). Notice that this diagram is simpler since unloadF does not change the state and the TVDs
for it are trivial.
Figure 19(e) gives the unreduced result of adding two outcomes for unload(bâˆ— , tâˆ— ), i.e.,
the result of adding [P r(unloadS(bâˆ— , tâˆ— ))âŠ—Regr(V0 , unloadS(bâˆ— , tâˆ— ))] to [P r(unloadF (bâˆ— , tâˆ— ))
âŠ—Regr(V0 , unloadF (bâˆ— , tâˆ— ))]. Note that we first standardize apart diagrams for unloadS(b âˆ— , tâˆ— )
and unloadF (bâˆ— , tâˆ— ) by respectively renaming b as b1 and b2 . Action parameters bâˆ— and tâˆ—
at this stage are considered as constants and we do not change them. Also note that the
recursive part of Apply (addition âŠ•) has performed some reductions, i.e., removing the node
rain when both of its children lead to value 10.
In Figure 19(e), we can apply R6 to node Bin(b2 , P aris) in the left branch. The
conditions
P7.1: [âˆƒb1 , Bin(b1 , P aris)] â†’ [âˆƒb1 , b2 , Bin(b1 , P aris) âˆ§ Bin(b2 , P aris)],
V7.1: min(Bin(b2 , P aris)â†“t ) = 10 â‰¥ max(Bin(b2 , P aris)â†“f ) = 9,
V7.2: Bin(b2 , P aris)â†“t is a constant
hold. According to Lemma 3 and Lemma 5 we can drop node Bin(b2 , P aris) and connect its
parent Bin(b1 , P aris) to its true branch. Figure 19(f ) gives the result after this reduction.
Next, consider the true child of Bin(b2 , P aris) and the true child of the root. The
conditions
P7.1: [âˆƒb1 , b2 , Â¬Bin(b1 , P aris) âˆ§ Bin(b2 , P aris)] â†’ [âˆƒb1 , Bin(b1 , P aris)],
V7.1: min(Bin(b1 , P aris)â†“t ) = 10 â‰¥ max(Bin(b2 , P aris)â†“t ) = 10,
V7.2: min(Bin(b1 , P aris)â†“t ) = 10 â‰¥ max(Bin(b2 , P aris)â†“f ) = 9
hold. According to Lemma 3 and Lemma 5, we can drop the node Bin(b2 , P aris) and
connect its parent Bin(b1 , P aris) to Bin(b2 , P aris)â†“f . Figure 19(g) gives the result after
unload(bâˆ— ,tâˆ— )
this reduction and now we get a fully reduced diagram. This is TV0
.
In the next step we perform object maximization to maximize over action parameters
bâˆ— and tâˆ— and get the best instance of the action unload. Note that bâˆ— and tâˆ— have now
become variables, and we can perform one more reduction: we can drop the equality on
the right branch by R9. Figure 19(h) gives the result after object maximization, i.e.,
unload(bâˆ— ,tâˆ— )
obj-max(TV0
). Note that we have renamed the action parameters to avoid the
repetition between iterations.
unload(bâˆ— ,tâˆ— )
Figure 19(i) gives the reduced result of multiplying Figure 19(h), obj-max(TV0
),
by Î³ = 0.9, and adding the reward function. This result is Qunload
.
1
5. The details do not change substantially if we use the order suggested in Section 3.5 (where equality is
first).

466

First Order Decision Diagrams for Relational MDPs

Bin (b, Paris)

V0

10

Bin (b, Paris)
10

b= b*

b= b*
On (b, t*)

Tin (t*, Paris)

Tin (t*, Paris)

10

0

7

9

1

3

(d)

(c)

Bin (b1, Paris)
10

0

rain

0

rain

(b)

Bin (b2, Paris)

Bin (b, Paris)

On (b, t*)

0
(a)

Bin (b, Paris)

Bin (b1, Paris)
10

Bin (b2, Paris)

Bin (b2, Paris)

rain
b1= b*
9
On (b1, t*)

7

Tin (t*, Paris)
10

rain

b1= b*

b1= b*
On (b1, t*)

On (b1, t*)

3 1 7

On (b1, t*)

Tin (t*, Paris)

Tin (t*, Paris)
0

rain

b1= b*

10

Tin (t*, Paris)

rain

9

3 1 7

9

(e)

(f)

Bin (b1, Paris)
10

Bin (b1, Paris)

b1= b*
On (b1, t*)

7

Q1unload

On (b1, t1)

10

0

6.3 8.1
(h)

V1

6.3 8.1
(l)

0

Bin (b, Paris)

0

19

Tin (t, Paris)

On (b, t*)

1

Tin (t*, Paris)

rain

Q

(i)

b= b*

On (b, t)

Tin (t, Paris)

(j)

0

(k)

Bin (b, Paris)

Bin (b, Paris)
19

0

drive
1

rain

9
(g)

19

Tin (t, Paris)

9

7

Bin (b, Paris)

On (b, t)

19

rain
0

Q1load

Bin (b, Paris)

Tin (t1, Paris)

Tin (t*, Paris)
rain

0

rain

Tin (t, Paris)

t= t*
0

0

On(b, t)

Tin (t, Paris)
0

rain
6.3 8.1

0

rain
6.3 8.1

âŠ•

b=b*

19

âŠ—

0

âŠ—

0

1
=

Tin (t, Paris)
0

rain
6.3 8.1
(n)

(m)

Figure 19: An example of value iteration in the Logistics Domain.

467

Wang, Joshi, & Khardon

We can calculate Qload
and Q1drive in the same way and results are shown in Figure 19(j)
1
and Figure 19(k) respectively. For drive the TVDs are trivial and the calculation is
relatively simple. For load, the potential loading of a box already in Paris is dropped from
the diagram by the reduction operators in the process of object maximization.
Figure 19(l) gives V1 , the result after maximizing over Qunload
, Qload
and Qdrive
. Here
1
1
1
again we standardized apart the diagrams, maximized over them, and then reduced the
result. In this case the diagram for unload dominates the other actions. Therefore Q unload
1
becomes V1 , the value function after the first iteration.
Now we can start the second iteration, i.e., computing V2 from V1 . Figure 19(m) gives
the result of block replacement in regression of V 1 through action alternative unloadS(bâˆ— , tâˆ— ).
Note that we have sorted the TVD for on(B, T ) so that it obeys the ordering we have chosen.
However, the diagram resulting from block replacement is not sorted.
To address this we use the block combination algorithm to combine blocks bottom
up. Figure 19(n) illustrates how we combine blocks T in(t, P aris), which is a TVD, and
its two children, which have been processed and are general FODDs. After we combine
T in(t, P aris) and its two children, On(b, t)â†“t has been processed. Since On(b, t)â†“f = 0,
now we can combine On(b, t) and its two children in the next step of block combination.
Continuing this process we get a sorted representation of Regr(V1 , unloadS(bâˆ— , tâˆ— )).
6.9 Extracting Optimal Policies
There is more than one way to represent policies with FODDs. Here we simply note that
a policy can be represented implicitly by a set of regressed value functions. After the value
iteration terminates, we can perform one more iteration and compute the set of Q-functions
using Equation 3.
Then, given a state s, we can compute the maximizing action as follows:
1. For each Q-function QA(~x) , compute MAPQA(~x) (s), where ~x are considered as variables.
2. For the maximum map obtained, record the action name and action parameters (from
the valuation) to obtain the maximizing action.
This clearly implements the policy represented by the value function. An alternative
approach that represents the policy explicitly was developed in the context of a policy
iteration algorithm (Wang & Khardon, 2007).

7. Discussion
ADDs have been used successfully to solve propositional factored MDPs. Our work gives one
proposal of lifting these ideas to RMDPs. While the general steps are similar, the technical
details are significantly more involved than the propositional case. Our decision diagram
representation combines the strong points of the SDP and ReBel approaches to RMDP. On
the one hand we get simple regression algorithms directly manipulating the diagrams. On
the other hand we get object maximization for free as in ReBel. We also get space saving
since different state partitions can share structure in the diagrams. A possible disadvantage
compared to ReBel is that the reasoning required for reduction operators might be complex.
468

First Order Decision Diagrams for Relational MDPs

In terms of expressiveness, our approach can easily capture probabilistic STRIPS style
formulations as in ReBel, allowing for more flexibility since we can use FODDs to capture
rewards and transitions. For example, our representation can capture universal effects of
actions. On the other hand, it is more limited than SDP since we cannot use arbitrary
formulas for rewards, transitions, and probabilistic choice. For example we cannot express
universal quantification using maximum aggregation, so these cannot be used in reward
functions or in action preconditions. Our approach can also capture grid-world RL domains
with state based reward (which are propositional) in factored form since the reward can be
described as a function of location.
By contrasting the single path semantics with the multiple path semantics we see an
interesting tension between the choice of representation and task. The multiple path method
does not directly support state partitions, which makes it awkward to specify distributions
and policies (since values and actions must both be specified at leaves). However, this
semantics simplifies many steps by easily supporting disjunction and maximization over
valuations which are crucial for for value iteration so it is likely to lead to significant saving
in space and time.
An implementation and empirical evaluation are in progress. The precise choice of
reduction operators and their application will be crucial to obtain an effective system, since
in general there is a tradeoff between run time needed for reductions and the size of resulting
FODDs. We can apply complex reduction operators to get the maximally reduced FODDs,
but it takes longer to perform the reasoning required. This optimization is still an open issue
both theoretically and empirically. Additionally, our implementation can easily incorporate
the idea of approximation by combining leaves with similar values to control the size of
FODDs (St-Aubin et al., 2000). This gives a simple way of trading off efficiency against
accuracy of the value functions.
There are many open issues concerning the current representation. Our results for
FODDs give a first step toward a complete generalization of ADDs. Crucially we do not
yet have a semantically appropriate normal form that is important in simplifying reasoning.
While one can define a normal form (cf., Garriga et al., 2007, for a treatment of conjunctions)
it is not clear if this can be calculated incrementally using local operations as in ADDs. It
would be interesting to investigate conditions that guarantee a normal form for a useful set
of reduction operators for FODDs.
Another possible improvement is that the representation can be modified to allow further
compression. For example we can allow edges to rename variables when they are traversed
so as to compress isomorphic sub-FODDs as illustrated above in Figure 17(c). Another
interesting possibility is a copy operator that evaluates several copies of a predicate (with
different variables) in the same node as illustrated in Figure 20. For such constructs to be
usable one must modify the FODD and MDP algorithmic steps to handle diagrams with
the new syntactic notation.

8. Conclusion
The paper makes two main contributions. First, we introduce FODDs, a generalization of
ADDs, for relational domains that may be useful in various applications. We have developed
calculus of FODDs and reduction operators to minimize their size but there are many open
469

Wang, Joshi, & Khardon

p (x) âˆ§ p (y)

p (x)
q (x)

0

q (x)

p (y) 0

f (y) 0

f (y) 0
2

0

2

1

1

Figure 20: Example illustrating the copy operator.

issues regarding the best choice of operators and reductions. The second contribution is
in developing a FODD-based value iteration algorithm for RMDPs that has the potential
for significant improvement over previous approaches. The algorithm performs general
relational probabilistic reasoning without ever grounding the domains and it is proved to
converge to the abstract optimal value function when such a solution exists.

References
Bahar, R. I., Frohm, E. A., Gaona, C. M., Hachtel, G. D., Macii, E., Pardo, A., & Somenzi,
F. (1993). Algebraic decision diagrams and their applications. In Proceedings of the
International Conference on Computer-Aided Design, pp. 188â€“191.
Bellman, R. E. (1957). Dynamic programming. Princeton University Press.
Blockeel, H., & De Raedt, L. (1998). Top down induction of first order logical decision trees.
Artificial Intelligence, 101, 285â€“297.
Boutilier, C., Dean, T., & Goldszmidt, M. (2000). Stochastic dynamic programming with
factored representations. Artificial Intelligence, 121(1), 49â€“107.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. Journal of Artificial Intelligence Research,
11, 1â€“94.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure in policy construction. In Proceedings of the International Joint Conference of Artificial Intelligence,
pp. 1104â€“1111.
Boutilier, C., Reiter, R., & Price, B. (2001). Symbolic dynamic programming for first-order
MDPs. In Proceedings of the International Joint Conference of Artificial Intelligence,
pp. 690â€“700.
Bryant, R. E. (1986). Graph-based algorithms for boolean function manipulation. IEEE
Transactions on Computers, C-35 (8), 677â€“691.
Bryant, R. E. (1992). Symbolic boolean manipulation with ordered binary decision diagrams. ACM Computing Surveys, 24 (3), 293â€“318.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction to Algorithms. MIT Press.
470

First Order Decision Diagrams for Relational MDPs

Driessens, K., Ramon, J., & GaÌˆrtner, T. (2006). Graph kernels and gaussian processes for
relational reinforcement learning. Machine Learning, 64 (1-3), 91â€“119.
Dzeroski, S., De Raedt, L., & Driessens, K. (2001). Relational reinforcement learning.
Machine Learning, 43, 7â€“52.
Feng, Z., & Hansen, E. A. (2002). Symbolic heuristic search for factored Markov Decision
Processes. In Proceedings of the National Conference on Artificial Intelligence, pp.
455â€“460.
Fern, A., Yoon, S., & Givan, R. (2003). Approximate policy iteration with a policy language
bias. In International Conference on Neural Information Processing Systems.
Fern, A., Yoon, S., & Givan, R. (2006). Approximate policy iteration with a policy language
bias: Solving relational Markov Decision Processes. Journal of Artificial Intelligence
Research, 25, 75â€“118.
Garriga, G., Khardon, R., & De Raedt, L. (2007). On mining closed sets in multi-relational
data. In Proceedings of the International Joint Conference of Artificial Intelligence,
pp. 804â€“809.
Gretton, C., & Thiebaux, S. (2004). Exploiting first-order regression in inductive policy
selection. In Proceedings of the Conference on Uncertainty in Artificial Intelligence,
pp. 217â€“225.
Groote, J. F., & Tveretina, O. (2003). Binary decision diagrams for first-order predicate
logic. The Journal of Logic and Algebraic Programming, 57, 1â€“22.
GroÃŸmann, A., HoÌˆlldobler, S., & Skvortsova, O. (2002). Symbolic dynamic programming
within the fluent calculus. In Proceedings of the IASTED International Conference
on Artificial and Computational Intelligence.
Guestrin, C., Koller, D., Gearhart, C., & Kanodia, N. (2003a). Generalizing plans to new
environments in relational MDPs. In Proceedings of the International Joint Conference
of Artificial Intelligence, pp. 1003â€“1010.
Guestrin, C., Koller, D., Par, R., & Venktaraman, S. (2003b). Efficient solution algorithms
for factored MDPs. Journal of Artificial Intelligence Research, 19, 399â€“468.
Hansen, E. A., & Feng, Z. (2000). Dynamic programming for POMDPs using a factored
state representation. In Proceedings of the International Conference on Artificial
Intelligence Planning Systems, pp. 130â€“139.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using decision diagrams. In Proceedings of the Conference on Uncertainty in Artificial
Intelligence, pp. 279â€“288.
HoÌˆolldobler, S., Karabaev, E., & Skvortsova, O. (2006). FluCaP: a heuristic search planner
for first-order MDPs. Journal of Artificial Intelligence Research, 27, 419â€“439.
Kersting, K., Otterlo, M. V., & De Raedt, L. (2004). Bellman goes relational. In Proceedings
of the International Conference on Machine Learning.
McMillan, K. L. (1993). Symbolic model checking. Kluwer Academic Publishers.
471

Wang, Joshi, & Khardon

Puterman, M. L. (1994). Markov decision processes: Discrete stochastic dynamic programming. Wiley.
Rivest, R. L. (1987). Learning decision lists. Machine Learning, 2 (3), 229â€“246.
Sanghai, S., Domingos, P., & Weld, D. (2005). Relational dynamic bayesian networks.
Journal of Artificial Intelligence Research, 24, 759â€“797.
Sanner, S., & Boutilier, C. (2005). Approximate linear programming for first-order MDPs.
In Proceedings of the Conference on Uncertainty in Artificial Intelligence.
Sanner, S., & Boutilier, C. (2006). Practical linear value-approximation techniques for firstorder MDPs. In Proceedings of the Conference on Uncertainty in Artificial Intelligence.
Sanner, S., & Boutilier, C. (2007). Approximate solution techniques for factored first-order
MDPs. In Proceedings of the International Conference on Automated Planning and
Scheduling.
Schuurmans, D., & Patrascu, R. (2001). Direct value approximation for factored MDPs. In
International Conference on Neural Information Processing Systems, pp. 1579â€“1586.
St-Aubin, R., Hoey, J., & Boutilier, C. (2000). APRICODD: Approximate policy construction using decision diagrams. In International Conference on Neural Information
Processing Systems, pp. 1089â€“1095.
Wang, C. (2007). First order Markov Decision Processes. Tech. rep. TR-2007-4, Computer
Science Department, Tufts University.
Wang, C., Joshi, S., & Khardon, R. (2007). First order decision diagrams for relational
MDPs. In Proceedings of the International Joint Conference of Artificial Intelligence,
pp. 1095â€“1100.
Wang, C., & Khardon, R. (2007). Policy iteration for relational MDPs. In Proceedings of
the Conference on Uncertainty in Artificial Intelligence.

472

Journal of Artificial Intelligence Research 31 (2008) 1-32

Submitted 5/07; published 01/08

M INI M AX S AT: An Efficient Weighted Max-SAT Solver
Federico Heras
Javier Larrosa
Albert Oliveras

FHERAS @ LSI . UPC . EDU
LARROSA @ LSI . UPC . EDU
OLIVERAS @ LSI . UPC . EDU

Technical University of Catalonia, LSI Department
Jordi Girona 1-3, 08034, Barcelona, Spain.

Abstract
In this paper we introduce M INI M AX S AT, a new Max-SAT solver that is built on top of M IN It incorporates the best current SAT and Max-SAT techniques. It can handle hard clauses
(clauses of mandatory satisfaction as in SAT), soft clauses (clauses whose falsification is penalized by a cost as in Max-SAT) as well as pseudo-boolean objective functions and constraints. Its
main features are: learning and backjumping on hard clauses; resolution-based and substractionbased lower bounding; and lazy propagation with the two-watched literal scheme. Our empirical
evaluation comparing a wide set of solving alternatives on a broad set of optimization benchmarks
indicates that the performance of M INI M AX S AT is usually close to the best specialized alternative
and, in some cases, even better.
I S AT +.

1. Introduction
Max-SAT is the optimization version of SAT where the goal is to satisfy the maximum number of
clauses. It is considered one of the fundamental combinatorial optimization problems and many important problems can be naturally expressed as Max-SAT. They include academic problems such as
max cut or max clique, as well as real problems in domains like routing, bioinformatics, scheduling
or electronic markets.
There is a long tradition of theoretical work about the structural complexity (Papadimitriou,
1994) and approximability (Karloff & Zwick, 1997) of Max-SAT. Most of this work is restricted to
the simplest case in which all clauses are equally important (i.e., unweighted Max-SAT) and have a
fixed size (mainly binary or ternary). From a practical point of view, significant progress has been
made in the last 3 years (Shen & Zhang, 2004; Larrosa & Heras, 2005; Larrosa, Heras, & de Givry,
2007; Xing & Zhang, 2005; Li, ManyaÌ€, & Planes, 2005, 2006). As a result, there is a handful of
new solvers that can deal, for the first time, with instances involving hundreds of variables.
The main motivation of our work comes from the study of Max-SAT instances modelling realworld problems. We usually encounter three features:
â€¢ The satisfaction of all clauses does not have the same importance, so each clause needs to be
associated with a weight that represents the cost of its violation. In the extreme case, which
often happens in practice as observed by Cha, Iwama, Kambayashi, and Miyazaki (1997),
there are clauses whose satisfaction is mandatory. They are usually modelled by associating
a very high weight with them.
â€¢ Literals do not appear randomly along the clauses. On the contrary, it is easy to identify
patterns, symmetries or other kinds of structures.
c
2008
AI Access Foundation. All rights reserved.

H ERAS , L ARROSA , & O LIVERAS

â€¢ In some problems there are mandatory clauses that reduce dramatically the number of feasible
assignments, so the optimization part of the problem only plays a secondary role. However,
in some other problems mandatory clauses are trivially satisfiable and the real difficulty lays
on the optimization part.
When we look at current Max-SAT solvers, we find that none of them is robust over these three
features. For instance, Li et al.â€™s (2005, 2006) solvers are restricted to formulas in which all clauses
are equally important (i.e. unweighted Max-SAT), Shen and Zhangâ€™s (2004) one is restricted to binary clauses, the one described by Larrosa et al. (2007) seems to be efficient on very overconstrained
problems (i.e., only a small fraction of the clauses can be simultaneously satisfied), while the one by
Alsinet, ManyaÌ€, and Planes (2005) seems to be efficient on slightly overconstrained problems (i.e.
almost all the clauses can be satisfied). The solver described by Argelich and Manya (2007), developed in parallel to the research described in this paper, can handle mandatory clauses and is the only
one that incorporates some learning, so it seems to perform well on structured problems. However,
all non-mandatory clauses must have the same weight. Finally, approaches based on translating a
Max-SAT instance into a SAT instance and solve them with a SAT solver seem to be effective in
highly structured problems in which almost all clauses are mandatory (Fu & Malik, 2006; Le Berre,
2006).
In this paper we introduce M INI M AX S AT, a new weighted Max-SAT solver that incorporates
the current best SAT and Max-SAT techniques. It is build on top of M INI S AT + (EeÌn & SoÌˆrensson,
2006), so it borrows its capability to deal with pseudo-boolean problems and all the M INI S AT (EeÌn
& SoÌˆrensson, 2003) features processing mandatory clauses such as learning and backjumping. We
have extended it allowing it to deal with weighted clauses, while preserving the two-watched literal
lazy propagation method. The main original contribution of M INI M AX S AT is that it implements
a novel and very efficient lower bounding technique. Specifically, it applies unit propagation in
order to detect disjoint subsets of mutually inconsistent clauses as done by Li et al. (2006). Then
it simplifies the problem following Larrosa and Heras (2005), Heras and Larrosa (2006), Larrosa
et al. (2007) in order to increment the lower bound. However, while in those works only the clauses
that accomplish specific patterns are transformed, in M INI M AX S AT there is no need to define such
patterns.
The structure of the paper is as follows: Section 2 provides preliminary definitions on SAT and
Section 3 presents state-of-the-art solving techniques incorporated in a modern SAT solver such as
M INI S AT. Then, Section 4 presents preliminary definitions on Max-SAT and Section 5 overviews
M INI M AX S AT. After that, Sections 6 and 7 focus on its lower bounding and additional features,
respectively. In Section 8 we present the benchmarks used in our empirical evaluation and we
report the experimental results. Finally, Section 9 presents related work and Section 10 concludes
and points out possible future work.

2. Preliminaries on SAT
In the sequel X = {x1 , x2 , . . . , xn } is the set of boolean variables. A literal is either a variable xi or its
negation xÌ„i . The variable to which literal l refers is noted var(l). Given a literal l, its negation lÂ¯ is xÌ„i
if l is xi and is xi if l is xÌ„i . A clause C is a disjunction of literals. The size of a clause, noted |C|, is the
number of literals that it has. The set of variables that appear in C is noted var(C). Sometimes we
associate a subscript Greek letter to a clause (e.g. (xi âˆ¨ x j )Î± ) in order to facilitate future references
of such clause.
2

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

Algorithm 1: DPLL basic structure.
Function Search() : boolean
1
InitQueue( ) ;
2
Loop
3
UP( ) ;
4
if Conflict then
5
AnalyzeConflict( ) ;
6
if Top Conflict then return f alse ;
else
7
LearnClause( ) ;
8
Backjump( ) ;
9
10
11
12

else if all variables assigned then return true ;
else
l := SelectLiteral( ) ;
Enqueue(Q, l) ;

An assignment is a set of literals not containing a variable and its negation. Assignments of
maximal size n are called complete, otherwise they are called partial. Given an assignment A , a
variable x is unassigned if neither x nor xÌ„ belong to A . Similarly, a literal l is unassigned if var(l)
is unassigned.
An assignment satisfies a literal iff it belongs to the assignment, it satisfies a clause iff it satisfies
one or more of its literals and it falsifies a clause iff it contains the negation of all its literals. In the
latter case we say that the clause is conflicting as it always happens with the empty clause, noted
2. A boolean formula F in conjunctive normal form (CNF) is a set of clauses representing their
conjunction. A model of F is a complete assignment that satisfies all the clauses in F .
If F has a model, we call it satisfiable, otherwise we say it is unsatisfiable. Moreover, if all
complete assignments satisfy F , we say that F is a tautology.
Clauses of size one are called unit clauses or simply units. When a formula contains a unit l, it
can be simplified by removing all clauses containing l and removing lÂ¯ from all the clauses where it
appears. The application of this rule until quiescence is called unit propagation (UP) and it is well
recognized as a fundamental propagation technique in all current SAT solvers.
Another well-known rule is resolution, which, given a formula containing two clauses of the
form (x âˆ¨ A), (xÌ„ âˆ¨ B) (called clashing clauses), allows one to add a new clause (A âˆ¨ B) (called the
resolvent).

3. Overview of State-of-the-art DPLL-based SAT Solvers
In this section we overview the architecture of SAT solvers based on the DPLL (Davis, Logemann,
& Loveland, 1962) procedure. This procedure, currently regarded as the most efficient complete
search procedure for SAT, performs a systematic depth-first search on the space of assignments. An
internal node is associated to a partial assignment and its two successors are obtained by selecting
an unassigned variable x and extending the current assignment with x and xÌ„, respectively. At each
visited node, new units are derived due to the application of unit propagation (UP). If that leads
3

H ERAS , L ARROSA , & O LIVERAS

Algorithm 2: Unit Propagation.
Function UP(Q) : Conflict
while (Q contains non-propagated literals) do
13
l := GetFirstNonPropagatedLit(Q); MarkAsPropagated(l) ;
14
foreach clause C âˆ¨ lÂ¯ that becomes unit or falsified do
15
if C âˆ¨ lÂ¯ becomes a unit q then Enqueue(Q, q) ;
16
else if C âˆ¨ lÂ¯ becomes falsified then return Conflict ;
return None ;

to a conflicting clause, the procedure backtracks, performing non-chronological backtracking and
clause learning, as originally proposed by Silva and Sakallah (1996).
An algorithmic description of the DPLL procedure appears in Algorithm 1. The algorithm uses a
propagation queue Q which contains all units pending propagation and also contains a representation
of the current assignment.
First, propagation queue Q is filled with the units contained in the original formula (line 1). The
main loop starts in line 2 and at each iteration procedure UP is in charge of propagating all pending
units (line 3). If a conflicting clause is found (line 4), the conflict is analyzed (line 5) and as a result
a new clause is learned (i.e, inferred and recorded, line 7).
Then, the procedure backtracks, using the propagation queue Q to undo the assignment until
exactly one of the literals of the learned clause becomes unassigned (line 8). If one can further
backtrack while still maintaining this condition, it is advantageous to do so (this is commonly referred to as backjumping or non-chronological backtracking, see Silva & Sakallah, 1996). If UP
leads to no conflict, a new unassigned literal is selected to extend the current partial assignment.
The new literal is added to Q (line 10) and a new iteration takes place.
The procedure stops when a complete assignment is found (line 9) or when a top level conflict
is found (line 6). In the first case, the procedure returns true which indicates that a model has been
found, while in the second case it returns f alse which means that no model exists for the input
formula.
The performance of DPLL-based SAT solvers was greatly improved in 2001, when the SAT
solver C HAFF (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001) incorporated the two-watched
literal scheme for efficient unit propagation, the First UIP scheme (Zhang, Madigan, Moskewicz,
& Malik, 2001) for clause learning and the cheap VSIDS branching heuristic. Currently, most stateof-the-art SAT solvers, like M INI S AT (EeÌn & SoÌˆrensson, 2003), implement small variations of all
these three features. In the following we describe them in more depth.
3.1 Unit Propagation
The aim of unit propagation is twofold: on the one hand, it finds all clauses that have become units
due to the current assignment, and on the other hand, it detects whether some clause has become
conflicting. A more concrete procedure is given in Algorithm 2. While non-propagated literals exist
in Q, it picks the oldest one l and marks it as propagated (line 13). Then all clauses containing lÂ¯
that may have become falsified or units are traversed (we will later describe how these clauses are
detected). If one of such clauses becomes a unit q, it is enqueued in Q to be propagated later (line
4

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

15). The procedure iterates until there are no more units to propagate or until a conflicting clause is
found (line 16).
There are two types of literals in Q: decision literals are those that the algorithm has heuristically
selected and assigned at a branching point (lines 11 and 12 in Algorithm 1); consequence literals are
those which are added because they are logical consequences of previous decision literals (line 15).
M INI S AT uses a non-standard queue to handle units pending propagation. Unlike classical queues,
after fetching an element, it is not removed, but just marked as such. Consequently, Q is formed
by two sets of elements: the already propagated literals and the literals pending propagation. The
advantage of such strategy is that at any execution point, Q also contains the current assignment.
Besides, the propagated literals of Q are divided into decision levels. Each decision level contains a
decision literal and the set of its related consequences. Furthermore, a literal l is associated with the
original clause that caused its propagation and it is noted as l(Î±); such a clause is usually referred
to as the reason of l. Note that a decision literal l does not have a reason and will be represented as
ld .
Example 1 Consider the formula {(xÌ„1 âˆ¨ x2 )Î± , (xÌ„1 âˆ¨ x3 )Î² , (xÌ„4 âˆ¨ xÌ„5 )Î³ }. Before starting the execution,
the propagation queue is empty Q = [k]. We use the symbol k to separate propagated literals (on
the left) from literals pending propagation (on the right). If literal x1 is selected, it is added to
Q. Before propagation the queue contains Q = [kxd1 ]. UP will propagate x1 and add two new
consequences x2 and x3 . The propagation queue is now Q = [xd1 kx2 (Î±), x3 (Î²)] and the current
assignment is {x1 , x2 , x3 }. The propagation of x2 and x3 does not add new literals to Q, so it becomes
Q = [xd1 , x2 (Î±), x3 (Î²)k]
If x4 is decided, UP will add a new consequence xÌ„5 . After the propagation, we have Q =
d
[x1 , x2 (Î±), x3 (Î²), xd4 , xÌ„5 (Î³)k]. The current assignment is {x1 , x2 , x3 , x4 , xÌ„5 }. Note that no more literals
can be propagated and a complete assignment has been found. Note as well that Q contains two
decision levels: the first one is formed by literals x1 , x2 and x3 while the second one is formed by
literals x4 and xÌ„5 .
3.1.1 L AZY DATA S TRUCTURES .
As mentioned, the aim of UP is to detect all units and all conflicting clauses. Taking into account
that this process typically takes up to 80% of the total runtime of a SAT solver, it is important to
design efficient data structures.
The first attempt was the use of adjacency lists. For each literal, one keeps the list of all clauses
in which the literal appears. Then, upon the addition of a literal l to the assignment, only clauses
containing lÂ¯ have to be traversed. The main drawback of further refinements to detect efficiently
when a clause has become unit, such as keeping counters indicating the number of unassigned
literals of a clause, is that they involved a considerable amount of work upon backtracking.
The method used by M INI S AT is the two-watched literal scheme introduced by Moskewicz et al.
(2001). Its basic idea is that a clause cannot be unit or conflicting if (i) it has one satisfied literal or
(ii) it has two unassigned literals.
The algorithm keeps two special literals for each clause, called the watched literals, initially
two unassigned literals, and tries to maintain the invariant that always one satisfied literal or two
unassigned literals are watched.
The invariant may be broken only if one of the two watched literals becomes falsified. In this
case, the clause is traversed looking for another non-false literal to watch in order to restore the
5

H ERAS , L ARROSA , & O LIVERAS

invariant. If one such literal cannot be found, the clause is declared to be true, unit or conflicting depending on the value of the other watched literal. Hence, when a literal l is added to the assignment,
the clauses that may have become falsified or unit (line 14 in Algorithm 2) are only those clauses
where lÂ¯ is watched.
The main advantage of such an approach is that no work on the clauses has to be done upon
backtracking. However, the main drawback is that the only way to know how many literals are
unassigned for a given clause is by traversing all its literals. Note that this information is used by
other techniques such as the Two-sided Jeroslow branching heuristic (See Section 3.3).
3.1.2 R ESOLUTION R EFUTATION T REES .
If UP detects a conflict, an unsatisfiable subset of clauses F 0 can be determined using the information provided by Q. Since F 0 is unsatisfiable, the empty clause 2 can be derived from F 0 via
resolution. Such resolution process is called a refutation. A refutation for an unsatisfiable clause set
F 0 is a resolution refutation tree (or simply a refutation tree) if every clause is used exactly once
during the resolution process.
A refutation tree Ï’ can be built from the propagation queue Q as follows: let C0 be the conflicting
clause. Traverse Q in a LIFO (Last In First Out) fashion until a clashing clause D0 is found. Then
resolution is applied between C0 and D0 , obtaining resolvent C1 . Next, the traversal of Q continues
until a clause D1 that clashes with C1 is found, giving resolvent C2 and we iterate the process until
the resolvent we obtain is the empty clause 2. The importance of refutation trees will become
relevant in Section 6.
Example 2 Consider F = {(xÌ„1 )Î± , (x1 âˆ¨ x4 )Î² , (x1 âˆ¨ x2 )Î³ , (x1 âˆ¨ x3 âˆ¨ xÂ¯4 )Î´ , (x1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 )Îµ , (x1 âˆ¨ xÂ¯5 )Ï• }.
If we apply unit propagation the unit clause Î± is enqueued producing Q = [kxÌ„1 (Î±)]. Then xÌ„1 is
propagated and Q becomes [xÌ„1 (Î±)kx4 (Î²), x2 (Î³), xÂ¯5 (Ï•)]. After that, literal x4 is propagated causing
clause Î´ to become unit and Q becomes [xÌ„1 (Î±), x4 (Î²)kx2 (Î³), xÂ¯5 (Ï•), x3 (Î´)]. After that, literal x2
is propagated and clause Îµ is found to be conflicting. Figure 1.a shows the state of Q after the
propagation.
Now we build the refutation tree. Starting from the tail of Q the first clause clashing with the
conflicting clause Îµ is Î´. Resolution between Îµ and Î´ generates the resolvent x1 âˆ¨ xÌ„2 âˆ¨ xÂ¯4 . The first
clause clashing with x2 is Î³, producing resolvent x1 âˆ¨ xÂ¯4 . The next clause clashing with x4 is Î² and
resolution generates x1 . Finally, we resolve with clause Î± and we obtain 2.Figure 1.b shows the
resulting refutation tree.
3.2 Learning and Backjumping
Learning and backjumping are best illustrated with an example (see Silva & Sakallah, 1996; Zhang
et al., 2001, for a precise description):
Example 3 Consider the formula {(xÌ„1 âˆ¨ x2 )Î± , (xÌ„3 âˆ¨ x4 )Î² , (xÌ„5 âˆ¨ xÌ„6 )Î³ , (xÌ„2 âˆ¨ xÌ„5 âˆ¨ x6 )Î´ } and the partial
assignment {x1 , x2 , x3 , x4 , x5 , xÌ„6 } that leads to a conflict over clause Î´. Suppose that the current
propagation queue is Q = [xd1 , x2 (Î±), xd3 , x4 (Î²), xd5 , xÌ„6 (Î³)k].
In the example it is easy to see that decision xd1 is incompatible with decision xd5 . Such incompatibility can be represented with clause (xÌ„1 âˆ¨ xÌ„5 ). Similarly, consequence x2 is incompatible with
decision xd5 and it can be represented with the clause (xÌ„2 âˆ¨ xÌ„5 ).
6

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

F = {(xÌ„1 )Î± , (x1 âˆ¨ x4 )Î² , (x1 âˆ¨ x2 )Î³ , (x1 âˆ¨ x3 âˆ¨ xÂ¯4 )Î´ , (x1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 )Îµ , (x1 âˆ¨ xÂ¯5 )Ï• }

(x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 )Îµ (x1 âˆ¨ x3 âˆ¨ xÂ¯4 )Î´
x3 (Î´)

x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯4

(x1 âˆ¨ x2 )Î³

x5 (Ï•)
x2 (Î³)

x1 âˆ¨ xÂ¯4

(x1 âˆ¨ x4 )Î²

x1

(xÂ¯1 )Î±

x4 (Î²)
xÌ„1 (Î±)

2
a)

b)

Figure 1: Graphical representation of the propagation queue Q and a refutation tree Ï’ of example
2. On the top, the original formula F . On the left, the propagation Q after step 1. Arrows
indicate the order in which resolving clauses are selected. On the right, the resolution tree
computed in step 2.

Clause learning implements different techniques that are used to discover such implicit incompatibilities and adds them to the formula. Learned clauses can accelerate the subsequent search,
since they can increase the potential of future UP executions. However, it has been observed that
unrestricted clause learning can be impractical in some cases (recorded clauses consume memory
and repeated recording may lead to its exhaustion). For this reason, current SAT solvers incorporate
different clause deletion policies in order to remove some of the learned clauses.
Learned clauses can also be used to backjump if their presence would have allowed a unit propagation at an earlier decision level. In this case, we say that the clause is asserting and backjumping
can proceed by going back to that level and adding the unit propagated literal. Among the several
automated ways of generating asserting clauses, M INI S AT uses the so-called First Unique Implication Point (1UIP) (Zhang et al., 2001).
3.3 Branching Heuristic
Branching occurs in the function SelectLiteral (Algorithm 1). When there are no more literals
to propagate, this function chooses one variable from all the unassigned ones and assigns it a value.
7

H ERAS , L ARROSA , & O LIVERAS

The importance of the branching heuristic is well known, since different branching heuristic may
produce different-sized search trees.
Early branching heuristics include the Bohmâ€™s Heuristic (Buro & BuÌˆning, 1993), the Maximum Ocurrences on Minimum sized clauses (MOM) (Freeman, 1995) and the Two sided-Jeroslow
Wang Heuristic (Jeroslow & Wang, 1990). Those heuristics try to choose the literal such that its
assignment will generate the largest number of implications or that satisfy most clauses. All these
heuristics are state dependent, that is, they use information about the state of the clauses given the
current assignment. In most of them, such information is the number of unassigned literals for each
clause. Hence, they were implemented jointly with data structures based on adjacency lists since
they keep such information. For instance, the Two sided-Jeroslow Wang Heuristic computes for
each literal l of F the following function:
J(l) =

âˆ‘

2âˆ’|C|

CâˆˆF
s.t. lâˆˆC

and selects the literal l that maximizes function J(l).
As solvers become more efficient, updating metrics of state-dependent heuristics dominates the
execution time. Hence M INI S AT uses a slight modification of a state-independent heuristic first
proposed by Moskewicz et al. (2001). Such heuristic, called Variable State Independent Decaying
Sum (VSIDS), selects the literal that appears more frequently over all clauses, but giving priority to
recently learned clauses. The advantage of this heuristic is that metrics only have to be updated when
clauses are learned. Since this only occurs occasionally, its computation has very low overhead. The
VSIDS heuristic suits perfectly with lazy data structures such as the two-watched literal scheme.

4. (Weighted) Max-SAT
A weighted clause is a pair (C, w), where C is a clause and w is an integer representing the cost
of its falsification, also called its weight. If a problem contains clauses that must be satisfied, we
call such clauses mandatory or hard and associate with them a special weight >. Non-mandatory
clauses are also called soft. A weighted formula in conjunctive normal form (WCNF) is a set of
weighted clauses. A model is a complete assignment that satisfies all mandatory clauses. The cost
of an assignment is the sum of weights of the clauses that it falsifies. Given a WCNF formula F ,
Weighted Max-SAT is the problem of finding a model of F of minimum cost. This cost will be
called the optimal cost of F . Note that if a formula contains only mandatory clauses, weighted
Max-SAT is equivalent to classical SAT. If all the clauses have weight 1, we have the so-called
(unweighted) Max-SAT problem. In the following, we will assume weighted Max-SAT.
We say that a weighted formula F 0 is a relaxation of a weighted formula F (noted F 0 v F ) if
the optimal cost of F 0 is less than or equal to the optimal cost in F (non-models are considered to
have cost infinity). We say that two weighted formulas F 0 and F are equivalent (noted F 0 â‰¡ F ) if
F 0 v F and F v F 0 .
Max-SAT simplification rules transforms a formula F into an equivalent, but presumably simpler formula F 0 . All SAT simplification rules (e.g. unit propagation, tautology removal,...) can be
directly applied to Max-SAT if restricted to mandatory clauses. However, several specific Max-SAT
simplification rules exist (Larrosa et al., 2007). For instance, if a formula contains clauses (C, u)
and (C, v), they can be replaced by (C, u + v). If it contains a clause (C, 0), it may be removed. If it
contains a unit (l, >), it can be simplified by removing all (including soft) clauses containing l and
8

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

removing lÂ¯ from all the clauses (including soft clauses) where it appears. The application of this
rule until quiescence is the natural extension of unit propagation to Max-SAT.
The empty clause may appear in a weighted formula. If its weight is >, it is clear that the
formula does not have any model. If its weight is w < >, the cost of any assignment will include
that weight, so w is an obvious lower bound of the formula optimal cost. Weighted empty clauses
and their interpretation in terms of lower bounds will become relevant in Section 6.
As shown by Larrosa et al. (2007), the notion of resolution can be extended to weighted formulas
as follows 1 ,
ï£¼
ï£±
(A âˆ¨ B, m),
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£½
ï£² (x âˆ¨ A, u âˆ’ m), ï£´
(xÌ„ âˆ¨ B, w âˆ’ m),
{(x âˆ¨ A, u), (xÌ„ âˆ¨ B, w)} â‰¡
ï£´
ï£´
ï£´
(x âˆ¨ A âˆ¨ BÌ„, m), ï£´
ï£´
ï£´
ï£´
ï£´
ï£¾
ï£³
(xÌ„ âˆ¨ AÌ„ âˆ¨ B, m)

where A and B are arbitrary disjunctions of literals and m = min{u, w}.
(x âˆ¨ A, u) and (xÌ„ âˆ¨ B, w) are called the prior clashing clauses, (A âˆ¨ B, m) is called the resolvent,
(x âˆ¨ A, u âˆ’ m) and (xÌ„ âˆ¨ B, w âˆ’ m) are called the posterior clashing clauses, and (x âˆ¨ A âˆ¨ BÌ„, m) and
(xÌ„ âˆ¨ AÌ„âˆ¨ B, m) are called the compensation clauses. The effect of Max-SAT resolution, as in classical
resolution, is to infer (namely, make explicit) a connection between A and B. However, there is an
important difference between classical resolution and Max-SAT resolution. While the former yields
the addition of a new clause, Max-RES is a transformation rule. Namely, it requires the replacement
of the left-hand clauses by the right-hand clauses. The reason is that some cost of the prior clashing
clauses must be substracted in order to compensate the new inferred information. Consequently,
Max-RES is better understood as a movement of knowledge in the formula.
The resolution rule for Max-SAT preserves equivalence (â‰¡). The last two compensation clauses
may lose the clausal form, so the following rule (Larrosa et al., 2007) may be needed to recover it:

A âˆ¨ lÂ¯ : |B| = 0
CNF(A âˆ¨ l âˆ¨ B, u) =
Â¯
{(A âˆ¨ l âˆ¨ B, u)} âˆªCNF(A âˆ¨ BÌ„, u) : |B| > 0

Example 4 If we apply weighted resolution to the following clauses {(x1 âˆ¨ x2 , 3), (xÌ„1 âˆ¨ x2 âˆ¨ x3 , 4)}
we obtain {(x2 âˆ¨ x2 âˆ¨ x3 , 3), (x1 âˆ¨ x2 , 3 âˆ’ 3), (xÌ„1 âˆ¨ x2 âˆ¨ x3 , 4 âˆ’ 3), (x1 âˆ¨ x2 âˆ¨ (x2 âˆ¨ x3 ), 3), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ x2 âˆ¨
x3 , 3)}. The first clause can be simplified. The second clause can be omitted because it weight is
zero. The fifth clause can be omitted because it is a tautology. The fourth element is not a clause
because it is not a simple disjunction. Hence, we apply CNF rule to it and we obtain two new
clauses CNF(x1 âˆ¨ x2 âˆ¨ (x2 âˆ¨ x3 ), 3) = {(x1 âˆ¨ x2 âˆ¨ xÌ„2 âˆ¨ x3 , 3), (x1 âˆ¨ x2 âˆ¨ xÌ„3 , 3)}. Note that the first new
clause is a tautology. Therefore, we obtain the equivalent formula {(x2 âˆ¨ x3 , 3), (xÌ„1 âˆ¨ x2 âˆ¨ x3 , 1), (x1 âˆ¨
x2 âˆ¨ xÌ„3 , 3)}.

5. Overview of M INI M AX S AT
M INI M AX S AT is a weighted Max-SAT solver built on top of M INI S AT + (EeÌn & SoÌˆrensson, 2006).
Any other DPLL-based SAT solver could have been used, but M INI S AT + was particularly wellsuited because of its short and open-source code. Besides, it can deal with pseudo-boolean constraints.
1. If A is the empty clause then AÌ„ represents a tautology. For the special weight >, we have the relations > âˆ’ m = >
and > âˆ’ > = > (Larrosa et al., 2007)

9

H ERAS , L ARROSA , & O LIVERAS

Algorithm 3: M INI M AX S AT basic structure.
Function Search() : integer
17
ub := LocalSearch(); lb := 0 ;
18
InitQueue(Q) ;
19
Loop
20
Propagate() ;
21
if Hard Conflict then
AnalyzeConflict() ;
if Top Level Hard Conflict then return ub ;
else
LearnClause() ;
Backjump() ;
22

23
24
25

26

else if Soft Conflict then
ChronologicalBactrack() ;
if End of Search then return ub ;
else if all variables assigned then
ub := lb ;
if ub = 0 then return ub ;
ChronologicalBactrack() ;
if End of Search then return ub ;
else
l := SelectLiteral() ;
Enqueue(Q, l) ;

Given a WCNF formula (possibly containing hard and soft clauses), M INI M AX S AT returns the
cost of the optimal model (or > if there is no model). This is achieved by means of a branch-andbound search, as it is usually done to solve optimization problems.
Like M INI S AT, the tree of assignments is traversed in a depth-first manner. At each search point,
the algorithm tries to simplify the current formula and, ideally, detect a conflict, which would mean
that the current partial assignment cannot be successfully extended. M INI M AX S AT distinguishes
two types of conflicts: hard and soft. Hard conflicts indicate that there is no model extending the
current partial assignment (namely, all the mandatory clauses cannot be simultaneously satisfied).
Hard conflicts are detected taking only into account hard clauses and using the methods of M INI S AT.
When a hard conflict occurs, M INI M AX S AT learns a hard clause and backjumps as M INI S AT would
do. Soft conflicts indicate that the current partial assignment cannot be extended to an optimal
assignment. In order to identify soft conflicts, the algorithm maintains two values during the search:
â€¢ The cost of the best model found so far, which is an upper bound ub of the optimal solution.
â€¢ An underestimation of the best cost that can be achieved extending the current partial assignment into a model, which is a lower bound lb of the current subproblem.
A soft conflict is detected when lb â‰¥ ub, because it means that the current assignment cannot lead to
an optimal model. When a soft conflict is detected, the algorithm backtracks chronologically. Note
10

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

Algorithm 4: MiniMaxSat propagation.
Function MS-UP() : conflict
while (Q contains non-propagated literals) do
27
l := GetFirstNonPropagatedLit(Q); MarkAsPropagated(l) ;
Â¯ ;
28
lb := lb +V (l))
29
if lb â‰¥ ub then return Soft Conflict ;
Â¯ >) that becomes unit or falsified do
30
foreach Hard clause (Câˆ¨ l,
Â¯
31
if (C âˆ¨ l, >) becomes unit (q, >) then Enqueue(Q, q) ;
Â¯ >) becomes falsified then return Hard Conflict ;
32
else if (C âˆ¨ l,
Â¯ u) that becomes unit do
33
foreach Soft clause (Câˆ¨ l,
Â¯
34
if (Câˆ¨ l, u) becomes a unit (q, u) then V (q) := V (q) + u ;

35
36
37
38
39

return None ;
Function Propagate() : conflict
c := MS-UP( ) ;
if c = Hard or Soft Conflict then return c ;
improveLB( ) ;
if lb â‰¥ ub then return Soft Conflict ;
return None ;

that one could also backjump by computing a clause expressing the reasons that led to lb â‰¥ ub.
However, in the presence of lots of soft clauses, this approach ends up creating too many long
clauses which affect negatively to the efficience of the solver and hence we decided to perform
simple chronological backtracking.
We also want to remark that any soft clause (C, w) with w â‰¥ ub must be satisfied in an optimal
assignment. Therefore, in the following we assume that such soft clauses are automatically transformed into hard clauses previous to search. Other than those ones, no other soft clause is promoted
into a hard one during the search.
An algorithmic description of M INI M AX S AT is presented in Algorithm 3. Before starting the
search, a good initial upper bound is obtained with a local search method (line 17) which may yield
the identification of some new hard clauses. In our current implementation we use U BCSAT (Tompkins & Hoos, 2004) with default parameters. The selected local search algorithm is IROTS (Iterated
Robust Tabu Search) (Smyth, Hoos, & StuÌˆtzle, 2003). Besides, the lower bound is initialized to
zero. Next, the queue Q is initialized with all unit hard clauses in the resulting formula (line 18).
The main loop starts in line 19 and each iteration is in charge of propagating all pending literals
(line 20) and, if no conflict is detected, attempting the extension of the current partial assignment
(line 26). Pending literals in Q are propagated in function Propagate (line 20), which may return a hard or soft conflict. If a hard conflict is encountered (line 21) the conflict is analyzed, a
new hard clause is learned and backjumping is performed. This is done as introduced in Section 3.
If a soft conflict is encountered (line 22) chronological backtracking is performed. If no conflict is
found (line 26), a literal is heuristically selected and added to Q for propagation in the next iteration.
However, if the current assignment is complete (line 23), the upper bound is updated. Search stops
if a zero-cost solution is found, since it cannot be further improved (line 24). Else, chronological
backtracking is performed (line 25). Note that backjumping leads to termination if a top level hard
11

H ERAS , L ARROSA , & O LIVERAS

conflict is found, while chronological backtracking leads to termination if the two values for the first
assigned variable have been tried.
Algorithm 4 describes the propagation process (function Propagate). It uses an array V (l)
which accumulates the weight of all soft clauses that have become unit over l; namely, original
clauses (A âˆ¨ l, w) such that the current assignment falsifies A. If no such clauses exists, we assume
V (l) = 0. First of all, it performs a Max-SAT-adapted form of unit propagation (MS-UP, line 35).
MS-UP iterates over the non-propagated literals l in Q (line 27). Firstly, adding l to the assignment
Â¯ we
may make a set of soft clauses falsified. Since the cost of all such clauses is kept in V (l),
add it to the lower bound (line 28). If the lower bound increment identifies a soft conflict, it is
returned (line 29). Then, if a hard clause becomes unit, the corresponding literal is added to Q
for future propagation (line 31). Finally, if a soft clause becomes a unit clause (q, u) (line 33), its
weight u is added to V (q) (line 34). If during this process a hard conflict is detected, the function
returns it (lines 32,36). Else, the algorithm attempts to detect a soft conflict with a call to procedure
improveLB (line 37), and it returns the soft conflict if it is found (line 38). In the next section a
detailed description of improveLB can be found. Finally, if no conflict is detected, the function
returns None (line 39).

6. Lower Bounding in M INI M AX S AT
In the following, we consider an arbitrary search state of M INI M AX S AT before the call to the
procedure improveLB. For the purpose of this section, such a search state can be characterized
by the current assignment. The current assignment determines the current subformula which is the
original formula conditioned by the current assignment: If a clause contains a literal that is part of
the current assignment, it is removed. Besides, all the literals whose negation appear in the current
assignment are removed from the clauses where they appear.
The value of lb maintained by M INI M AX S AT is precisely the aggregation of costs of all the
clauses that have become empty due to the current assignment. Similarly, we recall that the value
V (l) is the aggregation of costs of all the clauses that have become unit over l due to the current
assignment. Thus, the current subformula contains (2, lb) and (l,V (l)) for every l.
M INI M AX S AT computes its lower bound by deriving new soft empty clauses (2, w) through
a resolution process. Such clauses are added to the already existing clause (2, lb) producing an
increment of the lower bound.
Â¯ w) by (l, u âˆ’ m), (l,
Â¯ wâˆ’
As a first step, improveLB replaces each occurrence of (l, u) and (l,
m), (2, m) (with m = min{u, w}), which amounts to applying a restricted version of Max-SAT resolution known as Unit Neighborhood Resolution (UNR) (Larrosa et al., 2007).
It produces an immediate increment of the lower bound (i.e., the weight of the empty clause at
line 43) as it is illustrated in the following example,
Example 5 Consider the current state is {(2, 3), (x1 , 1), (x2 , 1), (xÌ„1 , 2), (xÌ„2 , 2), (x1 âˆ¨ x2 , 3)}. UNR
would resolve on clauses (x1 , 1) and (xÌ„1 , 2) replacing them by (xÌ„1 , 1) and (2, 1) (all other compensation clauses are removed because their weight is zero or they are tautologies). The two empty
clauses can be grouped into (2, 3 + 1 = 4). UNR would also resolve on clauses (x2 , 1) and (xÌ„2 , 2)
replacing them by (xÌ„2 , 1) and (2, 1). The two empty clauses can be grouped into (2, 4 + 1 = 5). So,
the new equivalent formula is {(2, 5), (xÌ„1 , 1), (xÌ„2 , 1), (x1 âˆ¨ x2 , 3)} with a higher lower bound of 5.
12

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

Algorithm 5: Lower Bounding in M INI M AX S AT
Function SUP() : conflict
40
InitQueue(Q) ;
while (Q contains non-propagated literals) do
l := GetFirstNonPropagatedLit(Q); MarkAsPropagated(l) ;
41
foreach (Hard or Soft) Clause C âˆ¨ lÂ¯ that becomes unit or falsified do
if C âˆ¨ lÂ¯ becomes a unit q then Enqueue(Q, q) ;
else if C âˆ¨ lÂ¯ becomes falsified then return conflict ;

42
43
44
45
46
47
48

return None ;
Procedure improveLB() : lb
Â¯ w) âˆˆ F do
foreach (l, v), (l,
Â¯ w âˆ’ m), (2, m) with m := min (v, w) ;
replace them by (l, v âˆ’ m), (l,
while SU P() = con f lict do
Ï’ := BuildTree() ;
m := minimum weight among clauses in Ï’;
if Condition then ApplyResolution( Ï’, m ) ;
else lb := lb + m; remove weight m from clauses in Ï’;

As a second step improveLB executes a simulation of unit propagation (SUP, line 44) in
which soft clauses are treated as if they were hard. First, SUP adds to Q all unit soft clauses (line
40). Then, the new literals in Q are propagated. When new (hard or soft) clauses become unit,
they are inserted in Q (line 41). If SUP yields a conflict, it means that there is a subset of (soft or
hard) clauses that cannot be simultaneously satisfied. We showed in Section 3 that Q can be used
to identify such subset and build a refutation tree Ï’. ImproveLB computes such a tree (line 45).
If we take into account again the weights of the clauses and apply Max-SAT resolution (Section 4)
as dictated by Ï’, one can see that it will produce a new clause (2, m), where m is the minimum
weight among all the clauses in the tree (line 46). It means that the extension of the current partial
assignment to the unassigned variables will have a cost of at least m.
It is important to remark that at each step in the Max-SAT resolution process we do not consider
the minimum of the weight of the two clauses, but rather the minimum of all the clauses in the
resolution tree. This is why m is passed as a parameter in line 47.
The result of the resolution process is the replacement of all the clauses in the leaves of Ï’ by
(2, m) and the corresponding compensation clauses (function ApplyResolution in line 47),
thus obtaining an equivalent formula with a lower bound increment of m. We call this procedure
resolution-based lower bounding.
Example 6 Consider the formula F = {(xÌ„1 , 2)Î± , (x1 âˆ¨ x4 , 1)Î² , (x1 âˆ¨ x2 , >)Î³ , (x1 âˆ¨ x3 âˆ¨ xÂ¯4 , 2)Î´ , (x1 âˆ¨
xÌ„2 âˆ¨ xÌ„3 , 3)Îµ , (x1 âˆ¨ xÂ¯5 , 1)Ï• }
Step 1. Apply SUP. Initially, the unit clause Î± is enqueued producing Q = [kxÌ„1 (Î±)]. Then
xÌ„1 is propagated and Q becomes [xÌ„1 (Î±)kx4 (Î²), x2 (Î³), xÂ¯5 (Ï•)]. Literal x4 is propagated and clause Î´
becomes unit, producing Q = [xÌ„1 (Î±), x4 (Î²)kx2 (Î³), xÂ¯5 (Ï•), x3 (Î´)]. After that, literal x2 is propagated
and clause Îµ is found to be conflicting. Figure 2.a shows the state of Q after the propagation.
13

H ERAS , L ARROSA , & O LIVERAS

F = {(xÌ„1 , 2)Î± , (x1 âˆ¨ x4 , 2)Î² , (x1 âˆ¨ x2 , >)Î³ , (x1 âˆ¨ x3 âˆ¨ xÂ¯4 , 2)Î´ , (x1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 , 3)Îµ , (x1 âˆ¨ xÂ¯5 , 1)Ï• }

(x1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 , 3)Îµ (x1 âˆ¨ x3 âˆ¨ xÂ¯4 , 2)Î´

x3 (Î´)

Îµ

Î´
Î³

x5 (Ï•)

Î²

x2 (Î³)

(x1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 , 1)
(x1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 âˆ¨ x4 , 2) (x1 âˆ¨ xÌ„2 âˆ¨ xÂ¯4 , 2) (x1 âˆ¨ x2 , >)Î³
(x1 âˆ¨ x2 âˆ¨ x3 âˆ¨ xÂ¯4 , 2)
(x1 âˆ¨ x2 , >)

(x1 âˆ¨ xÂ¯4 , 2)

(x1 âˆ¨ x4 , 2)Î²

Î±

x4 (Î²)
xÌ„1 (Î±)

(x1 , 2)

2

(xÂ¯1 , 2)Î±

(2, 2)

a)

b)

c)

F 0 = {(x1 âˆ¨ x2 , >), (x1 âˆ¨ xÂ¯5 , 1), (2, 2), (x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 , 1), (x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 âˆ¨ x4 , 2), (x1 âˆ¨ x2 âˆ¨ x3 âˆ¨ xÂ¯4 , 2)}
F

00

= {(x1 âˆ¨ x2 , >), (x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 , 1), (x1 âˆ¨ xÂ¯5 , 1), (2, 2)}

Figure 2: Graphical representation of M INI M AX S AT lower bounding. On the top, the original
current formula F . On the left, the propagation Q after step 1. In the middle, the structure
of the refutation tree computed by the simulation of UP in step 2. On the right, the
effect of actually executing the Max-SAT resolution (step 3). The resulting formula F 0
appears bellow. If substraction-based lower bounding is performed, step 3 is replaced by
a substraction of weights, producing formula F 00 .

Step 2. Build the simulated refutation tree. Starting from the tail of Q the first clause clashing
with the conflicting clause Îµ is Î´. Resolution between Îµ and Î´ generates the resolvent x1 âˆ¨ xÌ„2 âˆ¨ xÂ¯4 .
The first clause clashing with x2 is Î³, producing resolvent x1 âˆ¨ xÂ¯4 . The next clause clashing with
x4 is Î² and resolution generates x1 . Finally, we resolve with clause Î± and we obtain 2.Figure 2.b
shows the resulting resolution tree.
Step 3. Apply Max-SAT resolution. We apply Max-SAT resolution as indicated by the refutation
tree computed in Step 2. Figure 2.c graphically shows the result of the process. Leaf clauses are
the original (weighted) clauses involved in the resolution. Each internal node indicates a resolution
step. The resolvents appear in the junction of the edges. Beside each resolvent, inside a box, there
are the compensation clauses that must be added to the formula to preserve equivalence. Since
clauses that are used in resolution must be removed, the resulting formula F 0 consists of the root of
14

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

the tree ((2, 2)),all compensation clauses and all clauses not used in the refutation tree. That is, the
resulting formula is F 0 = {(x1 âˆ¨ x2 , >), (x1 âˆ¨ xÂ¯5 , 1), (2, 2), (x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 , 1), (x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 âˆ¨ x4 , 2), (x1 âˆ¨
x2 âˆ¨ x3 âˆ¨ xÂ¯4 , 2)}. The soundness of Max-SAT resolution guarantees that F â‰¡ F 0 .
Remark 1 All the transformations applied by the resolution-based lower bounding can be passed
on to descendent nodes because the changes preserve equivalence. Nevertheless, transformations
have to be restored when backtracking takes place.
An alternative to problem transformation through resolution is to identify the lower bound increment m and then substract it from all the clauses that would have participated in the resolution
tree. This procedure is similar to the lower bound computed by Li et al. (2005) and we call it
substraction-based (line 48) lower bounding.
Example 7 Consider formula F from the previous example. Steps 1 and 2 are identical. However,
substraction-based lower bounding would replace Step 3 by Step 3â€™ that substracts weight 2 from
the clauses that appear in the refutation tree and then adds (2, 2) to the formula. The result is
F 00 = {(x1 âˆ¨ x2 , >), (x1 âˆ¨ xÂ¯2 âˆ¨ xÂ¯3 , 1), (x1 âˆ¨ xÂ¯5 , 1), (2, 2)}. Note that F 00 v F .
Remark 2 All the substractions applied by the substraction-based lower bounding have to be restored before moving to a descendent node because they do not preserve equivalence.
After the increment of the lower bound with either technique, procedure SUP can be executed
again, which may yield new lower bound increments. The process is repeated until SUP does not
detect any conflict.
When comparing the two previous approaches, we observe that resolution-based lower bounding
has a larger overhead, because resolution steps need to be actually computed and their consequences
must be added to the current formula and removed upon backtracking. However, the effort invested
in the transformation may be well amortized because the increment obtained in the lower bound
becomes part of the current formula, so it does not have to be discovered again and again by all
the descendent nodes of the search. On the other hand, substraction-based lower bounding has a
smaller overhead because resolution needs not to be actually computed. This also facilitates the
context restoration upon backtracking.
M INI M AX S AT incorporates the two alternatives and chooses to apply one or the other heuristically (lines 47,48) depending on a specific condition (line 47). We observed that resolution-based
lower bounding seems to be more effective if resolution is only applied to low arity clauses. As a
consequence, after the identification of the resolution tree, M INI M AX S AT applies resolution-based
lower bounding only if the largest resolvent in the resolution tree has arity strictly less than 4. Otherwise, it applies substraction-based lower bounding. See Section 8 for more details.

7. Additional Features of M INI M AX S AT
In this section we overview other important features of M INI M AX S AT, namely the use of the twowatched literal scheme, its branching heuristic, the use of soft probing and how M INI M AX S AT
deals with pseudo-boolean functions.
15

H ERAS , L ARROSA , & O LIVERAS

7.1 Two-Watched Literals
M INI M AX S AT uses the two-watched literal scheme also on soft clauses. Recall that one of the main
advantages of this technique, when applied to pure SAT problems, is that when backtracking takes
place, no work has to be done on the clauses. Unfortunately, in the case of soft clauses some restoration needs to be done. When a soft clause becomes unit over literal l in function MS-UP, its weight
is added to V (l) and the clause is eliminated (or marked as eliminated) to avoid reusing it in the
lower bounding procedure. These changes, as well as any addition to lb, have to be restored when
backtracking is performed. However, note that during the executions of SUP (simulation of unit
propagation) all clauses are considered as hard. In this case the two-watched literal scheme works
exactly as in a SAT solver with both hard and soft clauses. When an inconsistency is detected by
SUP or it stops because there are no more literals to propagate, the initial state has to be recovered.
In that situation restoring the initial state is completely overhead free.
7.2 Branching Heuristic
M INI M AX S AT incorporates two alternative branching heuristics. The first one is the VSIDS heuristic (Moskewicz et al., 2001) disregarding soft clauses (that is, M INI S AT â€™ S default). This heuristic is
likely to be good in structured problems in which learning and backjumping play a significant role,
as well as in problems in which it is difficult to find models (namely, the satisfaction component of
the problem is more difficult than the optimization component). Since this heuristic disregards soft
clauses, it is likely to be ineffective in problems where it is easy to find models and the difficulty
is to find the optimal one and prove its optimality. In the extreme case, where problems only contain soft clauses (every complete assignment is a model) the VSIDS heuristic is blind and therefore
completely useless.
To overcome this limitation of VSIDS, M INI M AX S AT also incorporates the Weighted Jeroslow
heuristic (Heras & Larrosa, 2006). It is the extension of the SAT Jeroslow heuristic described in
Section 3. Given a weighted formula F, for each literal l of F the following function is defined:
J(l) =

âˆ‘

2âˆ’|C| Â· w

(C,w)âˆˆF
s.t. lâˆˆC

where mandatory clauses are assumed to have a weight equal to the upper bound ub. The heuristic
selects the literal with the highest value of J(l). Its main disadvantage is that metrics need to be
updated at each visited node. In combination with the two-watched literal this updating becomes
expensive and does not seem to pay off in general. Thus, in our current implementation of the
heuristic, the J(l) values are computed only at the root node and used throughout all the solving
process. We found in our experiments that this heuristic is a good alternative in problems where
the difficulty lies on the optimization part (e.g. problems with many models). M INI M AX S AT
automatically changes from VSIDS to weighted Jeroslow if the problem does not contain any literal
l such that there are some hard clauses with l and some other hard clauses with l.Â¯
In both heuristics, if there is some literal l such that V (l) + lb â‰¥ ub at some node of the search
tree, then lÂ¯ is the selected literal and l is never assigned.
16

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

7.3 Soft Probing
Probing is a well-known SAT technique that allows the formulation of hypothetical scenarios (Lynce
& Silva, 2003). The idea is to temporarily assume that l is a hard unit clause and then execute unit
propagation. If UP yields a conflict, we know that any model extending the current assignment must
contain l.Â¯ The process is iterated over all the literals until quiescence. Exhaustive experiments in
the SAT context indicate that it is too expensive to probe during the search (Le Berre, 2001; Lynce
& Silva, 2003), so it is normally done as a pre-process in order to reduce the initial number of
branching points.
We can easily extend this idea to Max-SAT. In that context, besides the discovery of unit hard
clauses, it may be used to make explicit weighted unit clauses. We call it soft probing. As in SAT, the
idea is to temporarily assume that l is a unit clause and then simulate unit propagation (i.e., execute
SUP()). Then, we build the resolution tree Ï’ from the propagation queue Q. If all the clauses in Ï’
are hard, we know that lÂ¯ must be added to the assignment. Else, we can reproduce Ï’ applying MaxÂ¯ m) where m is the minimum
SAT resolution with the weighted clauses and derive a unit clause (l,
weight among the clauses in Ï’. Having unit soft clauses upfront makes the future executions of
improveLB much more effective in the subsequent search. Besides, if we derive both (l, u) and
Â¯ w), we can generate via unit neighborhood resolution (see Example 5) an initial non-trivial lower
(l,
bound of min{u, w}. We tested soft probing during the search and as a preprocessing in several
benchmarks. We observed empirically that soft probing as a preprocessing was the best option as it
is in SAT.

Example 8 Consider formula F = {(x1 âˆ¨ x2 , 1)Î± , (x1 âˆ¨ x3 , 1)Î² , (xÌ„2 âˆ¨ xÌ„3 , 1)Î³ }. If we assume xÌ„1 by
adding it to Q and then execute SUP a conflict is reached. We obtain Q = [xÌ„d1 , x2 (Î±), x3 (Î²)] and
we detect that Î³ is a conflicting clause. The clauses involved in the refutation tree are Î³, Î², and Î±.
Resolving clauses Î³ and Î² results in {(x1 âˆ¨ x2 , 1)Î± , (x1 âˆ¨ xÌ„2 , 1), (x1 âˆ¨ x2 âˆ¨ x3 , 1), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 , 1)}. The
resolution of the previous resolvent and Î± produces the (equivalent) formula F 0 = {(x1 , 1), (x1 âˆ¨
x2 âˆ¨ x3 , 1), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 , 1)}.
7.4 Pseudo-boolean Functions
A pseudo-boolean optimization problem (PBO) (Barth, 1995; Sheini & Sakallah, 2006; EeÌn &
SoÌˆrensson, 2006) has the form:
minimize âˆ‘nj=1 c j Â· x j
subject to âˆ‘nj=1 ai j l j â‰¥ bi , i = 1 . . . m
where x j âˆˆ {0, 1}, l j is either x j or 1 âˆ’ x j , and c j , ai j and bi are non-negative integers.
If M INI M AX S AT is provided with a PBO instance, it translates it into a Max-SAT formula as follows: each pseudo boolean constraint is translated into a set of hard clauses using M INI S AT + (EeÌn
& SoÌˆrensson, 2006) (the algorithm heuristically decides the most appropriate translation choosing
among adders, sorters or BDDs). The objective function is translated into a set of soft unit clauses.
Each summand c j Â· x j becomes a new soft unit clause (xÌ„ j , c j ). After the translation M INI M AX S AT
is executed as usual.
17

H ERAS , L ARROSA , & O LIVERAS

8. Empirical Results
In this section we present the benchmarks and the solvers used in our empirical evaluation. Then,
we report the experiments performed in order to adjust the parameters of M INI M AX S AT. Finally, a
comparison with other solvers is presented.
8.1 Benchmarks and Encodings
Having a good set of problems is fundamental to show the effectiveness of new solvers. In the
following, we present several problems and we explain how to encode them as Weighted Max-SAT.
8.1.1 M AX - K -SAT
A k-SAT CNF formula is a CNF formula in which all clauses have size k. We generated random
unsatisfiable 2-SAT and 3-SAT formulas with the Cnfgen generator2 and solved the corresponding
MAX-SAT problem. In the benchmarks, we fixed the number of variables and varied the number of
clauses, which can be repeated.
8.1.2 M AX - CUT
Given a graph G = (V, E), a cut is defined by a subset of vertices U âŠ† V . The size of a cut is
the number of edges (vi , v j ) such that vi âˆˆ U and v j âˆˆ V âˆ’ U . The Max-cut problem consists on
finding a cut of maximum size. It can be encoded as Max-SAT associating one variable xi to each
graph vertex. Value true (respectively, false) indicates that vertex vi belongs to U (respectively, to
V âˆ’ U ). For each edge (vi , v j ), there are two soft clauses (xi âˆ¨ x j , 1), (xÌ„i âˆ¨ xÌ„ j , 1). Given a complete
assignment, the number of violated clauses is |E| âˆ’ S where S is the size of the cut associated to the
assignment. In our experiments we considered Max-Cut instances extracted from random graphs of
60 nodes with varying number of edges.
8.1.3 M AX - ONE
Given a satisfiable CNF formula, max-one is the problem of finding a model with a maximum
number of variables set to true. This problem can be encoded as Max-SAT by considering the
clauses in the original formula as mandatory and adding a weighted unary clause (xi , 1) for each
variable in the formula. Note that solving this problem is much harder than solving the usual SAT
problem, because the search cannot stop as soon as a model is found. The optimal model must be
found and its optimality must be proved. We considered the max-one problem over two types of
CNF formula: random 3-SAT instances of 120 variables (generated with Cnfgen), and structured
satisfiable instances coming from the 2002 SAT Competition3 .
8.1.4 M INIMUM V ERTEX C OVERING

AND

M AX -C LIQUE

Given a graph G = (V, E), a vertex covering is a set U âŠ† V such that for every edge (vi , v j ) either
vi âˆˆ U or v j âˆˆ U . The size of a vertex covering is |U |. The minimum vertex covering problem
consists in finding a covering of minimal size. It can be naturally formulated as (weighted) MaxSAT. We associate one variable xi to each graph vertex vi . Value true (respectively, false) indicates
2. A. van Gelder ftp://dimacs.rutgers.edu/pub/challenge/satisfiability/contributed/UCSC/instances
3. http://www.satcompetition.org/2002/

18

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

that vertex vi belongs to U (respectively, to V âˆ’U ). There is a binary hard (xi âˆ¨ x j , >) for each edge
(vi , v j ). It specifies that one or both of these two vertices have to be in the covering because there
is an edge connecting them. There is a unary clause (xÌ„i , 1) for each variable xi , in order to specify
that it is preferred not to add vertices to U . There is a simple way to transform minimum vertex
coverings into max-cliques and vice-versa (Fahle, 2002).
In our experiments, we considered maximum clique instances extracted from random graphs
with 150 nodes and varying number of edges. We also considered the 66 Max-Clique instances
from the DIMACS challenge4 .
8.1.5 C OMBINATORIAL AUCTIONS
A combinatorial auction is defined by a set of goods G and a set of bidders that bid for indivisible
subsets of goods. Each bid i is defined by the subset of requested goods Gi âŠ† G and the amount of
money offered. The bid-taker, who wants to maximize its revenue, must decide which bids are to be
accepted. Note that if two bids request the same good, they cannot be jointly accepted (Sandholm,
1999). In its Max-SAT encoding, there is one variable xi associated to each bid. There are unit
clauses (xi , ui ) indicating that if bid i is not accepted there is a loss of profit ui . Besides, for each
pair i, j of conflicting bids, there is a mandatory clause (xÌ„i âˆ¨ xÌ„ j , >).
In our experiments, we used the CATS generator (K. Leyton-Brown & Shoham, 2000) that
allows to generate random instances inspired from real-world scenarios. In particular, we generated
instances from the Regions, Paths and Scheduling distributions. The number of goods was fixed to
60 and we increased the number of bids. By increasing the number of bids, instances become more
constrained (namely, there are more conflicting pairs of bids) and harder to solve.
8.1.6 M ISCELLANEOUS
We also considered the following sets of instances widely used in the literature:
â€¢ The unsatisfiable instances of the 2nd DIMACS Implementation Challenge 5 considered by
de Givry, Larrosa, Meseguer, and Schiex (2003) and Li et al. (2005): random 3-SAT instances
(aim and dubois), pigeon hole problem (hole) and coloring problems (pret). Observe that all
these instances are modelled as unweighted Max-SAT (i.e. all clauses have weight 1).
â€¢ Max-CSP random instances generated using the protocol specified by Larrosa and Schiex
(2003) and de Givry, Heras, Larrosa, and Zytnicki (2005). We distinguish 4 different sets of
problems: Dense Loose (DL), Dense Tight (DT), Sparse Loose (SL) and Sparse Tight (ST).
Tight instances have about 20 variables while loose instances have about 40 variables. Each
set contains 10 instances with 3 values and 10 instances with 4 values per variable.
â€¢ Planning (Cooper, Cussat-Blanc, de Roquemaurel, & ReÌgnier, 2006) and graph coloring 6
structured instances taken from a Weighted Constraint Satisfaction Problem (WCSP) repository 7 .
4.
5.
6.
7.

ftp://dimacs.rutgers.edu/pub/challenge/graph/benchmarks/clique
http://mat.gsia.cmu.edu/challenge.html
http://mat.gsia.cmu.edu/COLORING02/benchmarks
http://mulcyber.toulouse.inra.fr/plugins/scmcvs/cvsweb.php/benchs/?cvsroot=toolbar

19

H ERAS , L ARROSA , & O LIVERAS

â€¢ Problems taken from the 2006 pseudo-boolean evaluation 8 : logic synthesis, misc (garden),
routing, MPI (Minimum Prime Implicant), MPS (miplib). These instances are encoded to
Max-SAT as specified in the previous section.
Note that Max-CSP, Planning and graph coloring instances are encoded into Max-SAT using the
direct encoding (Walsh, 2000).
8.2 Alternative Solvers
We compare M INI M AX S AT with several optimizers from different communities. We restricted our
comparison to freely available solvers. We considered the following ones:
â€¢ M AXSATZ (Li et al., 2006; Li, ManyaÌ€, & Planes, 2007). Unweighted Max-SAT solver. It was
the best unweighted Max-SAT solver in the 2006 Max-SAT Evaluation.
â€¢ M AX -DPLL (Heras & Larrosa, 2006; Larrosa et al., 2007). Weighted Max-SAT solver. It is
part of the T OOLBAR package. It was the best solver for weighted Max-SAT and the second
best solver for unweighted Max-SAT in the 2006 Max-SAT Evaluation.
â€¢ T OOLBAR (Larrosa, 2002; Larrosa & Schiex, 2003; de Givry et al., 2003, 2005). It is a
state-of-the-art Weighted CSP solver.
â€¢ P UEBLO 1.5 (Sheini & Sakallah, 2006). It is a pseudo-boolean solver. It ranked first on
several categories of the 2005 Pseudo Boolean Evaluation.
â€¢ M INISAT + (EeÌn & SoÌˆrensson, 2006). It is a pseudo-boolean solver that translates the problems into SAT and solves them with MiniSat. It ranked first on several categories of the 2005
Pseudo Boolean Evaluation.
Those instances taken from the pseudo-boolean evaluation were given in their original format to
P UEBLO and M INISAT +. All other instances were translated from Max-SAT to PBO by partitioning
the set of clauses into three sets: H contains the mandatory clauses (C, >), W contains the nonunary weighted clauses (C, u < >) and U contains the unary weighted clauses (l, u). For each
hard clause (C j , >) âˆˆ H there is a pseudo boolean constraint C0j â‰¥ 1, where C0j is obtained from
C j by replacing âˆ¨ by + and negated variables xÌ„ by 1 âˆ’ x. For each non-unary weighted clause
(C j , u j ) âˆˆ W there is a pseudo boolean constraint C0j + r j â‰¥ 1, where C0j is computed as before,
and r j is a new variable that, when set to 1, trivially satisfies the constraint. Finally, the objective
function to minimize is,

âˆ‘

u jr j +

âˆ‘

u jl j

(l j ,u j )âˆˆU

(C j ,u j )âˆˆW

8.3 Experimental Results
We divide the experiments in two parts. The purpose of the first part is to evaluate the impact
of the different techniques of M INI M AX S AT and set the different parameters. Since some of the
techniques can be effective in some benchmarks and useless or even counterproductive in some others (Brglez, Li, & Stallman, 2002), we aimed at finding a configuration such that M INI M AX S AT
8. http://www.cril.univ-artois.fr/PB06/

20

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

performs reasonably well on all the instances. The purpose of the second part is to compare M IN I M AX S AT with alternative solvers. Since some of these solvers are specifically designed for some
type of problems, we do not expect that M INI M AX S AT will outperform them. We rather want to
show the robustness of M INI M AX S AT by showing that it is usually close in performance with the
best alternative for each type of problems.
Results are presented in plots and tables. Regarding tables, the first column contains the name
of the set of problems. The second column shows the number of instances. The remaining columns
report the performance of the different solvers. Each cell contains the average cpu time that the
solver required to solve all instances. If some solver could not solve all the instances of a set, a
number inside brackets indicates the number of solved instances and the average cpu time only
takes into account solved instances. If a cell contains a dash, it means that no instance could be
solved within the time limit. Regarding plots, note that the legend goes in accordance with the
performance of the solvers. The time limit was set to 900 seconds for each instance.
Our solver, written in C++, was implemented on top of M INISAT + (EeÌn & SoÌˆrensson, 2006).
Executions were made on a 3.2 Ghz Xeon computer with Linux. In all the experiments with random
instances, samples had 30 instances and plots report mean cpu time in seconds.
8.4 Setting the Parameters of M INI M AX S AT
In the following we evaluate in order the importance of the following techniques inside M INI M AX S AT: lower bounding, soft probing, branching heuristics, learning and backjumping.
Starting from a basic version that guides search with the Jeroslow branching heuristic and has
the rest of techniques deactivated, we analyze them one by one. Each analysis studies one technique
and incorporates all the previously analyzed ones with the corresponding tuned parameters. In the
three first experiments we only consider little but challenging instances generated randomly in which
lower bounding plays a fundamental role to solve them. Finally, we consider structured instances in
which learning and backjumping is required to solve them.
8.4.1 L OWER

BOUNDING

In this experiment we analyze the impact of resolution-based lower bounding versus substractionbased lower bounding, as well as combined strategies. We considered the following combination
of the two techniques: when SUP detects an inconsistency and the refutation tree is computed,
we look at the resolvent with maximum size. If its size is less than or equal to a parameter K,
then resolution-based lower bounding is applied, otherwise substraction-based lower bounding is
applied. We tested K = {0, 1, 2, 3, 4, 5, âˆž}. Note that K = 0 corresponds to pure substraction-based
lower bounding (and therefore is similar to the approach of Li et al., 2005), while K = âˆž corresponds
to a pure resolution-based lower bounding.
The results are presented in Figure 3. As can be seen, the pure substraction-based lower bounding K = 0 is always the worst option. Better results are obtained as K increases. However, the
improvement stops (or nearly stops) when K = 3. When K > 3 no significant improvement is noticed. The plot omits the K = 4 and K = 5 case for clarity reasons. Since higher values of K may
produce new clauses of higher size and this may cause overhead in some instances, we set K = 3
for the rest of the experiments.
21

H ERAS , L ARROSA , & O LIVERAS

(a) Max-2-SAT, 100 variables

15
10

(b) Max-3-SAT, 60 variables

K=0
K=1
K=2
K=3
K=inf

cpu time

cpu time

20

5
0
200 300 400 500 600 700 800

60
50
40
30
20
10
0

K=0
K=1
K=2
K=inf
K=3

300

number of clauses

400

500

600

700

800

number of clauses

cpu time

(c) Max-CUT, 60 nodes
14
12
10
8
6
4
2
0
200

K=0
K=1
K=2
K=3
K=inf

250

300

350

400

450

number of nodes

Figure 3: Performance of M INI M AX S AT with different mixed lower boundings (K = 0, 1, 2, 3, inf).

8.4.2 S OFT

PROBING

In our second experiment, we evaluate the impact of soft probing. In our preliminary experiments,
we observed that soft probing was too time consuming, so we decided to limit soft probing as
follows. Initially, we assign a propagation level of 0 to the variable to probe. Then, each new literal
to propagate is assigned a propagation level L + 1 if the literal that produces its propagation has
level L. We limited probing to propagate literals with a maximum propagation level of M. We
finally restricted M â‰¤ 2 since it gives the best results. Note that a propagation level is not the same
as a decision level.
We compare three alternatives: probing at each node of the search (S), probing as a pre-process
before search (P) and no probing at all (N). The results, in Figure 4, indicates that probing during
search is the worst option for Max-2-SAT and Max-3-SAT while it produces some improvement in
Max-CUT. Finally, probing as a preprocessing gives slightly improvement for Max-2-SAT and the
best results for Max-CUT. Note that soft probing as a preprocessing on Max-3-SAT has no effect
and is omitted from the plot (its results are similar to N). Given these results, we decided to include
soft probing only as a preprocessing.
8.4.3 J EROSLOW

BRANCHING HEURISTIC

In the following experiment, we evaluate the importance of the weighted Jeroslow heuristic. Figure
5 shows the time difference between M INI M AX S AT with the Jeroslow heuristic as in the previous
two experiments (Jeroslow) and without heuristic (None). The results indicates that guiding search
with the Jeroslow heuristic gives important speed ups. Hence, we maintain the Jeroslow heuristic
for M INI M AX S AT.
22

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

(a) Max-2-SAT, 100 variables

cpu time

20
15

(b) Max-3-SAT, 60 variables

S
N
P

cpu time

25

10
5
0
200 300 400 500 600 700 800

70
60
50
40
30
20
10
0

S
N

300

number of clauses

400

500

600

700

800

number of clauses
(c) Max-CUT, 60 nodes

5

cpu time

4

N
S
P

3
2
1
0
300

350
400
450
number of nodes

500

Figure 4: Performance of M INI M AX S AT without soft probing, with probing as preprocessing (P)
and with probing during the search (S).

8.4.4 L EARNING ,

BACKJUMPING AND

VSIDS

In the final experiment, we evaluate the importance of learning and backjumping. For these experiments we use structured instances, since it is well known that learning and backjumping are only
useful in this type of problems. Besides, we also evaluate the importance of the VSIDS heuristic
in combination with learning and backjumping. Recall that this heuristic was specially designed to
work in cooperation with learning, so it is meaningless to analyze its effect by itself.
Table 6 reports the results of this experiment. The third column reports results without learning
and backjumping but with the lower bounding, probing and the Jeroslow heuristic (None). The
fourth column reports results adding learning and backjumping to the previous version (Learning).
The fifth column reports results adding learning, backjumping but changing the Jeroslow heuristic
by the VSIDS heuristic (VSIDS). The results show that M INI M AX S AT without learning and backjumping (None) is clearly the worst option. Significant improvements are obtained when learning
and backjumping (Learning) are added. Finally, adding the VSIDS heuristic (VSIDS) improve further the results specially on the routing instances. Based on those results, we incorporated learning
and backjumping to M INI M AX S AT.
Regarding the branching heuristic, for problems in which literals appear in hard clauses with
both polarities it applies the VSIDS heuristic, otherwise the Jeroslow heuristic is computed in the
root of the search tree as stated in Section 7. This choice is done once and for all before starting the
search.
23

H ERAS , L ARROSA , & O LIVERAS

(a) Max-2-SAT, 100 variables

15

(b) Max-3-SAT, 60 variables
100

None
Jeroslow

None
Jeroslow

80
cpu time

cpu time

20

10
5

60
40
20

0
200 300 400 500 600 700 800

0
300

number of clauses

400

500

600

700

800

number of clauses
(c) Max-CUT, 60 nodes

5
cpu time

4

None
Jeroslow

3
2
1
0
200 250 300 350 400 450 500
number of nodes

Figure 5: Performance of M INI M AX S AT without Heuristic (None) and with the Jeroslow heuristic
computed in the root node of the search tree (Jeroslow).

Problem
Max-One 3col
Max-One cnt
Max-One dp
Max-One ezfact32
Routing S3
Routing S4

n. inst.
40
3
6
10
5
10

None
âˆ’
13.57(1)
16.11(4)
654.94(2)
22.26(4)
âˆ’

Learning
29.06
119.53
40.03
0.70
1.02
410.61(2)

VSIDS
15.41
6.58
28.63
0.77
0.10
91.09(9)

Figure 6: Structured instances.
8.5 Comparison with Other Boolean Optimizers
When reporting results, we will omit a solver if it cannot deal with the corresponding instances
for technical reasons (e.g. it cannot deal with weighted clauses) or it performs extremely bad in
comparison with the others.
Figure 7 contains plots with the results on different benchmarks. Plots a and b reports results on
random unweighted Max-SAT instances. P UEBLO and M INISAT + are orders of magnitude slower,
so they are not included in the graphics. On Max-2-SAT (plot a), M INI M AX S AT lays between
M AX -DPLL and M AXSATZ, which is the best option. On Max-3-SAT (plot b) M INI M AX S AT
clearly outperforms M AX -DPLL and is very close to M AXSATZ, which is again the best. In both
Max-2-SAT and Max-3-SAT M AXSATZ is no more than 3 times faster than M INI M AX S AT.
24

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

Plot c reports results on random Max-CUT instances. M INI M AX S AT performs slightly better
than M AXSATZ, which is the second alternative.
On random Max-One (plot d) M INI M AX S AT is the best solver by far. Almost all instances are
solved instantly while P UEBLO and M AX -DPLL require up to 10 seconds in the most difficult instances. M INISAT + performs very poorly. The results on structured Max-One instances are reported
in Figure 9. M INISAT + seems to be the fastest in general. M INI M AX S AT is close in performance
to P UEBLO. Note, however, that in the d p instances, M INI M AX S AT is the only system solving all
instances.
Plot e reports the results on Random Max-Clique instances. M INI M AX S AT is the best solver, up
to an order of magnitude faster than M AX -DPLL, the second best option. P UEBLO and M INISAT +
perform poorly again. Regarding the structured Dimacs instances, M INI M AX S AT is again the best
option. It solves 36 instances within the time limit, while M AX -DPLL,M INISAT + and P UEBLO
solve 34, 22 and 18 respectively.
Plots f , g and h present the results on Combinatorial Auctions following different distributions.
On the paths distribution, M INI M AX S AT is the best solver, twice faster than M AX -DPLL, which
ranks second. On the regions distribution, M INI M AX S AT is the best solver while M AX -DPLL is
the second best solver requiring double time. On the paths and regions distributions, P UEBLO and
M INISAT + perform very poorly. On the scheduling distribution, M INISAT + is the best solver while
M INI M AX S AT and M AX -DPLL are about one order of magnitude slower.
Results regarding the unsatisfiable DIMACS instances are presented in Figure 8. Note that all
these instances have optimum cost 1. Hence, as soon as M INI M AX S AT find a solution of cost 1,
all the clauses are declared hard and learning and backjumping can be applied when hard conflicts
arise. The results indicate that M AXSATZ and M AX -DPLL do not solve any instance on some sets
(Pret150 and Aim200), while M INI M AX S AT solves all sets of instances with the best times in all
of them, except for the hole instances in which M AXSATZ is slightly faster. If we encode these
problems in the most advantageous way for P UEBLO and M INISAT +, that is, as decision problems
rather than optimization problems they solve all the instances with similar times to M INI M AX S AT.
On the planning instances (Fig. 10) P UEBLO is the best solver. M INI M AX S AT is the second best
solver, T OOLBAR is the third and the last one is M INISAT +. This is not surprising since T OOLBAR
does not perform learning over the hard constraints. Results regarding graph coloring instances are
presented in Fig. 10. As can be observed, M INI M AX S AT is able to solve one more instance than
T OOLBAR, while P UEBLO and M INISAT + solve many less instances. On the Max-CSP problems
(Fig. 10) T OOLBAR solves all the instances instantly while P UEBLO is the worst option unable to
solve a lot of instances. M INI M AX S AT is clearly the second best solver and M INI S AT + is the third
best performing solver. Note that both of them solve all the instances.
Results regarding the instances taken from the pseudo-boolean evaluation can be found in Figure
11. Note that this is the first time that a Max-SAT solver is tested on pseudo-boolean instances.
Results indicate that no solver consistently outperforms the other and that M INI M AX S AT is fairly
competitive with P UEBLO and M INISAT +.
Â¿From all these results we can conclude that M INI M AX S AT is a very robust Weighted MaxSAT solver. It is very competitive for pure optimization problems and for problems with lots of
hard clauses and, sometimes, it is the best option.
As a final remark, note that M INI M AX S AT and almost all the previous benchmarks were submitted to the Second Max-SAT Evaluation 2007, a co-located event of the Tenth International Conference on Theory and Applications of Satisfiability Testing. Hence, the interested reader can find a
25

H ERAS , L ARROSA , & O LIVERAS

(a) Max-2-SAT, 100 variables
50
30

cpu time

Max-DPLL
MiniMaxSat
Maxsatz

40
cpu time

(b) Max-3-SAT, 60 variables

20
10
0
200 300 400 500 600 700 800 900

300
250
200
150
100
50
0

Max-DPLL
MiniMaxSat
Maxsatz

300 400 500 600 700 800 900

number of clauses

number of clauses

(c) Max-CUT, 60 nodes

8

cpu time

Max-DPLL
Maxsatz
MiniMaxSat

10
cpu time

(d) Max-ONE, random 3-SAT, 120 variables

6
4
2
0
300

350

400

450

500

30
Minisat+
25
Pueblo
Max-DPLL
20
MiniMaxSat
15
10
5
0
150 200 250 300 350 400 450 500 550

number of edges

number of hard clauses

(e) Max-Clique, 150 nodes
50

Minisat+
Pueblo
Max-DPLL
MiniMaxSat

30

Pueblo
Minisat+
Max-DPLL
MiniMaxSat

80
cpu time

40
cpu time

(f) C. Auctions PATHS, 60 Goods
100

20
10

60
40
20

0

0
0

25

50

75

100

70 80 90 100 110 120 130 140 150

connectivity (%)

number of bids

(g) C. Auctions SCHEDULING, 60 Goods

cpu time

40
30

(h) C. Auctions REGIONS, 60 Goods
20

Pueblo
Max-DPLL
MiniMaxSat
Minisat+

cpu time

50

20

15
10

Minisat+
Pueblo
Max-DPLL
MiniMaxSat

5

10
0

0
100

70 80 90 100 110 120 130 140 150
number of bids

120

140

160

180

200

number of bids

Figure 7: Plots of different benchmarks. Note that the order in the legend goes in accordance with
the performance of the solvers.

more exhaustive comparison, including more instances and solvers, in the Second Max-SAT Evaluation 2007 web page9 . The results of such evaluation showed that M INI M AX S AT was the best
performing solver in two of the four existing categories.
9. http://www.maxsat07.udl.es/

26

M INI M AX S AT:

AN

n. inst.
13
4
4
5
8
8
8

Problem
Dubois
Pret60
Pret150
Hole
Aim50
Aim100
Aim200

E FFICIENT W EIGHTED M AX -SAT S OLVER

M INI M AX S AT
0.02
0.07
0.01
8.68
0.00
0.00
0.00

M AXSATZ
148.18(7)
10.06
âˆ’
8.34
0.01
9.55
âˆ’

M AX -DPLL
174.33(6)
22.00
âˆ’
28.00
0.00
172.00
âˆ’

Figure 8: Unsatisfiable DIMACS instances.

Problem
3col80
3col100
3col120
3col140
cnt
dp
ezfact32

n. inst.
10
10
10
10
3
6
10

M INI M AX S AT
0.15
2.25
20.49
38.33
6.59
28.81
0.77

P UEBLO
0.10
1.73
14.52
83.17
0.13
1.19(3)
0.34

M INISAT +
0.02
0.12
0.74
1.61
0.12
1.21(4)
0.33

Figure 9: Structured Max-one instances.

Problem
Planning
Graph Coloring
Max-CSP DL
Max-CSP DT
Max-CSP SL
Max-CSP ST

n. inst.
71
22
20
20
20
20

Toolbar
4.02
49.29(16)
0.08
0.00
0.01
0.00

M INI M AX S AT
3.81
4.16(17)
0.20
0.01
0.03
0.01

P UEBLO
0.16
68.50(11)
349.08(13)
âˆ’
123.67
âˆ’

M INISAT +
7.40
0.57(11)
8.60
2.40
0.48
1.29

Figure 10: Results for WCSP and Max-CSP instances.

9. Related Work
Some previous work has been done about incorporating SAT-techniques inside a Max-SAT solver.
Alsinet et al. (2005) presented a lazy data structure to detect when clauses become unit, but it requires a static branching heuristic. Argelich and ManyaÌ€ (2006a) test different versions of a branch
and bound procedure. One of these versions uses the two-watched literals, but it uses a very basic
lower bounding. We can conclude that none of these previous approaches is as general as our use of
the two-watched literals. As far as we know, the rest of Max-SAT solvers are based on adjacency
lists. Therefore, they are presumably inefficient for unit propagation (Lynce & Silva, 2005), par27

H ERAS , L ARROSA , & O LIVERAS

Problem
misc
Logic synthesis
MPI
MPS
Routing

n. inst.
7
17
148
16
15

M INI M AX S AT
3.08(5)
82.55(2)
37.35(107)
22.65(5)
58.74(14)

P UEBLO
8.51(5)
36.21(5)
32.04(101)
36.90(8)
5.96

M INISAT +
0.14(5)
253.93(5)
3.06(105)
8.50(8)
13.09

Figure 11: Results for pseudo-boolean instances.
ticularly in the presence of long clauses. Argelich and ManyaÌ€ (2006b) enhance a Max-SAT branch
and bound procedure with learning over hard constraints, but it is used in combination with simple lower bounding techniques. An improved version is presented by Argelich and Manya (2007)
with a more powerful lower bound, but it does not incorporate the two-watched literal scheme,
backjumping, etc. To the best of our knowledge, no Max-SAT solver incorporates backjumping.
Note that M INI M AX S AT restricts backjumping to the occurrence of hard conflicts. Related works
on the integration of backjumping techniques into branch and bound include work by Zivan and
Meisels (2007) for Weighted CSP, Manquinho and Silva (2004) for pseudo-boolean optimization,
and Nieuwenhuis and Oliveras (2006) for SAT Modulo Theories.
Most Max-SAT solvers use variations of what we call substraction-based lower bounding. In
most cases, they search for special patterns of mutually inconsistent subsets of clauses (Shen &
Zhang, 2004; Xing & Zhang, 2005; Alsinet et al., 2005). For efficiency reasons, these patterns are
always restricted to small sets of small arity clauses (2 or 3 clauses or arity less than 3). M INI M AX S AT uses a natural weighted extension of the approach proposed by Li et al. (2005). It was the
first one able to detect inconsistencies in arbitrarily large sets of arbitrarily large clauses.
The idea of what we call resolution-based lower bounding was inspired from the WCSP domain
(Larrosa, 2002; Larrosa & Schiex, 2003; de Givry et al., 2003, 2005) and it was first proposed in
the Max-SAT context by Larrosa and Heras (2005) and further developed by Li et al. (2007), Heras
and Larrosa (2006), and Larrosa et al. (2007). In these works, only special patterns of fixed-size
resolution trees were executed. The use of simulated unit propagation allows M INI M AX S AT to
identify arbitrarily large resolution trees. In the following example, we present two inconsistent
subsets of clauses that are detected by M INI M AX S AT and transformed into an equivalent formula
while previous solvers cannot transform them since they are limited to specific patterns:
â€¢ {(x1 , w1 ), (x2 , w2 ), (x3 , w3 ), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 , w4 )}
â€¢ {(x1 , w1 ), (xÌ„1 âˆ¨ x2 , w2 ), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ x3 , w3 ), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 âˆ¨ x4 , w4 ), (xÌ„1 âˆ¨ xÌ„2 âˆ¨ xÌ„3 âˆ¨ xÌ„4 , w5 )}
In the first case, M INI M AX S AT replaces the clauses by (2, m) with m = min{w1 , w2 , w3 , w4 }
and a set of compensation clauses. For the second case, M INI M AX S AT replaces it by (2, m) with
m = min{w1 , w2 , w3 , w4 , w5 } and a set of compensation clauses. In both cases, the equivalence is
preserved. However, other solvers in the literature detect those inconsistent subset of clauses but
cannot transform the problem into an equivalent one (Li et al., 2007) or simply cannot detect them
(Heras & Larrosa, 2006).
Our probing method to derive weighted unit clauses is related to the 2 âˆ’ RES and cycle rule
of Heras and Larrosa (2006) and Larrosa et al. (2007), to failed literals of Li et al. (2006), and
28

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

to singleton consistency in CSP (Debruyne & BessieÌ€re, 1999). Again, the use of simulated unit
propagation allows M INI M AX S AT to identify arbitrarily large resolution trees.

10. Conclusions and Future Work
M INI M AX S AT is an efficient and very robust Max-SAT solver that can deal with hard and soft
clauses as well as pseudo-boolean functions. It incorporates the best available techniques for each
type of problems, so its performance is similar to the best specialized solver. Besides the development of M INI M AX S AT combining, for the first time, known techniques from different fields, the
main original contribution of this paper is a novel lower bounding technique based on resolution.
M INI M AX S AT lower bounding combines in a very clean and elegant way most of the approaches that have been proposed in the last years, mainly based on unit-propagation-based lower
bounding and resolution-based problem transformation. In this paper we use the information provided by the propagation queue (i) to determine a subset of inconsistent clauses and (ii) to determine
a simple ordering in which resolution can be applied to increase the lower bound and generate an
equivalent formula. However, this is not necessarily the best ordering to do so. It is easy to see that
different orderings may generate resolvents and compensation clauses of different arities. If one
selects the ordering that generates the smallest resolvents and compensation clauses the resulting
formula may be presumably simpler. Future work concerns the study of such orderings, the development of VSIDS-like heuristics for soft clauses and backjumping techniques for soft conflicts.

Acknowledgments
We would like to thank to Niklas EeÌn and Niklas SoÌˆrensson for making M INISAT + code publicly
available. We are also grateful to the anonymous referees for their helpful suggestions on improving
the paper.
This work has been partially supported by the Spanish Ministry of Education and Science
through the projects TIN2006-15387-C03-02 (Heras and Larrosa) and TIN2004-03382 (Oliveras).

References
Alsinet, T., ManyaÌ€, F., & Planes, J. (2005). Improved Exact Solvers for Weighted Max-SAT. In
Proceedings of SATâ€™05, Vol. 3569 of LNCS, pp. 371â€“377. Springer.
Argelich, J., & ManyaÌ€, F. (2006a). Exact Max-SAT solvers for over-constrained problems. J.
Heuristics, 12(4-5), 375â€“392.
Argelich, J., & ManyaÌ€, F. (2006b). Learning Hard Constraints in Max-SAT. In Proceedings of
CSCLPâ€™06, Vol. 4651 of LNCS, pp. 1â€“12. Springer.
Argelich, J., & Manya, F. (2007). Partial Max-SAT Solvers with Clause Learning. In Proceedings
of SATâ€™07, Vol. 4501 of LNCS, pp. 28â€“40. Springer.
Barth, P. (1995). A Davis-Putnam Based Enumeration Algorithm for Linear pseudo-Boolean Optimization. Research report MPI-I-95-2-003, Max-Planck-Institut fuÌˆr Informatik, Im Stadtwald, D-66123 SaarbruÌˆcken, Germany.
Brglez, F., Li, X., & Stallman, M. (2002). The role of a skeptic agent in testing and benchmarking
of SAT algorithms. In In Proceedings of SATâ€™02, pp. 354â€“361.
29

H ERAS , L ARROSA , & O LIVERAS

Buro, M., & BuÌˆning, H. K. (1993). Report on a SAT Competition. Bulletin of the European
Association for Theoretical Computer Science, 49, 143â€“151.
Cha, B., Iwama, K., Kambayashi, Y., & Miyazaki, S. (1997). Local search algorithms for partial
MAXSAT. In Proceedings of AAAIâ€™97, pp. 263â€“268. The MIT Press.
Cooper, M., Cussat-Blanc, S., de Roquemaurel, M., & ReÌgnier, P. (2006). Soft Arc Consistency
Applied to Optimal Planning. In Proceedings of CPâ€™06, Vol. 4204 of LNCS, pp. 680â€“684.
Springer.
Davis, M., Logemann, G., & Loveland, G. (1962). A machine program for theorem proving. Communications of the ACM, 5, 394â€“397.
de Givry, S., Heras, F., Larrosa, J., & Zytnicki, M. (2005). Existential arc consistency: getting
closer to full arc consistency in weighted CSPs. In Proceedings of the 19th IJCAI, pp. 84â€“89.
Professional Book Center.
de Givry, S., Larrosa, J., Meseguer, P., & Schiex, T. (2003). Solving Max-SAT as weighted CSP. In
Proceedings of CPâ€™03, Vol. 2833 of LNCS, pp. 363â€“376. Springer.
Debruyne, R., & BessieÌ€re, C. (1999). Some practicable filtering techniques for the constraint satisfaction problem. In Proceedings of ICJAIâ€™97, pp. 412â€“417. Morgan Kaufmann.
EeÌn, N., & SoÌˆrensson, N. (2003). An Extensible SAT-solver. In Proceedings of SATâ€™03, Vol. 2919
of LNCS, pp. 502â€“518. Springer.
EeÌn, N., & SoÌˆrensson, N. (2006). Translating Pseudo-Boolean Constraints into SAT. Journal on
Satisfiability, Boolean Modeling and Computation, 2, 1â€“26.
Fahle, T. (2002). Simple and fast: Improving a branch-and-bound algorithm for maximum clique.
In Proceedings of ESAâ€™02, Vol. 2461 of LNCS, pp. 485â€“498. Springer.
Freeman, J. W. (1995). Improvements to Propositional Satisfiability Search Algorithms. Ph.D.
thesis, University of Pennsylvania.
Fu, Z., & Malik, S. (2006). On Solving the Partial MAX-SAT Problem. In Proceedings of SATâ€™06,
Vol. 4121 of LNCS, pp. 252â€“265. Springer.
Heras, F., & Larrosa, J. (2006). New Inference Rules for Efficient Max-SAT Solving. In Proceedings
of the 21th AAAI. AAAI Press.
Jeroslow, R. G., & Wang, J. (1990). Solving propositional satisfiability problems. Annals of Mathematics and Artificial Intelligence, 1, 167â€“187.
K. Leyton-Brown, M. P., & Shoham, Y. (2000). Towards a universal test suite for combinatorial
auction algorithms. In Proceedings of ACM Conference on Electronic Commerceâ€™00, pp.
66â€“76.
Karloff, H. J., & Zwick, U. (1997). A 7/8-Approximation Algorithm for MAX 3SAT?. In FOCS,
pp. 406â€“415.
Larrosa, J., & Heras, F. (2005). Resolution in Max-SAT and its relation to local consistency for
weighted CSPs. In Proceedings of IJCAIâ€™05, pp. 193â€“198. Professional Book Center.
Larrosa, J., Heras, F., & de Givry, S. (2007). A logical approach to efficient max-sat solving. In
Artificial Intelligence. To appear.
30

M INI M AX S AT:

AN

E FFICIENT W EIGHTED M AX -SAT S OLVER

Larrosa, J., & Schiex, T. (2003). In the quest of the best form of local consistency for weighted
CSP. In Proceedings of the 18th IJCAI, pp. 239â€“244.
Larrosa, J. (2002). Node and Arc Consistency in Weighted CSP. In Proceedings of AAAIâ€™02, pp.
48â€“53. AAAI Press.
Le Berre, D. (2001). Exploiting the real power of Unit Propagation Lookahead. In Proceedings of
LICS Workshop on Theory and Applications of Satisfiability Testing.
Le Berre, D. (2006). The SAT4j project for Max-SAT.. http://www.sat4j.org/.
Li, C., ManyaÌ€, F., & Planes, J. (2005). Exploiting Unit Propagation to Compute Lower Bounds
in Branch and Bound Max-SAT Solvers. In Proceedings of CPâ€™05, Vol. 3709 of LNCS, pp.
403â€“414.
Li, C., ManyaÌ€, F., & Planes, J. (2007). New Inference Rules for Max-SAT. In Journal of Artificial
Intelligence Research. To appear.
Li, C.-M., ManyaÌ€, F., & Planes, J. (2006). Detecting Disjoint Inconsistent Subformulas for Computing Lower Bounds for Max-SAT. In Proceedings of the 21th AAAI. AAAI Press.
Lynce, I., & Silva, J. P. M. (2003). Probing-Based Preprocessing Techniques for Propositional
Satisfiability. In Proceedings of ICTAIâ€™03, pp. 105â€“111. IEEE Computer Society.
Lynce, I., & Silva, J. P. M. (2005). Efficient data structures for backtrack search SAT solvers. Ann.
Math. Artif. Intell., 43(1), 137â€“152.
Manquinho, V. M., & Silva, J. P. M. (2004). Satisfiability-Based Algorithms for Boolean Optimization. Ann. Math. Artif. Intell., 40(3-4), 353â€“372.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering an
Efficient SAT Solver. In Proceedings of DACâ€™01, pp. 530â€“535. ACM.
Nieuwenhuis, R., & Oliveras, A. (2006). On SAT Modulo Theories and Optimization Problems. In
Proceedings of SATâ€™06, Vol. 4121 of LNCS, pp. 156â€“169. Springer.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley, USA.
Sandholm, T. (1999). An Algorithm for Optimal Winner Determination in Combinatorial Auctions.
In Proceedings of IJCAIâ€™99, pp. 542â€“547. Morgan Kaufmann.
Sheini, H. M., & Sakallah, K. A. (2006). Pueblo: A Hybrid Pseudo-Boolean SAT Solver. Journal
on Satisfiability, Boolean Modeling and Computation, 2, 165â€“189.
Shen, H., & Zhang, H. (2004). Study of lower bounds for Max-2-SAT. In Proceedings of AAAIâ€™04,
pp. 185â€“190. AAAI Press / The MIT Press.
Silva, J. P. M., & Sakallah, K. A. (1996). GRASP - a new search algorithm for satisfiability. In
ICCAD, pp. 220â€“227.
Smyth, K., Hoos, H. H., & StuÌˆtzle, T. (2003). Iterated Robust Tabu Search for MAX-SAT. In
Proceedings of AIâ€™03, Vol. 2671 of LNCS, pp. 129â€“144. Springer.
Tompkins, D. A. D., & Hoos, H. H. (2004). UBCSAT: An Implementation and Experimentation
Environment for SLS Algorithms for SAT & MAX-SAT. In Proceedings of SATâ€™04, Vol.
3542 of LNCS, pp. 306â€“320. Springer.
Walsh, T. (2000). SAT v CSP. In Proceedings of CPâ€™00, Vol. 1894 of LNCS, pp. 441â€“456. Springer.
31

H ERAS , L ARROSA , & O LIVERAS

Xing, Z., & Zhang, W. (2005). MaxSolver: An efficient exact algorithm for (weighted) maximum
satisfiability. Artificial Intelligence, 164(1-2), 47â€“80.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient Conflict Driven Learning in Boolean Satisfiability Solver. In Proceedings of ICCADâ€™01, pp. 279â€“285.
Zivan, R., & Meisels, A. (2007). Conflict directed Backjumping for MaxCSPs. In Proceedings of
IJCAIâ€™07, pp. 198â€“204.

32

Journal of Artificial Intelligence Research 31 (2008) 543-590

Submitted 08/07; published 03/08

Creating Relational Data from Unstructured and
Ungrammatical Data Sources
Matthew Michelson
Craig A. Knoblock

michelso@isi.edu
knoblock@isi.edu

University of Southern California
Information Sciences Instistute
4676 Admiralty Way
Marina del Rey, CA 90292 USA

Abstract
In order for agents to act on behalf of users, they will have to retrieve and integrate
vast amounts of textual data on the World Wide Web. However, much of the useful data
on the Web is neither grammatical nor formally structured, making querying difficult.
Examples of these types of data sources are online classifieds like Craigslist1 and auction
item listings like eBay.2 We call this unstructured, ungrammatical data â€œposts.â€ The
unstructured nature of posts makes query and integration difficult because the attributes
are embedded within the text. Also, these attributes do not conform to standardized values,
which prevents queries based on a common attribute value. The schema is unknown and
the values may vary dramatically making accurate search difficult. Creating relational
data for easy querying requires that we define a schema for the embedded attributes and
extract values from the posts while standardizing these values. Traditional information
extraction (IE) is inadequate to perform this task because it relies on clues from the data,
such as structure or natural language, neither of which are found in posts. Furthermore,
traditional information extraction does not incorporate data cleaning, which is necessary to
accurately query and integrate the source. The two-step approach described in this paper
creates relational data sets from unstructured and ungrammatical text by addressing both
issues. To do this, we require a set of known entities called a â€œreference set.â€ The first step
aligns each post to each member of each reference set. This allows our algorithm to define a
schema over the post and include standard values for the attributes defined by this schema.
The second step performs information extraction for the attributes, including attributes not
easily represented by reference sets, such as a price. In this manner we create a relational
structure over previously unstructured data, supporting deep and accurate queries over the
data as well as standard values for integration. Our experimental results show that our
technique matches the posts to the reference set accurately and efficiently and outperforms
state-of-the-art extraction systems on the extraction task from posts.

1. Introduction
The future vision of the Web includes computer agents searching for information, making
decisions and taking actions on behalf of human users. For instance, an agent could query
a number of data sources to find the lowest price for a given car and then email the user
the car listing, along with directions to the seller and available appointments to see the car.
1. www.craigslist.org
2. www.ebay.com
c
2008
AI Access Foundation. All rights reserved.

Michelson & Knoblock

This requires the agent to contain two data gathering mechanisms: the ability to query
sources and the ability to integrate relevant sources of information.
However, these data gathering mechanisms assume that the sources themselves are designed to support relational queries, such as having well defined schema and standard values
for the attributes. Yet this is not always the case. There are many data sources on the
World Wide Web that would be useful to query, but the textual data within them is unstructured and is not designed to support querying. We call the text of such data sources
â€œposts.â€ Examples of â€œpostsâ€ include the text of eBay auction listings, Internet classifieds
like Craigslist, bulletin boards such as Bidding For Travel3 , or even the summary text below
the hyperlinks returned after querying Google. As a running example, consider the three
posts for used car classifieds shown in Table 1.

Table 1: Three posts for Honda Civics from Craigslist
Craigslist Post
93 civic 5speed runs great obo (ri) $1800
93- 4dr Honda Civc LX Stick Shift $1800
94 DEL SOL Si Vtec (Glendale) $3000

The current method to query posts, whether by an agent or a person, is keyword search.
However, keyword search is inaccurate and cannot support relational queries. For example,
a difference in spelling between the keyword and that same attribute within a post would
limit that post from being returned in the search. This would be the case if a user searched
the example listings for â€œCivicâ€ since the second post would not be returned. Another factor
which limits keyword accuracy is the exclusion of redundant attributes. For example, some
classified posts about cars only include the car model, and not the make, since the make is
implied by the model. This is shown in the first and third post of Table 1. In these cases,
if a user does a keyword search using the make â€œHonda,â€ these posts will not be returned.
Moreover, keyword search is not a rich query framework. For instance, consider the
query, What is the average price for all Hondas from 1999 or later? To do this with
keyword search requires a user to search on â€œHondaâ€ and retrieve all that are from 1999
or later. Then the user must traverse the returned set, keeping track of the prices and
removing incorrectly returned posts.
However, if a schema with standardized attribute values is defined over the entities in
the posts, then a user could run the example query using a simple SQL statement and
do so accurately, addressing both problems created by keyword search. The standardized
attribute values ensure invariance to issues such as spelling differences. Also, each post is
associated with a full schema with values, so even though a post might not contain a car
make, for instance, its schema does and has the correct value for it, so it will be returned
in a query on car makes. Furthermore, these standardized values allow for integration of
the source with outside sources. Integrating sources usually entails joining the two sources
directly on attributes or translations of the attributes. Without standardized values and
3. www.biddingfortravel.com

544

Relational Data from Unstructured Data Sources

a schema, it would not be possible to link these ungrammatical and unstructured data
sources with outside sources. This paper addresses the problem of adding a schema with
standardized attributes over the set of posts, creating a relational data set that can support
deep and accurate queries.
One way to create a relational data set from the posts is to define a schema and
then fill in values for the schema elements using techniques such as information extraction. This is sometimes called semantic annotation. For example, taking the second
post of Table 1 and semantically annotating it might yield â€œ93- 4dr Honda Civc LX Stick
Shift $1800 <make>Honda< \make> <model>Civc< \model> <trim>4dr LX< \trim>
<year>1993< \year> <price>1800< \price>.â€ However, traditional information extraction, relies on grammatical and structural characteristics of the text to identify the attributes
to extract. Yet posts by definition are not structured or grammatical. Therefore, wrapper
extraction technologies such as Stalker (Muslea, Minton, & Knoblock, 2001) or RoadRunner
(Crescenzi, Mecca, & Merialdo, 2001) cannot exploit the structure of the posts. Nor are
posts grammatical enough to exploit Natural Language Processing (NLP) based extraction
techniques such as those used in Whisk (Soderland, 1999) or Rapier (Califf & Mooney,
1999).
Beyond the difficulties in extracting the attributes within a post using traditional extraction methods, we also require that the values for the attributes are standardized, which
is a process known as data cleaning. Otherwise, querying our newly relational data would
be inaccurate and boil down to keyword search. For instance, using the annotation above,
we would still need to query where the model is â€œCivcâ€ to return this record. Traditional
extraction does not address this.
However, most data cleaning algorithms assume that there are tuple-to-tuple transformations (Lee, Ling, Lu, & Ko, 1999; Chaudhuri, Ganjam, Ganti, & Motwani, 2003). That
is, there is some function that maps the attributes of one tuple to the attributes of another. This approach would not work on ungrammatical and unstructured data, where all
the attributes are embedded within the post, which maps to a set of attributes from the
reference set. Therefore we need to take a different approach to the problems of figuring
out the attributes within a post and cleaning them.
Our approach to creating relational data sets from unstructured and ungrammatical
posts exploits â€œreference sets.â€ A reference set consists of collections of known entities
with the associated, common attributes. A reference set can be an online (or offline) set
of reference documents, such as the CIA World Fact Book.4 It can also be an online (or
offline) database, such as the Comics Price Guide.5 With the Semantic Web one can envision
building reference sets from the numerous ontologies that already exist. Using standardized
ontologies to build reference sets allows a consensus agreement upon reference set values,
which implies higher reliability for these reference sets over others that might exist as one
expertâ€™s opinion. Using our car example, a reference set might be the Edmunds car buying
guide6 , which defines a schema for cars as well as standard values for attributes such as
the model and the trim. In order to construct reference sets from Web sources, such as the
4. http://www.cia.gov/cia/publications/factbook/
5. www.comicspriceguide.com
6. www.edmunds.com

545

Michelson & Knoblock

Edmunds car buying guide, we use wrapper technologies (Agent Builder7 in this case) to
scrape data from the Web source, using the schema that the source defines for the car.
To use a reference set to build a relational data set we exploit the attributes in the
reference set to determine the attributes from the post that can be extracted. The first step
of our algorithm finds the best matching member of the reference set for the post. This is
called the â€œrecord linkageâ€ step. By matching a post to a member of the reference set we
can define schema elements for the post using the schema of the reference set, and we can
provide standard attributes for these attributes by using the attributes from the reference
set when a user queries the posts.
Next, we perform information extraction to extract the actual values in the post that
match the schema elements defined by the reference set. This step is the information
extraction step. During the information extraction step, the parts of the post are extracted
that best match the attribute values from the reference set member chosen during the
record linkage step. In this step we also extract attributes that are not easily represented
by reference sets, such as prices or dates. Although we already have the schema and
standardized attributes required to create a relational data set over the posts, we still
extract the actual attributes embedded within the post so that we can more accurately
learn to extract the attributes not represented by a reference set, such as prices and dates.
While these attributes can be extracted using regular expressions, if we extract the actual
attributes within the post we might be able to do so more accurately. For example, consider
the â€œFord 500â€ car. Without actually extracting the attributes within a post, we might
extract â€œ500â€ as a price, when it is actually a car name. Our overall approach is outlined
in Figure 1.
Although we previously describe a similar approach to semantically annotating posts
(Michelson & Knoblock, 2005), this paper extends that research by combining the annotation with our work on more scalable record matching (Michelson & Knoblock, 2006). Not
only does this make the matching step for our annotation more scalable, it also demonstrates
that our work on efficient record matching extends to our unique problem of matching posts,
with embedded attributes, to structured, relational data. This paper also presents a more
detailed description than our past work, including a more thorough evaluation of the procedure than previously, using larger experimental data sets including a reference set that
includes tens of thousands of records.
This article is organized as follows. We first describe our algorithm for aligning the
posts to the best matching members of the reference set in Section 2. In particular, we
show how this matching takes place, and how we efficiently generate candidate matches
to make the matching procedure more scalable. In Section 3, we demonstrate how to
exploit the matches to extract the attributes embedded within the post. We present some
experiments in Section 4, validating our approaches to blocking, matching and information
extraction for unstructured and ungrammatical text. We follow with a discussion of these
results in Section 5 and then present related work in Section 6. We finish with some final
thoughts and conclusions in Section 7.

7. A product of Fetch Technologies http://www.fetch.com/products.asp

546

Relational Data from Unstructured Data Sources

Figure 1: Creating relational data from unstructured sources

2. Aligning Posts to a Reference Set
To exploit the reference set attributes to create relational data from the posts, the algorithm needs to first decide which member of the reference set best matches the post. This
matching, known as record linkage (Fellegi & Sunter, 1969), provides the schema and attribute values necessary to query and integrate the unstructured and ungrammatical data
source. Record linkage can be broken into two steps: generating candidate matches, called
â€œblockingâ€; and then separating the true matches from these candidates in the â€œmatchingâ€
step.
In our approach, the blocking generates candidate matches based on similarity methods
over certain attributes from the reference set as they compare to the posts. For our cars
example, the algorithm may determine that it can generate candidates by finding common
tokens between the posts and the make attribute of the reference set. This step is detailed
in Section 2.1 and is crucial in limiting the number of candidates matches we later examine
during the matching step. After generating candidates, the algorithm generates a large set
of features between each post and its candidate matches from the reference set. Using these
features, the algorithm employs machine learning methods to separate the true matches
from the false positives generated during blocking. This matching is detailed in Section 2.2.
547

Michelson & Knoblock

2.1 Generating Candidates by Learning Blocking Schemes for Record Linkage
It is infeasible to compare each post to all of the members of a reference set. Therefore a
preprocessing step generates candidate matches by comparing all the records between the
sets using fast, approximate methods. This is called blocking because it can be thought of
as partitioning the full cross product of record comparisons into mutually exclusive blocks
(Newcombe, 1967). That is, to block on an attribute, first we sort or cluster the data sets
by the attribute. Then we apply the comparison method to only a single member of a block.
After blocking, the candidate matches are examined in detail to discover true matches.
There are two main goals of blocking. First, blocking should limit the number of candidate matches, which limits the number of expensive, detailed comparisons needed during
record linkage. Second, blocking should not exclude any true matches from the set of candidate matches. This means there is a trade-off between finding all matching records and
limiting the size of the candidate matches. So, the overall goal of blocking is to make the
matching step more scalable, by limiting the number of comparisons it must make, while
not hindering its accuracy by passing as many true matches to it as possible.
Most blocking is done using the multi-pass approach (Hernandez & Stolfo, 1998), which
combines the candidates generated during independent runs. For example, with our cars
data, we might make one pass over the data blocking on tokens in the car model, while
another run might block using tokens of the make along with common tokens in the trim
values. One can view the multi-pass approach as a rule in disjunctive normal form, where
each conjunction in the rule defines each run, and the union of these rules combines the
candidates generated during each run. Using our example, our rule might become ({tokenmatch, model} âˆ§ ({token-match, year}) âˆª ({token-match, make})). The effectiveness of the
multi-pass approach hinges upon which methods and attributes are chosen in the conjunctions.
Note that each conjunction is a set of {method, attribute} pairs, and we do not make
restrictions on which methods can be used. The set of methods could include full string
metrics such as cosine similarity, simple common token matching as outlined above, or even
state-of-the-art n-gram methods as shown in our experiments. The key for methods is not
necessarily choosing the fastest (though we show how to account for the method speed
below), but rather choosing the methods that will generate the smallest set of candidate
matches that still cover the true positives, since it is the matching step that will consume
the most time.
Therefore, a blocking scheme should include enough conjunctions to cover as many true
matches as it can. For example, the first conjunct might not cover all of the true matches
if the datasets being compared do not overlap in all of the years, so the second conjunct
can cover the rest of the true matches. This is the same as adding more independent runs
to the multi-pass approach.
However, since a blocking scheme includes as many conjunctions as it needs, these
conjunctions should limit the number of candidates they generate. For example, the second
conjunct is going to generate a lot of unnecessary candidates since it will return all records
that share the same make. By adding more {method, attribute} pairs to a conjunction, we
can limit the number of candidates it generates. For example, if we change ({token-match,
548

Relational Data from Unstructured Data Sources

make}) to ({token-match, make} âˆ§ {token-match, trim}) we still cover new true matches,
but we generate fewer additional candidates.
Therefore effective blocking schemes should learn conjunctions that minimize the false
positives, but learn enough of these conjunctions to cover as many true matches as possible. These two goals of blocking can be clearly defined by the Reduction Ratio and Pairs
Completeness (Elfeky, Verykios, & Elmagarmid, 2002).
The Reduction Ratio (RR) quantifies how well the current blocking scheme minimizes
the number of candidates. Let C be the number of candidate matches and N be the size of
the cross product between both data sets.
RR = 1 âˆ’ C/N
It should be clear that adding more {method,attribute} pairs to a conjunction increases
its RR, as when we changed ({token-match, zip}) to ({token-match, zip} âˆ§ {token-match,
first name}).
Pairs Completeness (PC) measures the coverage of true positives, i.e., how many of the
true matches are in the candidate set versus those in the entire set. If Sm is the number of
true matches in the candidate set, and Nm is the number of matches in the entire dataset,
then:
P C = Sm /Nm
Adding more disjuncts can increase our PC. For example, we added the second conjunction to our example blocking scheme because the first did not cover all of the matches.
The blocking approach in this paper, â€œBlocking Scheme Learnerâ€ (BSL), learns effective
blocking schemes in disjunctive normal form by maximizing the reduction ratio and pairs
completeness. In this way, BSL tries to maximize the two goals of blocking. Previously we
showed BSL aided the scalability of record linkage (Michelson & Knoblock, 2006), and this
paper extends that idea by showing that it also can work in the case of matching posts to
the reference set records.
The BSL algorithm uses a modified version of the Sequential Covering Algorithm (SCA),
used to discover disjunctive sets of rules from labeled training data (Mitchell, 1997). In
our case, SCA will learn disjunctive sets of conjunctions consisting of {method, attribute}
pairs. Basically, each call to LEARN-ONE-RULE generates a conjunction, and BSL keeps
iterating over this call, covering the true matches left over after each iteration. This way
SCA learns a full blocking scheme. The BSL algorithm is shown in Table 2.
There are two modifications to the classic SCA algorithm, which are shown in bold.
First, BSL runs until there are no more examples left to cover, rather than stopping at
some threshold. This ensures that we maximize the number of true matches generated as
candidates by the final blocking rule (Pairs Completeness). Note that this might, in turn,
yield a large number of candidates, hurting the Reduction Ratio. However, omitting true
matches directly affects the accuracy of record linkage, and blocking is a preprocessing step
for record linkage, so it is more important to cover as many true matches as possible. This
way BSL fulfills one of the blocking goals: not eliminating true matches if possible. Second,
if we learn a new conjunction (in the LEARN-ONE-RULE step) and our current blocking
scheme has a rule that already contains the newly learned rule, then we can remove the
rule containing the newly learned rule. This is an optimization that allows us to check rule
containment as we go, rather than at the end.
549

Michelson & Knoblock

Table 2: Modified Sequential Covering Algorithm
SEQUENTIAL-COVERING(class, attributes, examples)
LearnedRules â† {}
Rule â† LEARN-ONE-RULE (class, attributes, examples)
While examples left to cover, do
LearnedRules â† LearnedRules âˆª Rule
Examples â† Examples - {Examples covered by Rule}
Rule â† LEARN-ONE-RULE (class, attributes, examples)
If Rule contains any previously learned rules, remove these
contained rules.
Return LearnedRules

The rule containment is possible because we can guarantee that we learn less restrictive
rules as we go. We can prove this guarantee as follows. Our proof is done by contradiction.
Assume we have two attributes A and B, and a method X. Also, assume that our previously
learned rules contain the following conjunction, ({X, A}) and we currently learned the rule
({X, A}âˆ§ {X, B}). That is, we assume our learned rules contains a rule that is less
specific than the currently learned rule. If this were the case, then there must be at least
one training example covered by ({X, A}âˆ§ {X, B}) that is not covered by ({X, A}), since
SCA dictates that we remove all examples covered by ({X, A}) when we learn it. Clearly,
this cannot happen, since any examples covered by the more specific ({X, A}âˆ§ {X, B})
would have been covered by ({X, A}) already and removed, which means we could not have
learned the rule ({X, A}âˆ§ {X, B}). Thus, we have a contradiction.
As we stated before, the two main goals of blocking are to minimize the size of the candidate set, while not removing any true matches from this set. We have already mentioned
how BSL maximizes the number of true positives in the candidate set and now we describe
how BSL minimizes the overall size of the candidate set, which yields more scalable record
linkage. To minimize the candidate setâ€™s size, we learn as restrictive a conjunction as we
can during each call to LEARN-ONE-RULE during the SCA. We define restrictive as minimizing the number of candidates generated, as long as a certain number of true matches are
still covered. (Without this restriction, we could learn conjunctions that perfectly minimize
the number of candidates: they simply return none.)
To do this, the LEARN-ONE-RULE step performs a general-to-specific beam search. It
starts with an empty conjunction and at each step adds the {method, attribute} pair that
yields the smallest set of candidates that still cover at least a set number of true matches.
That is, we learn the conjunction that maximizes the Reduction Ratio, while at the same
time covering a minimum value of Pairs Completeness. We use a beam search to allow for
some backtracking, since the search is greedy. However, since the beam search goes from
general-to-specific, we can ensure that the final rule is as restrictive as possible. The full
LEARN-ONE-RULE is given in Table 3.
The constraint that a conjunction has a minimum PC ensures that the learned conjunction does not over-fit to the data. Without this restriction, it would be possible for
LEARN-ONE-RULE to learn a conjunction that returns no candidates, uselessly producing
an optimal RR.
550

Relational Data from Unstructured Data Sources

The algorithmâ€™s behavior is well defined for the minimum PC threshold. Consider,
the case where the algorithm is learning as restrictive a rule as it can with the minimum
coverage. In this case, the parameter ends up partitioning the space of the cross product of
example records by the threshold amount. That is, if we set the threshold amount to 50%
of the examples covered, the most restrictive first rule covers 50% of the examples. The
next rule covers 50% of what is remaining, which is 25% of the examples. The next will
cover 12.5% of the examples, etc. In this sense, the parameter is well defined. If we set the
threshold high, we will learn fewer, less restrictive conjunctions, possibly limiting our RR,
although this may increase PC slightly. If we set it lower, we cover more examples, but we
need to learn more conjuncts. These newer conjuncts, in turn, may be subsumed by later
conjuncts, so they will be a waste of time to learn. So, as long as this parameter is small
enough, it should not affect the coverage of the final blocking scheme, and smaller than that
just slows down the learning. We set this parameter to 50% for our experiments8 .
Now we analyze the running time of BSL and we show how BSL can take into account
the running time of different blocking methods, if need be. Assume that we have x (method,
attribute) pairs such as (token, f irst âˆ’ name). Now, assume that our beam size is b, since
we use general-to-specific beam-search in our Learn-One-Rule procedure. Also, for the time
being, assume each (method, attribute) pair can generate its blocking candidates in O(1)
time. (We relax this assumption later.) Each time we hit Learn-One-Rule within BSL, we
will try all rules in the beam with all of the (attribute, method) pairs not in the current
beam rules. So, in the worst case, this takes O(bx) each time, since for each (method,
attribute) pair in the beam, we try it against all other (method, attribute) pairs. Now, in
the worst case, each learned disjunct would only cover 1 training example, so our rule is
a disjunction of all pairs x. Therefore, we run the Learn-One-Rule x times, resulting in a
learning time of O(bx2 ). If we have e training examples, the full training time is O(ebx2 ),
for BSL to learn the blocking scheme.
Now, while we assumed above that each (method, attribute) runs in O(1) time, this is
clearly not the case, since there is a substantial amount of literature on blocking methods and
8. Setting this parameter lower than 50% had an insignificant effect on our results, and setting it much
higher, to 90%, only increased the PC by a small amount (if at all), while decreasing the RR.

Table 3: Learning a conjunction of {method, attribute} pairs
LEARN-ONE-RULE (attributes, examples, min thresh, k)
Best-Conjunction â† {}
Candidate-conjunctions â† all {method, attribute} pairs
While Candidate-conjunctions not empty, do
For each ch âˆˆ Candidate-conjunctions
If not first iteration
ch â† ch âˆª {method,attribute}
Remove any ch that are duplicates, inconsistent or not max. specific
if REDUCTION-RATIO(ch) > REDUCTION-RATIO(Best-Conjunction)
and PAIRS-COMPLETENESS(ch) â‰¥ min thresh
Best-Conjunction â† ch
Candidate-conjunctions â† best k members of Candidate-conjunctions
return Best-conjunction

551

Michelson & Knoblock

further the blocking times can vary significantly (Bilenko, Kamath, & Mooney, 2006). Let
us define a function tx (e) that represents how long it takes for a single (method, attribute)
pair in x to generate the e candidates in our training example. Using this notation, our
Learn-One-Rule time becomes O(b(xtx (e))) (we run tx (e) time for each pair in x) and so our
full training time becomes O(eb(xtx (e))2 ). Clearly such a running time will be dominated
by the most expensive blocking methodology. Once a rule is learned, it is bounded by the
time it takes to run the rule and (method, attribute) pairs involved, so it takes O(xtx (n)),
where n is the number of records we are classifying.
From a practical standpoint, we can easily modify BSL to account for the time it takes
certain blocking methods to generate their candidates. In the Learn-One-Rule step, we
change the performance metric to reflect both Reduction Ratio and blocking time as a
weighted average. That is, given Wrr as the weight for Reduction Ratio and Wb as the
weight for the blocking time, we modify Learn-One-Rule to maximize the performance of
any disjunct based on this weighted average. Table 4 shows the modified version of LearnOne-Rule, and the changes are shown in bold.

Table 4: Learning a conjunction of {method, attribute} pairs using weights
LEARN-ONE-RULE (attributes, examples, min thresh, k)
Best-Conj â† {}
Candidate-conjunctions â† all {method, attribute} pairs
While Candidate-conjunctions not empty, do
For each ch âˆˆ Candidate-conjunctions
If not first iteration
ch â† ch âˆª {method,attribute}
Remove any ch that are duplicates, inconsistent or not max. specific
SCORE(ch) = Wrr âˆ—REDUCTION-RATIO(ch)+Wb âˆ—BLOCK-TIME(ch)
SCORE(Best-Conj) = Wrr âˆ—REDUCTION-RATIO(Best-conj)+Wb âˆ—BLOCK-TIME(Best-conj)
if SCORE(ch) > SCORE(Best-conj)
and PAIRS-COMPLETENESS(ch) â‰¥ min thresh
Best-conj â† ch
Candidate-conjunctions â† best k members of Candidate-conjunctions
return Best-conj

Note that when we set Wb to 0, we are using the same version of Learn-One-Rule
as used throughout this paper, where we only consider the Reduction Ratio. Since our
methods (token and n-gram match) are simple to compute, requiring more time to build
the initial index than to do the candidate generation, we can safely set Wb to 0. Also,
making this trade-off of time versus reduction might not always be an appropriate decision.
Although a method may be fast, if it does not sufficiently reduce the reduction ratio, then
the time it takes the record linkage step might increase more than the time it would have
taken to run the blocking using a method that provides a larger increase in reduction ratio.
Since classification often takes much longer than candidate generation, the goal should be
to minimize candidates (maximize reduction ratio), which in turn minimizes classification
time. Further, the key insight of BSL is not only that we choose the blocking method,
but more importantly that we choose the appropriate attributes to block on. In this sense,
BSL is more like a feature selection algorithm than a blocking method. As we show in our
552

Relational Data from Unstructured Data Sources

experiments, for blocking it is more important to pick the right attribute combinations, as
BSL does, even using simple methods, than to do blocking using the most sophisticated
methods.
We can easily extend our BSL algorithm to handle the case of matching posts to members
of the reference set. This is a special case because the posts have all the attributes embedded
within them while the reference set data is relational and structured into schema elements.
To handle this special case, rather than matching attribute and method pairs across the
data sources during our LEARN-ONE-RULE, we instead compare attribute and method
pairs from the relational data to the entire post. This is a small change, showing that the
same algorithm works well even in this special case.
Once we learn a good blocking scheme, we can now efficiently generate candidates from
the post set to align to the reference set. This blocking step is essential for mapping large
amounts of unstructured and ungrammatical data sources to larger and larger reference
sets.
2.2 The Matching Step
From the set of candidates generated during blocking one can find the member of the
reference set that best matches the current post. That is, one data sourceâ€™s record (the
post) must align to a record from the other data source (the reference set candidates).
While the whole alignment procedure is referred to as record linkage (Fellegi & Sunter,
1969), we refer to finding the particular matches after blocking as the â€œmatching step.â€

Figure 2: The traditional record linkage problem
However, the record linkage problem presented in this article differs from the â€œtraditionalâ€
record linkage problem and is not well studied. Traditional record linkage matches a record
from one data source to a record from another data source by relating their respective,
decomposed attributes. For instance, using the second post from Table 1, and assuming
decomposed attributes, the make from the post is compared to the make of the reference
553

Michelson & Knoblock

Figure 3: The problem of matching a post to the reference set
set. This is also done for the models, the trims, etc. The record from the reference set that
best matches the post based on the similarities between the attributes would be considered
the match. This is represented in Figure 2. Yet, the attributes of the posts are embedded
within a single piece of text and not yet identified. This text is compared to the reference
set, which is already decomposed into attributes and which does not have the extraneous
tokens present in the post. Figure 3 depicts this problem. With this type of matching
traditional record linkage approaches do not apply.
Instead, the matching step compares the post to all of the attributes of the reference set
concatenated together. Since the post is compared to a whole record from the reference set
(in the sense that it has all of the attributes), this comparison is at the â€œrecord levelâ€ and
it approximately reflects how similar all of the embedded attributes of the post are to all of
the attributes of the candidate match. This mimics the idea of traditional record linkage,
that comparing all of the fields determines the similarity at the record level.
However, by using only the record level similarity it is possible for two candidates to
generate the same record level similarity while differing on individual attributes. If one of
these attributes is more discriminative than the other, there needs to be some way to reflect
that. For example, consider Figure 4. In the figure, the two candidates share the same make
and model. However, the first candidate shares the year while the second candidate shares
the trim. Since both candidates share the same make and model, and both have another
attribute in common, it is possible that they generate the same record level comparison. Yet,
a trim on car, especially with a rare thing like a â€œHatchbackâ€ should be more discriminative
than sharing a year, since there are lots of cars with the same make, model and year, that
differ only by the trim. This difference in individual attributes needs to be reflected.
To discriminate between attributes, the matching step borrows the idea from traditional
record linkage that incorporating the individual comparisons between each attribute from
554

Relational Data from Unstructured Data Sources

Figure 4: Two records with equal record level but different field level similarities

each data source is the best way to determine a match. That is, just the record level
information is not enough to discriminate matches, field level comparisons must be exploited
as well. To do â€œfield levelâ€ comparisons the matching step compares the post to each
individual attribute of the reference set.
These record and field level comparisons are represented by a vector of different similarity functions called RL scores. By incorporating different similarity functions, RL scores
reflects the different types of similarity that exist between text. Hence, for the record level
comparison, the matching step generates the RL scores vector between the post and all of
the attributes concatenated. To generate field level comparisons, the matching step calculates the RL scores between the post and each of the individual attributes of the reference
set. All of these RL scores vectors are then stored in a vector called VRL . Once populated,
VRL represents the record and field level similarities between a post and a member of the
reference set.
In the example reference set from Figure 3, the schema has 4 attributes <make, model,
trim, year >. Assuming the current candidate is <â€œHondaâ€, â€œCivicâ€, â€œ4D LXâ€, â€œ1993â€>,
then the VRL looks like:

VRL =<RL
RL
RL
RL
RL

scores(post,
scores(post,
scores(post,
scores(post,
scores(post,

â€œHondaâ€),
â€œCivicâ€),
â€œ4D LXâ€),
â€œ1993â€),
â€œHonda Civic 4D LX 1993â€)>

Or more generally:
555

Michelson & Knoblock

VRL =<RL scores(post,
RL scores(post,
...,
RL scores(post,
RL scores(post,

attribute1 ),
attribute2 ),
attributen ),
attribute1 attribute2 . . . attributen )>

The RL scores vector is meant to include notions of the many ways that exist to define
the similarity between the textual values of the data sources. It might be the case that
one attribute differs from another in a few misplaced, missing or changed letters. This sort
of similarity identifies two attributes that are similar, but misspelled, and is called â€œedit
distance.â€ Another type of textual similarity looks at the tokens of the attributes and
defines similarity based upon the number of tokens shared between the attributes. This
â€œtoken levelâ€ similarity is not robust to spelling mistakes, but it puts no emphasis on the
order of the tokens, whereas edit distance requires that the order of the tokens match in
order for the attributes to be similar. Lastly, there are cases where one attribute may sound
like another, even if they are both spelled differently, or one attribute may share a common
root word with another attribute, which implies a â€œstemmedâ€ similarity. These last two
examples are neither token nor edit distance based similarities.
To capture all these different similarity types, the RL scores vector is built of three vectors that reflect the each of the different similarity types discussed above. Hence, RL scores
is:
RL scores(post, attribute)=<token scores(post, attribute),
edit scores(post, attribute),
other scores(post, attribute)>
The vector token scores comprises three token level similarity scores. Two similarity
scores included in this vector are based on the Jensen-Shannon distance, which defines
similarities over probability distributions of the tokens. One uses a Dirichlet prior (Cohen,
Ravikumar, & Feinberg, 2003) and the other smooths its token probabilities using a JelenikMercer mixture model (Zhai & Lafferty, 2001). The last metric in the token scores vector
is the Jaccard similarity.
With all of the scores included, the token scores vector takes the form:
token scores(post, attribute)=<Jensen-Shannon-Dirichlet(post, attribute),
Jensen-Shannon-JM-Mixture(post, attribute),
Jaccard(post, attribute)>
The vector edit scores consists of the edit distance scores which are comparisons between
strings at the character level defined by operations that turn one string into another. For
instance, the edit scores vector includes the Levenshtein distance (Levenshtein, 1966), which
returns the minimum number of operations to turn string S into string T, and the SmithWaterman distance (Smith & Waterman, 1981) which is an extension to the Levenshtein
distance. The last score in the vector edit scores is the Jaro-Winkler similarity (Winkler
& Thibaudeau, 1991), which is an extension of the Jaro metric (Jaro, 1989) used to find
similar proper nouns. While not a strict edit-distance, because it does not regard operations
of transformations, the Jaro-Winkler metric is a useful determinant of string similarity.
With all of the character level metrics, the edit scores vector is defined as:
556

Relational Data from Unstructured Data Sources

edit scores(post, attribute)=<Levenshtein(post, attribute),
Smith-Waterman(post, attribute),
Jaro-Winkler(post, attribute)>
All the similarities in the edit scores and token scores vector are defined in the SecondString package (Cohen et al., 2003) which was used for the experimental implementation
as described in Section 4.
Lastly, the vector other scores captures the two types of similarity that did not fit into
either the token level or edit distance similarity vector. This vector includes two types
of string similarities. The first is the Soundex score between the post and the attribute.
Soundex uses the phonetics of a token as a basis for determining the similarity. That
is, misspelled words that sound the same will receive a high Soundex score for similarity.
The other similarity is based upon the Porter stemming algorithm (Porter, 1980), which
removes the suffixes from strings so that the root words can be compared for similarity.
This helps alleviate possible errors introduced by the prefix assumption introduced by the
Jaro-Winkler metric, since the stems are scored rather than the prefixes. Including both of
these scores, the other scores vector becomes:
other scores(post, attribute)=<Porter-Stemmer(post, attribute),
Soundex(post, attribute)>

Figure 5: The full vector of similarity scores used for record linkage
Figure 5 shows the full composition of VRL , with all the constituent similarity scores.
Once a VRL is constructed for each of the candidates, the matching step then performs
a binary rescoring on each VRL to further help determine the best match amongst the candidates. This rescoring helps determine the best possible match for the post by separating
557

Michelson & Knoblock

out the best candidate as much as possible. Because there might be a few candidates with
similarly close values, and only one of them is a best match, the rescoring emphasizes the
best match by downgrading the close matches so that they have the same element values as the more obvious non-matches, while boosting the difference in score with the best
candidateâ€™s elements.
To rescore the vectors of candidate set C, the rescoring method iterates through the
elements xi of all VRL âˆˆC, and the VRL (s) that contain the maximum value for xi map this
xi to 1, while all of the other VRL (s) map xi to 0. Mathematically, the rescoring method is:
âˆ€VRLj âˆˆ C, j = 0... |C|




âˆ€xi âˆˆ VRLj , i = 0... VRLj 
(

f (xi , VRLj ) =

1, xi = max(âˆ€xt âˆˆ VRLs , VRLs âˆˆ C, t = i, s = 0... |C|)
0, otherwise

For example, suppose C contains 2 candidates, VRL1 and VRL2 :
VRL1 = <{.999,...,1.2},...,{0.45,...,0.22}>
VRL2 = <{.888,...,0.0},...,{0.65,...,0.22}>
After rescoring they become:
VRL1 = <{1,...,1},...,{0,...,1}>
VRL2 = <{0,...,0},...,{1,...,1}>
After rescoring, the matching step passes each VRL to a Support Vector Machine (SVM)
(Joachims, 1999) trained to label them as matches or non-matches. The best match is the
candidate that the SVM classifies as a match, with the maximally positive score for the
decision function. If more than one candidate share the same maximum score from the
decision function, then they are thrown out as matches. This enforces a strict 1-1 mapping
between posts and members of the reference set. However, a 1-n relationship can be captured
by relaxing this restriction. To do this the algorithm keeps either the first candidate with
the maximal decision score, or chooses one randomly from the set of candidates with the
maximum decision score.
Although we use SVMs in this paper to differentiate matches from non-matches, the
algorithm is not strictly tied to this method. The main characteristics for our learning
problem are that the feature vectors are sparse (because of the binary rescoring) and the
concepts are dense (since many useful features may be needed and thus none should be
pruned by feature selection). We also tried to use a NaÄ±Ìˆve Bayes classifier for our matching
task, but it was monumentally overwhelmed by the number of features and the number
of training examples. Yet this is not to say that other methods that can deal with sparse
feature vectors and dense concepts, such as online logistic regression or boosting, could not
be used in place of SVM.
After the match for a post is found, the attributes of the matching reference set member
are added as annotation to the post by including the values of the reference set attributes
with tags that reflect the schema of the reference set. The overall matching algorithm is
shown in Figure 6.
558

Relational Data from Unstructured Data Sources

Figure 6: Our approach to matching posts to records from a reference set
In addition to providing a standardized set of values to query the posts, these standardized values allow for integration with outside sources because the values can be standardized
to canonical values. For instance, if we want to integrate our car classifieds with a safety
ratings website, we can now easily join the sources across the attribute values. In this
manner, by approaching annotation as a record linkage problem, we can create relational
data from unstructured and ungrammatical data sources. However, to aid in the extraction
of attributes not easily represented in reference sets, we perform information extraction on
the posts as well.

3. Extracting Data from Posts
Although the record linkage step creates most of the relational data from the posts, there
are still attributes we would like to extract from the post which are not easily represented
by reference sets, which means the record linkage step can not be used for these attributes.
Examples of such attributes are dates and prices. Although many of these such attributes
can be extracted using simple techniques, such as regular expressions, we can make their
extraction and annotation ever more accurate by using sophisticated information extraction.
To motivate this idea, consider the Ford car model called the â€œ500.â€ If we just used regular
expressions, we might extract 500 as the price of the car, but this would not be the case.
However, if we try to extract all of the attributes, including the model, then we would
extract â€œ500â€ as the model correctly. Furthermore, we might want to extract the actual
attributes from a post, as they are, and our extraction algorithm allows this.
To perform extraction, the algorithm infuses information extraction with extra knowledge, rather than relying on possibly inconsistent characteristics. To garner this extra
559

Michelson & Knoblock

knowledge, the approach exploits the idea of reference sets by using the attributes from
the matching reference set member as a basis for identifying similar attributes in the post.
Then, the algorithm can label these extracted values from the post with the schema from
the reference set, thus adding annotation based on the extracted values.
In a broad sense, the algorithm has two parts. First we label each token with a possible
attribute label or as â€œjunkâ€ to be ignored. After all the tokens in a post are labeled, we
then clean each of the extracted labels. Figure 7 shows the whole procedure graphically,
in detail, using the second post from Table 1. Each of the steps shown in this figure are
described in detail below.

Figure 7: Extraction process for attributes
To begin the extraction process, the post is broken into tokens. Using the first post
from Table 1 as an example, set of tokens becomes, {â€œ93â€, â€œcivicâ€, â€œ5speedâ€,...}. Each of
these tokens is then scored against each attribute of the record from the reference set that
was deemed the match.
To score the tokens, the extraction process builds a vector of scores, VIE . Like the VRL
vector of the matching step, VIE is composed of vectors which represent the similarities
between the token and the attributes of the reference set. However, the composition of
VIE is slightly different from VRL . It contains no comparison to the concatenation of all
the attributes, and the vectors that compose VIE are different from those that compose
VRL . Specifically, the vectors that form VIE are called IE scores, and are similar to the
560

Relational Data from Unstructured Data Sources

RL scores that compose VRL , except they do not contain the token scores component, since
each IE scores only uses one token from the post at a time.
The RL scores vector:
RL scores(post, attribute)=<token scores(post, attribute),
edit scores(post, attribute),
other scores(post, attribute)>
becomes:
IE scores(token, attribute)=<edit scores(token, attribute),
other scores(token, attribute)>
The other main difference between VIE and VRL is that VIE contains a unique vector
that contains user defined functions, such as regular expressions, to capture attributes that
are not easily represented by reference sets, such as prices or dates. These attribute types
generally exhibit consistent characteristics that allow them to be extracted, and they are
usually infeasible to represent in reference sets. This makes traditional extraction methods
a good choice for these attributes. This vector is called common scores because the types
of characteristics used to extract these attributes are â€œcommonâ€ enough between to be used
for extraction.
Using the first post of Table 1, assume the reference set match has the make â€œHonda,â€
the model â€œCivicâ€ and the year â€œ1993.â€ This means the matching tuple would be {â€œHondaâ€,
â€œCivicâ€, â€œ1993â€}. This match generates the following VIE for the token â€œcivicâ€ of the post:
VIE =<common scores(â€œcivicâ€),
IE scores(â€œcivicâ€,â€œHondaâ€),
IE scores(â€œcivicâ€,â€œCivicâ€),
IE scores(â€œcivicâ€,â€œ1993â€)>
More generally, for a given token, VIE looks like:
VIE =<common scores(token),
IE scores(token, attribute1 ),
IE scores(token, attribute2 )
...,
IE scores(token, attributen )>
Each VIE is then passed to a structured SVM (Tsochantaridis, Joachims, Hofmann,
& Altun, 2005; Tsochantaridis, Hofmann, Joachims, & Altun, 2004) trained to give it an
attribute type label, such as make, model, or price. Intuitively, similar attribute types
should have similar VIE vectors. The makes should generally have high scores against the
make attribute of the reference set, and small scores against the other attributes. Further,
structured SVMs are able to infer the extraction labels collectively, which helps in deciding
between possible token labels. This makes the use of structured SVMs an ideal machine
learning method for our task. Note that since each VIE is not a member of a cluster where
the winner takes all, there is no binary rescoring.
Since there are many irrelevant tokens in the post that should not be annotated, the SVM
learns that any VIE that does associate with a learned attribute type should be labeled as
561

Michelson & Knoblock

â€œjunkâ€, which can then be ignored. Without the benefits of a reference set, recognizing junk
is difficult because the characteristics of the text in the posts are unreliable. For example, if
extraction relies solely on capitalization and token location, the junk phrase â€œGreat Dealâ€
might be annotated as an attribute. Many traditional extraction systems that work in
the domain of ungrammatical and unstructured text, such as addresses and bibliographies,
assume that each token of the text must be classified as something, an assumption that
cannot be made with posts.
Nonetheless, it is possible that a junk token will receive an incorrect class label. For
example, if a junk token has enough matching letters, it might be labeled as a trim (since
trims may only be a single letter or two). This leads to noisy tokens within the whole
extracted trim attribute. Therefore, labeling tokens individually gives an approximation of
the data to be extracted.
The extraction approach can overcome the problems of generating noisy, labeled tokens
by comparing the whole extracted field to its analogue reference set attribute. After all
tokens from a post are processed, whole attributes are built and compared to the corresponding attributes from the reference set. This allows removal of the tokens that introduce
noise in the extracted attribute.
The removal of noisy tokens from an extracted attribute starts with generating two
baseline scores between the extracted attribute and the reference set attribute. One is a
Jaccard similarity, to reflect the token level similarity between the two attributes. However,
since there are many misspellings and such, an edit-distance based similarity metric, the
Jaro-Winkler metric, is also used. These baselines demonstrate how accurately the system
extracted/classified the tokens in isolation.
Using the first post of Table 1 as our ongoing example, assume the phrase â€œcivic (ri)â€
was extracted as the model. This might occur if there is a car with the model Civic Rx,
for instance. In isolation, the token â€œ(ri)â€ could be the â€œRxâ€ of the model. Comparing this
extracted car model to the reference attribute â€œCivicâ€ generates a Jaccard similarity of 0.5
and a Jaro-Winkler score of 0.83. This is shown at the top of Figure 8.
Next, the cleaning method goes through the extracted attribute, removing one token at
a time and calculating new Jaccard and Jaro-Winkler similarities. If both new scores are
higher than the baselines, that token becomes a removal candidate. After all the tokens are
processed in this way, the removal candidate with the highest scores is removed, and the
whole process is repeated. The scores derived using the removed token then become the
new baseline to compare against. The process ends when there are no more tokens that
yield improved scores over the baselines.
Shown as â€œIteration 1â€ in Figure 8, the cleaning method finds that â€œ(ri)â€ is a removal
candidate since removing this token from the extracted car model yields a Jaccard score of
1.0 and a Jaro-Winkler score of 1.0, which are both higher than the baseline scores. Since
it has the highest scores after trying each token in the iteration, it is removed and the
baseline scores update. Then, since none of the remaining tokens provide improved scores
(since there are none), the process terminates, yielding a more accurate attribute value.
This is shown as â€œIteration 2â€ in Figure 8. Note that this process would keep iterating,
until no tokens can be removed that improve the scores over the baseline. The pseudocode
for the algorithm is shown in Figure 9.
562

Relational Data from Unstructured Data Sources

Figure 8: Improving extraction accuracy with reference set attributes
Note, however, that we do not limit the machine learning component of our extraction
algorithm to SVMs. Instead, we claim that in some cases, reference sets can aid extraction
in general, and to test this, in our architecture we can replace the SVM component with
other methods. For example, in our extraction experiments we replace the SVM extractor
with a Conditional Random Field (CRF) (Lafferty, McCallum, & Pereira, 2001) extractor
that uses the VIE as features.
Therefore, the whole extraction process takes a token of the text, creates the VIE and
passes this to the machine-learning extractor which generates a label for the token. Then
each field is cleaned and the extracted attribute is saved.

4. Results
The Phoebus system was built to experimentally validate our approach to building relational
data from unstructured and ungrammatical data sources. Specifically, Phoebus tests the
techniqueâ€™s accuracy in both the record linkage and the extraction, and incorporates the
BSL algorithm for learning and using blocking schemes. The experimental data, comes from
three domains of posts: hotels, comic books, and cars.
The data from the hotel domain contains the attributes hotel name, hotel area, star
rating, price and dates, which are extracted to test the extraction algorithm. This data
comes from the Bidding For Travel website9 which is a forum where users share successful
bids for Priceline on items such as airline tickets and hotel rates. The experimental data
is limited to postings about hotel rates in Sacramento, San Diego and Pittsburgh, which
compose a data set with 1125 posts, with 1028 of these posts having a match in the reference
set. The reference set comes from the Bidding For Travel hotel guides, which are special
9. www.biddingfortravel.com

563

Michelson & Knoblock

Algorithm 3.1: CleanAttribute(E, R)
comment: Clean extracted attribute E using reference set attribute R
RemovalCandidates C â† null
JaroW inklerBaseline â† JaroWinkler(E, R)
JaccardBaseline â† Jaccard(E, R)
for each token t âˆˆ E
ï£±
X t â† RemoveToken(t, E)
ï£´
ï£´
ï£´
ï£´
JaroW inklerXt â† JaroWinkler(X t , R)
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
Xt â† Jaccard(X t , R)
ï£±
ï£²Jaccard
ï£´
JaroW
inklerXt >JaroW inklerBaseline
ï£²
do
ï£´
ï£´
if and
ï£´
ï£´
ï£´
ï£´
ï£³Jaccard >Jaccard
ï£´
ï£´
Xt
Baseline
ï£´
n
ï£´
ï£´
ï£³
then C â† C âˆª t
(

if

C = null
return (E)
(
E â† RemoveMaxCandidate(C,E)
else
CleanAttribute(E, R)

Figure 9: Algorithm to clean an extracted attribute
posts listing all of the hotels ever posted about a given area. These special posts provide
hotel names, hotel areas and star ratings, which are the reference set attributes. Therefore,
these are the 3 attributes for which the standardized values are used, allowing us to treat
these posts as a relational data set. This reference set contains 132 records.
The experimental data for the comic domain comes from posts for items for sale on
eBay. To generate this data set, eBay was searched by the keywords â€œIncredible Hulkâ€ and
â€œFantastic Fourâ€ in the comic books section of their website. (This returned some items
that are not comics, such as tâ€“shirts and some sets of comics not limited to those searched
for, which makes the problem more difficult.) The returned records contain the attributes
comic title, issue number, price, publisher, publication year and the description, which are
extracted. (Note: the description is a few word description commonly associated with a
comic book, such as 1st appearance the Rhino.) The total number of posts in this data
set is 776, of which 697 have matches. The comic domain reference set uses data from the
Comics Price Guide10 , which lists all the Incredible Hulk and Fantastic Four comics. This
reference set has the attributes title, issue number, description, and publisher and contains
918 records.
The cars data consists of posts made to Craigslist regarding cars for sale. This dataset
consists of classifieds for cars from Los Angeles, San Francisco, Boston, New York, New
10. http://www.comicspriceguide.com/

564

Relational Data from Unstructured Data Sources

Jersey and Chicago. There are a total of 2,568 posts in this data set, and each post
contains a make, model, year, trim and price. The reference set for the Cars domain comes
from the Edmunds11 car buying guide. From this data set we extracted the make, model,
year and trim for all cars from 1990 to 2005, resulting in 20,076 records. There are 15,338
matches between the posts to Craigslist and the cars from Edmunds.
Unlike the hotels and comics domains, a strict 1-1 relationship between the post and
reference set was not enforced in the cars domain. As described previously, Phoebus relaxed the 1-1 relationship to form a 1-n relationship between the posts and the reference
set. Sometimes the records do not contain enough attributes to discriminate a single best
reference member. For instance, posts that contain just a model and a year might match a
couple of reference set records that would differ on the trim attribute, but have the same
make, model, and year. Yet, we can still use this make, model and year accurately for
extraction. So, in this case, as mentioned previously, we pick one of the matches. This way,
we exploit the attributes that we can from the reference set, since we have confidence in
those.
For the experiments, posts in each domain are split into two folds, one for training and
one for testing. This is usually called two-fold cross validation. However, in many cases twofold cross validation results in using 50% of the data for training and 50% for testing. We
believe that this is too much data to have to label, especially as data sets become large, so
our experiments instead focus on using less training data. One set of experiments uses 30%
of the posts for training and tests on the remaining 70%, and the second set of experiments
uses just 10% of the posts to train, testing on the remaining 90%. We believe that training
on small amounts of data, such as 10%, is an important empirical procedure since real
world data sets are large and labeling 50% of such large data sets is time consuming and
unrealistic. In fact, the size of the Cars domain prevented us from using 30% of the data for
training, since the machine learning algorithms could not scale to the number of training
tuples this would generate. So for the Cars domain we only run experiments training on
10% of the data. All experiments are performed 10 times, and the average results for these
10 trials are reported.
4.1 Record Linkage Results
In this subsection we report our record linkage results, broken down into separate discussions
of our blocking results and our matching results.
4.1.1 Blocking Results
In order for the BSL algorithm to learn a blocking scheme, it must be provided with methods
it can use to compare the attributes. For all domains and experiments we use two common
methods. The first, which we call â€œtoken,â€ compares any matching token between the
attributes. The second method, â€œngram3,â€ considers any matching 3-grams between the
attributes.
It is important to note that a comparison between BSL and other blocking methods, such
as the Canopies method (McCallum, Nigam, & Ungar, 2000) and Bigram indexing (Baxter,
Christen, & Churches, 2003), is slightly misaligned because the algorithms solve different
11. www.edmunds.com

565

Michelson & Knoblock

problems. Methods such as Bigram indexing are techniques that make the process of each
blocking pass on an attribute more efficient. The goal of BSL, however, is to select which
attribute combinations should be used for blocking as a whole, trying different attribute and
method pairs. Nonetheless, we contend that it is more important to select the right attribute
combinations, even using simple methods, than it is to use more sophisticated methods, but
without insight as to which attributes might be useful. To test this hypothesis, we compare
BSL using the token and 3-gram methods to Bigram indexing over all of the attributes.
This is equivalent to forming a disjunction over all attributes using Bigram indexing as the
method. We chose Bigram indexing in particular because it is designed to perform â€œfuzzy
blockingâ€ which seems necessary in the case of noisy post data. As stated previously (Baxter
et al., 2003), we use a threshold of 0.3 for Bigram indexing, since that works the best. We
also compare BSL to running a disjunction over all attributes using the simple token method
only. In our results, we call this blocking rule â€œDisjunction.â€ This disjunction mirrors the
idea of picking the simplest possible blocking method: namely using all attributes with a
very simple method.
As stated previously, the two goals of blocking can be quantified by the Reduction Ratio
(RR) and the Pairs Completeness (PC). Table 5 shows not only these values but also how
many candidates were generated on average over the entire test set, comparing the three
different approaches. Table 5 also shows how long it took each method to learn the rule
and run the rule. Lastly, the column â€œTime matchâ€ shows how long the classifier needs to
run given the number of candidates generated by the blocking scheme.
Table 6 shows a few example blocking schemes that the algorithm generated. For a
comparison of the attributes BSL selected to the attributes picked manually for different
domains where the data is structured the reader is pointed to our previous work on the
topic (Michelson & Knoblock, 2006).
The results of Table 5 validate our idea that it is more important to pick the correct
attributes to block on (using simple methods) than to use sophisticated methods without
attention to the attributes. Comparing the BSL rule to the Bigram results, the combination
of PC and RR is always better using BSL. Note that although in the Cars domain Bigram
took significantly less time with the classifier due to its large RR, it did so because it only
had a PC of 4%. In this case, Bigrams was not even covering 5% of the true matches.
Further, the BSL results are better than using the simplest method possible (the Disjuction), especially in the cases where there are many records to test upon. As the number of
records scales up, it becomes increasingly important to gain a good RR, while maintaining
a good PC value as well. This savings is dramatically demonstrated by the Cars domain,
where BSL outperformed the Disjunction in both PC and RR.
One surprising aspect of these results is how prevalent the token method is within all the
domains. We expect that the ngram method would be used almost exclusively since there
are many spelling mistakes within the posts. However, this is not the case. We hypothesize
that the learning algorithm uses the token methods because they occur with more regularity
across the posts than the common ngrams would since the spelling mistakes might vary quite
differently across the posts. This suggests that there might be more regularity, in terms of
what we can learn from the data, across the posts than we initially surmised.
Another interesting result is the poor reduction ratio of the Comic domain. This happens
because most of the rules contain the disjunct that finds a common token within the comic
566

Relational Data from Unstructured Data Sources

Hotels (30%)
BSL
Disjunction
Bigrams
Hotels (10%)
BSL
Disjunction
Bigrams
Comics (30%)
BSL
Disjunction
Bigrams
Comics (10%)
BSL
Disjunction
Bigrams
Cars (10%)
BSL
Disjunction
Bigrams

RR

PC

# Cands

Time Learn (s)

Time Run (s)

Time match (s)

81.56
67.02
61.35

99.79
99.82
72.77

19,153
34,262
40,151

69.25
0
0

24.05
12.49
1.2

60.93
109.00
127.74

84.47
66.91
60.71

99.07
99.82
90.39

20,742
44,202
52,492

37.67
0
0

31.87
15.676
1.57

65.99
140.62
167.00

42.97
37.39
36.72

99.75
100.00
69.20

284,283
312,078
315,453

85.59
0
0

36.66
45.77
102.23

834.94
916.57
926.48

42.97
37.33
36.75

99.74
100.00
88.41

365,454
401,541
405,283

34.26
0
0

35.65
52.183
131.34

1,073.34
1,179.32
1,190.31

88.48
87.92
97.11

92.23
89.90
4.31

5,343,424
5,603,146
1,805,275

465.85
0
0

805.36
343.22
996.45

25,114.09
26.334.79
8,484.79

Table 5: Blocking results using the BSL algorithm (amount of data used for training shown
in parentheses).

Hotels Domain (30%)
({hotel area,token} âˆ§ {hotel name,token} âˆ§ {star rating, token}) âˆª ({hotel name, ngram3})
Hotels Domain (10%)
({hotel area,token} âˆ§ {hotel name,token}) âˆª ({hotel name,ngram3})
Comic Domain (30%)
({title, token})
Comic Domain (10%)
({title, token}) âˆª ({issue number,token} âˆ§ {publisher,token} âˆ§ {title,ngram3})
Cars Domain (10%)
({make,token}) âˆª ({model,ngram3}) âˆª ({year,token} âˆ§ {make,ngram3})
Table 6: Some example blocking schemes learned for each of the domains.

567

Michelson & Knoblock

title. This rule produces such a poor reduction ratio because the value for this attribute is
the same across almost all reference set records. That is to say, when there are just a few
unique values for the BSL algorithm to use for blocking, the reduction ratio will be small.
In this domain, there are only two values for the comic title attribute, â€œFantastic Fourâ€ and
â€œIncredible Hulk.â€ So it makes sense that if blocking is done using the title attribute only,
the reduction is about half, since blocking on the value â€œFantastic Fourâ€ just gets rid of the
â€œIncredible Hulkâ€ comics. This points to an interesting limitation of the BSL algorithm. If
there are not many distinct values for the different attribute and method pairs that BSL
can use to learn from, then this lack of values cripples the performance of the reduction
ratio. Intuitively though, this makes sense, since it is hard to distinguish good candidate
matches from bad candidate matches if they share the same attribute values.
Another result worth mentioning is that in the Hotels domain we get a lower RR but
the same PC when we use less training data. This happens because our BSL algorithm
runs until it has no more examples to cover, so if those last few examples introduce a new
disjunct that produces a lot of candidates, while only covering a few more true positives,
then this would cause the RR to decrease, while keeping the PC at the same high rate.
This is in fact what happens in this case. One way to curb this behavior would be to set
some sort of stopping threshold for BSL, but as we said, maximizing the PC is the most
important thing, so we choose not to do this. We want BSL to cover as many true positives
as it can, even if that means losing a bit in the reduction.
In fact, we next test this notion explicitly. We set a threshold in the SCA such that
after 95% of the training examples are covered, the algorithm stops and returns the learned
blocking scheme. This helps to avoid the situation where BSL learns a very general conjunction, solely to cover the last few remaining training examples. When that happens, BSL
might end up lowering the RR, at the expense of covering just those last training examples,
because the rule learned to cover those last examples is overly general and returns too many
candidate matches.
Domain
Hotels Domain
No Thresh (30%)
95% Thresh (30%)
Comic Domain
No Thresh (30%)
95% Thresh (30%)
Cars Domain
No Thresh (10%)
95% Thresh (10%)

Record Linkage
F-Measure

RR

PC

90.63
90.63

81.56
87.63

99.79
97.66

91.30
91.47

42.97
42.97

99.75
99.69

77.04
67.14

88.48
92.67

92.23
83.95

Table 7: A comparison of BSL covering all training examples, and covering 95% of the
training examples

568

Relational Data from Unstructured Data Sources

Table 7 shows that when we use a threshold in the Hotels and Cars domain we see a
statistically significant drop in Pairs Completeness with a statistically significant increase
in Reduction Ratio.12 This is expected behavior since the threshold causes BSL to kick
out of SCA before it can cover the last few training examples, which in turn allows BSL
to retain a rule with high RR, but lower PC. However, when we look at the record linkage
results, we see that this threshold does in fact have a large effect.13 Although there is no
statistically significant difference in the F-measure for record linkage in the Hotels domain,
the difference in Cars domain is dramatic. When we use a threshold, the candidates not
discovered by the rule generated when using the threshold have an effect of 10% on the final
F-measure match results.14 Therefore, since the F-measure results differ by so much, we
conclude that it is worthwhile to maximize PC when learning rules with BSL, even if the
RR may decrease. That is to say, even in the presence of noise, which in turn may lead to
overly generic blocking schemes, BSL should try to maximize the true matches it covers,
because avoiding even the most difficult cases to cover may affect the matching results. As
we see in Table 7, this is especially true in the Cars domain where matching is much more
difficult than in the Hotels domain.
Interestingly, in the Comic domain we do not see a statistically significant difference
in the RR and PC. This is because across trials we almost always learn the same rule
whether we use a threshold or not, and this rule covers enough training examples that the
threshold is not hit. Further, there is no statistically significant change in the F-measure
record linkage results for this domain. This is expected since BSL would generate the same
candidate matches, whether it uses the threshold or not, since in both cases it almost always
learns the same blocking rules.
Our results using BSL are encouraging because they show that the algorithm also works
for blocking when matching unstructured and ungrammatical text to a relational data
source. This means the algorithm works in this special case too, not just the case of
traditional record linkage where we are matching one structured source to another. This
means our overall algorithm for semantic annotation is much more scalable because we are
using fewer candidate matches than in our previous work (Michelson & Knoblock, 2005).
4.1.2 Matching Results
Since this alignment approach hinges on leveraging reference sets, it becomes necessary to
show the matching step performs well. To measure this accuracy, the experiments employ
the usual record linkage statistics:
P recision =
Recall =

#CorrectM atches
#T otalM atchesM ade
#CorrectM atches
#P ossibleM atches

12. Bold means statistically significant using a two-tailed t-test with Î± set to 0.05
13. Please see subsection 4.1.2 for a description of the record linkage experiments and results.
14. Much of this difference is attributed to the non-threshold version of the algorithm learning a final
predicate that includes the make attribute by itself, which the version with a threshold does not learn.
Since each make attribute value covers many records, it generates many candidates which results in
increasing PC while reducing RR.

569

Michelson & Knoblock

F âˆ’ M easure =

2 âˆ— P recision âˆ— Recall
P recison + Recall

The record linkage approach in this article is compared to WHIRL (Cohen, 2000).
WHIRL performs record linkage by performing soft-joins using vector-based cosine similarities between the attributes. Other record linkage systems require decomposed attributes for
matching, which is not the case with the posts. WHIRL serves as the benchmark because it
does not have this requirement. To mirror the alignment task of Phoebus, the experiment
supplies WHIRL with two tables: the test set of posts (either 70% or 90% of the posts) and
the reference set with the attributes concatenated to approximate a record level match. The
concatenation is also used because when matching on each individual attribute, it is not
obvious how to combine the matching attributes to construct a whole matching reference
set member.
To perform the record linkage, WHIRL does soft-joins across the tables, which produces
a list of matches, ordered by descending similarity score. For each post with matches from
the join, the reference set member(s) with the highest similarity score(s) is called its match.
In the Cars domain the matches are 1-N, so this means that only 1 match from the reference
set will be exploited later in the information extraction step. To mirror this idea, the number
of possible matches in a 1-N domain is counted as the number of posts that have a match in
the reference set, rather than the reference set members themselves that match. Also, this
means that we only add a single match to our total number of correct matches for a given
post, rather than all of the correct matches, since only one matters. This is done for both
WHIRL and Phoebus, and more accurately reflects how well each algorithm would perform
as the processing step before our information extraction step.
The record linkage results for both Phoebus and WHIRL are shown in Table 8. Note
that the amount of training data for each domain is shown in parentheses. All results
are statistically significant using a two-tailed paired t-test with Î±=0.05, except for the
precision between WHIRL and Phoebus in the Cars domain, and the precision between
Phoebus trained on 10% and 30% of the training data in the Comic domain.
Phoebus outperforms WHIRL because it uses many similarity types to distinguish
matches. Also, since Phoebus uses both a record level and attribute level similarities,
it is able to distinguish between records that differ in more discriminative attributes. This
is especially apparent in the Cars domain. First, these results indicate the difficulty of
matching car posts to the large reference set. This is the largest experimental domain yet
used for this problem, and it is encouraging how well our approach outperforms the baseline. It is also interesting that the results suggest that both techniques are equally accurate
in terms of precision (in fact, there is no statistically significant difference between them
in this sense) but Phoebus is able to retrieve many more relevant matches. This means
Phoebus can capture more rich features that predict matches than WHIRLâ€™s cosine similarity alone. We expect this behavior because Phoebus has a notion of both field and token
level similarity, using many different similarity measures. This justifies our use of the many
similarity types and field and record level information, since our goal is to find as many
matches as we can.
It is also encouraging that using only 10% of the data for labeling, Phoebus is able to
perform almost as well as using 30% of the data for training. Since the amount of data on
the Web is vast, only having to label 10% of the data to get comparative results is preferable
570

Relational Data from Unstructured Data Sources

Hotel
Phoebus (30%)
Phoebus (10%)
WHIRL
Comic
Phoebus (30%)
Phoebus (10%)
WHIRL
Cars
Phoebus (10%)
WHIRL

Precision

Recall

F-measure

87.70
87.85
83.53

93.78
92.46
83.61

90.63
90.09
83.13

87.49
85.35
73.89

95.46
93.18
81.63

91.30
89.09
77.57

69.98
70.43

85.68
63.36

77.04
66.71

Table 8: Record linkage results

when the cost of labeling data is great. Especially since the clean annotation, and hence
relational data, comes from correctly matching the posts to the reference set, not having
to label much of the data is important if we want this technique to be widely applicable.
In fact, we faced this practical issue ourselves in the Cars domain where we were unable
to use 30% for training since the machine learning method would not scale to the number
of candidates generated by this much training data. So, the fact that we can report good
results with just 10% training data allows us to extend this work to the much larger Cars
domain.
While our method performs well and outperforms WHIRL, from the results above, it is
not clear whether it is the use of the many string metrics, the inclusion of the attributes and
their concatenation or the SVM itself that provides this advantage. To test the advantages
of each piece, we ran several experiments isolating each of these ideas.
First, we ran Phoebus matching on only the concatenation of the attributes from the
reference set, rather than the concatenation and all the attributes individually. Earlier, we
stated that we use the concatenation to mirror the idea of record level similarity and we also
use each attribute to mirror field level similarity. It is our hypothesis that in some cases,
a post will match different reference set records with the same record level score (using
the concatenation), but it will do so matching on different attributes. By removing the
individual attributes and leaving only the concatenation of them for matching, we can test
how the concatenation influences the matching in isolation. Table 9 shows these results for
the different domains.
For the Cars and Comic domains we see an improvement in F-measure, indicating that
that using the attributes and the concatenation is much better for matching than using the
concatenation alone. This supports our notion that we also need a method to capture the
significance of matching individual attributes since some attributes are better indicators of
matching than others. It is also interesting to note that for both these domains, WHIRL does
a better job than the machine learning using only the concatenation, even though WHIRL
571

Michelson & Knoblock

Hotels
Phoebus (30%)
Concatenation Only
WHIRL
Comic
Phoebus (30%)
Concatenation Only
WHIRL
Cars
Phoebus (10%)
Concatenation Only
WHIRL

Precision

Recall

F-Measure

87.70
88.49
83.61

93.78
93.19
83.53

90.63
90.78
83.13

87.49
61.81
73.89

95.46
46.55
81.63

91.30
51.31
77.57

69.98
47.94
70.43

85.68
58.73
63.36

77.04
52.79
66.71

Table 9: Matching using only the concatenation

also uses a concatenation of the attributes. This is because WHIRL uses informationretrieval-style matching to find the best match, and the machine learning technique tries to
learn the characteristics of the best match. Clearly, it is very difficult to learn what such
characteristics are.
In the Hotels domain, we do not find a statistically significant difference in F-measure
using the concatenation alone. This means that the concatenation is sufficient to determine
the matches, so there is no need for individual fields to play a role. More specifically,
the hotel name and area seem to be the most important attributes for matching and by
including them as part of the concatenation, the concatenation is still distinguishable enough
between all records to determine matches. Since in two of the three domains we see a
huge improvement, and we never lose in F-measure, using both the concatenation and the
individual attributes is valid for the matching. Also, since in two domains the concatenation
alone was worse than WHIRL, we conclude that part of the reason Phoebus can outperform
WHIRL is the use of the individual attributes for matching.
Our next experiment tests how important it is to include all of the string metrics in our
feature vector for matching. To test this idea, we compare using all the metrics to using
just one, the Jensen-Shannon distance. We choose the Jensen-Shannon distance because it
outperformed both TF/IDF and even a â€œsoftâ€ TF/IDF (one that accounts for fuzzy token
matches) in the task of selecting the right reference sets for a given set of posts (Michelson
& Knoblock, 2007). These results are shown in Table 10.
As Table 10 shows, using all the metrics yielded a statistically significant, large improvement in F-measure for the Comic and Cars domains. This means that some of the
other string metrics, such as the edit distances, were capturing similarities that the JensenShannon distance alone did not. Interestingly, in both domains, using Phoebus with only
the Jensen-Shannon distance does not dominate WHIRLâ€™s performance. Therefore, the
results of Table 10 and Table 9 demonstrate that Phoebus benefits from the combination
572

Relational Data from Unstructured Data Sources

Hotels
Phoebus (30%)
Jensen-Shannon Only
WHIRL
Comic
Phoebus (30%)
Jensen-Shannon Only
WHIRL
Cars
Phoebus (10%)
Jensen-Shannon Only
WHIRL

Precision

Recall

F-Measure

87.70
89.65
83.61

93.78
92.28
83.53

90.63
90.94
83.13

87.49
65.36
73.89

95.46
69.96
81.63

91.30
67.58
77.57

69.98
72.87
70.43

85.68
59.43
63.36

77.04
67.94
66.71

Table 10: Using all string metrics versus using only the Jensen-Shannon distance

of many, varied similarity metrics along with the use of individual attributes for field level
similarities, and both of these aspects contribute to Phoebus outperforming WHIRL.
In the case of the Hotels data, there is not a statistically significant difference in the
matching results, so in this case the other metrics do not provide relevant information for
matching. Therefore, all the matches missed by the Jensen-Shannon only method are also
missed when we include all of the metrics. Hence, either these missed matches are very
difficult to discover, or we do not have a string metric in our method yet that can capture
the similarity. For example, when the post has a token â€œDTâ€ and the reference set record it
should match has a hotel area of â€œDowntown,â€ then an abbreviation metric could capture
this relationship. However, Phoebus does not include an abbreviation similarity measure.
Since none of the techniques in isolation consistently outperforms WHIRL, we conclude
that Phoebus outperforms WHIRL because it combines multiple string metrics, it uses both
individual attributes and the concatenation, and, as stated in Section 2.2, the SVM classifier
is well suited for our record linkage task. These results also justify our inclusion of many
metrics and the individual attributes, along with our use of SVM as our classifier.
Our last matching experiment justifies our binary rescoring mechanism. Table 11 shows
the results of performing the binary rescoring for record linkage versus not performing this
binary recoring. We hypothesize earlier in this paper that the binary rescoring will allow
the classifier to more accurately make match decisions because the rescoring separates out
the best candidate as much as possible. Table 11 shows this to be the case, as across all
domains when we perform the binary rescoring we gain a statistically significant amount
in the F-measure. This shows that the record linkage is more easily able to identify the
true matches from the possible candidates when the only difference in the record linkage
algorithm is the use of binary rescoring.
573

Michelson & Knoblock

Hotels
Phoebus (30%)
No Binary Rescoring
Phoebus (10%)
No Binary Rescoring
Comic
Phoebus (30%)
No Binary Rescoring
Phoebus (10%)
No Binary Rescoring
Cars
Phoebus (10%)
No Binary Rescoring

Precision

Recall

F-Measure

87.70
75.44
87.85
73.49

93.78
81.82
92.46
78.40

90.63
78.50
90.09
75.86

87.49
84.87
85.35
81.52

95.46
89.91
93.18
88.26

91.30
87.31
89.09
84.75

69.98
39.78

85.68
48.77

77.04
43.82

Table 11: Record linkage results with and without binary rescoring

4.2 Extraction Results
This section presents results that experimentally validate our approach to extracting the
actual attributes embedded within the post. We also compare our approach to two other
information extraction methods that rely on the structure or grammar of the posts.
First, the experiments compare Phoebus against a baseline Conditional Random Field
(CRF) (Lafferty et al., 2001) extractor. A Conditional Random Field is a probabilistic
model that can label and segment data. In labeling tasks, such as Part-of-Speech tagging, CRFs outperform Hidden Markov Models and Maximum-Entropy Markov Models.
Therefore, by representing the state-of-the-art probabilistic graphical model, they present a
strong comparison to our approach to extraction. CRFs have also been used effectively for
information extraction. For instance, CRFs have been used to combine information extraction and coreference resolution with good results (Wellner, McCallum, Peng, & Hay, 2004).
These experiments use the Simple Tagger implementation of CRFs from the MALLET
(McCallum, 2002) suite of text processing tools.
Further, as stated in Section 3 on Extraction, we also created a version of Phoebus that
uses CRFs, which we call PhoebusCRF. PhoebusCRF uses the same extraction features
(VIE ) as Phoebus using the SVM, such as the common score regular expressions and the
string similarity metrics. We include PhoebusCRF to show that extraction in general can
benefit from our reference set matching.
Second, the experiments compare Phoebus to Natural Language Processing (NLP) based
extraction techniques. Since the posts are ungrammatical and have unreliable lexical characteristics, these NLP based systems are not expected to do as well on this type of data.
The Amilcare system (Ciravegna, 2001), which uses shallow NLP for extraction, has been
shown to outperform other symbolic systems in extraction tasks, and so we use Amilcare
as the other system to compare against. Since Amilcare can exploit gazetteers for extra
574

Relational Data from Unstructured Data Sources

information, for our experiments Amilcare receives the reference data as a gazetteer to aid
the extraction. Both Simple Tagger and Amilcare are used with default settings.
Lastly, we compare Phoebus trained using 30% of the data for training to Phoebus
trained using 10% of the data. (We do this for PhoebusCRF as well.) In our experimental
results, the amount of training data is put in parentheses.
One component of the extraction vector VIE is the vector common scores, which includes
user defined functions, such as regular expressions. Since these are the only domain specific
functions used in the algorithm, the common scores for each domain must be specified.
For the Hotels domain, the common scores includes the functions matchPriceRegex and
matchDateRegex. Each of these functions gives a positive score if a token matches a price or
date regular expression, and 0 otherwise. For the Comic domain, common scores contains
the functions matchPriceRegex and matchYearRegex, which also give positive scores when a
token matches the regular expression. In the Cars domain, common scores uses the function
matchPriceRegex (since year is an attribute of the reference set, we do not use a common
score to capture its form).
For the cars data set, not all of the posts were labeled for training and testing the
extraction. For this domain, we only labeled 702 of the posts for extraction, and use these
for training and testing the extraction algorithm. Note, however, that Phoebus does perform
the extraction on all of the posts, it just is not able to report results for those. In fact, a
running demo of Phoebus, in the Cars domain is live.15
The extraction results are presented using Precision, Recall and F-Measure. Note that
these extraction results are â€œfield levelâ€ results. This means that an extraction is counted
as correct only if all tokens that compromise that field in the post are correctly labeled.
Although this is a much stricter rubric of correctness, it more accurately models how useful
an extraction system would be. Tables 12, 13 and 14 show the results of correctly labeling
the tokens within the posts with the correct attribute label for the Hotel, Comic and Cars
domains, respectively. Attributes in italics are attributes that exist in the reference set.
The column Freq shows the average number of fields in the test set that have the associated
label. Also, observe that a * means that results between the highest Phoebus score (Phoebus
or PhoebusCRF) and the highest baseline (Amilcare or Simple Tagger CRF) F-Measure are
not statistically significant using a two-tailed paired t-test with Î±=0.05.
Phoebus and PhoebusCRF outperform the other systems on almost all attributes (13 of
16), as shown in Table 15. In fact, there was only one attribute where the baseline system
was the best: using Amilcare to extract the Date attribute in the Hotels domain. For this
attribute, Phoebus and PhoebusCRF both use the common-score regular-expression as the
main identifying feature. Since this regular expression is user supplied, we propose that a
better regular expression could make Phoebus/PhoebusCRF extract these dates even more
accurately, overcoming this baseline. Since both systems perform well using the reference
set data to aid the extraction, these results show that using reference sets can greatly aid
extraction. This is especially evident when we compare PhoebusCRF to the Simple Tagger
CRF, since the difference between these two extraction methods is the reference set attribute
similarity scores and the common scores.
15. http://www.isi.edu/integration/Phoebus/demos.html This demo uses an extraction model trained on
the 702 labeled extraction examples, and has been running live for months as of the writing of this
article.

575

Michelson & Knoblock

Area

Date

Name

Price

Star

Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF(30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)

Hotel
Recall
83.73
77.80
85.13
80.71
78.62
64.78
85.41
82.13
87.20
84.39
63.60
86.18
77.27
75.59
85.70
81.46
74.43
58.96
93.06
93.12
92.56
90.34
71.68
88.04
97.39
96.94
96.83
96.17
97.16
95.58

Precision
84.76
83.58
86.93
83.38
79.38
71.59
87.02
83.06
87.11
84.48
63.25
94.10
75.18
74.25
85.07
81.69
84.86
67.44
98.38
98.46
94.90
92.60
73.45
91.10
97.01
96.90
98.06
96.74
96.55
97.35

F-Measure
84.23
80.52
86.02
82.01
79.00
68.01
86.21
82.59
87.15
84.43
63.42
89.97
76.21
74.92
85.38
81.57
79.29
62.91
95.65
95.72
93.71
91.46
72.55
89.54
97.20
96.92
97.44
96.45
96.85
96.46

Frequency
~580

~700

~750

~720

~730

Table 12: Field level extraction results: Hotels domain

576

Relational Data from Unstructured Data Sources

Descript.

Issue

Price

Publisher

Title

Year

Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)
Phoebus (30%)
Phoebus (10%)
PhoebusCRF (30%)
PhoebusCRF (10%)
Simple Tagger CRF (30%)
Amilcare (30%)

Comic
Recall
32.43
30.16
26.02
15.45
32.30
8.00
83.39
80.90
87.77
83.01
78.31
77.66
68.09
39.84
51.06
29.09
44.24
41.21
100.00
99.85
77.91
53.22
78.13
63.75
89.34
89.37
92.93
90.64
93.57
89.88
78.44
77.50
76.24
54.63
39.93
77.05

Precision
30.71
27.15
33.03
26.83
34.75
52.55
83.65
82.17
88.70
84.68
77.81
89.11
90.00
60.00
85.34
55.40
84.44
66.67
85.38
83.89
88.30
87.29
88.52
90.48
89.34
89.37
93.70
92.13
92.79
95.65
97.69
97.35
93.46
85.07
72.89
85.67

F-Measure
31.51
28.52
28.95
18.54
33.43*
13.78
83.52
81.52
88.23
83.84
78.05
82.98
77.39*
46.91
61.16
35.71
55.77
50.93
92.09
91.18
82.50
64.26
82.72
74.75
89.34
89.37
93.31*
91.37
93.18
92.65
86.99
86.28
83.80
66.14
51.54
81.04

Frequency
~90

~510

~15

~60

~540

~100

Table 13: Field level extraction results: Comic domain.

577

Michelson & Knoblock

Make

Model

Price

Trim

Year

Phoebus (10%)
PhoebusCRF (10%)
Simple Tagger CRF (10%)
Amilcare (10%)
Phoebus (10%)
PhoebusCRF (10%)
Simple Tagger CRF (10%)
Amilcare (10%)
Phoebus (10%)
PhoebusCRF (10%)
Simple Tagger CRF (10%)
Amilcare (10%)
Phoebus (10%)
PhoebusCRF (10%)
Simple Tagger CRF (10%)
Amilcare (10%)
Phoebus (10%)
PhoebusCRF (10%)
Simple Tagger CRF (10%)
Amilcare (10%)

Cars
Recall
98.21
90.73
85.68
97.58
92.61
84.58
78.76
78.44
97.17
93.59
83.66
90.06
63.11
55.61
55.94
27.21
88.48
85.54
91.12
86.32

Precision
99.93
96.71
95.69
91.76
96.67
94.10
91.21
84.31
95.91
92.59
98.16
91.27
70.15
64.95
66.49
53.99
98.23
96.44
76.78
91.92

F-Measure
99.06
93.36
90.39
94.57
94.59
88.79
84.52
81.24
96.53
93.09
90.33
90.28
66.43
59.28
60.57
35.94
93.08
90.59
83.31
88.97

Frequency
~580

~620

~580

~375

~600

Table 14: Field level extraction results: Cars domain.

Domain
Hotel
Comic
Cars
All

Phoebus
1
2
5
8

Num. of Max. F-Measures
PhoebusCRF Amilcare Simple Tagger
3
1
0
1
0
0
0
0
0
4
1
0

Total Attributes
5
6
5
16

Table 15: Summary results for extraction showing the number of times each system had
statistically significant highest F-Measure for an attribute.

578

Relational Data from Unstructured Data Sources

Phoebus performs especially well in the Cars domain, where it is the best system on
all the attributes. One interesting thing to note about this result is that while the record
linkage results are not spectacular for the Cars domain, they are good enough to yield very
high extraction results. This is because most times when the system is not picking the best
match from the reference set, it is still picking one that is close enough such that most
of the reference set attributes are useful for extraction. This is why the trim extraction
results are the lowest, because that is often the attribute that determines a match from a
non-match. The record linkage step likely selects a car that is close, but differs in the trim,
so the match is incorrect and the trim will most likely not be extracted correctly, but the
rest of the attributes can be extracted using the reference set member.
A couple of other interesting notes come from these results. One of the most intriguing
aspects of these results is that they allow us to estimate some level of structure for different
attributes within a domain. Since CRFs rely more on the structure of the tokens within
a post than the structured SVM method, we hypothesize that in the domains with more
structure, PhoebusCRF should perform best and in the domains with the least structure,
Phoebus should perform best. Table 15 shows this to be the case. PhoebusCRF dominates
the Hotels domain, where, for example, many posts have a structure where the star rating
comes before the hotel name. So using such structure should allow the extractor to get
the hotel name more accurately than not using this information. Therefore we see that
overall there is structure within the Hotels domain because PhoebusCRF is the method
that performs best, not Phoebus. Contrast this with the Cars domain, which is highly
unstructured, where Phoebus performs the best across all attributes. In this domain there
are many missing tokens and the order of attributes is more varied. The Comic domain is
varied with both some attributes that exhibit structure and some that do not, and as Table
15 shows, so are the cases where Phoebus or PhoebusCRF dominates. However, although
the Hotels data exhibits some structure, the important aspect of this research is that using
Phoebus allows one to perform extraction without assuming any structure in the data.
Also, a result worth noting is that the price attribute in the Comic domain is a bit
misleading. In fact, none of the systems were statistically significant with respect to each
other because there were so few prices to extract that the F-Measures were all over for all
the systems.
Another aspect that came to light with statistical significance is the generalization of the
algorithm. For the Hotels and Comic domains, where we were able to use both 30% and 10%
of the data for training, there are not many cases with a statistically significant difference
in the F-Measures for the extracted attributes using Phoebus. In the Hotels domain the
name, the area and date had statistically significant F-Measures between training on 30%
and 10% of the data, and in the Comic domain only the difference in F-Measure between the
issue and description attributes were significant (though the description was borderline).
This means of the 11 attributes in both domains, roughly half of them were insignificant.
Therefore there is little difference in extraction whether we use 10% of the data for training
or 30%, so the extraction algorithm generalizes very well. This is important since labeling
data for extraction is very time consuming and expensive.
One interesting result to note is that except for the comic price (which was insignificant
for all systems) and the hotel date (which was close), Phoebus, using either 10% or 30%
training data, outperformed all of the other systems on the attributes that were not included
579

Michelson & Knoblock

in the reference set. This lends credibility to our claim earlier in the section that by training
the system to extract all of the attributes, even those in the reference set, we can more
accurately extract attributes not in the reference set because we are training the system to
identify what something is not.
The overall performance of Phoebus validates this approach to semantic annotation. By
infusing information extraction with the outside knowledge of reference sets, Phoebus is
able to perform well across three different domains, each representative of a different type
of source of posts: the auction sites, Internet classifieds and forum/bulletin boards.

5. Discussion
The goal of this research is to produce relational data from unstructured and ungrammatical
data sources so that they can be accurately queried and integrated with other sources. By
representing the attributes embedded within a post with the standardized values from the
reference set, we can support structural queries and integration. For instance, we can
perform aggregate queries because we can treat the data source as a relational database
now. Furthermore, we have standardized values for performing joins across data sources,
a key for integration of multiple sources. These standardized values also aid in the cases
where the post actually does not contain the attribute. For instance, in Table 1, two of
the listings do not include the make â€œHonda.â€ However, once matched to the reference set,
they contain a standardized value for this attribute which can then be used for querying and
integrating these posts. This is especially powerful since the posts never explicitly stated
these attribute values. The reference set attributes also provide a solution for the cases
where the extraction is extremely difficult. For example, none of the systems extracted
the description attribute of the Comic domain well. However, if one instead considers
the description attribute from the reference set, which is quantified by the record linkage
results for the Comic domain, this yields an improvement of over 50% in the F-Measure for
identifying the description for a post.
It may seem that using the reference set attributes for annotation is enough since the
values are already cleaned, and that extraction is unnecessary. However, this is not the case.
For one thing, one may want to see the actual values entered for different attributes. For
instance, a user might want to discover the most common spelling mistake or abbreviation
for a attribute. Also, there are cases when the extraction results outperform the record
linkage results. This happens because even if a post is matched to an incorrect member of
the reference set, that incorrect member is most likely very close to the correct match, and
so it can be used to correctly extract much of the information. For a strong example of this,
consider the Cars domain. The F-measure for the record linkage results are not as good as
those for the extraction results in this domain. This means most matches that were chosen
where probably incorrect because they differ from the correct match by something small.
For example, a true match could have the trim as â€œ2 Doorâ€ while the incorrectly chosen
match might have the trim â€œ4 Door,â€ but there would still be enough information, such as
the rest of the trim tokens, the year, the make and the model to correctly extract those
different attributes from the post itself. By performing the extraction for the values from
the post itself, we can overcome the mistakes of the record linkage step because we can still
exploit most of the information in the incorrectly chosen reference set member.
580

Relational Data from Unstructured Data Sources

Extraction on all of the attributes also helps our system classify (and ignore) â€œjunkâ€
tokens. Labeling something as junk is much more descriptive if it is labeled junk out of
many possible class labels that could share lexical characteristics. This helps improve the
extraction results on items that are not in the reference set, such as prices and dates.
On the topic of reference sets, it is important to note that the algorithm is not tied to
a single reference set. The algorithm extends to include multiple reference sets by iterating
the process for each reference set used.
Consider the following two cases. First, suppose a user wants to extract conference
names and cities and she has individual lists of each. If the approach is confined to using
one reference set, that would require constructing a reference set that contains the power set
of cities crossed with conference names. This approach would not scale for many attributes
from distinct sources. However, if these lists are used as two reference sets, one for each
attribute, the algorithm can run once with the conference name data, and once with a
reference set of cities. This iterative exploitation of the reference sets allows for n reference
set attributes to be added without a combinatorial explosion.
The next interesting case is when a post contains more than one of the same attribute.
For example, a user needs to extract two cities from some post. If one reference set is used,
then it includes the cross product of all cities. However, using a single reference set of city
names can be done by slightly modifying the algorithm. The new algorithm makes a first
pass with the city reference set. During this pass, the record linkage match will either be
one of the cities that matches best, or a tie between them. In the case of a tie, choose the
first match. Using this reference city, our system can then extract the city from the post,
and remove it from the post. Then our system simply runs the process again, which will
catch the second city, using the same, single reference set. This could be repeated as many
times as needed.
One issue that arises with reference sets is the discrepancy between userâ€™s knowledge
and the domain experts who generally create the reference sets. In the Cars domain, for
instance, users will interchangeably use the attribute values â€œhatchback,â€ â€œliftback,â€ and
â€œwagon.â€ The reference set never includes the term â€œliftbackâ€ which suggests it is a synonym
for hatchback used in common speech, but not in Edmundâ€™s automobile jargon. The term
â€œwagonâ€ is used by Edmunds, but it is not used for some of the cars that users describe
as â€œhatchbacks.â€ This implies a slight difference in meaning between the two, according to
the reference set authors.
Two issues arise from these discrepancies. The first is the users interchanging the words
can cause some problems for the extraction and for the record linkage, but this can be
overcome by incorporating some sort of thesaurus into the algorithm. During record linkage,
a thesaurus could expand certain attribute values used for matching, for example including
â€œhatchbackâ€ and â€œliftbackâ€ when the reference set attribute includes the term â€œwagon.â€
However, there are more subtle issues here. It is mostly not the case that a â€œhatchbackâ€ is
called a â€œwagonâ€ but it does happen that a â€œwagonâ€ is called a â€œhatchback.â€ The frequency
of replacement must be taken into consideration so that errant matches are not created.
How to automate this is a line of future research. The other issue arises from trusting
the correctness of the Edmunds source. We assume Edmunds is right to define one car
as a â€œwagonâ€ which has a different meaning from classifying it as a â€œhatchback.â€ In fact,
581

Michelson & Knoblock

Edmunds classifies the Mazda Protege5 as a â€œwagon,â€ while Kelly Blue Book16 classifies it
as a â€œhatchback.â€ This seems to invalidate the idea that â€œwagonâ€ is different in meaning
from â€œhatchback.â€ They appear to be simple synonyms, but this would remain unknown
without the outside knowledge of Kelly Blue Book. More generally, one assumes that the
reference set is a correct set of standardized values, but this is not an absolute truth. That is
why the most meaningful reference sets are those that can be constructed from agreed-upon
ontologies from the Semantic Web. For instance, a reference set derived from an ontology
for cars created by all of the biggest automotive businesses should alleviate many of the
issues in meaning, and a thesaurus scheme could work out the discrepancies introduced by
the users, rather than the reference sets.

6. Related Work
Our research is driven by the principal that the cost of annotating documents for the
Semantic Web should be free, that is, automatic and invisible to users (Hendler, 2001).
Many researchers have followed this path, attempting to automatically mark up documents
for the Semantic Web, as proposed here (Cimiano, Handschuh, & Staab, 2004; Dingli,
Ciravegna, & Wilks, 2003; Handschuh, Staab, & Ciravegna, 2002; Vargas-Vera, Motta,
Domingue, Lanzoni, Stutt, & Ciravegna, 2002). However, these systems rely on lexical
information, such as part-of-speech tagging or shallow Natural Language Processing to do
their extraction/annotation (e.g., Amilcare, Ciravegna, 2001). This is not an option when
the data is ungrammatical, like the post data. In a similar vein, there are systems such as
ADEL (Lerman, Gazen, Minton, & Knoblock, 2004) which rely on the structure to identify
and annotate records in Web pages. Again, the failure of the posts to exhibit structure
makes this approach inappropriate. So, while there is a fair amount of work in automatic
labeling, there is little emphasis on techniques that could label text that is both unstructured
and ungrammatical.
Although the idea of record linkage is not new (Fellegi & Sunter, 1969) and is well studied
even now (Bilenko & Mooney, 2003) most current research focuses on matching one set of
records to another set of records based on their decomposed attributes. There is little work
on matching data sets where one record is a single string composed of the other data setâ€™s
attributes to match on, as in the case with posts and reference sets. The WHIRL system
(Cohen, 2000) allows for record linkage without decomposed attributes, but as shown in
Section 4.1 Phoebus outperforms WHIRL, since WHIRL relies solely on the vector-based
cosine similarity between the attributes, while Phoebus exploits a larger set of features to
represent both field and record level similarity. We note with interest the EROCS system
(Chakaravarthy, Gupta, Roy, & Mohania, 2006) where the authors tackle the problem of
linking full text documents with relational databases. The technique involves filtering out
all non-nouns from the text, and then finding the matches in the database. This is an
intriguing approach; interesting future work would involve performing a similar filtering for
larger documents and then applying the Phoebus algorithm to match the remaining nouns
to reference sets.
Using the reference setâ€™s attributes as normalized values is similar to the idea of data
cleaning. However, most data cleaning algorithms assume tuple-to-tuple transformations
16. www.kbb.com

582

Relational Data from Unstructured Data Sources

(Lee et al., 1999; Chaudhuri et al., 2003). That is, some function maps the attributes of
one tuple to the attributes of another. This approach would not work on ungrammatical
and unstructured data, where all attributes are embedded within the post, which maps to
a set of attributes from the reference set.
Although our work describes a technique for information extraction, many methods,
such as Conditional Random Fields (CRF), assume at least some structure in the extracted
attributes to do the extraction. As our extraction experiments show, Phoebus outperforms such methods, such as the Simple Tagger implementation of Conditional Random
Fields (McCallum, 2002). Other IE approaches, such as Datamold (Borkar, Deshmukh, &
Sarawagi, 2001) and CRAM (Agichtein & Ganti, 2004), segment whole records (like bibliographies) into attributes, with little structural assumption. In fact, CRAM even uses
reference sets to aid its extraction. However, both systems require that every token of a
record receive a label, which is not possible with posts that are filled with irrelevant, â€œjunkâ€
tokens. Along the lines of CRAM and Datamold, the work of Bellare and McCallum (2007)
uses a reference set to train a CRF to extract data, which is similar to our PhoebusCRF
implementation. However, there are two differences between PhoebusCRF and their work
(Bellare & McCallum, 2007). First, the work of Bellare and McCallum (2007) mentions
that reference set records are matched using simple heuristics, but it is unclear how this is
done. In our work, matching is done explicitly and accurately through record linkage. Second, their work only uses the records from the reference set to label tokens for training an
extraction module, while PhoebusCRF uses the actual values from the matching reference
set record to produce useful features for extraction and annotation.
Another IE approach similar to ours performs named entity recognition using â€œSemiCRFsâ€ with a dictionary component (Cohen & Sarawagi, 2004), which functions like a
reference set. However, in their work the dictionaries are defined as lists of single attribute
entities, so finding an entity in the dictionary is a look-up task. Our reference sets are
relational data, so finding the match becomes a record linkage task. Further, their work on
Semi-CRFs (Cohen & Sarawagi, 2004) focuses on the task of labeling segments of tokens
with a uniform label, which is especially useful for named entity recognition. In the case
of posts, however, Phoebus needs to relax such a restriction because in some cases such
segments will be interrupted, as the case of a hotel name with the area in the middle of
the hotel name segment. So, unlike their work, Phoebus makes no assumptions about the
structure of posts. Recently, Semi-CRFs have been extended to use database records in the
task of integrating unstructured data with relational databases (Mansuri & Sarawagi, 2006).
This work is similar to ours in that it links unstructured data, such as paper citations, with
relational databases, such as reference sets of authors and venues. The difference is that we
view this as a record linkage task, namely finding the right reference set tuple to match. In
their paper, even though they use matches from the database to aid extraction, they view
the linkage task as an extraction procedure followed by a matching task. Lastly, we are
not the first to consider structured SVMs for information extraction. Previous work used
structured SVMs to perform Named Entity Recognition (Tsochantaridis et al., 2005) but
their extraction task does not use reference sets.
Our method of aiding information extraction with outside information (in the form of
reference sets) is similar to the work on ontology-based information extraction (Embley,
Campbell, Jiang, Liddle, Ng, Quass, & Smith, 1999). Later versions of their work even talk
583

Michelson & Knoblock

about using ontology-based information extraction as a means to semantically annotate unstructured data such as car classifieds (Ding, Embley, & Liddle, 2006). However, in contrast
to our work, the information extraction is performed by a keyword-lookup into the ontology
along with structural and contextual rules to aid the labeling. The ontology itself contains
keyword misspellings and abbreviations, so that the look-up can be performed in the presence of noisy data. We believe the ontology-based extraction approach is less scalable than
a record linkage type matching task because creating and maintaining the ontology requires
extensive data engineering in order to encompass all possible common spelling mistakes and
abbreviations. Further, if new data is added to the ontology, additional data engineering
must be performed. In our work, we can simply add new tuples to our reference set. Lastly,
in contrast to our work, this ontology based work assumes contextual and structural rules
will apply, making an assumption about the data to extract from. In our work, we make
no such assumptions about the structure of the text we are extracting from.
Yet another interesting approach to information extraction using ontologies is the Textpresso system which extracts data from biological text (MuÌˆller & Sternberg, 2004). This
system uses a regular expression based keyword look-up to label tokens in some text based
on the ontology. Once all tokens are labeled, Textpresso can perform â€œfact extractionâ€
by extracting sequences of labeled tokens that fit a particular pattern, such as gene-allele
reference associations. Although this system again uses a reference set for extraction, it
differs in that it does a keyword look-up into the lexicon.
In recent work on learning efficient blocking schemes Bilenko et al., (2006) developed a
system for learning disjunctive normal form blocking schemes. However, they learn their
schemes using a graphical set covering algorithm, while we use a version of the Sequential
Covering Algorithm (SCA). There are also similarities between our BSL algorithm and work
on mining association rules from transaction data (Agrawal, Imielinski, & Swami, 1993).
Both algorithms discover propositional rules. Further, both algorithms use multiple passes
over a data set to discover their rules. However despite these similarities, the techniques
really solve different problems. BSL generates a set of candidate matches with a minimal
number of false positives. To do this, BSL learns conjunctions that are maximally specific
(eliminating many false positives) and unions them together as a single disjunctive rule (to
cover the different true positives). Since the conjunctions are maximally specific, BSL uses
SCA underneath, which learns rules in a depth-first, general to specific manner (Mitchell,
1997). On the other hand, the work of mining association rules (Agrawal et al., 1993) looks
for actual patterns in the data that represent some internal relationships. There may be
many such relationships in the data that could be discovered, so this approach covers the
data in a breadth-first fashion, selecting the set of rules at each iteration and extending
them by appending to each a new possible item.

7. Conclusion
This article presents an algorithm for semantically annotating text that is ungrammatical
and unstructured. Unstructured, ungrammatical sources contain much information, but
cannot support structured queries. Our technique allows for more informative use of the
sources. Using our approach, eBay agents could monitor the auctions looking for the best
deals, or a user could find the average price of a four-star hotel in San Diego. Such semantic
584

Relational Data from Unstructured Data Sources

annotation is necessary as society transitions into the Semantic Web, where information
requires annotation to be useful for agents, but users are unwilling to do the extra work to
provide the required annotation.
In the future, our technique could link with a mediator framework (Thakkar, Ambite, &
Knoblock, 2004) for automatically acquiring reference sets. This is similar to automatically
incorporating secondary sources for record linkage (Michalowski, Thakkar, & Knoblock,
2005). The automatic formulation of queries to retrieve the correct domain reference set
is a direction of future research. With a mediator framework in place, Phoebus could
incorporate as many reference sets as needed for full coverage of possible attribute values
and attribute types.
Unsupervised approaches to record linkage and extraction are also topics of future research. By including unsupervised record linkage and extraction with a mediator component, the approach would be entirely self-contained, making semantic annotation of posts
a more automatic process. Also, the current implementation only gives one class label per
token. Ideally Phoebus would give a token all possible labels, and then remove the extraneous tokens when the systems cleans the attributes, as described in Section 3. This
disambiguation should lead to much higher accuracy during extraction.
Future work could investigate the inclusion of thesauri for terms in the attributes, with
the frequency of replacement of the terms taken into consideration. Also, exploring technologies that automatically construct the reference sets (and eventually thesauri) from the
numerous ontologies on the Semantic Web is an intriguing research path.
The long term goal for annotation and extraction from unstructured, ungrammatical
sources involves automating the entire process. If the record linkage and extraction methods
could become unsupervised, then our approach could automatically generate and incorporate the reference sets, and then apply them to automatically annotate the data source.
This would be an ideal approach for making the Semantic Web more useful â€“ with no user
involvement.

Acknowledgments
This research is based upon work supported in part by the National Science Foundation under award number IIS-0324955, in part by the Air Force Office of Scientific Research under
grant number FA9550-07-1-0416, and in part by the Defense Advanced Research Projects
Agency (DARPA), through the Department of the Interior, NBC, Acquisition Services Division, under Contract No. NBCHD030010.
The U.S.Government is authorized to reproduce and distribute reports for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions
contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of any of the
above organizations or any person connected with them.
585

Michelson & Knoblock

References
Agichtein, E., & Ganti, V. (2004). Mining reference tables for automatic text segmentation.
In the Proceedings of the 10th ACM Conference on Knowledge Discovery and Data
Mining, pp. 20 â€“ 29. ACM Press.
Agrawal, R., Imielinski, T., & Swami, A. (1993). Mining association rules between sets of
items in large databases. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 207â€“216. ACM Press.
Baxter, R., Christen, P., & Churches, T. (2003). A comparison of fast blocking methods for
record linkage. In Proceedings of the 9th ACM SIGKDD Workshop on Data Cleaning,
Record Linkage, and Object Identification, pp. 25â€“27.
Bellare, K., & McCallum, A. (2007). Learning extractors from unlabeled text using relevant
databases. In Proceedings of the AAAI Workshop on Information Integration on the
Web, pp. 10â€“16.
Bilenko, M., Kamath, B., & Mooney, R. J. (2006). Adaptive blocking: Learning to scale up
record linkage and clustering. In Proceedings of the 6th IEEE International Conference
on Data Mining, pp. 87â€“96.
Bilenko, M., & Mooney, R. J. (2003). Adaptive duplicate detection using learnable string
similarity measures. In Proceedings of the 9th ACM International Conference on
Knowledge Discovery and Data Mining, pp. 39â€“48. ACM Press.
Borkar, V., Deshmukh, K., & Sarawagi, S. (2001). Automatic segmentation of text into
structured records. In Proceedings of the ACM SIGMOD International Conference on
Management of Data, pp. 175â€“186. ACM Press.
Califf, M. E., & Mooney, R. J. (1999). Relational learning of pattern-match rules for
information extraction. In Proceedings of the 16th National Conference on Artificial
Intelligence, pp. 328â€“334.
Chakaravarthy, V. T., Gupta, H., Roy, P., & Mohania, M. (2006). Efficiently linking text
documents with relevant structured information. In Proceedings of the International
Conference on Very Large Data Bases, pp. 667â€“678. VLDB Endowment.
Chaudhuri, S., Ganjam, K., Ganti, V., & Motwani, R. (2003). Robust and efficient fuzzy
match for online data cleaning. In Proceedings of ACM SIGMOD International Conference on Management of Data, pp. 313â€“324. ACM Press.
Cimiano, P., Handschuh, S., & Staab, S. (2004). Towards the self-annotating web. In
Proceedings of the 13th International Conference on World Wide Web, pp. 462â€“471.
ACM Press.
Ciravegna, F. (2001). Adaptive information extraction from text by rule induction and
generalisation.. In Proceedings of the 17th International Joint Conference on Artificial
Intelligence, pp. 1251â€“1256.
586

Relational Data from Unstructured Data Sources

Cohen, W., & Sarawagi, S. (2004). Exploiting dictionaries in named entity extraction: combining semi-markov extraction processes and data integration methods. In Proceedings
of the 10th ACM International Conference on Knowledge Discovery and Data Mining,
pp. 89â€“98, Seattle, Washington. ACM Press.
Cohen, W. W. (2000). Data integration using similarity joins and a word-based information
representation language. ACM Transactions on Information Systems, 18 (3), 288â€“321.
Cohen, W. W., Ravikumar, P., & Feinberg, S. E. (2003). A comparison of string metrics
for matching names and records. In Proceedings of the ACM SIGKDD Workshop on
Data Cleaning, Record Linkage, and Object Consoliation, pp. 13â€“18.
Crescenzi, V., Mecca, G., & Merialdo, P. (2001). Roadrunner: Towards automatic data
extraction from large web sites. In Proceedings of 27th International Conference on
Very Large Data Bases, pp. 109â€“118. VLDB Endowment.
Ding, Y., Embley, D. W., & Liddle, S. W. (2006). Automatic creation and simplified querying of semantic web content: An approach based on information-extraction ontologies.
In Proceedings of the Asian Semantic Web Conference, pp. 400â€“414.
Dingli, A., Ciravegna, F., & Wilks, Y. (2003). Automatic semantic annotation using unsupervised information extraction and integration. In Proceedings of the K-CAP Workshop on Knowledge Markup and Semantic Annotation.
Elfeky, M. G., Verykios, V. S., & Elmagarmid, A. K. (2002). TAILOR: A record linkage
toolbox. In Proceedings of 18th International Conference on Data Engineering, pp.
17â€“28.
Embley, D. W., Campbell, D. M., Jiang, Y. S., Liddle, S. W., Ng, Y.-K., Quass, D., &
Smith, R. D. (1999). Conceptual-model-based data extraction from multiple-record
web pages. Data Knowledge Engineering, 31 (3), 227â€“251.
Fellegi, I. P., & Sunter, A. B. (1969). A theory for record linkage. Journal of the American
Statistical Association, 64, 1183â€“1210.
Handschuh, S., Staab, S., & Ciravegna, F. (2002). S-cream - semi-automatic creation of
metadata. In Proceedings of the 13th International Conference on Knowledge Engineering and Knowledge Management, pp. 165â€“184. Springer Verlag.
Hendler, J. (2001). Agents and the semantic web. IEEE Intelligent Systems, 16 (2), 30â€“37.
Hernandez, M. A., & Stolfo, S. J. (1998). Real-world data is dirty: Data cleansing and the
merge/purge problem. Data Mining and Knowledge Discovery, 2 (1), 9â€“37.
Jaro, M. A. (1989). Advances in record-linkage methodology as applied to matching the
1985 census of tampa, florida. Journal of the American Statistical Association, 89,
414â€“420.
Joachims, T. (1999). Advances in Kernel Methods - Support Vector Learning, chap. 11:
Making large-Scale SVM Learning Practical. MIT-Press.
587

Michelson & Knoblock

Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th
International Conference on Machine Learning, pp. 282â€“289. Morgan Kaufmann.
Lee, M.-L., Ling, T. W., Lu, H., & Ko, Y. T. (1999). Cleansing data for mining and
warehousing. In Proceedings of the 10th International Conference on Database and
Expert Systems Applications, pp. 751â€“760. Springer-Verlag.
Lerman, K., Gazen, C., Minton, S., & Knoblock, C. A. (2004). Populating the semantic web.
In Proceedings of the AAAI Workshop on Advances in Text Extraction and Mining.
Levenshtein, V. I. (1966). Binary codes capable of correcting deletions, insertions, and
reversals. English translation in Soviet Physics Doklady, 10 (8), 707â€“710.
Mansuri, I. R., & Sarawagi, S. (2006). Integrating unstructured data into relational
databases. In Proceedings of the International Conference on Data Engineering, p. 29.
IEEE Computer Society.
McCallum, A. (2002).
Mallet:
http://mallet.cs.umass.edu.

A

machine

learning

for

language

toolkit.

McCallum, A., Nigam, K., & Ungar, L. H. (2000). Efficient clustering of high-dimensional
data sets with application to reference matching. In Proceedings of the 6th ACM
SIGKDD, pp. 169â€“178.
Michalowski, M., Thakkar, S., & Knoblock, C. A. (2005). Automatically utilizing secondary
sources to align information across sources. In AI Magazine, Special Issue on Semantic
Integration, Vol. 26, pp. 33â€“45.
Michelson, M., & Knoblock, C. A. (2005). Semantic annotation of unstructured and ungrammatical text. In Proceedings of the 19th International Joint Conference on Artificial
Intelligence, pp. 1091â€“1098.
Michelson, M., & Knoblock, C. A. (2006). Learning blocking schemes for record linkage. In
Proceedings of the 21st National Conference on Artificial Intelligence.
Michelson, M., & Knoblock, C. A. (2007). Unsupervised information extraction from unstructured, ungrammatical data sources on the world wide web. International Journal
of Document Analysis and Recognition (IJDAR), Special Issue on Noisy Text Analytics.
Mitchell, T. M. (1997). Machine Learning. McGraw-Hill, New York.
MuÌˆller, H.-M., & Sternberg, E. E. K. P. W. (2004). Textpresso: An ontology-based information retrieval and extraction system for biological literature. PLoS Biology, 2 (11).
Muslea, I., Minton, S., & Knoblock, C. A. (2001). Hierarchical wrapper induction for
semistructured information sources. Autonomous Agents and Multi-Agent Systems,
4 (1/2), 93â€“114.
588

Relational Data from Unstructured Data Sources

Newcombe, H. B. (1967). Record linkage: The design of efficient systems for linking records
into individual and family histories. American Journal of Human Genetics, 19 (3),
335â€“359.
Porter, M. F. (1980). An algorithm for suffix stripping. Program, 14 (3), 130â€“137.
Smith, T. F., & Waterman, M. S. (1981). Identification of common molecular subsequences.
Journal of Molecular Biology, 147, 195â€“197.
Soderland, S. (1999). Learning information extraction rules for semi-structured and free
text. Machine Learning, 34 (1-3), 233â€“272.
Thakkar, S., Ambite, J. L., & Knoblock, C. A. (2004). A data integration approach to
automatically composing and optimizing web services. In Proceedings of the ICAPS
Workshop on Planning and Scheduling for Web and Grid Services.
Tsochantaridis, I., Hofmann, T., Joachims, T., & Altun, Y. (2004). Support vector machine
learning for interdependent and structured output spaces. In Proceedings of the 21st
International Conference on Machine Learning, p. 104. ACM Press.
Tsochantaridis, I., Joachims, T., Hofmann, T., & Altun, Y. (2005). Large margin methods
for structured and interdependent output variables. Journal of Machine Learning
Research, 6, 1453â€“1484.
Vargas-Vera, M., Motta, E., Domingue, J., Lanzoni, M., Stutt, A., & Ciravegna, F. (2002).
MnM: Ontology driven semi-automatic and automatic support for semantic markup.
In Proceedings of the 13th International Conference on Knowledge Engineering and
Management, pp. 213â€“221.
Wellner, B., McCallum, A., Peng, F., & Hay, M. (2004). An integrated, conditional model
of information extraction and coreference with application to citation matching. In
Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence, pp. 593â€“
601.
Winkler, W. E., & Thibaudeau, Y. (1991). An application of the fellegi-sunter model of
record linkage to the 1990 U.S. Decennial Census. Tech. rep., Statistical Research
Report Series RR91/09 U.S. Bureau of the Census.
Zhai, C., & Lafferty, J. (2001). A study of smoothing methods for language models applied
to ad hoc information retrieval. In Proceedings of the 24th ACM SIGIR Conference
on Research and Development in Information Retrieval, pp. 334â€“342. ACM Press.

589

Journal of Artificial Intelligence Research 31 (2008) 273-318

Submitted 07/07; published 02/08

Modular Reuse of Ontologies: Theory and Practice
Bernardo Cuenca Grau
Ian Horrocks
Yevgeny Kazakov

berg@comlab.ox.ac.uk
ian.horrocks@comlab.ox.ac.uk
yevgeny.kazakov@comlab.ox.ac.uk

Oxford University Computing Laboratory
Oxford, OX1 3QD, UK

Ulrike Sattler

sattler@cs.man.ac.uk

School of Computer Science
The University of Manchester
Manchester, M13 9PL, UK

Abstract
In this paper, we propose a set of tasks that are relevant for the modular reuse of ontologies. In order to formalize these tasks as reasoning problems, we introduce the notions
of conservative extension, safety and module for a very general class of logic-based ontology
languages. We investigate the general properties of and relationships between these notions
and study the relationships between the relevant reasoning problems we have previously
identified. To study the computability of these problems, we consider, in particular, Description Logics (DLs), which provide the formal underpinning of the W3C Web Ontology
Language (OWL), and show that all the problems we consider are undecidable or algorithmically unsolvable for the description logic underlying OWL DL. In order to achieve a
practical solution, we identify conditions sufficient for an ontology to reuse a set of symbols â€œsafelyâ€â€”that is, without changing their meaning. We provide the notion of a safety
class, which characterizes any sufficient condition for safety, and identify a family of safety
classesâ€“called localityâ€”which enjoys a collection of desirable properties. We use the notion
of a safety class to extract modules from ontologies, and we provide various modularization algorithms that are appropriate to the properties of the particular safety class in use.
Finally, we show practical benefits of our safety checking and module extraction algorithms.

1. Motivation
Ontologiesâ€”conceptualizations of a domain shared by a community of usersâ€”play a major role in the Semantic Web, and are increasingly being used in knowledge management
systems, e-Science, bio-informatics, and Grid applications (Staab & Studer, 2004).
The design, maintenance, reuse, and integration of ontologies are complex tasks. Like
software engineers, ontology engineers need to be supported by tools and methodologies
that help them to minimize the introduction of errors, i.e., to ensure that ontologies are
consistent and do not have unexpected consequences. In order to develop this support, important notions from software engineering, such as module, black-box behavior, and controlled
interaction, need to be adapted.
Recently, there has been growing interest in the topic of modularity in ontology engineering (Seidenberg & Rector, 2006; Noy, 2004a; Lutz, Walther, & Wolter, 2007; Cuenca
Grau, Parsia, Sirin, & Kalyanpur, 2006b; Cuenca Grau, Horrocks, Kazakov, & Sattler,
c
2008
AI Access Foundation. All rights reserved.

Cuenca Grau, Horrocks, Kazakov, & Sattler

2007), which has been motivated by the above-mentioned application needs. In this paper,
we focus on the use of modularity to support the partial reuse of ontologies. In particular,
we consider the scenario in which we are developing an ontology P and want to reuse a set
S of symbols from a â€œforeignâ€ ontology Q without changing their meaning.
For example, suppose that an ontology engineer is building an ontology about research
projects, which specifies different types of projects according to the research topic they
focus on. The ontology engineer in charge of the projects ontology P may use terms such
as Cystic Fibrosis and Genetic Disorder in his descriptions of medical research projects. The
ontology engineer is an expert on research projects; he may be unfamiliar, however, with
most of the topics the projects cover and, in particular, with the terms Cystic Fibrosis and
Genetic Disorder. In order to complete the projects ontology with suitable definitions for
these medical terms, he decides to reuse the knowledge about these subjects from a wellestablished medical ontology Q.
The most straightforward way to reuse these concepts is to construct the logical union
P âˆª Q of the axioms in P and Q. It is reasonable to assume that the additional knowledge
about the medical terms used in both P and Q will have implications on the meaning of the
projects defined in P; indeed, the additional knowledge about the reused terms provides new
information about medical research projects which are defined using these medical terms.
Less intuitive is the fact that importing Q may also result in new entailments concerning
the reused symbols, namely Cystic Fibrosis and Genetic Disorder. Since the ontology engineer
of the projects ontology is not an expert in medicine and relies on the designers of Q, it is
to be expected that the meaning of the reused symbols is completely specified in Q; that
is, the fact that these symbols are used in the projects ontology P should not imply that
their original â€œmeaningâ€ in Q changes. If P does not change the meaning of these symbols
in Q, we say that P âˆª Q is a conservative extension of Q
In realistic application scenarios, it is often unreasonable to assume the foreign ontology
Q to be fixed; that is, Q may evolve beyond the control of the modelers of P. The ontology
engineers in charge of P may not be authorized to access all the information in Q or,
most importantly, they may decide at a later time to reuse the symbols Cystic Fibrosis and
Genetic Disorder from a medical ontology other than Q. For application scenarios in which
the external ontology Q may change, it is reasonable to â€œabstractâ€ from the particular Q
under consideration. In particular, given a set S of â€œexternal symbolsâ€, the fact that the
axioms in P do not change the meaning of any symbol in S should be independent of the
particular meaning ascribed to these symbols by Q. In that case, we will say that P is safe
for S.
Moreover, even if P â€œsafelyâ€ reuses a set of symbols from an ontology Q, it may still
be the case that Q is a large ontology. In particular, in our example, the foreign medical
ontology may be huge, and importing the whole ontology would make the consequences
of the additional information costly to compute and difficult for our ontology engineers in
charge of the projects ontology (who are not medical experts) to understand. In practice,
therefore, one may need to extract a module Q1 of Q that includes only the relevant information. Ideally, this module should be as small as possible while still guarantee to capture
the meaning of the terms used; that is, when answering queries against the research projects
ontology, importing the module Q1 would give exactly the same answers as if the whole
medical ontology Q had been imported. In this case, importing the module will have the
274

Modular Reuse of Ontologies: Theory and Practice

same observable effect on the projects ontology as importing the entire ontology. Furthermore, the fact that Q1 is a module in Q should be independent of the particular P under
consideration.
The contributions of this paper are as follows:
1. We propose a set of tasks that are relevant to ontology reuse and formalize them as
reasoning problems. To this end, we introduce the notions of conservative extension,
safety and module for a very general class of logic-based ontology languages.
2. We investigate the general properties of and relationships between the notions of
conservative extension, safety, and module and use these properties to study the relationships between the relevant reasoning problems we have previously identified.
3. We consider Description Logics (DLs), which provide the formal underpinning of the
W3C Web Ontology Language (OWL), and study the computability of our tasks. We
show that all the tasks we consider are undecidable or algorithmically unsolvable for
the description logic underlying OWL DLâ€”the most expressive dialect of OWL that
has a direct correspondence to description logics.
4. We consider the problem of deciding safety of an ontology for a signature. Given that
this problem is undecidable for OWL DL, we identify sufficient conditions for safety,
which are decidable for OWL DLâ€”that is, if an ontology satisfies our conditions
then it is safe; the converse, however, does not necessarily hold. We propose the
notion of a safety class, which characterizes any sufficiency condition for safety, and
identify a family of safety classesâ€“called localityâ€”which enjoys a collection of desirable
properties.
5. We next apply the notion of a safety class to the task of extracting modules from
ontologies; we provide various modularization algorithms that are appropriate to the
properties of the particular safety class in use.
6. We present empirical evidence of the practical benefits of our techniques for safety
checking and module extraction.
This paper extends the results in our previous work (Cuenca Grau, Horrocks, Kutz, &
Sattler, 2006; Cuenca Grau et al., 2007; Cuenca Grau, Horrocks, Kazakov, & Sattler, 2007).

2. Preliminaries
In this section we introduce description logics (DLs) (Baader, Calvanese, McGuinness,
Nardi, & Patel-Schneider, 2003), a family of knowledge representation formalisms which
underlie modern ontology languages, such as OWL DL (Patel-Schneider, Hayes, & Horrocks, 2004). A hierarchy of commonly-used description logics is summarized in Table 1.
The syntax of a description logic L is given by a signature and a set of constructors. A
signature (or vocabulary) Sg of a DL is the (disjoint) union of countably infinite sets AC
of atomic concepts (A, B, . . . ) representing sets of elements, AR of atomic roles (r, s, . . . )
representing binary relations between elements, and Ind of individuals (a, b, c, . . . ) representing constants. We assume the signature to be fixed for every DL.
275

Cuenca Grau, Horrocks, Kazakov, & Sattler

DLs

Constructors
Con
>, A, C1 u C2 , âˆƒR.C
â€“ppâ€“, Â¬C
â€“ppâ€“

Axioms [ Ax ]
TBox
ABox
A â‰¡ C, C1 v C2 a : C, r(a, b)
â€“ppâ€“
â€“ppâ€“
â€“ppâ€“
â€“ppâ€“

Rol
RBox
EL
r
ALC â€“ppâ€“
S â€“ppâ€“
Trans(r)
+ I
râˆ’
+ H
R 1 v R2
+ F
Funct(R)
+ N
(> n S)
+ Q
(> n S.C)
+ O
{i}
Here r âˆˆ AR, A âˆˆ AC, a, b âˆˆ Ind, R(i) âˆˆ Rol, C(i) âˆˆ Con, n â‰¥ 1 and S âˆˆ Rol is a simple
role (see (Horrocks & Sattler, 2005)).
Table 1: The hierarchy of standard description logics

Every DL provides constructors for defining the set Rol of (general) roles (R, S, . . . ),
the set Con of (general) concepts (C, D, . . . ), and the set Ax of axioms (Î±, Î², . . . ) which is
a union of role axioms (RBox), terminological axioms (TBox) and assertions (ABox).
EL (Baader, Brandt, & Lutz, 2005) is a simple description logic which allows one to
construct complex concepts using conjunction C1 u C2 and existential restriction âˆƒR.C
starting from atomic concepts A, roles R and the top concept >. EL provides no role
constructors and no role axioms; thus, every role R in EL is atomic. The TBox axioms of
EL can be either concept definitions A â‰¡ C or general concept inclusion axioms (GCIs)
C1 v C2 . EL assertions are either concept assertions a : C or role assertions r(a, b). In this
paper we assume the concept definition A â‰¡ C is an abbreviation for two GCIs A v C and
C v A.
The basic description logic ALC (Schmidt-SchauÃŸ & Smolka, 1991) is obtained from EL
by adding the concept negation constructor Â¬C. We introduce some additional constructors
as abbreviations: the bottom concept âŠ¥ is a shortcut for Â¬>, the concept disjunction C1 t C2
stands for Â¬(Â¬C1 u Â¬C2 ), and the value restriction âˆ€R.C stands for Â¬(âˆƒR.Â¬C). In contrast
to EL, ALC can express contradiction axioms like > v âŠ¥. The logic S is an extension of
ALC where, additionally, some atomic roles can be declared to be transitive using a role
axiom Trans(r).
Further extensions of description logics add features such as inverse roles râˆ’ (indicated
by appending a letter I to the name of the logic), role inclusion axioms (RIs) R1 v R2 (+H),
functional roles Funct(R) (+F), number restrictions (> n S), with n â‰¥ 1, (+N ), qualified
number restrictions (> n S.C), with n â‰¥ 1, (+Q)1 , and nominals {a} (+O). Nominals make
it possible to construct a concept representing a singleton set {a} (a nominal concept) from
an individual a. These extensions can be used in different combinations; for example ALCO
is an extension of ALC with nominals; SHIQ is an extension of S with role hierarchies,
1. the dual constructors (6 n S) and (6 n S.C) are abbreviations for Â¬(> n + 1 S) and Â¬(> n + 1 S.Â¬C),
respectively

276

Modular Reuse of Ontologies: Theory and Practice

inverse roles and qualified number restrictions; and SHOIQ is the DL that uses all the
constructors and axiom types we have presented.
Modern ontology languages, such as OWL, are based on description logics and, to a certain extent, are syntactic variants thereof. In particular, OWL DL corresponds to SHOIN
(Horrocks, Patel-Schneider, & van Harmelen, 2003). In this paper, we assume an ontology
O based on a description logic L to be a finite set of axioms in L. The signature of an
ontology O (of an axiom Î±) is the set Sig(O) (Sig(Î±)) of atomic concepts, atomic roles and
individuals that occur in O (respectively in Î±).
The main reasoning task for ontologies is entailment: given an ontology O and an axiom
Î±, check if O implies Î±. The logical entailment |= is defined using the usual Tarski-style
set-theoretic semantics for description logics as follows. An interpretation I is a pair I =
(âˆ†I , Â·I ), where âˆ†I is a non-empty set, called the domain of the interpretation, and Â·I is the
interpretation function that assigns: to every A âˆˆ AC a subset AI âŠ† âˆ†I , to every r âˆˆ AR
a binary relation rI âŠ† âˆ†I Ã— âˆ†I , and to every a âˆˆ Ind an element aI âˆˆ âˆ†I . Note that the
sets AC, AR and Ind are not defined by the interpretation I but assumed to be fixed for
the ontology language (DL).
The interpretation function Â·I is extended to complex roles and concepts via DLconstructors as follows:
(>)I
(C u D)I
(âˆƒR.C)I
(Â¬C)I
(râˆ’ )I

=
=
=
=
=

âˆ†
C I âˆ© DI
{x âˆˆ âˆ†I | âˆƒy.hx, yi âˆˆ RI âˆ§ y âˆˆ C I }
âˆ†I \ C I
{hx, yi | hy, xi âˆˆ rI }

(> n R)I = { x âˆˆ âˆ†I | ]{y âˆˆ âˆ†I | hx, yi âˆˆ RI } â‰¥ n }
(> n R.C)I = { x âˆˆ âˆ†I | ]{y âˆˆ âˆ†I | hx, yi âˆˆ RI âˆ§ y âˆˆ C I } â‰¥ n }
{a}I = {aI }
The satisfaction relation I |= Î± between an interpretation I and a DL axiom Î± (read as I
satisfies Î±, or I is a model of Î±) is defined as follows:
I |= C1 v C2 iff C1I âŠ† C2I ;
I |= R1 v R2 iff R1I âŠ† R2I ;

I |= a : C iff aI âˆˆ C I ;
I |= r(a, b) iff haI , bI i âˆˆ rI ;

I |= Trans(r) iff âˆ€x, y, z âˆˆ âˆ†I [ hx, yi âˆˆ rI âˆ§ hy, zi âˆˆ rI â‡’ hx, zi âˆˆ rI ];
I |= Funct(R) iff âˆ€x, y, z âˆˆ âˆ†I [ hx, yi âˆˆ RI âˆ§ hx, zi âˆˆ RI â‡’ y = z ];
An interpretation I is a model of an ontology O if I satisfies all axioms in O. An
ontology O implies an axiom Î± (written O |= Î±) if I |= Î± for every model I of O. Given
a set I of interpretations, we say that an axiom Î± (an ontology O) is valid in I if every
interpretation I âˆˆ I is a model of Î± (respectively O). An axiom Î± is a tautology if it is valid
in the set of all interpretations (or, equivalently, is implied by the empty ontology).
We say that two interpretations I = (âˆ†I , Â·I ) and J = (âˆ†J , Â·J ) coincide on the subset
S of the signature (notation: I|S = J |S ) if âˆ†I = âˆ†J and X I = X J for every X âˆˆ S. We
say that two sets of interpretations I and J are equal modulo S (notation: I|S = J|S ) if for
every I âˆˆ I there exits J âˆˆ J such that J |S = I|S and for every J âˆˆ J there exists I âˆˆ I
such that I|S = J |S .
277

Cuenca Grau, Horrocks, Kazakov, & Sattler

Ontology of medical research projects P:
P1

Genetic Disorder Project â‰¡ Project u âˆƒhas Focus.Genetic Disorder

P2

Cystic Fibrosis EUProject â‰¡ EUProject u âˆƒhas Focus.Cystic Fibrosis

P3

EUProject v Project

P4

âˆƒhas Focus.> v Project

E1

Project u (Genetic Disorder ::
u Cystic Fibrosis) v âŠ¥

E2

âˆ€ has Focus.Cystic Fibrosis v âˆƒhas Focus.Genetic Disorder

::

Ontology of medical terms Q:
M1 Cystic Fibrosis â‰¡ Fibrosis u âˆƒlocated In.Pancreas u âˆƒhas Origin.Genetic Origin
M2 Genetic Fibrosis â‰¡ Fibrosis u âˆƒhas Origin.Genetic Origin
M3 Fibrosis u âˆƒlocated In.Pancreas v Genetic Fibrosis
M4 Genetic Fibrosis v Genetic Disorder
M5 DEFBI Gene v Immuno Protein Gene u âˆƒassociated With.Cystic Fibrosis
Figure 1: Reusing medical terminology in an ontology on research projects

3. Ontology Integration and Knowledge Reuse
In this section, we elaborate on the ontology reuse scenario sketched in Section 1. Based on
this application scenario, we motivate and define the reasoning tasks to be investigated in
the remainder of the paper. In particular, our tasks are based on the notions of a conservative
extension (Section 3.2), safety (Sections 3.2 and 3.3) and module (Section 3.4). These notions
are defined relative to a language L. Within this section, we assume that L is an ontology
language based on a description logic; in Section 3.6, we will define formally the class of
ontology languages for which the given definitions of conservative extensions, safety and
modules apply. For the convenience of the reader, all the tasks we consider in this paper
are summarized in Table 2.
3.1 A Motivating Example
Suppose that an ontology engineer is in charge of a SHOIQ ontology on research projects,
which specifies different types of projects according to the research topic they are concerned
with. Assume that the ontology engineer defines two conceptsâ€”Genetic Disorder Project and
Cystic Fibrosis EUProjectâ€”in his ontology P. The first one describes projects about genetic
disorders; the second one describes European projects about cystic fibrosis, as given by the
axioms P1 and P2 in Figure 1. The ontology engineer is an expert on research projects: he
knows, for example, that every instance of EUProject must be an instance of Project (the
concept-inclusion axiom P3) and that the role has Focus can be applied only to instances
of Project (the domain axiom P4). He may be unfamiliar, however, with most of the topics
the projects cover and, in particular, with the terms Cystic Fibrosis and Genetic Disorder
mentioned in P1 and P2. In order to complete the projects ontology with suitable definitions
278

Modular Reuse of Ontologies: Theory and Practice

for these medical terms, he decides to reuse the knowledge about these subjects from a wellestablished and widely-used medical ontology.
Suppose that Cystic Fibrosis and Genetic Disorder are described in an ontology Q containing the axioms M1-M5 in Figure 1. The most straightforward way to reuse these concepts
is to import in P the ontology Qâ€”that is, to add the axioms from Q to the axioms in P
and work with the extended ontology P âˆª Q. Importing additional axioms into an ontology
may result in new logical consequences. For example, it is easy to see that axioms M1â€“M4
in Q imply that every instance of Cystic Fibrosis is an instance of Genetic Disorder:
Q |= Î± := (Cystic Fibrosis v Genetic Disorder)

(1)

Indeed, the concept inclusion Î±1 := (Cystic Fibrosis v Genetic Fibrosis) follows from axioms
M1 and M2 as well as from axioms M1 and M3; Î± follows from axioms Î±1 and M4.
Using inclusion Î± from (1) and axioms P1â€“P3 from ontology P we can now prove that
every instance of Cystic Fibrosis EUProject is also an instance of Genetic Disorder Project:
P âˆª Q |= Î² := (Cystic Fibrosis EUProject v Genetic Disorder Project)

(2)

This inclusion Î², however, does not follow from P aloneâ€”that is, P 6|= Î². The ontology
engineer might be not aware of Entailment (2), even though it concerns the terms of primary
scope in his projects ontology P.
It is natural to expect that entailments like Î± in (1) from an imported ontology Q result
in new logical consequences, like Î², in (2), over the terms defined in the main ontology P.
One would not expect, however, that the meaning of the terms defined in Q changes as a
consequence of the import since these terms are supposed to be completely specified within
Q. Such a side effect would be highly undesirable for the modeling of ontology P since the
ontology engineer of P might not be an expert on the subject of Q and is not supposed to
alter the meaning of the terms defined in Q not even implicitly.
The meaning of the reused terms, however, might change during the import, perhaps due
to modeling errors. In order to illustrate such a situation, suppose that the ontology engineer
has learned about the concepts Genetic Disorder and Cystic Fibrosis from the ontology Q
(including the inclusion (1)) and has decided to introduce additional axioms formalizing
the following statements:
â€œEvery instance of Project is different from every instance of Genetic Disorder
and
every instance of Cystic Fibrosis.â€
:::

(3)

â€œ::::::
Every::::::::
project that has Focus on Cystic Fibrosis, also has Focus on Genetic Disorderâ€

(4)

Note that the statements (3) and (4) can be thought of as adding new information about
projects and, intuitively, they should not change or constrain the meaning of the medical
terms.
Suppose the ontology engineer has formalized the statements (3) and (4) in ontology
P using axioms E1 and E2 respectively. At this point, the ontology engineer has introduced modeling errors and, as a consequence, axioms E1 and E2 do not correspond to (3)
and (4): E1 actually formalizes the following statement: â€œEvery instance of Project is different from every common instance of Genetic Disorder and Cystic Fibrosisâ€, and E2 expresses
279

Cuenca Grau, Horrocks, Kazakov, & Sattler

that â€œEvery object that either has Focus on nothing, or has Focus only on Cystic Fibrosis,
also has Focus on Genetic Disorderâ€. These kinds of modeling errors are difficult to detect,
especially when they do not cause inconsistencies in the ontology.
Note that, although axiom E1 does not correspond to fact (3), it is still a consequence
of (3) which means that it should not constrain the meaning of the medical terms. On the
other hand, E2 is not a consequence of (4) and, in fact, it constrains the meaning of medical
terms. Indeed, the axioms E1 and E2 together with axioms P1-P4 from P imply new axioms
about the concepts Cystic Fibrosis and Genetic Disorder, namely their disjointness:
P |= Î³ := (Genetic Disorder u Cystic Fibrosis v âŠ¥)

(5)

The entailment (5) can be proved using axiom E2 which is equivalent to:
> v âˆƒhas Focus.(Genetic Disorder t Â¬Cystic Fibrosis)

(6)

The inclusion (6) and P4 imply that every element in the domain must be a projectâ€”that
is, P |= (> v Project). Now, together with axiom E1, this implies (5).
The axioms E1 and E2 not only imply new statements about the medical terms, but also
cause inconsistencies when used together with the imported axioms from Q. Indeed, from
(1) and (5) we obtain P âˆª Q |= Î´ := (Cystic Fibrosis v âŠ¥), which expresses the inconsistency
of the concept Cystic Fibrosis.
To summarize, we have seen that importing an external ontology can lead to undesirable
side effects in our knowledge reuse scenario, like the entailment of new axioms or even inconsistencies involving the reused vocabulary. In the next section we discuss how to formalize
the effects we consider undesirable.
3.2 Conservative Extensions and Safety for an Ontology
As argued in the previous section, an important requirement for the reuse of an ontology Q
within an ontology P should be that P âˆª Q produces exactly the same logical consequences
over the vocabulary of Q as Q alone does. This requirement can be naturally formulated
using the well-known notion of a conservative extension, which has recently been investigated in the context of ontologies (Ghilardi, Lutz, & Wolter, 2006; Lutz et al., 2007).
Definition 1 (Deductive Conservative Extension). Let O and O1 âŠ† O be two Lontologies, and S a signature over L. We say that O is a deductive S-conservative extension
of O1 w.r.t. L, if for every axiom Î± over L with Sig(Î±) âŠ† S, we have O |= Î± iff O1 |= Î±.
We say that O is a deductive conservative extension of O1 w.r.t. L if O is a deductive
S-conservative extension of O1 w.r.t. L for S = Sig(O1 ).
â™¦
In other words, an ontology O is a deductive S-conservative extension of O1 for a
signature S and language L if and only if every logical consequence Î± of O constructed
using the language L and symbols only from S, is already a logical consequence of O1 ; that
is, the additional axioms in O \ O1 do not result into new logical consequences over the
vocabulary S. Note that if O is a deductive S-conservative extension of O1 w.r.t. L, then
O is a deductive S1 -conservative extension of O1 w.r.t. L for every S1 âŠ† S.
The notion of a deductive conservative extension can be directly applied to our ontology
reuse scenario.
280

Modular Reuse of Ontologies: Theory and Practice

Definition 2 (Safety for an Ontology). Given L-ontologies O and O0 , we say that O
is safe for O0 (or O imports O0 in a safe way) w.r.t. L if O âˆª O0 is a deductive conservative
extension of O0 w.r.t. L.
â™¦
Hence, the first reasoning task relevant for our ontology reuse scenario can be formulated
as follows:
T1.

given L-ontologies O and O0 , determine if O is safe for O0 w.r.t. L.

We have shown in Section 3.1 that, given P consisting of axioms P1â€“P4, E1, E2, and Q
consisting of axioms M1â€“M5 from Figure 1, there exists an axiom Î´ = (Cystic Fibrosis v âŠ¥)
that uses only symbols in Sig(Q) such that Q 6|= Î´ but P âˆª Q |= Î´. According to Definition 1,
this means that P âˆª Q is not a deductive conservative extension of Q w.r.t. any language
L in which Î´ can be expressed (e.g. L = ALC). It is possible, however, to show that if the
axiom E2 is removed from P then for the resulting ontology P1 = P \ {E2}, P1 âˆª Q is a
deductive conservative extension of Q. The following notion is useful for proving deductive
conservative extensions:
Definition 3 (Model Conservative Extension, Lutz et al., 2007).
Let O and O1 âŠ† O be two L-ontologies and S a signature over L. We say that O is a model
S-conservative extension of O1 , if for every model I of O1 , there exists a model J of O
such that I|S = J |S . We say that O is a model conservative extension of O1 if O is a model
S-conservative extension of O1 for S = Sig(O1 ).
â™¦
The notion of model conservative extension in Definition 3 can be seen as a semantic
counterpart for the notion of deductive conservative extension in Definition 1: the latter is
defined in terms of logical entailment, whereas the former is defined in terms of models.
Intuitively, an ontology O is a model S-conservative extension of O1 if for every model of
O1 one can find a model of O over the same domain which interprets the symbols from S
in the same way. The notion of model conservative extension, however, does not provide
a complete characterization of deductive conservative extensions, as given in Definition 1;
that is, this notion can be used for proving that an ontology is a deductive conservative
extension of another, but not vice versa:
Proposition 4 (Model vs. Deductive Conservative Extensions, Lutz et al., 2007)
1. For every two L-ontologies O, O1 âŠ† O, and a signature S over L, if O is a model
S-conservative extension of O1 then O is a deductive S-conservative extension of O1
w.r.t. L;
2. There exist two ALC ontologies O and O1 âŠ† O such that O is a deductive conservative
extension of O1 w.r.t. ALC, but O is not a model conservative extension of O1 .
Example 5 Consider an ontology P1 consisting of axioms P1â€“P4, and E1 and an ontology
Q consisting of axioms M1â€“M5 from Figure 1. We demonstrate that P1 âˆª Q is a deductive
conservative extension of Q. According to proposition 4, it is sufficient to show that P1 âˆª Q
is a model conservative extension of Q; that is, for every model I of Q there exists a model
J of P1 âˆª Q such that I|S = J |S for S = Sig(Q).
281

Cuenca Grau, Horrocks, Kazakov, & Sattler

The required model J can be constructed from I as follows: take J to be identical to I except for the interpretations of the atomic concepts Genetic Disorder Project,
Cystic Fibrosis EUProject, Project, EUProject and the atomic role has Focus, all of which
we interpret in J as the empty set. It is easy to check that all the axioms P1â€“P4, E1 are
satisfied in J and hence J |= P1 . Moreover, since the interpretation of the symbols in Q
remains unchanged, we have I|Sig(Q) = J |Sig(Q) and J |= Q. Hence, P1 âˆª Q is a model
conservative extension of Q.
For an example of Statement 2 of the Proposition, we refer the interested reader to the
literature (Lutz et al., 2007, p. 455).
â™¦
3.3 Safety of an Ontology for a Signature
So far, in our ontology reuse scenario we have assumed that the reused ontology Q is fixed
and the axioms of Q are just copied into P during the import. In practice, however, it
is often convenient to keep Q separate from P and make its axioms available on demand
via a reference. This makes it possible to continue developing P and Q independently. For
example, the ontology engineers of the project ontology P may not be willing to depend
on a particular version of Q, or may even decide at a later time to reuse the medical terms
(Cystic Fibrosis and Genetic Disorder) from another medical ontology instead. Therefore, for
many application scenarios it is important to develop a stronger safety condition for P
which depends as little as possible on the particular ontology Q to be reused. In order to
formulate such condition, we abstract from the particular ontology Q to be imported and
focus instead on the symbols from Q that are to be reused:
Definition 6 (Safety for a Signature). Let O be a L-ontology and S a signature over L.
We say that O is safe for S w.r.t. L, if for every L-ontology O0 with Sig(O) âˆ© Sig(O0 ) âŠ† S,
we have that O is safe for O0 w.r.t. L; that is, O âˆª O0 is a deductive conservative extension
of O0 w.r.t. L.
â™¦
Intuitively, in our knowledge reuse scenario, an ontology O is safe for a signature S w.r.t.
a language L if and only if it imports in a safe way any ontology O0 written in L that shares
only symbols from S with O. The associated reasoning problem is then formulated in the
following way:
T2.

given an L-ontology O and a signature S over L,
determine if O is safe for S w.r.t. L.

As seen in Section 3.2, the ontology P consisting of axioms P1â€“P4, E1, E2 from Figure 1,
does not import Q consisting of axioms M1â€“M5 from Figure 1 in a safe way for L = ALC.
According to Definition 6, since Sig(P) âˆ© Sig(Q) âŠ† S = {Cystic Fibrosis, Genetic Disorder},
the ontology P is not safe for S w.r.t. L.
In fact, it is possible to show a stronger result, namely, that any ontology O containing
axiom E2 is not safe for S = {Cystic Fibrosis, Genetic Disorder} w.r.t. L = ALC. Consider an
ontology O0 = {Î²1 , Î²2 }, where Î²1 = (> v Cystic Fibrosis) and Î²2 = (Genetic Disorder v âŠ¥).
Since E2 is equivalent to axiom (6), it is easy to see that O âˆª O0 is inconsistent. Indeed E2,
Î²1 and Î²2 imply the contradiction Î± = (> v âŠ¥), which is not entailed by O0 . Hence, O âˆª O0
is not a deductive conservative extension of O0 . By Definition 6, since Sig(O) âˆ© Sig(O0 ) âŠ† S,
this means that O is not safe for S.
282

Modular Reuse of Ontologies: Theory and Practice

It is clear how one could prove that an ontology O is not safe for a signature S: simply find
an ontology O0 with Sig(O) âˆ© Sig(O0 ) âŠ† S, such that O âˆª O0 is not a deductive conservative
extension of O0 . It is not so clear, however, how one could prove that O is safe for S. It
turns out that the notion of model conservative extensions can also be used for this purpose.
The following lemma introduces a property which relates the notion of model conservative
extension with the notion of safety for a signature. Intuitively, it says that the notion of
model conservative extension is stable under expansion with new axioms provided they
share only symbols from S with the original ontologies.
Lemma 7 Let O, O1 âŠ† O, and O0 be L-ontologies and S a signature over L such that
O is a model S-conservative extension of O1 and Sig(O) âˆ© Sig(O0 ) âŠ† S. Then O âˆª O0 is a
model S0 -conservative extension of O1 âˆª O0 for S0 = S âˆª Sig(O0 ).
Proof. In order to show that OâˆªO0 is a model S0 -conservative extension of O1 âˆªO0 according
to Definition 3, let I be a model of O1 âˆª O0 . We just construct a model J of O âˆª O0 such
that I|S0 = J |S0 .
(])
Since O is a model S-conservative extension of O1 , and I is a model of O1 , by Definition 3
there exists a model J1 of O such that I|S = J1 |S . Let J be an interpretation such
that J |Sig(O) = J1 |Sig(O) and J |S0 = I|S0 . Since Sig(O) âˆ© S0 = Sig(O) âˆ© (S âˆª Sig(O0 )) âŠ†
S âˆª (Sig(O) âˆ© Sig(O0 )) âŠ† S and I|S = J1 |S , such interpretation J always exists. Since
J |Sig(O) = J1 |Sig(O) and J1 |= O, we have J |= O; since J |S0 = I|S0 , Sig(O0 ) âŠ† S0 , and
I |= O0 , we have J |= O0 . Hence J |= O âˆª O0 and I|S0 = J |S0 , which proves (]).
Lemma 7 allows us to identify a condition sufficient to ensure the safety of an ontology
for a signature:
Proposition 8 (Safety for a Signature vs. Model Conservative Extensions)
Let O be an L-ontology and S a signature over L such that O is a model S-conservative
extension of the empty ontology O1 = âˆ…; that is, for every interpretation I there exists a
model J of O such that J |S = I|S . Then O is safe for S w.r.t. L.
Proof. In order to prove that O is safe for S w.r.t. L according to Definition 6, take any
SHOIQ ontology O0 such that Sig(O) âˆ© Sig(O0 ) âŠ† S. We need to demonstrate that O âˆª O0
is a deductive conservative extension of O0 w.r.t. L.
(])
Indeed, by Lemma 7, since O is a model S-conservative extension of O1 = âˆ…, and
Sig(O)âˆ©Sig(O0 ) âŠ† S, we have that OâˆªO0 is a model S0 -conservative extension of O1 âˆªO0 = O0
for S0 = S âˆª Sig(O0 ). In particular, since Sig(O0 ) âŠ† S0 , we have that O âˆª O0 is a deductive
conservative extension of O0 , as was required to prove (]).
Example 9 Let P1 be the ontology consisting of axioms P1â€“P4, and E1 from Figure 1.
We show that P1 is safe for S = {Cystic Fibrosis, Genetic Disorder} w.r.t. L = SHOIQ. By
Proposition 8, in order to prove safety for P1 it is sufficient to demonstrate that P1 is a
model S-conservative extension of the empty ontology, that is, for every S-interpretation I
there exists a model J of P1 such that I|S = J |S .
Consider the model J obtained from I as in Example 5. As shown in Example 5, J is
a model of P1 and I|Sig(Q) = J |Sig(Q) where Q consists of axioms M1â€“M5 from Figure 1.
In particular, since S âŠ† Sig(Q), we have I|S = J |S .
â™¦
283

Cuenca Grau, Horrocks, Kazakov, & Sattler

3.4 Extraction of Modules from Ontologies
In our example from Figure 1 the medical ontology Q is very small. Well established medical
ontologies, however, can be very large and may describe subject matters in which the designer of P is not interested. For example, the medical ontology Q could contain information
about genes, anatomy, surgical techniques, etc.
Even if P imports Q without changing the meaning of the reused symbols, processingâ€”
that is, browsing, reasoning over, etcâ€”the resulting ontology P âˆª Q may be considerably
harder than processing P alone. Ideally, one would like to extract a (hopefully small) fragment Q1 of the external medical ontologyâ€”a moduleâ€”that describes just the concepts that
are reused in P.
Intuitively, when answering an arbitrary query over the signature of P, importing the
module Q1 should give exactly the same answers as if the whole ontology Q had been
imported.
Definition 10 (Module for an Ontology). Let O, O0 and O10 âŠ† O0 be L-ontologies.
We say that O10 is a module for O in O0 w.r.t. L, if O âˆª O0 is a deductive S-conservative
extension of O âˆª O10 for S = Sig(O) w.r.t. L.
â™¦
The task of extracting modules from imported ontologies in our ontology reuse scenario
can be thus formulated as follows:
T3.

given L-ontologies O, O0 ,
compute a module O10 for O in O0 w.r.t. L.

Example 11 Consider the ontology P1 consisting of axioms P1â€“P4, E1 and the ontology Q
consisting of axioms M1â€“M5 from Figure 1. Recall that the axiom Î± from (1) is a consequence of axioms M1, M2 and M4 as well as of axioms M1, M3 and M4 from ontology Q.
In fact, these sets of axioms are actually minimal subsets of Q that imply Î±. In particular,
for the subset Q0 of Q consisting of axioms M2, M3, M4 and M5, we have Q0 6|= Î±. It can
be demonstrated that P1 âˆª Q0 is a deductive conservative extension of Q0 . In particular
P1 âˆª Q0 6|= Î±. But then, according to Definition 10, Q0 is not a module for P1 in Q w.r.t.
L = ALC or its extensions, since P1 âˆª Q is not an deductive S-conservative extension of
P1 âˆª Q0 w.r.t. L = ALC for S = Sig(P1 ). Indeed, P1 âˆª Q |= Î±, Sig(Î±) âŠ† S but P1 âˆª Q0 6|= Î±.
Similarly, one can show that any subset of Q that does not imply Î± is not a module in Q
w.r.t. P1 .
On the other hand, it is possible to show that both subsets Q1 = {M1, M2, M4} and
Q2 = {M1, M3, M4} of Q are modules for P1 in Q w.r.t. L = SHOIQ. To do so, Definition 10, we need to demonstrate that P1 âˆª Q is a deductive S-conservative extension of
both P1 âˆª Q1 and P1 âˆª Q2 for S = Sig(P1 ) w.r.t. L. As usual, we demonstrate a stronger
fact, that P1 âˆª Q is a model S-conservative extension of P1 âˆª Q1 and of P1 âˆª Q2 for S which
is sufficient by Claim 1 of Proposition 4.
In order to show that P1 âˆª Q is a model S-conservative extension of P1 âˆª Q1 for S =
Sig(P1 ), consider any model I of P1 âˆª Q1 . We need to construct a model J of P1 âˆª Q
such that I|S = J |S . Let J be defined exactly as I except that the interpretations of the
atomic concepts Fibrosis, Pancreas, Genetic Fibrosis, and Genetic Origin are defined as the
interpretation of Cystic Fibrosis in I, and the interpretations of atomic roles located In and
284

Modular Reuse of Ontologies: Theory and Practice

has Origin are defined as the identity relation. It is easy to see that axioms M1â€“M3 and M5
are satisfied in J . Since we do not modify the interpretation of the symbols in P1 , J also
satisfies all axioms from P1 . Moreover, J is a model of M4, because Genetic Fibrosis and
Genetic Disorder are interpreted in J like Cystic Fibrosis and Genetic Disorder in I, and I is
a model of Q1 , which implies the concept inclusion Î± = (Cystic Fibrosis v Genetic Disorder).
Hence we have constructed a model J of P1 âˆª Q such that I|S = J |S , thus P1 âˆª Q is a
model S-conservative extension of P1 âˆª Q1 .
In fact, the construction above works if we replace Q1 with any subset of Q that implies
Î±. In particular, P1 âˆª Q is also a model S-conservative extension of P1 âˆª Q2 . In this way, we
have demonstrated that the modules for P in Q are exactly those subsets of Q that imply
Î±.
â™¦
An algorithm implementing the task T3 can be used for extracting a module from an
ontology Q imported into P prior to performing reasoning over the terms in P. However,
when the ontology P is modified, the module has to be extracted again since a module Q1
for P in Q might not necessarily be a module for the modified ontology. Since the extraction
of modules is potentially an expensive operation, it would be more convenient to extract a
module only once and reuse it for any version of the ontology P that reuses the specified
symbols from Q. This idea motivates the following definition:
Definition 12 (Module for a Signature). Let O0 and O10 âŠ† O0 be L-ontologies and S
a signature over L. We say that O10 is a module for S in O0 (or an S-module in O0 ) w.r.t.
L, if for every L-ontology O with Sig(O) âˆ© Sig(O0 ) âŠ† S, we have that O10 is a module for O
in O0 w.r.t. L.
â™¦
Intuitively, the notion of a module for a signature is a uniform analog of the notion of a
module for an ontology, in a similar way as the notion of safety for a signature is a uniform
analog of safety for an ontology. The reasoning task corresponding to Definition 12 can be
formulated as follows:
T4.

given a L-ontology O0 and a signature S over L,
compute a module O10 for S in O0 .

Continuing Example 11, it is possible to demonstrate that any subset of Q that implies
axiom Î±, is in fact a module for S = {Cystic Fibrosis, Genetic Disorder} in Q, that is, it can
be imported instead of Q into every ontology O that shares with Q only symbols from S. In
order to prove this, we use the following sufficient condition based on the notion of model
conservative extension:
Proposition 13 (Modules for a Signature vs. Model Conservative Extensions)
Let O0 and O10 âŠ† O0 be L-ontologies and S a signature over L such that O0 is a model
S-conservative extension of O10 . Then O10 is a module for S in O0 w.r.t. L.
Proof. In order to prove that O10 is a module for S in O0 w.r.t. L according to Definition 12,
take any SHOIQ ontology O such that Sig(O) âˆ© Sig(O0 ) âŠ† S. We need to demonstrate
that O10 is a module for O in O0 w.r.t. L, that is, according to Definition 10, O âˆª O0 is a
deductive S0 -conservative extension of O âˆª O10 w.r.t. L for S0 = Sig(O).
(])
285

Cuenca Grau, Horrocks, Kazakov, & Sattler

Indeed, by Lemma 7, since O0 is a model S-conservative extension of O10 , and Sig(O0 ) âˆ©
Sig(O) âŠ† S, we have that O0 âˆª O is a model S00 -conservative extension of O10 âˆª O for
S00 = S âˆª Sig(O). In particular, since S0 = Sig(O) âŠ† S00 , we have that O0 âˆª O is a deductive
S0 -conservative extension of O10 âˆª O w.r.t. L, as was required to prove (]).
Example 14 Let Q and Î± be as in Example 11. We demonstrate that any subset Q1 of Q
which implies Î± is a module for S = {Cystic Fibrosis, Genetic Disorder} in Q. According to
Proposition 13, it is sufficient to demonstrate that Q is a model S-conservative extension of
Q1 , that is, for every model I of Q1 there exists a model J of Q such that I|S = J |S . It is
easy to see that if the model J is constructed from I as in Example 11, then the required
property holds.
â™¦
Note that a module for a signature S in Q does not necessarily contain all the axioms that
contain symbols from S. For example, the module Q1 consisting of the axiom M1, M2 and
M4 from Q does not contain axiom M5 which mentions the atomic concept Cystic Fibrosis
from S. Also note that even in a minimal module like Q1 there might still be some axioms
like M2 that do not mention symbols from S at all.
3.5 Minimal Modules and Essential Axioms
One is usually not interested in extracting arbitrary modules from a reused ontology, but
in extracting modules that are easy to process afterwards. Ideally, the extracted modules
should be as small as possible. Hence it is reasonable to consider the problem of extracting
minimal modules; that is, modules that contain no other module as a subset.
Examples 11 and 14 demonstrate that a minimal module for an ontology or a signature
is not necessarily unique: the ontology Q consisting of axioms M1â€“M5 has two minimal modules Q1 = {M1, M2, M4}, and Q2 = {M1, M3, M4}, for the ontology P1 = {P1, P2, P3, E1}
as well as for the signature S = {Cystic Fibrosis, Genetic Disorder}, since these are the minimal sets of axioms that imply axiom Î± = (Cystic Fibrosis v Genetic Disorder). Depending
on the application scenario, one can consider several variations of tasks T3 and T4 for computing minimal modules. In some applications it might be necessary to extract all minimal
modules, whereas in others any minimal module suffices.
Axioms that do not occur in a minimal module in Q are not essential for P because
they can always be removed from every module of Q, thus they never need not be imported
into P. This is not true for the axioms that occur in minimal modules of Q. It might be
necessary to import such axioms into P in order not to lose essential information from Q.
These arguments motivate the following notion:
Definition 15 (Essential Axiom). Let O and O0 be L-ontologies, S a signature and Î±
an axiom over L. We say that Î± is essential for O in O0 w.r.t. L if Î± is contained in any
minimal module in O0 for O w.r.t. L. We say that Î± is an essential axiom for S in O0 w.r.t.
L (or S-essential in O0 ) if Î± is contained in some minimal module for S in O0 w.r.t. L. â™¦
In our example above the axioms M1â€“M4 from Q are essential for the ontology P1 and
for the signature S = {Cystic Fibrosis, Genetic Disorder}, but the axiom M5 is not essential.
In certain situations one might be interested in computing the set of essential axioms of
an ontology, which can be done by computing the union of all minimal modules. Note that
286

Modular Reuse of Ontologies: Theory and Practice

Notation

Input

Task

Checking Safety:
T1

O, O0 , L

Check if O is safe for O0 w.r.t. L

T2

O, S, L

Check if O is safe for S w.r.t. L

Extracting of [all / some / union of] [minimal] module(s):
T3[a,s,u][m]

O, O0 , L

Extract modules in O0 w.r.t. O and L

T4[a,s,u][m]

O0 , S, L

Extract modules for S in O0 w.r.t. L

where O, O0 are ontologies and S a signature over L
Table 2: Summary of reasoning tasks relevant for ontology integration and reuse
computing the union of minimal modules might be easier than computing all the minimal
modules since one does not need to identify which axiom belongs to which minimal module.
In Table 2 we have summarized the reasoning tasks we found to be potentially relevant
for ontology reuse scenarios and have included the variants T3am, T3sm, and T3um of the
task T3 and T4am, T4sm, and T4um of the task T4 for computation of minimal modules
discussed in this section.
Further variants of the tasks T3 and T4 could be considered relevant to ontology reuse.
For example, instead of computing minimal modules, one might be interested in computing
modules with the smallest number of axioms, or modules of the smallest size measured in
the number of symbols, or in any other complexity measure of the ontology. The theoretical
results that we will present in this paper can easily be extended to many such reasoning
tasks.
3.6 Safety and Modules for General Ontology Languages
All the notions introduced in Section 3 are defined with respect to an â€œontology languageâ€.
So far, however, we have implicitly assumed that the ontology languages are the description
logics defined in Section 2â€”that is, the fragments of the DL SHOIQ. The notions considered in Section 3 can be applied, however, to a much broader class of ontology languages.
Our definitions apply to any ontology language with a notion of entailment of axioms from
ontologies, and a mechanism for identifying their signatures.
Definition 16. An ontology language is a tuple L = (Sg, Ax, Sig, |=), where Sg is a set
of signature elements (or vocabulary) of L, Ax is a set of axioms in L, Sig is a function
that assigns to every axiom Î± âˆˆ Ax a finite set Sig(Î±) âŠ† Sg called the signature of Î±, and
|= is the entailment relation between sets of axioms O âŠ† Ax and axioms Î± âˆˆ Ax, written
O |= Î±. An ontology over L is a finiteSset of axioms O âŠ† Ax. We extend the function Sig
to ontologies O as follows: Sig(O) := Î±âˆˆO Sig(Î±).
â™¦
Definition 16 provides a very general notion of an ontology language. A language L is
given by a set of symbols (a signature), a set of formulae (axioms) that can be constructed
over those symbols, a function that assigns to each formula its signature, and an entailment
relation between sets of axioms. The ontology language OWL DL as well as all description
287

Cuenca Grau, Horrocks, Kazakov, & Sattler

logics defined in Section 2 are examples of ontology languages in accordance to Definition 16.
Other examples of ontology languages are First Order Logic, Second Order Logic, and Logic
Programs.
It is easy to see that the notions of deductive conservative extension (Definition 1), safety
(Definitions 2 and 6) and modules (Definitions 10 and 12), as well as all the reasoning tasks
from Table 2, are well-defined for every ontology language L given by Definition 16. The
definition of model conservative extension (Definition 3) and the propositions involving
model conservative extensions (Propositions 4, 8, and 13) can be also extended to other
languages with a standard Tarski model-theoretic semantics, such as Higher Order Logic.
To simplify the presentation, however, we will not formulate general requirements on the
semantics of ontology languages, and assume that we deal with sublanguages of SHOIQ
whenever semantics is taken into account.
In the remainder of this section, we establish the relationships between the different
notions of safety and modules for arbitrary ontology languages.
Proposition 17 (Safety vs. Modules for an Ontology) Let L be an ontology language,
and let O, O0 , and O10 âŠ† O0 be ontologies over L. Then:
1. O0 is safe for O w.r.t. L iff the empty ontology is a module for O in O0 w.r.t. L.
2. If O0 \ O10 is safe for O âˆª O10 then O10 is a module for O in O0 w.r.t. L.
Proof. 1. By Definition 2, O0 is safe for O w.r.t. L iff (a) O âˆª O0 is a deductive conservative
extension of O w.r.t. L. By Definition 10, the empty ontology O00 = âˆ… is a module for O in
O0 w.r.t. L iff (b) O âˆª O0 is a deductive S-conservative extension of O âˆª O00 = O w.r.t. L
for S = Sig(O). It is easy to see that (a) is the same as (b).
2. By Definition 2, O0 \ O10 is safe for O âˆª O10 w.r.t. L iff (c) O âˆª O10 âˆª (O0 \ O10 ) = O âˆª O0
is a deductive conservative extension of O âˆª O10 w.r.t. L. In particular, O âˆª O0 is a deductive
S-conservative extension of O âˆª O10 w.r.t. L for S = Sig(O), which implies, by Definition 10,
that O10 is a module for O in O0 w.r.t. L.
We also provide the analog of Proposition 17 for the notions of safety and modules for
a signature:
Proposition 18 (Safety vs. Modules for a Signature) Let L be an ontology language,
O0 and O10 âŠ† O0 , ontologies over L, and S a subset of the signature of L. Then:
1. O0 is safe for S w.r.t. L iff the empty ontology O00 = âˆ… is an S-module in O0 w.r.t. L.
2. If O0 \ O10 is safe for S âˆª Sig(O10 ) w.r.t. L, then O10 is an S-module in O0 w.r.t. L.
Proof. 1. By Definition 6, O0 is safe for S w.r.t. L iff (a) for every O with Sig(O0 ) âˆ© Sig(O) âŠ†
S, it is the case that O0 is safe for O w.r.t. L. By Definition 12, O00 = âˆ… is an S-module
in O0 w.r.t. L iff (b) for every O with Sig(O0 ) âˆ© Sig(O) âŠ† S, it is the case that O00 = âˆ… is
a module for O in O0 w.r.t. L. By Claim 1 of Proposition 17, it is easy to see that (a) is
equivalent to (b).
2. By Definition 6, O0 \ O10 is safe for S âˆª Sig(O10 ) w.r.t. L iff (c) for every O, with
Sig(O0 \ O10 ) âˆ© Sig(O) âŠ† S âˆª Sig(O10 ), we have that O0 \ O10 is safe for O w.r.t. L. By
288

Modular Reuse of Ontologies: Theory and Practice

Definition 12, O10 is an S-module in O0 w.r.t. L iff (d) for every O with Sig(O0 )âˆ©Sig(O) âŠ† S,
we have that O10 is a module for O in O0 w.r.t. L.
In order to prove that (c) implies (d), let O be such that Sig(O0 ) âˆ© Sig(O) âŠ† S. We need
to demonstrate that O10 is a module for O in O0 w.r.t. L.
(?)
0
0
0
0
0
0
Let OÌƒ := O âˆª O1 . Note that Sig(O \ O1 ) âˆ© Sig(OÌƒ) = Sig(O \ O1 ) âˆ© (Sig(O) âˆª Sig(O1 )) âŠ†
(Sig(O0 \ O10 ) âˆ© Sig(O)) âˆª Sig(O10 ) âŠ† S âˆª Sig(O10 ). Hence, by (c) we have that O0 \ O10 is safe
for OÌƒ = O âˆª O10 w.r.t. L which implies by Claim 2 of Proposition 17 that O10 is a module
for O in O0 w.r.t. L (?).

4. Undecidability and Complexity Results
In this section we study the computational properties of the tasks in Table 2 for ontology
languages that correspond to fragments of the description logic SHOIQ. We demonstrate
that most of these reasoning tasks are algorithmically unsolvable even for relatively inexpressive DLs, and are computationally hard for simple DLs.
Since the notions of modules and safety are defined in Section 3 using the notion of
deductive conservative extension, it is reasonable to identify which (un)decidability and
complexity results for conservative extensions are applicable to the reasoning tasks in Table 2. The computational properties of conservative extensions have recently been studied
in the context of description logics. Given O1 âŠ† O over a language L, the problem of
deciding whether O is a deductive conservative extension of O1 w.r.t. L is 2-EXPTIMEcomplete for L = ALC (Ghilardi et al., 2006). This result was extended by Lutz et al.
(2007), who showed that the problem is 2-EXPTIME-complete for L = ALCIQ and undecidable for L = ALCIQO. Recently, the problem has also been studied for simple DLs; it
has been shown that deciding deductive conservative extensions is EXPTIME-complete for
L = EL(Lutz & Wolter, 2007). These results can be immediately applied to the notions of
safety and modules for an ontology:
Proposition 19 Given ontologies O and O0 over L, the problem of determining whether
O is safe for O0 w.r.t. L is EXPTIME-complete for L = EL, 2-EXPTIME-complete for
L = ALC and L = ALCIQ, and undecidable for L = ALCIQO. Given ontologies O, O0 ,
and O10 âŠ† O0 over L, the problem of determining whether O10 is a module for O in O0 is
EXPTIME-complete for L = EL, 2-EXPTIME complete for L = ALC and L = ALCIQ,
and undecidable for L = ALCIQO.
Proof. By Definition 2, an ontology O is safe for O0 w.r.t. L iff O âˆª O0 is a deductive
conservative extension of O0 w.r.t. L. By Definition 2, an ontology O10 is a module for O in
O0 w.r.t. L if O âˆª O0 is a deductive S-conservative extension of O âˆª O10 for S = Sig(O) w.r.t.
L. Hence, any algorithm for checking deductive conservative extensions can be reused for
checking safety and modules.
Conversely, we demonstrate that any algorithm for checking safety or modules can be
used for checking deductive conservative extensions. Indeed, O is a deductive conservative
extension of O1 âŠ† O w.r.t. L iff O\O1 is safe for O1 w.r.t. L iff, by Claim 1 of Proposition 17,
O0 = âˆ… is a module for O1 in O \ O1 w.r.t. L .

289

Cuenca Grau, Horrocks, Kazakov, & Sattler

Corollary 20 There exist algorithms performing tasks T1, and T3[a,s,u]m from Table 2
for L = EL and L = ALCIQ that run in EXPTIME and 2-EXPTIME respectively. There
is no algorithm performing tasks T1, or T3[a,s,u]m from Table 2 for L = ALCIQO.
Proof. The task T1 corresponds directly to the problem of checking the safety of an ontology,
as given in Definition 2.
Suppose that we have a 2-EXPTIME algorithm that, given ontologies O, O0 and O10 âŠ†
0
O , determines whether O10 is a module for O in O0 w.r.t. L = ALCIQ. We demonstrate
that this algorithm can be used to solve the reasoning tasks T3am, T3sm and T3um for
L = ALCIQ in 2-EXPTIME. Indeed, given ontologies O and O0 , one can enumerate all
subsets of O0 and check in 2-EXPTIME which of these subsets are modules for O in O0
w.r.t. L. Then we can determine which of these modules are minimal and return all of them,
one of them, or the union of them depending on the reasoning task.
Finally, we prove that solving any of the reasoning tasks T3am, T3sm and T3um is not
easier than checking the safety of an ontology. Indeed, by Claim 1 of Proposition 17, an
ontology O is safe for O0 w.r.t. L iff O0 = âˆ… is a module for O0 in O w.r.t. L. Note that
the empty ontology O0 = âˆ… is a module for O0 in O w.r.t. L iff O0 = âˆ… is the only minimal
module for O0 in O w.r.t. L.
We have demonstrated that the reasoning tasks T1 and T3[a,s,u]m are computationally
unsolvable for DLs that are as expressive as ALCQIO, and are 2-EXPTIME-hard for ALC.
In the remainder of this section, we focus on the computational properties of the reasoning
tasks T2 and T4[a,s,u]m related to the notions of safety and modules for a signature. We
demonstrate that all of these reasoning tasks are undecidable for DLs that are as expressive
as ALCO.
Theorem 21 (Undecidability of Safety for a Signature) The problem of checking
whether an ontology O consisting of a single ALC-axiom is safe for a signature S is undecidable w.r.t. L = ALCO.
Proof. The proof is a variation of the construction for undecidability of deductive conservative extensions in ALCQIO (Lutz et al., 2007), based on a reduction to a domino tiling
problem.
A domino system is a triple D = (T, H, V ) where T = {1, . . . , k} is a finite set of tiles
and H, V âŠ† T Ã— T are horizontal and vertical matching relations. A solution for a domino
system D is a mapping ti,j that assigns to every pair of integers i, j â‰¥ 1 an element of T ,
such that hti,j , ti,j+1 i âˆˆ H and hti,j , ti+1,j i âˆˆ V . A periodic solution for a domino system
D is a solution ti,j for which there exist integers m â‰¥ 1 , n â‰¥ 1 called periods such that
ti+m,j = ti,j and ti,j+n = ti,j for every i, j â‰¥ 1.
Let D be the set of all domino systems, Ds be the subset of D that admit a solution and
Dps be the subset of Ds that admit a periodic solution. It is well-known (BoÌˆrger, GraÌˆdel,
& Gurevich, 1997, Theorem 3.1.7) that the sets D \ Ds and Dps are recursively inseparable,
that is, there is no recursive (i.e. decidable) subset D0 âŠ† D of domino systems such that
Dps âŠ† D0 âŠ† Ds .
We use this property in our reduction. For each domino system D, we construct a
signature S = S(D), and an ontology O = O(D) which consists of a single ALC-axiom such
that:
290

Modular Reuse of Ontologies: Theory and Practice

(q1 )

> v A1 t Â· Â· Â· t Ak

where T = {1, . . . , k}

(q2 )

At u At0 v âŠ¥
F
At v âˆƒrH .( ht,t0 iâˆˆH At0 )
F
At v âˆƒrV .( ht,t0 iâˆˆV At0 )

1 â‰¤ t < t0 â‰¤ k

(q3 )
(q4 )

1â‰¤tâ‰¤k
1â‰¤tâ‰¤k

Figure 2: An ontology Otile = Otile (D) expressing tiling conditions for a domino system D
(a) if D does not have a solution then O = O(D) is safe for S = S(D) w.r.t. L = ALCO,
and
(b) if D has a periodic solution then O = O(D) is not safe for S = S(D) w.r.t. L = ALCO.
In other words, for the set D0 consisting of the domino systems D such that O = O(D)
is not safe for S = S(D) w.r.t. L = ALCO, we have Dps âŠ† D0 âŠ† Ds . Since D \ Ds and Dps
are recursively inseparable, this implies undecidability for D0 and hence for the problem of
checking if O is S-safe w.r.t. L = ALCO, because otherwise one can use this problem for
deciding membership in D0 .
The signature S = S(D), and the ontology O = O(D) are constructed as follows. Given
a domino system D = (T, H, V ), let S consist of fresh atomic concepts At for every t âˆˆ T and
two atomic roles rH and rV . Consider an ontology Otile in Figure 2 constructed for D. Note
that Sig(Otile ) = S. The axioms of Otile express the tiling conditions for a domino system
D, namely (q1 ) and (q2 ) express that every domain element is assigned with a unique tile
t âˆˆ T ; (q3 ) and (q4 ) express that every domain element has horizontal and vertical matching
successors.
Now let s be an atomic role and B an atomic concept such that s, B âˆˆ
/ S. Let O := {Î²}
where:
i
hF
Î² := > v âˆƒs.
(Ci vDi )âˆˆOtile (Ci u Â¬Di ) t (âˆƒrH .âˆƒrV .B u âˆƒrV .âˆƒrH .Â¬B)
We say that rH and rV commute in an interpretation I = (âˆ†I , Â·I ) if for all domain
elements a, b, c, d1 and d2 from âˆ†I such that ha, bi âˆˆ rH I , hb, d1 i âˆˆ rV I , ha, ci âˆˆ rV I , and
hc, d2 i âˆˆ rH I , we have d1 = d2 . The following claims can be easily proved:
Claim 1.

If Otile (D) has a model I in which rH and rV commute, then D has a solution.

Indeed a model I = (âˆ†, Â·I ) of Otile (D) can be used to guide the construction of a solution
ti,j for D as follows. For every i, j â‰¥ 1, we construct ti,j inductively together with elements
ai,j âˆˆ âˆ†I such that hai,j , ai,j+1 i âˆˆ rV I and hai,j , ai+1,j i âˆˆ rH I . We set a1,1 to any element
from âˆ†I .
Now suppose ai,j with i, j â‰¥ 1 is constructed. Since I is a model of axioms (q1 ) and
(q2 ) from Figure 2, we have a unique At with 1 â‰¤ t â‰¤ k such that ai,j âˆˆ At I . Then we set
ti,j := t. Since I is a model of axioms (q3 ) and (q4 ) and ai,j âˆˆ At I there exist b, c âˆˆ âˆ†I
and t0 , t00 âˆˆ T such that hai,j , bi âˆˆ rH I , hai,j , ci âˆˆ rV I , ht, t0 i âˆˆ H, ht, t00 i âˆˆ V , b âˆˆ At0 I ,
and c âˆˆ At00 I . In this case we assign ai,j+1 := b, ai+1,j := c, ti,j+1 := t0 , and ti+1,j := t00 .
Note that some values of ai,j and ti,j can be assigned two times: ai+1,j+1 and ti+1,j+1 are
constructed for ai,j+1 and ai,j+1 . However, since rV and rH commute in I, the value for
291

Cuenca Grau, Horrocks, Kazakov, & Sattler

ai+1,j+1 is unique, and because of (q2 ), the value for ti+1,j+1 is unique. It is easy to see that
ti,j is a solution for D.
Claim 2.

If I is a model of Otile âˆª O, then rH and rV do not commute in I.

Indeed, it is easy to see that Otile âˆª O |= (> v âˆƒs.[âˆƒrH .âˆƒrV .B u âˆƒrV .âˆƒrH .Â¬B]). Hence, if
I = (âˆ†I , Â·I ) is a model of Otile âˆª O, then there exist a, b, c, d1 and d2 such that hx, ai âˆˆ sI
for every x âˆˆ âˆ†I , ha, bi âˆˆ rH I , hb, d1 i âˆˆ rV I , d1 âˆˆ B I , ha, ci âˆˆ rV I , hc, d2 i âˆˆ rH I , and
d2 âˆˆ (Â¬B)I . This implies that d1 6= d2 , and so, rh and rV do not commute in I.
Finally, we demonstrate that O = O(D) satisfies properties (a) and (b).
In order to prove property (a) we use the sufficient condition for safety given in Proposition 8 and demonstrate that if D has no solution then for every interpretation I there
exists a model J of O such that J |S = I|S . By Proposition 8, this will imply that O is safe
for S w.r.t. L.
Let I be an arbitrary interpretation. Since D has no solution, then by the contra-positive
of Claim 1 either (1) I is not a model of Otile , or (2) rH and rV do not commute in I. We
demonstrate for both of these cases how to construct the required model J of O such that
J |S = I|S .
Case (1). If I = (âˆ†I , Â·I ) is not a model of Otile then there exists an axiom (Ci v Di ) âˆˆ
Otile such that I 6|= (Ci v Di ). That is, there exists a domain element a âˆˆ âˆ†I such that
a âˆˆ CiI but a 6âˆˆ DiI . Let us define J to be identical to I except for the interpretation of the
atomic role s which we define in J as sJ = {hx, ai | x âˆˆ âˆ†}. Since the interpretations of
the symbols in S have remained unchanged, we have a âˆˆ CiJ , a âˆˆ Â¬DiJ , and so J |= (> v
âˆƒs.[Ci u Â¬Dj ]). This implies that J |= Î², and so, we have constructed a model J of O such
that J |S = I|S .
Case (2). Suppose that rH and rV do not commute in I = (âˆ†I , Â·I ). This means that
there exist domain elements a, b, c, d1 and d2 from âˆ†I with ha, bi âˆˆ rH I , hb, d1 i âˆˆ rV I ,
ha, ci âˆˆ rV I , and hc, d2 i âˆˆ rH I , such that d1 6= d2 . Let us define J to be identical to I except
for the interpretation of the atomic role s and the atomic concept B. We interpret s in J as
sJ = {hx, ai | x âˆˆ âˆ†}. We interpret B in J as B J = {d1 }. Note that a âˆˆ (âˆƒrH .âˆƒrV .B)J and
a âˆˆ (âˆƒrV .âˆƒrH .Â¬B)J since d1 6= d2 . So, we have J |= (> v âˆƒs.[âˆƒrH .âˆƒrV .B u âˆƒrV .âˆƒrH .Â¬B])
which implies that J |= Î², and thus, we have constructed a model J of O such that
J |S = I|S .
In order to prove property (b), assume that D has a periodic solution ti,j with the
periods m, n â‰¥ 1. We demonstrate that O is not S-safe w.r.t. L. For this purpose we
construct an ALCO-ontology O0 with Sig(O) âˆ© Sig(O0 ) âŠ† S such that O âˆª O0 |= (> v âŠ¥),
but O0 6|= (> v âŠ¥). This will imply that O is not safe for O0 w.r.t. L = ALCO, and, hence,
is not safe for S w.r.t. L = ALCO.
We define O0 such that every model of O0 is a finite encoding of the periodic solution ti,j
with the periods m and n. For every pair (i, j) with 1 â‰¤ i â‰¤ m and 1 â‰¤ j â‰¤ n we introduce
a fresh individual ai,j and define O0 to be an extension of Otile with the following axioms:
(p1 ) {ai1 ,j } v âˆƒrV .{ai2 ,j }

(p2 ) {ai1 ,j } v âˆ€rV .{ai2 ,j },

i2 = i1 + 1

mod m

(p3 ) {ai,j1 } v âˆƒrH .{ai,j2 }

(p4 ) {ai,j1 } v âˆ€rH .{ai,j2 },
j2 = j1 + 1
F
(p5 ) > v 1â‰¤iâ‰¤m, 1â‰¤jâ‰¤n {ai,j }

mod n

292

Modular Reuse of Ontologies: Theory and Practice

The purpose of axioms (p1 )â€“(p5 ) is to ensure that rH and rV commute in every model of
O0 . It is easy to see that O0 has a model corresponding to every periodic solution for D with
periods m and n. Hence O0 6|= (> v âŠ¥). On the other hand, by Claim 2, since O0 contains
Otile , then in every model of O0 âˆª O, rH and rV do not commute. This is only possible if
O0 âˆª O have no models, so O0 âˆª O |= (> v âŠ¥).
A direct consequence of Theorem 21 and Proposition 18 is the undecidability of the
problem of checking whether a subset of an ontology is a module for a signature:
Corollary 22 Given a signature S and ALC-ontologies O0 and O10 âŠ† O0 , the problem of
determining whether O10 is an S-module in O0 w.r.t. L = ALCO is undecidable.
Proof. By Claim 1 of Proposition 18, O is S-safe w.r.t. L if O0 = âˆ… is an S-module in O
w.r.t. L. Hence any algorithm for recognizing modules for a signature in L can be used for
checking if an ontology is safe for a signature in L.
Corollary 23 There is no algorithm that can perform tasks T2, or T4[a,s,u]m for L =
ALCO.
Proof. Theorem 21 directly implies that there is no algorithm for task T2, since this task
corresponds to the problem of checking safety for a signature.
Solving any of the reasoning tasks T4am, T4sm, or T4um for L is at least as hard as
checking the safety of an ontology, since, by Claim 1 of Proposition 18, an ontology O is
S-safe w.r.t. L iff O0 = âˆ… is (the only minimal) S-module in O w.r.t. L.

5. Sufficient Conditions for Safety
Theorem 21 establishes the undecidability of checking whether an ontology expressed in
OWL DL is safe w.r.t. a signature. This undecidability result is discouraging and leaves
us with two alternatives: First, we could focus on simple DLs for which this problem is
decidable. Alternatively, we could look for sufficient conditions for the notion of safetyâ€”
that is, if an ontology satisfies our conditions, then we can guarantee that it is safe; the
converse, however, does not necessarily hold.
The remainder of this paper focuses on the latter approach. Before we go any further,
however, it is worth noting that Theorem 21 still leaves room for investigating the former
approach. Indeed, safety may still be decidable for weaker description logics, such as EL,
or even for very expressive logics such as SHIQ. In the case of SHIQ, however, existing
results (Lutz et al., 2007) strongly indicate that checking safety is likely to be exponentially
harder than reasoning and practical algorithms may be hard to design. This said, in what
follows we will focus on defining sufficient conditions for safety that we can use in practice
and restrict ourselves to OWL DLâ€”that is, SHOIQâ€”ontologies.
5.1 Safety Classes
In general, any sufficient condition for safety can be defined by giving, for each signature
S, the set of ontologies over a language that satisfy the condition for that signature. These
ontologies are then guaranteed to be safe for the signature under consideration. These
intuitions lead to the notion of a safety class.
293

Cuenca Grau, Horrocks, Kazakov, & Sattler

Definition 24 (Class of Ontologies, Safety Class). A class of ontologies for a language
L is a function O(Â·) that assigns to every subset S of the signature of L, a subset O(S)
of ontologies in L. A class O(Â·) is anti-monotonic if S1 âŠ† S2 implies O(S2 ) âŠ† O(S1 ); it is
compact when O âˆˆ O(S âˆ© Sig(O)) for each O âˆˆ O(S); and it is subset-closed if O1 âŠ† O2
and O2 âˆˆ O(S) implies O1 âˆˆ O(S); it is union-closed if O1 âˆˆ O(S) and O2 âˆˆ O(S) implies
(O1 âˆª O2 ) âˆˆ O(S).
A safety class (also called a sufficient condition to safety) for an ontology language L
is a class of ontologies O(Â·) for L such that for each S it is the case that (i) âˆ… âˆˆ O(S), and
(ii) each ontology O âˆˆ O(S) is S-safe for L.
â™¦
Intuitively, a class of ontologies is a collection of sets of ontologies parameterized by a
signature. A safety class represents a sufficient condition for safety: each ontology in O(S)
should be safe for S. Also, w.l.o.g., we assume that the the empty ontology âˆ… belongs to
every safety class for every signature. In what follows, whenever an ontology O belongs to
a safety class for a given signature and the safety class is clear from the context, we will
sometimes say that O passes the safety test for S.
Safety classes may admit many natural properties, as given in Definition 24. Antimonotonicity intuitively means that if an ontology O can be proved to be safe w.r.t. S
using the sufficient condition, then O can be proved to be safe w.r.t. every subset of S.
Compactness means that it is sufficient to consider only common elements of Sig(O) and S
for checking safety. Subset-closure (union closure) means that if O (O1 and O2 ) satisfy the
sufficient condition for safety, then every subset of O (the union of O1 and O2 ) also satisfies
this condition.
5.2 Locality
In this section we introduce a family of safety classes for L = SHOIQ that is based on the
semantic properties underlying the notion of model conservative extensions. In Section 3,
we have seen that, according to Proposition 8, one way to prove that O is S-safe is to show
that O is a model S-conservative extension of the empty ontology.
The following definition formalizes the classes of ontologies, called local ontologies, for
which safety can be proved using Proposition 8.
Definition 25 (Class of Interpretations, Locality). Given a SHOIQ signature S,
we say that a set of interpretations I is local w.r.t. S if for every SHOIQ-interpretation I
there exists an interpretation J âˆˆ I such that I|S = J |S .
A class of interpretations is a function I(Â·) that given a SHOIQ signature S returns a set
of interpretations I(S); it is local if I(S) is local w.r.t. S for every S; it is monotonic if S1 âŠ† S2
implies I(S1 ) âŠ† I(S2 ); it is compact if for every S1 , S2 and S such that (S1 M S2 ) âˆ© S = âˆ…
we have that I(S1 )|S = I(S2 )|S , where S1 M S2 is the symmetric difference of sets S1 and
S2 defined by S1 M S2 := S1 \ S2 âˆª S2 \ S1 .
Given a class of interpretations I(Â·), we say that O(Â·) is the class of ontologies O(Â·) based
on I(Â·) if for every S, O(S) is the set of ontologies that are valid in I(S); if I(Â·) is local then
we say that O(Â·) is a class of local ontologies, and for every S and O âˆˆ O(S) and every
Î± âˆˆ O, we say that O and Î± are local (based on I(Â·)).
â™¦

294

Modular Reuse of Ontologies: Theory and Practice

râ†âˆ…
Example 26 Let IAâ†âˆ…
(Â·) be a class of SHOIQ interpretations defined as follows. Given a
râ†âˆ…
signature S, the set IAâ†âˆ… (S) consists of interpretations J such that rJ = âˆ… for every atomic
râ†âˆ…
role r âˆˆ
/ S and AJ = âˆ… for every atomic concept A âˆˆ
/ S. It is easy to show that IAâ†âˆ…
(S)
I
I
is local for every S, since for every interpretation I = (âˆ† , Â· ) and the interpretation
J = (âˆ†J , Â·J ) defined by âˆ†J := âˆ†I , rJ = âˆ… for r âˆˆ
/ S, AJ = âˆ… for A âˆˆ
/ S, and X J := X I
râ†âˆ…
râ†âˆ…
râ†âˆ…
for the remaining symbols X, then J âˆˆ IAâ†âˆ… (S) and I|S = J |S . Since IAâ†âˆ…
(S1 ) âŠ† IAâ†âˆ…
(S2 )
râ†âˆ…
râ†âˆ…
for every S1 âŠ† S2 , it is the case that IAâ†âˆ… (Â·) is monotonic; IAâ†âˆ… (Â·) is also compact, since for
râ†âˆ…
râ†âˆ…
(S2 ) are defined differently
(S1 ) and IAâ†âˆ…
every S1 and S2 the sets of interpretations IAâ†âˆ…
only for elements in S1 M S2 .
râ†âˆ…
râ†âˆ…
Given a signature S, the set AxAâ†âˆ…
(S) of axioms that are local w.r.t. S based on IAâ†âˆ…
(S)
râ†âˆ…
consists of all axioms Î± such for every J âˆˆ IAâ†âˆ… (S), it is the case that J |= Î±. Then the
râ†âˆ…
râ†âˆ…
râ†âˆ…
(S).
(S) iff O âŠ† AxAâ†âˆ…
(Â·) is defined by O âˆˆ OAâ†âˆ…
class of local ontologies based on IAâ†âˆ…
â™¦

Proposition 27 (Locality Implies Safety) Let O(Â·) be a class of ontologies for SHOIQ
based on a local class of interpretations I(Â·). Then O(Â·) is a subset-closed and union-closed
safety class for L = SHOIQ. Additionally, if I(Â·) is monotonic, then O(Â·) is anti-monotonic,
and if I(Â·) is compact then O(Â·) is also compact.
Proof. Assume that O(Â·) is a class of ontologies based on I(Â·). Then by Definition 25 for
every SHOIQ signature S, we have O âˆˆ O(S) iff O is valid in I(S) iff J |= O for every
interpretation J âˆˆ I(S). Since I(Â·) is a local class of interpretations, we have that for
every SHOIQ-interpretation I there exists J âˆˆ I(S) such that J |S = I|S . Hence for
every O âˆˆ I(S) and every SHOIQ interpretation I there is a model J âˆˆ I(S) such that
J |S = I|S , which implies by Proposition 8 that O is safe for S w.r.t. L = SHOIQ. Thus
O(Â·) is a safety class.
The fact that O(Â·) is subset-closed and union-closed follows directly from Definition 25
since (O1 âˆª O2 ) âˆˆ O(S) iff (O1 âˆª O2 ) is valid in I(S) iff O1 and O2 are valid in I(S) iff
O1 âˆˆ O(S) and O2 âˆˆ O(S). If I(Â·) is monotonic then I(S1 ) âŠ† I(S2 ) for every S1 âŠ† S2 , and
so O âˆˆ O(S2 ) implies that O is valid in I(S2 ) which implies that O is valid in I(S1 ) which
implies that O âˆˆ O(S1 ). Hence O(Â·) is anti-monotonic.
If I(Â·) is compact then for every S1 , S2 and S such that (S1 M S2 ) âˆ© S = âˆ… we have
that I(S1 )|S = I(S2 )|S , hence for every O with Sig(O) âŠ† S we have that O is valid in
I(S1 ) iff O is valid in I(S2 ), and so, O âˆˆ O(S1 ) iff O âˆˆ O(S2 ). In particular, O âˆˆ O(S) iff
O âˆˆ O(S âˆ© Sig(O)) since (S M (S âˆ© Sig(O))) âˆ© Sig(O) = (S \ Sig(O)) âˆ© Sig(O) = âˆ…. Hence,
O(Â·) is compact.
râ†âˆ…
Corollary 28 The class of ontologies OAâ†âˆ…
(S) defined in Example 26 is an anti-monotonic
compact subset-closed and union-closed safety class.

Example 29 Recall that in Example 5 from Section 3, we demonstrated that the ontology
P1 âˆª Q given in Figure 1 with P1 = {P1, . . . , P4, E1} is a deductive conservative extension
of Q for S = {Cystic Fibrosis, Genetic Disorder}. This has been done by showing that every
S-interpretation I can be expanded to a model J of axioms P1â€“P4, E1 by interpreting
the symbols in Sig(P1 ) \ S as the empty set. In terms of Example 26 this means that
295

Cuenca Grau, Horrocks, Kazakov, & Sattler

râ†âˆ…
râ†âˆ…
P1 âˆˆ OAâ†âˆ…
(S). Since OAâ†âˆ…
(Â·) is a class of local ontologies, by Proposition 27, the ontology
P1 is safe for S w.r.t. L = SHOIQ.
â™¦

Proposition 27 and Example 29 suggest a particular way of proving the safety of ontologies. Given a SHOIQ ontology O and a signature S it is sufficient to check whether
râ†âˆ…
(S); that is, whether every axiom Î± in O is satisfied by every interpretation from
O âˆˆ OAâ†âˆ…
râ†âˆ…
IAâ†âˆ… (S). If this property holds, then O must be safe for S according to Proposition 27.
It turns out that this notion provides a powerful sufficiency test for safety which works
surprisingly well for many real-world ontologies, as will be shown in Section 8. In the next
section we discuss how to perform this test in practice.
5.3 Testing Locality
râ†âˆ…
In this section, we focus in more detail on the safety class OAâ†âˆ…
(Â·), introduced in Example 26. When ambiguity does not arise, we refer to this safety class simply as locality.2
râ†âˆ…
From the definition of AxAâ†âˆ…
(S) given in Example 26 it is easy to see that an axiom Î± is
râ†âˆ…
local w.r.t. S (based on IAâ†âˆ… (S)) if Î± is satisfied in every interpretation that fixes the interpretation of all atomic roles and concepts outside S to the empty set. Note that for defining
locality we do not fix the interpretation of the individuals outside S, but in principle, this
could be done. The reason is that there is no elegant way to describe such interpretations.
Namely, every individual needs to be interpreted as an element of the domain, and there is
no â€œcanonicalâ€ element of every domain to choose.
In order to test the locality of Î± w.r.t. S, it is sufficient to interpret every atomic concept
and atomic role not in S as the empty set and then check if Î± is satisfied in all interpretations
of the remaining symbols. This observation suggests the following test for locality:

Proposition 30 (Testing Locality) Given a SHOIQ signature S, concept C, axiom Î±
and ontology O let Ï„ (C, S), Ï„ (Î±, S) and Ï„ (O, S) be defined recursively as follows:
Ï„ (C, S) ::=

Ï„ (>, S)
| Ï„ (A, S)
| Ï„ ({a}, S)
| Ï„ (C1 u C2 , S)
| Ï„ (Â¬C1 , S)
| Ï„ (âˆƒR.C1 , S)
| Ï„ (> n R.C 1 , S)

= >;
= âŠ¥ if A âˆˆ
/ S and otherwise = A;
= {a};
= Ï„ (C1 , S) u Ï„ (C2 , S);
= Â¬Ï„ (C1 , S);
= âŠ¥ if Sig(R) * S and otherwise = âˆƒR.Ï„ (C1 , S);
= âŠ¥ if Sig(R) * S and otherwise = (> n R.Ï„ (C1 , S)).

Ï„ (C1 v C2 , S) = (Ï„ (C1 , S) v Ï„ (C2 , S));
| Ï„ (R1 v R2 , S) = (âŠ¥ v âŠ¥) if Sig(R1 ) * S, otherwise
= âˆƒR1 .> v âŠ¥ if Sig(R2 ) * S, otherwise = (R1 v R2 );
| Ï„ (a : C, S)
= a : Ï„ (C, S);
| Ï„ (r(a, b), S)
= > v âŠ¥ if r âˆˆ
/ S and otherwise = r(a, b);
| Ï„ (Trans(r), S) = âŠ¥ v âŠ¥ if r âˆˆ
/ S and otherwise = Trans(r);
| Ï„ (Funct(R), S) = âŠ¥ v âŠ¥ if Sig(R) * S and otherwise = Funct(R).
S
Ï„ (O, S) ::=
Î±âˆˆO Ï„ (Î±, S)
Ï„ (Î±, S) ::=

2. This notion of locality is exactly the one we used in our previous work (Cuenca Grau et al., 2007).

296

(a)
(b)
(c)
(d)
(e)
(f )
(g)
(h)
(i)
(j)
(k)
(l)
(m)
(n)

Modular Reuse of Ontologies: Theory and Practice

râ†âˆ…
Then, O âˆˆ OAâ†âˆ…
(S) iff every axiom in Ï„ (O, S) is a tautology.

Proof. It is easy to check that for every atomic concept A and atomic role r from Ï„ (C, S),
we have A âˆˆ S and r âˆˆ S, in other words, all atomic concepts and roles that are not in S
are eliminated by the transformation.3 It is also easy to show by induction that for every
râ†âˆ…
interpretation I âˆˆ IAâ†âˆ…
(S), we have C I = (Ï„ (C, S))I and that I |= Î± iff I |= Ï„ (Î±, S). Hence
râ†âˆ…
an axiom Î± is local w.r.t. S iff I |= Î± for every interpretation I âˆˆ IAâ†âˆ…
(S) iff I |= Ï„ (Î±, S)
râ†âˆ…
for every Sig(Î±)-interpretation I âˆˆ IAâ†âˆ… (S) iff Ï„ (Î±, S) is a tautology.
Example 31 Let O = {Î±} be the ontology consisting of axiom Î± = M2 from Figure 1. We
demonstrate using Proposition 30 that O is local w.r.t. S1 = {Fibrosis, Genetic Origin}, but
not local w.r.t. S2 = {Genetic Fibrosis, has Origin}.
Indeed, according to Proposition 30, in order to check whether O is local w.r.t. S1 it is
sufficient to perform the following replacements in Î± (the symbols from S1 are underlined):

M2

âŠ¥ [by (f)]
âŠ¥ [by (b)]
}|
{
z
}|
{
z
Genetic Fibrosis â‰¡ Fibrosis u âˆƒhas Origin.Genetic Origin

(7)

Similarly, in order to check whether O is local w.r.t. S2 , it is sufficient to perform the
following replacements in Î± (the symbols from S2 are underlined):
âŠ¥ [by (b)]
âŠ¥ [by (b)]
}|
{
z }| {
z
M2 Genetic Fibrosis â‰¡ Fibrosis u âˆƒhas Origin.Genetic Origin

(8)

In the first case we obtain Ï„ (M2, S1 ) = (âŠ¥ â‰¡ Fibrosis u âŠ¥) which is a SHOIQ-tautology.
Hence O is local w.r.t. S1 and hence by Proposition 8 is S1 -safe w.r.t. SHOIQ. In the
second case Ï„ (M2, S2 ) = (Genetic Fibrosis â‰¡ âŠ¥ u âˆƒhas Origin.âŠ¥) which is not a SHOIQ
tautology, hence O is not local w.r.t. S2 .
â™¦
5.4 A Tractable Approximation to Locality
One of the important conclusions of Proposition 30 is that one can use the standard capabilities of available DL-reasoners such as FaCT++ (Tsarkov & Horrocks, 2006), RACER
(MoÌˆller & Haarslev, 2003), Pellet (Sirin & Parsia, 2004) or KAON2 (Motik, 2006) for testing
locality since these reasoners, among other things, allow testing for DL-tautologies. Checking for tautologies in description logics is, theoretically, a difficult problem (e.g. for the
DL SHOIQ it is known to be NEXPTIME-complete, Tobies, 2000). There are, however,
several reasons to believe that the locality test would perform well in practice. The primary
reason is that the sizes of the axioms which need to be tested for tautologies are usually
relatively small compared to the sizes of ontologies. Secondly, modern DL reasoners are
highly optimized for standard reasoning tasks and behave well for most realistic ontologies.
In case reasoning is too costly, it is possible to formulate a tractable approximation to the
locality conditions for SHOIQ:
3. Recall that the constructors âŠ¥, C1 t C2 , âˆ€R.C, and (6 n R.C) are assumed to be expressed using >,
C1 u C2 , âˆƒR.C and (> n R.C), hence, in particular, every role Râˆ… with Sig(Râˆ… ) * S occurs in O as either
âˆƒRâˆ… .C, (> n Râˆ… .C), Râˆ… v R, R v Râˆ… , Trans(Râˆ… ), or Funct(Râˆ… ), and hence will be eliminated. All atomic
concepts Aâˆ… âˆˆ
/ S will be eliminated likewise. Note that it is not necessarily the case that Sig(Ï„ (Î±, S)) âŠ† S,
since Ï„ (Î±, S) may still contain individuals that do not occur in S.

297

Cuenca Grau, Horrocks, Kazakov, & Sattler

Definition 32 (Syntactic Locality for SHOIQ). Let S be a signature. The following
grammar recursively defines two sets of concepts Conâˆ…(S) and Conâˆ†(S) for a signature S:
Conâˆ…(S) ::= Aâˆ… | Â¬C âˆ† | C u C âˆ… | C âˆ… u C | âˆƒRâˆ… .C | âˆƒR.C âˆ… | (> n Râˆ… .C) | (> n R.C âˆ… ) .
Conâˆ†(S) ::= > | Â¬C âˆ… | C1âˆ† u C2âˆ† .
where Aâˆ… âˆˆ
/ S is an atomic concept, Râˆ… (possibly the inverse of) an atomic role râˆ… âˆˆ
/ S, C
âˆ† âˆˆ Conâˆ†(S), and i âˆˆ {1, 2}.
any concept, R any role, C âˆ… âˆˆ Conâˆ…(S), C(i)
An axiom Î± is syntactically local w.r.t. S if it is of one of the following forms: (1) Râˆ… v R,
or (2) Trans(râˆ… ), or (3) Funct(Râˆ… ), or (4) C âˆ… v C, or (5) C v C âˆ† , or (6) a : C âˆ† . We denote
râ†âˆ…
by AËœxAâ†âˆ…
(S) the set of all SHOIQ-axioms that are syntactically local w.r.t. S.
râ†âˆ…
A SHOIQ-ontology O is syntactically local w.r.t. S if O âŠ† AËœxAâ†âˆ…
(S). We denote by
râ†âˆ…
OÌƒAâ†âˆ… (S) the set of all SHOIQ ontologies that are syntactically local w.r.t. S.
â™¦
Intuitively, syntactic locality provides a simple syntactic test to ensure that an axiom is
râ†âˆ…
satisfied in every interpretation from IAâ†âˆ…
(S). It is easy to see from the inductive definitions
âˆ…
âˆ†
of Con (S) and Con (S) in Definition 32 that for every interpretation I = (âˆ†I , Â·I ) from
râ†âˆ…
IAâ†âˆ…
(S) it is the case that (C âˆ… )I = âˆ… and (C âˆ† )I = âˆ†I for every C âˆ… âˆˆ Conâˆ…(S) and
âˆ†
C âˆˆ Conâˆ†(S). Hence, every syntactically local axiom is satisfied in every interpretation
râ†âˆ…
I from IAâ†âˆ…
(S), and so we obtain the following conclusion:
râ†âˆ…
râ†âˆ…
Proposition 33 AËœxAâ†âˆ…
(S) âŠ† AxAâ†âˆ…
(S).

Further, it can be shown that the safety class for SHOIQ based on syntactic locality
enjoys all of the properties from Definition 24:
râ†âˆ…
Proposition 34 The class of syntactically local ontologies OÌƒAâ†âˆ…
(Â·) given in Definition 32
is an anti-monotonic, compact, subset-closed, and union-closed safety class.
râ†âˆ…
râ†âˆ…
(Â·) is a safety class by Proposition 33. Anti-monotonicity for OÌƒAâ†âˆ…
(Â·) can
Proof. OÌƒAâ†âˆ…
âˆ…
âˆ…
âˆ†
be shown by induction, by proving that Con (S2 ) âŠ† Con (S1 ), Con (S2 ) âŠ† Conâˆ†(S1 )
râ†âˆ…
râ†âˆ…
and AËœxAâ†âˆ…
(S2 ) âŠ† AËœxAâ†âˆ…
(S1 ) when S1 âŠ† S2 . Also one can show by induction that
râ†âˆ…
râ†âˆ…
râ†âˆ…
râ†âˆ…
Ëœ
Ëœ
Î± âˆˆ AxAâ†âˆ… (S) iff Î± âˆˆ AxAâ†âˆ… (S âˆ© Sig(Î±)), so OÌƒAâ†âˆ…
(Â·) is compact. Since O âˆˆ OÌƒAâ†âˆ…
(S)
râ†âˆ…
râ†âˆ…
Ëœ
iff O âŠ† AxAâ†âˆ… (S), we have that OÌƒAâ†âˆ… (Â·) is subset-closed and union-closed.

Example 35 (Example 31 continued) It is easy to see that axiom M2 from Figure 1 is
syntactically local w.r.t. S1 = {Fibrosis, Genetic Origin}. Below we indicate sub-concepts in
Î± from Conâˆ…(S1 ):

M2

âˆˆ Conâˆ…(S1 ) [matches Aâˆ… ]
âˆˆ Conâˆ…(S1 ) [matches âˆƒRâˆ… .C]
z
}|
{
z
}|
{
Genetic Fibrosis â‰¡ Fibrosis u âˆƒhas Origin.Genetic Origin
(9)
|
{z
}
âˆˆ Conâˆ…(S1 ) [matches C u C âˆ… ]

It is easy to show in a similar way that axioms P1 â€”P4, and E1 from Figure 1 are syntactically local w.r.t. S = {Cystic Fibrosis, Genetic Disorder}. Hence the ontology P1 =
{P1, . . . , P4, E1} considered in Example 29 is syntactically local w.r.t. S.
â™¦
298

Modular Reuse of Ontologies: Theory and Practice

râ†âˆ— (S)
IAâ†âˆ—

r, A 6âˆˆ S :

râ†âˆ…
IAâ†âˆ…
(S)
râ†âˆ†Ã—âˆ†
IAâ†âˆ…
(S)
râ†id (S)
IAâ†âˆ…

rJ

AJ

râ†âˆ— (S)
IAâ†âˆ—

âˆ…

âˆ…

râ†âˆ…
IAâ†âˆ†
(S)

âˆ…

râ†âˆ†Ã—âˆ†
IAâ†âˆ†
(S)

âˆ…

râ†id (S)
IAâ†âˆ†

âˆ†J Ã— âˆ†J
{hx, xi | x âˆˆ âˆ†J }

r, A 6âˆˆ S :

rJ

AJ

âˆ…

âˆ†J

âˆ†J Ã— âˆ†J
{hx, xi | x âˆˆ âˆ†J }

âˆ†J
âˆ†J

Table 3: Examples for Different Local Classes of Interpretations
The converse of Proposition 33 does not hold in general since there are semantically
local axioms that are not syntactically local. For example, the axiom Î± = (A v A t B) is
local w.r.t. every S since it is a tautology (and hence true in every interpretation). On the
other hand, it is easy to see that Î± is not syntactically local w.r.t. S = {A, B} according to
Definition 32 since it involves symbols in S only. Another example, which is not a tautology,
is a GCI Î± = (âˆƒr.Â¬A v âˆƒr.Â¬B). The axiom Î± is semantically local w.r.t. S = {r}, since
Ï„ (Î±, S) = (âˆƒr.Â¬âŠ¥ v âˆƒr.Â¬âŠ¥) is a tautology, but not syntactically local. These examples show
that the limitation of our syntactic notion of locality is its inability to â€œcompareâ€ different
occurrences of concepts from the given signature S. As a result, syntactic locality does not
detect all tautological axioms. It is reasonable to assume, however, that tautological axioms
do not occur often in realistic ontologies. Furthermore, syntactic locality checking can be
performed in polynomial time by matching an axiom according to Definition 32.
Proposition 36 There exists an algorithm that given a SHOIQ ontology O and a sigrâ†âˆ…
nature S, determines whether O âˆˆ OÌƒAâ†âˆ…
(S), and whose running time is polynomial in
|O| + |S|, where |O| and |S| are the number of symbols occurring in O and S respectively.4
5.5 Other Locality Classes
râ†âˆ…
The locality condition given in Example 26 based on a class of local interpretations IAâ†âˆ…
(Â·)
is just a particular example of locality which can be used for testing safety. Other classes
of local interpretations can be constructed in a similar way by fixing the interpretations
of elements outside S to different values. In Table 3 we have listed several such classes of
local interpretations where we fix the interpretation of atomic roles outside S to be either
the empty set âˆ…, the universal relation âˆ† Ã— âˆ†, or the identity relation id on âˆ†, and the
interpretation of atomic concepts outside S to either the empty set âˆ… or the set âˆ† of all
elements.
Each local class of interpretations in Table 3 defines a corresponding class of local
ontologies analogously to Example 26. In Table 4 we have listed all of these classes together
with examples of typical types of axioms used in ontologies. These axioms are assumed
to be an extension of our project ontology from Figure 1. We indicate which axioms are
local w.r.t. S for which locality conditions assuming, as usual, that the symbols from S are
underlined.
It can be seen from Table 4 that different types of locality conditions are appropriate
râ†âˆ…
for different types of axioms. The locality condition based on IAâ†âˆ…
(S) captures the domain
axiom P4, definition P5, the disjointness axiom P6, and the functionality axiom P7 but

4. We assume that the numbers in number restrictions are written down using binary coding.

299

Cuenca Grau, Horrocks, Kazakov, & Sattler

râ†âˆ…
Aâ†âˆ…

râ†âˆ†Ã—âˆ†
Aâ†âˆ…

râ†id
Aâ†âˆ…

râ†âˆ…
Aâ†âˆ†

râ†âˆ†Ã—âˆ†
Aâ†âˆ†

râ†id
Aâ†âˆ†

3

7

7

3

3

3

3

3

3

7

7

7

P6 Project u Bio Medicine v âŠ¥

3

3

3

7

7

7

P7 Funct(has Focus)

3

7

3

3

7

3

P8 Human Genome : Project

7

7

7

3

3

3

P9 has Focus(Human Genome, Gene)

7

3

7

7

3

7

7

7

7

7

7

7

Î±

? Î± âˆˆ Ax

Axiom

P4 âˆƒhas Focus.> v Project
P5

E2

BioMedical Project â‰¡ Project u
u âˆƒhas Focus.Bio Medicine

âˆ€has Focus.Cystic Fibrosis v
v âˆƒhas Focus.Cystic Fibrosis

Table 4: A Comparison between Different Types of Locality Conditions

neither of the assertions P8 or P9, since the individuals Human Genome and Gene prevent
us from interpreting the atomic role has Focus and atomic concept Project with the empty
râ†âˆ†Ã—âˆ†
(S), where the atomic roles and concepts outside
set. The locality condition based on IAâ†âˆ†
S are interpreted as the largest possible sets, can capture such assertions but are generally
poor for other types of axioms. For example, the functionality axiom P7 is not captured
by this locality condition since the atomic role has Focus is interpreted as the universal
relation âˆ†Ã—âˆ†, which is not necessarily functional. In order to capture such functionality
râ†id (S) or I râ†id (S), where every atomic role outside
axioms, one can use locality based on IAâ†âˆ…
Aâ†âˆ†
S is interpreted with the identity relation id on the interpretation domain. Note that the
modeling error E2 is not local for any of the given locality conditions. Note also that it is
not possible to come up with a locality condition that captures all the axioms P4â€“P9, since
in P6 and P8 together imply axiom Î² = ({Human Genome} u Bio Medicine v âŠ¥) which
uses the symbols from S only. Hence, every subset of P containing P6 and P8 is not safe
w.r.t. S, and so cannot be local w.r.t. S.
It might be possible to come up with algorithms for testing locality conditions for the
classes of interpretation in Table 3 similar to the ones presented in Proposition 30. For
râ†âˆ…
example, locality based on the class IAâ†âˆ†
(S) can be tested as in Proposition 30, where the
case (a) of the definition for Ï„ (C, S) is replaced with the following:
Ï„ (A, S)

= > if A âˆˆ
/ S and otherwise = A

(a0 )

râ†âˆ†Ã—âˆ†
râ†id (S), checking
For the remaining classes of interpretations, that is for IAâ†âˆ—
(S) and IAâ†âˆ—
locality, however, is not that straightforward, since it is not clear how to eliminate the
universal roles and identity roles from the axioms and preserve validity in the respective
classes of interpretations.
Still, it is easy to come up with tractable syntactic approximations for all the locality
conditions considered in this section in a similar manner to what has been done in Section 5.4. The idea is the same as that used in Definition 32, namely to define two sets
Conâˆ…(S) and Conâˆ†(S) of concepts for a signature S which are interpreted as the empty

300

Modular Reuse of Ontologies: Theory and Practice

Conâˆ…(S) ::= Â¬C âˆ† | C u C âˆ… | C âˆ… u C

Conâˆ†(S) ::= > | Â¬C âˆ… | C1âˆ† u C2âˆ†

| âˆƒR.C âˆ… | > n R.C âˆ…

râ†âˆ— (Â·):
for IAâ†âˆ†

| Aâˆ†

râ†âˆ— (Â·):
for IAâ†âˆ…

| Aâˆ…

râ†âˆ†Ã—âˆ†
for IAâ†âˆ—
(Â·):

| âˆƒRâˆ†Ã—âˆ† .C âˆ† | (> n Râˆ†Ã—âˆ† .C âˆ† )

râ†âˆ…
for IAâ†âˆ—
(Â·):

| âˆƒRâˆ… .C | > n Râˆ… .C

râ†id (Â·):
for IAâ†âˆ—

| âˆƒRid .C âˆ† | (> 1 Rid .C âˆ† ) .

râ†id (Â·):
for IAâ†âˆ—

| (> m Rid .C), m â‰¥ 2 .

râ†âˆ— (S) ::= C âˆ… v C | C v C âˆ† | a : C âˆ†
AËœxAâ†âˆ—
râ†âˆ…
for IAâ†âˆ—
(Â·):

| Râˆ… v R | Trans(râˆ… ) | Funct(Râˆ… )

râ†âˆ†Ã—âˆ†
for IAâ†âˆ—
(Â·):

| R v Râˆ†Ã—âˆ† | Trans(râˆ†Ã—âˆ† ) | râˆ†Ã—âˆ† (a, b)

râ†id (Â·):
for IAâ†âˆ—

| Trans(rid ) | Funct(Rid )

Where:
Aâˆ… , Aâˆ† , râˆ… , râˆ†Ã—âˆ† , rid 6âˆˆ S;
Sig(Râˆ… ), Sig(Râˆ†Ã—âˆ† ), Sig(Rid ) * S;
âˆ† âˆˆ Conâˆ†(S);
C âˆ… âˆˆ Conâˆ…(S), C(i)
C is any concept, R is any role

Figure 3: Syntactic Locality Conditions for the Classes of Interpretations in Table 3
set and, respectively, as âˆ†I in every interpretation I from the class and see in which situations DL-constructors produce the elements from these sets. In Figure 3 we gave recursive
râ†âˆ— (S) that correspond to classes I râ†âˆ— (S) of
definitions for syntactically local axioms AËœxAâ†âˆ—
Aâ†âˆ—
interpretations from Table 3, where some cases in the recursive definitions are present only
for the indicated classes of interpretations.
5.6 Combining and Extending Safety Classes
In the previous section we gave examples of several safety classes based on different local
classes of interpretations and demonstrated that different classes are suitable for different
types of axioms. In order to check safety of ontologies in practice, one may try to apply
different sufficient tests and check if any of them succeeds. Obviously, this gives a more
powerful sufficient condition for safety, which can be seen as the union of the safety classes
used in the tests.
Formally, given two classes of ontologies O1 (Â·) and O2 (Â·), their union (O1 âˆª O2 )(Â·) is a
class of ontologies defined by (O1 âˆªO2 )(S) = O1 (S)âˆªO2 (S). It is easy to see by Definition 24
that if both O1 (Â·) and O2 (Â·) are safety classes then their union (O1 âˆª O2 )(Â·) is a safety
class. Moreover, if each of the safety classes is also anti-monotonic or subset-closed, then
the union is anti-monotonic, or respectively, subset-closed as well. Unfortunately the unionclosure property for safety classes is not preserved under unions, as demonstrated in the
following example:
râ†âˆ†Ã—âˆ†
râ†âˆ…
Example 37 Consider the union (OAâ†âˆ…
âˆª OAâ†âˆ†
)(Â·) of two classes of local ontologies
râ†âˆ†Ã—âˆ†
râ†âˆ…
OAâ†âˆ… (Â·) and OAâ†âˆ† (Â·) defined in Section 5.5. This safety class is not union-closed since,
for example, the ontology O1 consisting of axioms P4â€“P7 from Table 4 satisfies the first
locality condition, the ontology O2 consisting of axioms P8â€“P9 satisfies the second locality
condition, but their union O1 âˆªO2 satisfies neither the first nor the second locality condition
and, in fact, is not even safe for S as we have shown in Section 5.5.
â™¦

As shown in Proposition 33, every locality condition gives a union-closed safety class;
however, as seen in Example 37, the union of such safety classes might be no longer unionclosed. One may wonder if locality classes already provide the most powerful sufficient
301

Cuenca Grau, Horrocks, Kazakov, & Sattler

conditions for safety that satisfy all the desirable properties from Definition 24. Surprisingly
this is the case to a certain extent for some locality classes considered in Section 5.5.
Definition 38 (Maximal Union-Closed Safety Class). A safety class O2 (Â·) extends
a safety class O1 (Â·) if O1 (S) âŠ† O2 (S) for every S. A safety class O1 (Â·) is maximal unionclosed for a language L if O1 (Â·) is union-closed and for every union-closed safety class O2 (Â·)
that extends O1 (Â·) and every O over L we have that O âˆˆ O2 (S) implies O âˆˆ O1 (S).
â™¦
râ†âˆ…
râ†âˆ…
Proposition 39 The classes of local ontologies OAâ†âˆ…
(Â·) and OAâ†âˆ†
(Â·) defined in Section 5.5
are maximal union-closed safety classes for L = SHIQ.

Proof. According to Definition 38, if a safety class O(Â·) is not maximal union-closed for a
language L, then there exists a signature S and an ontology O over L, such that (i) O âˆˆ
/
O(S), (ii) O is safe w.r.t. S in L, and (iii) for every P âˆˆ O(S), it is the case that O âˆª P is
safe w.r.t. S in L; that is, for every ontology Q over L with Sig(Q) âˆ© Sig(O âˆª P) âŠ† S it is
the case that O âˆª P âˆª Q is a deductive conservative extension of Q. We demonstrate that
râ†âˆ…
râ†âˆ…
this is not possible for O(Â·) = OAâ†âˆ…
(Â·) or O(Â·) = OAâ†âˆ†
(Â·)
râ†âˆ…
We first consider the case O(Â·) = OAâ†âˆ… (Â·) and then show how to modify the proof for
râ†âˆ…
the case O(Â·) = OAâ†âˆ†
(Â·).
Let O be an ontology over L that satisfies conditions (i)â€“(iii) above. We define ontologies
P and Q as follows. Take P to consist of the axioms A v âŠ¥ and âˆƒr.> v âŠ¥ for every atomic
râ†âˆ…
concept A and atomic role r from Sig(O) \ S. It is easy to see that P âˆˆ OAâ†âˆ…
(S). Take Q
to consist of all tautologies of form âŠ¥ v A and âŠ¥ v âˆƒr.> for every A, r âˆˆ S. Note that
Sig(O âˆª P) âˆ© Sig(Q) âŠ† S. We claim that O âˆª P âˆª Q is not a deductive Sig(Q)-conservative
extension of Q.
(])
râ†âˆ…
Intuitively, the ontology P is chosen in such a way that P âˆˆ OAâ†âˆ…
(S) and O âˆª P âˆª Q
râ†âˆ…
has only models from IAâ†âˆ…
(S). Q is an ontology which implies nothing but tautologies and
uses all the atomic concepts and roles from S.
râ†âˆ…
râ†âˆ…
Since O âˆˆ
/ OAâ†âˆ…
(S), there exists an axiom Î± âˆˆ O such that Î± âˆˆ
/ AxAâ†âˆ…
(S). Let
Î² := Ï„ (Î±, S) where Ï„ (Â·, Â·) is defined as in Proposition 30. As has been shown in the proof of
râ†âˆ…
this proposition, I |= Î± iff I |= Î² for every I âˆˆ IAâ†âˆ…
(S). Now, since O |= Î± and O âˆª P âˆª Q
râ†âˆ…
has only models from IAâ†âˆ… (S), it is the case that O âˆª P âˆª Q |= Î². By Proposition 30, since Î²
râ†âˆ…
does not contain individuals, we have that Sig(Î²) âŠ† S = Sig(Q) and, since Î± âˆˆ
/ AxAâ†âˆ…
(S),
Î² is not a tautology, thus Q 6|= Î². Hence, by Definition 1, O âˆª P âˆª Q is not a deductive
Sig(Q)-conservative extension of Q (]).
râ†âˆ…
For O(Â·) = OAâ†âˆ†
(Â·) the proof can be repeated by taking P to consist of axioms > v A
and âˆƒr.> v âŠ¥ for all A, r âˆˆ Sig(O) \ S, and modifying Ï„ (Â·, Â·) as has been discussed in
Section 5.5.
There are some difficulties in extending the proof of Proposition 39 to other locality
classes considered in Section 5.5. First, it is not clear how to force interpretations of roles
to be the universal or identity relation using SHOIQ axioms. Second, it is not clear how
to define the function Ï„ (Â·, Â·) in these cases (see a related discussion in Section 5.5). Note
also that the proof of Proposition 39 does not work in the presence of nominals, since
this will not guarantee that Î² = Ï„ (Î±, S) contains symbols from S only (see Footnote 3 on
râ†âˆ…
râ†âˆ…
p. 297). Hence there is probably room to extend the locality classes OAâ†âˆ…
(Â·) and OAâ†âˆ†
(Â·)
for L = SHOIQ while preserving union-closure.
302

Modular Reuse of Ontologies: Theory and Practice

6. Extracting Modules Using Safety Classes
In this section we revisit the problem of extracting modules from ontologies. As shown in
Corollary 23 in Section 4, there exists no general procedure that can recognize or extract
all the (minimal) modules for a signature in an ontology in finite time.
The techniques described in Section 5, however, can be reused for extracting particular
families of modules that satisfy certain sufficient conditions. Proposition 18 establishes the
relationship between the notions of safety and module; more precisely, a subset O1 of O is
an S-module in O provided that O \ O1 is safe for S âˆª Sig(O1 ). Therefore, any safety class
O(Â·) can provide a sufficient condition for testing modulesâ€”that is, in order to prove that
O1 is a S-module in O, it is sufficient to show that O \ O1 âˆˆ O(S âˆª Sig(O1 )). A notion of
modules based on this property can be defined as follows.
Definition 40 (Modules Based on Safety Class).
Let L be an ontology language and O(Â·) be a safety class for L. Given an ontology O and
a signature S over L, we say that Om âŠ† O is an O(Â·)-based S-module in O if O \ Om âˆˆ
O(S âˆª Sig(Om )).
â™¦
Remark 41 Note that for every safety class O(Â·), ontology O and signature S, there exists
at least one O(Â·)-based S-module in O, namely O itself; indeed, by Definition 24, the empty
ontology âˆ… = O \ O also belongs to O(S) for every O(Â·) and S.
Note also that it follows from Definition 40 that Om is an O(Â·)-based S-module in O iff
Om is an O(Â·)-based S0 -module in O for every S0 with S âŠ† S0 âŠ† (S âˆª Sig(Om )).
â™¦
It is clear that, according to Definition 40, any procedure for checking membership of a
safety class O(Â·) can be used directly for checking whether Om is a module based on O(Â·).
In order to extract an O(Â·)-module, it is sufficient to enumerate all possible subsets of the
ontology and check if any of these subsets is a module based on O(Â·).
In practice, however, it is possible to avoid checking all the possible subsets of the
input ontology. Figure 4 presents an optimized version of the module-extraction algorithm.
The procedure manipulates configurations of the form Om | Ou | Os , which represent a
partitioning of the ontology O into three disjoint subsets Om , Ou and Os . The set Om
accumulates the axioms of the extracted module; the set Os is intended to be safe w.r.t.
S âˆª Sig(Om ). The set Ou , which is initialized to O, contains the unprocessed axioms. These
axioms are distributed among Om and Os according to rules R1 and R2. Given an axiom Î±
from Ou , rule R1 moves Î± into Os provided Os remains safe w.r.t. S âˆª Sig(Om ) according
to the safety class O(Â·). Otherwise, rule R2 moves Î± into Om and moves all axioms from
Os back into Ou , since Sig(Om ) might expand and axioms from Os might become no longer
safe w.r.t. S âˆª Sig(Om ). At the end of this process, when no axioms are left in in Ou , the
set Om is an O(Â·)-based module in O.
The rewrite rules R1 and R2 preserve invariants I1â€“I3 given in Figure 4. Invariant I1
states that the three sets Om , Ou and Os form a partitioning of O; I2 states that the set Os
satisfies the safety test for S âˆª Sig(Om ) w.r.t. O(Â·); finally, I3 establishes that the rewrite
rules either add elements to Om , or they add elements to Os without changing Om ; in other
words, the pair (|Om |, |Os |) consisting of the sizes for these sets increases in lexicographical
order.
303

Cuenca Grau, Horrocks, Kazakov, & Sattler

Input:

an ontology O, a signature S, a safety class O(Â·)

Output:

a module Om in O based on O(Â·)
unprocessed
â†“

Configuration: Om | Ou | Os ;
â†‘

â†‘

module

safe

Initial Configuration =

âˆ…|O|âˆ…

Termination Condition: Ou = âˆ…

Rewrite rules:
R1. Om | Ou âˆª {Î±} | Os =â‡’ Om | Ou | Os âˆª {Î±}

if (Os âˆª {Î±}) âˆˆ O(S âˆª Sig(Om ))

R2. Om | Ou âˆª {Î±} | Os =â‡’ Om âˆª {Î±} | Ou âˆª Os | âˆ…

if (Os âˆª {Î±}) 6âˆˆ O(S âˆª Sig(Om ))

Invariants for Om | Ou | Os :
I1. O = Om ] Ou ] Os

0 | O0 | O0 :
Invariant for Om | Ou | Os =â‡’ Om
u
s
0 |, |O 0 |)
I3. (|Om |, |Os |) <lex (|Om
s

I2. Os âˆˆ O(S âˆª Sig(Om ))
Figure 4: A Procedure for Computing Modules Based on a Safety Class O(Â·)
Proposition 42 (Correctness of the Procedure from Figure 4) Let O(Â·) be a safety
class for an ontology language L, O an ontology over L, and S a signature over L. Then:
(1) The procedure in Figure 4 with input O, S, O(Â·) terminates and returns an O(Â·)based S-module Om in O; and
(2) If, additionally, O(Â·) is anti-monotonic, subset-closed and union-closed, then there
is a unique minimal O(Â·)-based S-module in O, and the procedure returns precisely this
minimal module.
Proof. (1) The procedure based on the rewrite rules from Figure 4 always terminates for
the following reasons: (i) for every configuration derived by the rewrite rules, the sets Om ,
Ou and Os form a partitioning of O (see invariant I1 in Figure 4), and therefore the size
of every set is bounded; (ii) at each rewrite step, (|Om |, |Os |) increases in lexicographical
order (see invariant I3 in Figure 4). Additionally, if Ou 6= âˆ… then it is always possible to
apply one of the rewrite rules R1 or R2, and hence the procedure always terminates with
Ou = âˆ…. Upon termination, by invariant I1 from Figure 4, O is partitioned into Om and Os
and by invariant I2, Os âˆˆ O(S âˆª Sig(Om )), which implies, by Definition 40, that Om is an
O(Â·)-based S-module in O.
(2) Now, suppose that, in addition, O(Â·) is an anti-monotonic, subset-closed, and union0 is an O(Â·)-based S-module in O. We demonstrate
closed safety class, and suppose that Om
by induction that for every configuration Om | Ou | Os derivable from âˆ… | O | âˆ… by rewrite
0 . This will prove that the module computed
rules R1 and R2, it is the case that Om âŠ† Om
by the procedure is a subset of every O(Â·)-based S-module in O, and hence, is the smallest
O(Â·)-based S-module in O.
0 . The rewrite rule R1 does not change
Indeed, for the base case we have Om = âˆ… âŠ† Om
the set Om . For the rewrite rule R2 we have: Om | Ou âˆª {Î±} | Os =â‡’ Om âˆª {Î±} | Ou âˆª Os | âˆ…
if (Os âˆª {Î±}) 6âˆˆ O(S âˆª Sig(Om )).
(])
304

Modular Reuse of Ontologies: Theory and Practice

Input: an ontology O, a signature S, a safety class O(Â·)
Output: a module Om in O based on O(Â·)
Initial Configuration =

âˆ…|O|âˆ…

Termination Condition: Ou = âˆ…

Rewrite rules:
R1.

Om | Ou âˆª {Î±} | Os =â‡’ Om | Ou | Os âˆª {Î±}

if {Î±} âˆˆ O(S âˆª Sig(Om ))

R2. Om | Ou âˆª {Î±} | OsÎ± âˆª Os =â‡’ Om âˆª {Î±} | Ou âˆª OsÎ± | Os if {Î±} 6âˆˆ O(S âˆª Sig(Om )), and
Sig(Os ) âˆ© Sig(Î±) âŠ† Sig(Om )
Figure 5: An Optimized Procedure for Computing Modules Based on a Compact SubsetClosed Union-Closed Safety Class O(Â·)
0 but O âˆª {Î±} * O 0 . Then Î± âˆˆ O 0 := O \ O 0 .
Suppose, to the contrary, that Om âŠ† Om
m
m
s
m
0 is an O(Â·)-based S-module in O, we have that O 0 âˆˆ O(S âˆª Sig(O 0 )). Since O(Â·)
Since Om
s
m
0 )). Since O
0
is subset-closed, {Î±} âˆˆ O(S âˆª Sig(Om
m âŠ† Om and O(Â·) is anti-monotonic, we
have {Î±} âˆˆ O(S âˆª Sig(Om )). Since by invariant I2 from Figure 4, Os âˆˆ O(S âˆª Sig(Om )) and
O(Â·) is union-closed, Os âˆª {Î±} âˆˆ O(S âˆª Sig(Om )), which contradicts (]). This contradiction
0 .
implies that the rule R2 also preserves property Om âŠ† Om

Claim (1) of Proposition 42 establishes that the procedure from Figure 4 terminates for
every input and produces a module based on a given safety class. Moreover, it is possible
to show that this procedure runs in polynomial time assuming that the safety test can be
also performed in polynomial time.
If the safety class O(Â·) satisfies additional desirable properties, like those based on classes
of local interpretations described in Section 5.2, the procedure, in fact, produces the smallest
possible module based on the safety class, as stated in claim (2) of Proposition 42. In this
case, it is possible to optimize the procedure shown in Figure 4. If O(Â·) is union closed,
then, instead of checking whether (Os âˆª {Î±}) âˆˆ O(S âˆª Sig(Om )) in the conditions of rules
R1 and R2, it is sufficient to check if {Î±} âˆˆ O(S âˆª Sig(Om )) since it is already known that
Os âˆˆ O(S âˆª Sig(Om )). If O(Â·) is compact and subset closed, then instead of moving all the
axioms in Os to Ou in rule R2, it is sufficient to move only those axioms OsÎ± that contain
at least one symbol from Î± which did not occur in Om before, since the set of remaining
axioms will stay in O(S âˆª Sig(Om )). In Figure 5 we present an optimized version of the
algorithm from Figure 4 for such locality classes.
Example 43 In Table 5 we present a trace of the algorithm from Figure 5 for the ontology O
consisting of axioms M1â€“M5 from Figure 1, signature S = {Cystic Fibrosis, Genetic Disorder}
râ†âˆ…
and safety class O(Â·) = OAâ†âˆ…
(Â·) defined in Example 26. The first column of the table lists
the configurations obtained from the initial configuration âˆ… | O | âˆ… by applying the rewrite
rules R1 and R2 from Figure 5; in each row, the underlined axiom Î± is the one that is being
tested for safety. The second column of the table shows the elements of S âˆª Sig(Om ) that
have appeared for the current configuration but have not been present for the preceding
configurations. In the last column we indicate whether the first conditions of the rules R1
râ†âˆ…
and R2 are fulfilled for the selected axiom Î± from Ou â€”that is, whether Î± is local for IAâ†âˆ…
(Â·).
The rewrite rule corresponding to the result of this test is applied to the configuration.
305

Cuenca Grau, Horrocks, Kazakov, & Sattler

Om | Ou , Î± | Os

New elements in S âˆª Sig(Om )

1 âˆ’ | M1, M2, M3, M4, M5 | âˆ’ Cystic Fibrosis, Genetic Disorder

{Î±} âˆˆ O(S âˆª Sig(Om ))?
Yes

â‡’

R1

2

âˆ’ | M1, M3, M4, M5 | M2

âˆ’

Yes

â‡’

R1

3

âˆ’ | M1, M4, M5 | M2, M3

âˆ’

No

â‡’

R2

4

M1 | M2, M3, M4, M5 | âˆ’

Fibrosis, located In, Pancreas,
has Origin, Genetic Origin

No

â‡’

R2

5

M1, M3 | M2, M4, M5 | âˆ’

Genetic Fibrosis

No

â‡’

R2

6

M1, M3, M4 | M2, M5 | âˆ’

âˆ’

Yes

â‡’

R1

7

M1, M3, M4 | M2 | M5

âˆ’

No

â‡’

R2

8

M1, M2, M3, M4 | âˆ’ | M5

âˆ’

Table 5: A trace of the Procedure in Figure 5 for the input Q = {M1, . . . , M5} from Figure 1
and S = {Cystic Fibrosis, Genetic Disorder}

Note that some axioms Î± are tested for safety several times for different configurations,
because the set Ou may increase after applications of rule R2; for example, the axiom
Î± = M2 is tested for safety in both configurations 1 and 7, and Î± = M3 in configurations
2 and 4. Note also that different results for the locality tests are obtained in these cases:
both M2 and M3 were local w.r.t. S âˆª Sig(Om ) when Om = âˆ…, but became non-local when
new axioms were added to Om . It is also easy to see that, in our case, syntactic locality
produces the same results for the tests.
In our example, the rewrite procedure produces a module Om consisting of axioms M1â€“
M4. Note that it is possible to apply the rewrite rules for different choices of the axiom
Î± in Ou , which results in a different computation. In other words, the procedure from
Figure 5 has implicit non-determinism. According to Claim (2) of Proposition 42 all such
râ†âˆ…
computations should produce the same module Om , which is the smallest OAâ†âˆ…
(Â·)-based
S-module in O; that is, the implicit non-determinism in the procedure from Figure 5 does
not have any impact on the result of the procedure. However, alternative choices for Î±
may result in shorter computations: in our example we could have selected axiom M1 in
the first configuration instead of M2 which would have led to a shorter trace consisting of
configurations 1, and 4â€“8 only.
â™¦
It is worth examining the connection between the S-modules in an ontology O based on
a particular safety class O(Â·) and the actual minimal S-modules in O. It turns out that any
O(Â·)-based module Om is guaranteed to cover the set of minimal modules, provided that
O(Â·) is anti-monotonic and subset-closed. In other words, given O and S, Om contains all
the S-essential axioms in O. The following Lemma provides the main technical argument
underlying this result.
Lemma 44 Let O(Â·) be an anti-monotonic subset-closed safety class for an ontology language L, O an ontology, and S a signature over L. Let O1 be an S-module in O w.r.t. L
and Om an O(Â·)-based S-module in O. Then O2 := O1 âˆ© Om is an S-module in O w.r.t. L.
306

Modular Reuse of Ontologies: Theory and Practice

Proof. By Definition 40, since Om is an O(Â·)-based S-module in O, we have that O \ Om âˆˆ
O(S âˆª Sig(Om )). Since O1 \ O2 = O1 \ Om âŠ† O \ Om and O(Â·) is subset-closed, it is the case
that O1 \ O2 âˆˆ O(S âˆª Sig(Om )). Since O(Â·) is anti-monotonic, and O2 âŠ† Om , we have that
O1 \ O2 âˆˆ O(S âˆª Sig(O2 )), hence, O2 is an O(Â·)-based S-module in O1 . In particular O2 is
an S-module in O1 w.r.t. L. Since O1 is an S-module in O w.r.t. L, O2 is an S-module in
O w.r.t. L.
Corollary 45 Let O(Â·) be an anti-monotonic, subset-closed safety class for L and Om be
an O(Â·)-based S-module in O. Then Om contains all S-essential axioms in O w.r.t. L.
Proof. Let O1 be a minimal S-module in O w.r.t. L. We demonstrate that O1 âŠ† Om . Indeed,
otherwise, by Lemma 44, O1 âˆ© Om is an S-module in O w.r.t. L which is strictly contained
in O1 . Hence Om is a superset of every minimal S-module in O and hence, contains all
S-essential axioms in O w.r.t. L.
As shown in Section 3.4, all the axioms M1â€“M4 are essential for the ontology O and
signature S considered in Example 43. We have seen in this example that the locality-based
S-module extracted from O contains all of these axioms, in accordance to Corollary 45. In
our case, the extracted module contains only essential axioms; in general, however, localitybased modules might contain non-essential axioms.
An interesting application of modules is the pruning of irrelevant axioms when checking
if an axiom Î± is implied by an ontology O. Indeed, in order to check whether O |= Î±
it suffices to retrieve the module for Sig(Î±) and verify if the implication holds w.r.t. this
module. In some cases, it is sufficient to extract a module for a subset of the signature of
Î± which, in general, leads to smaller modules. In particular, in order to test subsumption
between a pair of atomic concepts, if the safety class being used enjoys some nice properties
then it suffices to extract a module for one of them, as given by the following proposition:
Proposition 46 Let O(Â·) be a compact union-closed safety class for an ontology language
L, O an ontology and A, B atomic concepts. Let OA be an O(Â·)-based module in O for
S = {A} in O. Then:
1 If O |= Î± := (A v B) and {B v âŠ¥} âˆˆ O(âˆ…) then OA |= Î±;
2 If O |= Î± := (B v A) and {> v B} âˆˆ O(âˆ…) then OA |= Î±;
Proof. 1. Consider two cases: (a) B âˆˆ Sig(OA ) and (b) B âˆˆ
/ Sig(OA ).
(a) By Remark 41 it is the case that OA is an O(Â·)-based module in O for S = {A, B}.
Since Sig(Î±) âŠ† S, by Definition 12 and Definition 1, it is the case that O |= Î± implies
OA |= Î±.
(b) Consider O0 = O âˆª{B v âŠ¥}. Since Sig(B v âŠ¥) = {B} and B âˆˆ
/ Sig(OA ), {B v âŠ¥} âˆˆ
O(âˆ…) and O(Â·) is compact, by Definition 24 it is the case that {B v âŠ¥} âˆˆ O(S âˆª Sig(OA )).
Since OA is an O(Â·)-based S-module in O, by Definition 40, then O \ OA âˆˆ O(S âˆª Sig(OA )).
Since O(Â·) is union-closed, it is the case that (O \ OA ) âˆª {B v âŠ¥} âˆˆ O(S âˆª Sig(OA )). Note
that B v âŠ¥ 6âˆˆ OA , since B 6âˆˆ Sig(OA ), hence (O \ OA ) âˆª {B v âŠ¥} = O0 \ OA , and, by
Definition 40, we have that OA is an O(Â·)-based S-module in O0 . Now, since O |= (A v B),
it is the case that O0 |= (A v âŠ¥), and hence, since OA is a module in O0 for S = {A}, we
have that OA |= (A v âŠ¥) which implies OA |= (A v B).
307

Cuenca Grau, Horrocks, Kazakov, & Sattler

2. The proof of this case is analogous to that for Case 1: Case (a) is applicable without
changes; in Case (b) we show that OA is an O(Â·)-based module for S = {A} in O0 =
O âˆª {> v B}, and, hence, since O0 |= (> v A), it is the case that OB |= (> v A), which
implies O0 |= (B v A).
râ†âˆ— (Â·) and
Corollary 47 Let O be a SHOIQ ontology and A, B atomic concepts. Let OAâ†âˆ…
râ†âˆ— (Â·) be locality classes based on local classes of interpretations of form I râ†âˆ— (Â·) and
OAâ†âˆ†
Aâ†âˆ…
râ†âˆ—
râ†âˆ— (Â·) and
IAâ†âˆ† (Â·), respectively, from Table 3. Let OA be a module for S = {A} based on OAâ†âˆ…
râ†âˆ— (Â·). Then O |= (A v B) iff O |= (A v B) iff
OB be a module for S = {B} based on OAâ†âˆ†
A
OB |= (A v B).
râ†âˆ— (âˆ…) and {> v A} âˆˆ O râ†âˆ— (âˆ†).
Proof. It is easy to see that {B v âŠ¥} âˆˆ OAâ†âˆ…
Aâ†âˆ†

Proposition 46 implies that a module based on a safety class for a single atomic concept
A can be used for capturing either the super-concepts (Case 1), or the sub-concepts (Case
2) B of A, provided that the safety class captures, when applied to the empty signature,
axioms of the form B v âŠ¥ (Case 1) or (> v B) (Case 2). That is, B is a super-concept or
a sub-concept of A in the ontology if and only if it is such in the module. This property
can be used, for example, to optimize the classification of ontologies. In order to check if
the subsumption A v B holds in an ontology O, it is sufficient to extract a module in
O for S = {A} using a modularization algorithm based on a safety class in which the
ontology {B v âŠ¥} is local w.r.t. the empty signature, and check whether this subsumption
holds w.r.t. the module. For this purpose, it is convenient to use a syntactically tractable
approximation of the safety class in use; for example, one could use the syntactic locality
conditions given in Figure 3 instead of their semantic counterparts.
It is possible to combine modularization procedures to obtain modules that are smaller
than the ones obtained using these procedures individually. For example, in order to check
râ†âˆ— (Â·)-based module M for
the subsumption O |= (A v B) one could first extract a OAâ†âˆ…
1
S = {A} in O; by Corollary 47 this module is complete for all the super-concepts of A in
O, including Bâ€”that is, if an atomic concept is a super-concept of A in O, then it is also a
râ†âˆ— (Â·)-based module M for S = {B} in
super-concept of A in M1 . One could extract a OAâ†âˆ†
2
M1 which, by Corollary 47, is complete for all the sub-concepts of B in M1 , including A.
Indeed, M2 is an S-module in M1 for S = {A, B} and M1 is an S-module in the original
ontology O. By Proposition 46, therefore, it is the case that M2 is also an S-module in O.

7. Related Work
We have seen in Section 3 that the notion of conservative extension is valuable in the formalization of ontology reuse tasks. The problem of deciding conservative extensions has been
recently investigated in the context of ontologies (Ghilardi et al., 2006; Lutz et al., 2007;
Lutz & Wolter, 2007). The problem of deciding whether P âˆª Q is a deductive S-conservative
extension of Q is EXPTIME-complete for EL (Lutz & Wolter, 2007), 2-EXPTIME-complete
w.r.t. ALCIQ (Lutz et al., 2007) (roughly OWL-Lite), and undecidable w.r.t. ALCIQO
(roughly OWL DL). Furthermore, checking model conservative extensions is already undecidable for EL (Lutz & Wolter, 2007), and for ALC it is even not semi-decidable (Lutz
et al., 2007).
308

Modular Reuse of Ontologies: Theory and Practice

In the last few years, a rapidly growing body of work has been developed under the
headings of Ontology Mapping and Alignment, Ontology Merging, Ontology Integration,
and Ontology Segmentation (Kalfoglou & Schorlemmer, 2003; Noy, 2004a, 2004b). This field
is rather diverse and has roots in several communities.
In particular, numerous techniques for extracting fragments of ontologies for the purposes of knowledge reuse have been proposed. Most of these techniques rely on syntactically
traversing the axioms in the ontology and employing various heuristics to determine which
axioms are relevant and which are not.
An example of such a procedure is the algorithm implemented in the Prompt-Factor
tool (Noy & Musen, 2003). Given a signature S and an ontology Q, the algorithm retrieves a fragment Q1 âŠ† Q as follows: first, the axioms in Q that mention any of the
symbols in S are added to Q1 ; second, S is expanded with the symbols in Sig(Q1 ). These
steps are repeated until a fixpoint is reached. For our example in Section 3, when S =
{Cystic Fibrosis, Genetic Disorder}, and Q consists of axioms M1â€“M5 from Figure 1, the algorithm first retrieves axioms M1, M4, and M5 containing these terms, then expands S with
the symbols mentioned in these axioms, such that S contains all the symbols of Q. After
this step, all the remaining axioms of Q are retrieved. Hence, the fragment extracted by
the Prompt-Factor algorithm consists of all the axioms M1-M5. In this case, the PromptFactor algorithm extracts a module (though not a minimal one). In general, however, the
extracted fragment is not guaranteed to be a module. For example, consider an ontology
Q = {A â‰¡ Â¬A, B v C} and Î± = (C v B). The ontology Q is inconsistent due to the
axiom A â‰¡ Â¬A: any axiom (and Î± in particular) is thus a logical consequence of Q. Given
S = {B, C}, the Prompt-Factor algorithm extracts Q2 = {B v C}; however, Q2 6|= Î±, and
so Q2 is not a module in Q. In general, the Prompt-Factor algorithm may fail even if Q is
consistent. For example, consider an ontology Q = {> v {a}, A v B}, Î± = (A v âˆ€r.A),
and S = {A}. It is easy to see that Q is consistent, admits only single element models,
and Î± is satisfied in every such a model; that is, Q |= Î±. In this case, the Prompt-Factor
algorithm extracts Q1 = {A v B}, which does not imply Î±.
Another example is Seidenbergâ€™s segmentation algorithm (Seidenberg & Rector, 2006),
which was used for segmentation of the medical ontology GALEN (Rector & Rogers, 1999).
Currently, the full version of GALEN cannot be processed by reasoners, so the authors
investigate the possibility of splitting GALEN into small â€œsegmentsâ€ which can be processed
by reasoners separately. The authors describe a segmentation procedure which, given a set
of atomic concepts S, computes a â€œsegmentâ€ for S in the ontology. The description of
the procedure is very high-level. The authors discuss which concepts and roles should be
included in the segment and which should not. In particular, the segment should contain
all â€œsuper-â€ and â€œsub-â€ concepts of the input concepts, concepts that are â€œlinkedâ€ from the
input concepts (via existential restrictions) and their â€œsuper-conceptsâ€, but not their â€œsubconceptsâ€; for the included concepts, also â€œtheir restrictionsâ€, â€œintersectionâ€, â€œunionâ€, and
â€œequivalent conceptsâ€ should be considered by including the roles and concepts they contain,
together with their â€œsuper-conceptsâ€ and â€œsuper-rolesâ€ but not their â€œsub-conceptsâ€ and
â€œsub-rolesâ€. From the description of the procedure it is not entirely clear whether it works
with a classified ontology (which is unlikely in the case of GALEN since the full version of
GALEN has not been classified by any existing reasoner), or, otherwise, how the â€œsuper-â€
and â€œsub-â€ concepts are computed. It is also not clear which axioms should be included in
309

Cuenca Grau, Horrocks, Kazakov, & Sattler

the segment in the end, since the procedure talks only about the inclusion of concepts and
roles.
A different approach to module extraction proposed in the literature (Stuckenschmidt
& Klein, 2004) consists of partitioning the concepts in an ontology to facilitate visualization
of and navigation through an ontology. The algorithm uses a set of heuristics for measuring
the degree of dependency between the concepts in the ontology and outputs a graphical
representation of these dependencies. The algorithm is intended as a visualization technique,
and does not establish a correspondence between the nodes of the graph and sets of axioms
in the ontology.
What is common between the modularization procedures we have mentioned is the lack
of a formal treatment for the notion of module. The papers describing these modularization
procedures do not attempt to formally specify the intended outputs of the procedures, but
rather argue what should be in the modules and what not based on intuitive notions. In
particular, they do not take the semantics of the ontology languages into account. It might
be possible to formalize these algorithms and identify ontologies for which the â€œintuitionbasedâ€ modularization procedures work correctly. Such studies are beyond the scope of this
paper.
Module extraction in ontologies has also been investigated from a formal point of view
(Cuenca Grau et al., 2006b). Cuenca Grau et al. (2006) define a notion of a module QA in an
ontology Q for an atomic concept A. One of the requirements for the module is that Q should
be a conservative extension of QA (in the paper QA is called a logical module in Q). The
paper imposes an additional requirement on modules, namely that the module QA should
entail all the subsumptions in the original ontology between atomic concepts involving A and
other atomic concepts in QA . The authors present an algorithm for partitioning an ontology
into disjoint modules and proved that the algorithm is correct provided that certain safety
requirements for the input ontology hold: the ontology should be consistent, should not
contain unsatisfiable atomic concepts, and should have only â€œsafeâ€ axioms (which in our
terms means that they are local for the empty signature). In contrast, the algorithm we
present here works for any ontology, including those containing â€œnon-safeâ€ axioms.
The growing interest in the notion of â€œmodularityâ€ in ontologies has been recently
reflected in a workshop on modular ontologies5 held in conjunction with the International
Semantic Web Conference (ISWC-2006). Concerning the problem of ontology reuse, there
have been various proposals for â€œsafelyâ€ combining modules; most of these proposals, such
as E-connections (Cuenca Grau, Parsia, & Sirin, 2006a), Distributed Description Logics
(Borgida & Serafini, 2003) and Package-based Description Logics (Bao, Caragea, & Honavar,
2006) propose a specialized semantics for controlling the interaction between the importing
and the imported modules to avoid side-effects. In contrast to these works, we assume here
that reuse is performed by simply building the logical union of the axioms in the modules
under the standard semantics, and we establish a collection of reasoning services, such as
safety testing, to check for side-effects. The interested reader can find in the literature a
detailed comparison between the different approaches for combining ontologies (Cuenca
Grau & Kutz, 2007).
5. for information see the homepage of the workshop http://www.cild.iastate.edu/events/womo.html

310

Modular Reuse of Ontologies: Theory and Practice

8. Implementation and Proof of Concept
In this section, we provide empirical evidence of the appropriateness of locality for safety
testing and module extraction. For this purpose, we have implemented a syntactic locarâ†âˆ†Ã—âˆ†
râ†âˆ…
lity checker for the locality classes OÌƒAâ†âˆ…
(Â·) and OÌƒAâ†âˆ†
(Â·) as well as the algorithm for
extracting modules given in Figure 5 from Section 6.
râ†âˆ…
First, we show that the locality class OÌƒAâ†âˆ…
(Â·) provides a powerful sufficiency test for
râ†âˆ…
safety which works for many real-world ontologies. Second, we show that OÌƒAâ†âˆ…
(Â·)-based
modules are typically very small compared to both the size of the ontology and the modules
extracted using other techniques. Third, we report on our implementation in the ontology
editor Swoop (Kalyanpur, Parsia, Sirin, Cuenca Grau, & Hendler, 2006) and illustrate the
râ†âˆ†Ã—âˆ†
râ†âˆ…
combination of the modularization procedures based on the classes OÌƒAâ†âˆ…
(Â·) and OÌƒAâ†âˆ†
(Â·).
8.1 Locality for Testing Safety
râ†âˆ…
We have run our syntactic locality checker for the class OÌƒAâ†âˆ…
(Â·) over the ontologies from a
library of 300 ontologies of various sizes and complexity some of which import each other
(Gardiner, Tsarkov, & Horrocks, 2006).6 For all ontologies P that import an ontology Q,
we check if P belongs to the locality class for S = Sig(P) âˆ© Sig(Q).
It turned out that from the 96 ontologies in the library that import other ontologies, all
but 11 were syntactically local for S (and hence also semantically local for S). From the 11
non-local ontologies, 7 are written in the OWL-Full species of OWL (Patel-Schneider et al.,
2004) to which our framework does not yet apply. The remaining 4 non-localities are due
to the presence of so-called mapping axioms of the form A â‰¡ B 0 , where A âˆˆ
/ S and B 0 âˆˆ S.
Note that these axioms simply indicate that the atomic concepts A, B 0 in the two ontologies
under consideration are synonyms. Indeed, we were able to easily repair these non-localities
as follows: we replace every occurrence of A in P with B 0 and then remove this axiom from
the ontology. After this transformation, all 4 non-local ontologies turned out to be local.

8.2 Extraction of Modules
In this section, we compare three modularization7 algorithms that we have implemented
using Manchesterâ€™s OWL API:8
A1: The Prompt-Factor algorithm (Noy & Musen, 2003);
A2: The segmentation algorithm proposed by Cuenca Grau et al. (2006);
râ†âˆ…
A3: Our modularisation algorithm (Algorithm 5), based on the locality class OÌƒAâ†âˆ…
(Â·).

The aim of the experiments described in this section is not to provide a throughout comparison of the quality of existing modularization algorithms since each algorithm extracts
â€œmodulesâ€ according to its own requirements, but rather to give an idea of the typical size
of the modules extracted from real ontologies by each of the algorithms.
6. The library is available at http://www.cs.man.ac.uk/~horrocks/testing/
7. In this section by â€œmoduleâ€ we understand the result of the considered modularization procedures which
may not necessarily be a module according to Definition 10 or 12
8. http://sourceforge.net/projects/owlapi

311

Cuenca Grau, Horrocks, Kazakov, & Sattler

(a) Modularization
of NCI
(a)
Modularization
of NCI

(b) Modularization
Modularization of of
GALEN-Small
(b)
GALEN-Small

(c) Modularization
Modularization of SNOMED
(c)
of SNOMED

(d) Modularization
Modularization of GALEN-Full
(d)
of GALEN-Full

(e) Small
Small modules
of of
GALEN-Full
(e)
modules
GALEN-Full

(f) Large
Large modules
of of
GALEN-Full
(f)
modules
GALEN-Full

Figure 6: Distribution for the sizes of syntactic locality-based modules: the X-Axis gives the
number of concepts in the modules and the Y-Axis the number of modules extracted for
each size range.

312

Modular Reuse of Ontologies: Theory and Practice

A2: Segmentation

A3: Loc.-based mod.

] Atomic

A1: Prompt-Factor

Concepts

Max.(%)

Avg.(%)

Max.(%)

Avg.(%)

Max.(%)

Avg.(%)

NCI

27772

87.6

75.84

55

30.8

0.8

0.08

SNOMED

255318

100

100

100

100

0.5

0.05

GO

Ontology

22357

1

0.1

1

0.1

0.4

0.05

SUMO

869

100

100

100

100

2

0.09

GALEN-Small

2749

100

100

100

100

10

1.7

GALEN-Full

24089

100

100

100

100

29.8

3.5

SWEET

1816

96.4

88.7

83.3

51.5

1.9

0.1

DOLCE-Lite

499

100

100

100

100

37.3

24.6

Table 6: Comparison of Different Modularization Algorithms

As a test suite, we have collected a set of well-known ontologies available on the Web,
which we divided into two groups:
Simple. In this group, we have included the National Cancer Institute (NCI) Ontology,9
the SUMO Upper Ontology,10 the Gene Ontology (GO),11 and the SNOMED Ontology12 .
These ontologies are expressed in a simple ontology language and are of a simple structure;
in particular, they do not contain GCIs, but only definitions.
Complex. This group contains the well-known GALEN ontology (GALEN-Full),13 the
DOLCE upper ontology (DOLCE-Lite),14 and NASAâ€™s Semantic Web for Earth and Environmental Terminology (SWEET)15 . These ontologies are complex since they use many
constructors from OWL DL and/or include a significant number of GCIs. In the case of
GALEN, we have also considered a version GALEN-Small that has commonly been used as
a benchmark for OWL reasoners. This ontology is almost 10 times smaller than the original
GALEN-Full ontology, yet similar in structure.
Since there is no benchmark for ontology modularization and only a few use cases are
available, there is no systematic way of evaluating modularization procedures. Therefore
we have designed a simple experiment setup which, even if it may not necessarily reflect
an actual ontology reuse scenario, it should give an idea of typical module sizes. For each
ontology, we took the set of its atomic concepts and extracted modules for every atomic
concept. We compare the maximal and average sizes of the extracted modules.
It is worth emphasizing here that our algorithm A3 does not just extract a module for
the input atomic concept: the extracted fragment is also a module for its whole signature,
which typically includes a fair amount of other concepts and roles.
9.
10.
11.
12.
13.
14.
15.

http://www.mindswap.org/2003/CancerOntology/nciOncology.owl
http://ontology.teknowledge.com/
http://www.geneontology.org
http://www.snomed.org
http://www.openclinical.org/prj_galen.html
http://www.loa-cnr.it/DOLCE.html
http://sweet.jpl.nasa.gov/ontology/
313

Cuenca Grau, Horrocks, Kazakov, & Sattler

râ†âˆ†Ã—âˆ†
râ†âˆ…
(a) Concepts DNA Sequence and (b) OÌƒAâ†âˆ…
(S)-based module for (c) OÌƒAâ†âˆ†
(S)-based module for
Microanatomy in NCI
DNA Sequence in NCI
Micro Anatomy in the fragment 7b

Figure 7: The Module Extraction Functionality in Swoop
The results we have obtained are summarized in Table 6. The table provides the size
of the largest module and the average size of the modules obtained using each of these
algorithms. In the table, we can clearly see that locality-based modules are significantly
smaller than the ones obtained using the other methods; in particular, in the case of SUMO,
DOLCE, GALEN and SNOMED, the algorithms A1 and A2 retrieve the whole ontology as
the module for each input signature. In contrast, the modules we obtain using our algorithm
are significantly smaller than the size of the input ontology.
For NCI, SNOMED, GO and SUMO, we have obtained very small locality-based modules. This can be explained by the fact that these ontologies, even if large, are simple
in structure and logical expressivity. For example, in SNOMED, the largest locality-based
module obtained is approximately 0.5% of the size of the ontology, and the average size of
the modules is 1/10 of the size of the largest module. In fact, most of the modules we have
obtained for these ontologies contain less than 40 atomic concepts.
For GALEN, SWEET and DOLCE, the locality-based modules are larger. Indeed, the
largest module in GALEN-Small is 1/10 of the size of the ontology, as opposed to 1/200
in the case of SNOMED. For DOLCE, the modules are even biggerâ€”1/3 of the size of
the ontologyâ€”which indicates that the dependencies between the different concepts in the
ontology are very strong and complicated. The SWEET ontology is an exception: even
though the ontology uses most of the constructors available in OWL, the ontology is heavily
underspecified, which yields small modules.
In Figure 6, we have a more detailed analysis of the modules for NCI, SNOMED,
GALEN-Small and GALEN-Full. Here, the X-axis represents the size ranges of the ob314

Modular Reuse of Ontologies: Theory and Practice

tained modules and the Y-axis the number of modules whose size is within the given range.
The plots thus give an idea of the distribution for the sizes of the different modules.
For SNOMED, NCI and GALEN-Small, we can observe that the size of the modules
follows a smooth distribution. In contrast, for GALEN-Full, we have obtained a large number
of small modules and a significant number of very big ones, but no medium-sized modules
in-between. This abrupt distribution indicates the presence of a big cycle of dependencies in
the ontology. The presence of this cycle can be spotted more clearly in Figure 6(f); the figure
shows that there is a large number of modules of size in between 6515 and 6535 concepts.
This cycle does not occur in the simplified version of GALEN and thus we obtain a smooth
distribution for that case. In contrast, in Figure 6(e) we can see that the distribution for
the â€œsmallâ€ modules in GALEN-Full is smooth and much more similar to the one for the
simplified version of GALEN.
The considerable differences in the size of the modules extracted by algorithms A1 â€“
A3 are due to the fact that these algorithms extract modules according to different requirements. Algorithm A1 produces a fragment of the ontology that contains the input atomic
concept and is syntactically separated from the rest of the axiomsâ€”that is, the fragment
and the rest of the ontology have disjoint signatures. Algorithm A2 extracts a fragment of
the ontology that is a module for the input atomic concept and is additionally semantically
separated from the rest of the ontology: no entailment between an atomic concept in the
module and an atomic concept not in the module should hold in the original ontology. Since
our algorithm is based on weaker requirements, it is to be expected that it extracts smaller
modules. What is surprising is that the difference in the size of modules is so significant.
In order to explore the use of our results for ontology design and analysis, we have
integrated our algorithm for extracting modules in the ontology editor Swoop (Kalyanpur
et al., 2006). The user interface of Swoop allows for the selection of an input signature and
the retrieval of the corresponding module.16
Figure 7a shows the classification of the concepts DNA Sequence and Microanatomy in
râ†âˆ…
the NCI ontology. Figure 7b shows the minimal OÌƒAâ†âˆ…
(Â·)-based module for DNA Sequence,
râ†âˆ…
as obtained in Swoop. Recall that, according to Corollary 47, a OÌƒAâ†âˆ…
(Â·)-based module for an
atomic concept contains all necessary axioms for, at least, all its (entailed) super-concepts
in O. Thus this module can be seen as the â€œupper ontologyâ€ for A in O. In fact, Figure 7
shows that this module contains only the concepts in the â€œpathâ€ from DNA Sequence to
the top level concept Anatomy Kind. This suggests that the knowledge in NCI about the
particular concept DNA Sequence is very shallow in the sense that NCI only â€œknowsâ€ that a
DNA Sequence is a macromolecular structure, which, in the end, is an anatomy kind. If one
wants to refine the module by only including the information in the ontology necessary to
râ†âˆ†Ã—âˆ†
entail the â€œpathâ€ from DNA Sequence to Micro Anatomy, one could extract the OÌƒAâ†âˆ†
(Â·)based module for Micro Anatomy in the fragment 7b. By Corollary 47, this module contains
all the sub-concepts of Micro Anatomy in the previously extracted module. The resulting
module is shown in Figure 7b.

16. The tool can be downloaded at http://code.google.com/p/swoop/

315

Cuenca Grau, Horrocks, Kazakov, & Sattler

9. Conclusion
In this paper, we have proposed a set of reasoning problems that are relevant for ontology
reuse. We have established the relationships between these problems and studied their computability. Using existing results (Lutz et al., 2007) and the results obtained in Section 4, we
have shown that these problems are undecidable or algorithmically unsolvable for the logic
underlying OWL DL. We have dealt with these problems by defining sufficient conditions
for a solution to exist, which can be computed in practice. We have introduced and studied
the notion of a safety class, which characterizes any sufficiency condition for safety of an
ontology w.r.t. a signature. In addition, we have used safety classes to extract modules from
ontologies.
For future work, we would like to study other approximations which can produce small
modules in complex ontologies like GALEN, and exploit modules to optimize ontology
reasoning.

References
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL envelope. In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,
Edinburgh, Scotland, UK, July 30-August 5, 2005, pp. 364â€“370. Professional Book
Center.
Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2003). The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press.
Bao, J., Caragea, D., & Honavar, V. (2006). On the semantics of linking and importing in
modular ontologies. In Proceedings of the 5th International Semantic Web Conference
(ISWC-2006), Athens, GA, USA, November 5-9, 2006, Vol. 4273 of Lecture Notes in
Computer Science, pp. 72â€“86.
BoÌˆrger, E., GraÌˆdel, E., & Gurevich, Y. (1997). The Classical Decision Problem. Perspectives
of Mathematical Logic. Springer-Verlag. Second printing (Universitext) 2001.
Borgida, A., & Serafini, L. (2003). Distributed description logics: Assimilating information
from peer sources. J. Data Semantics, 1, 153â€“184.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2007). A logical framework
for modularity of ontologies. In IJCAI-07, Proceedings of the Twentieth International
Joint Conference on Artificial Intelligence, Hyderabad, India, January 2007, pp. 298â€“
304. AAAI.
Cuenca Grau, B., & Kutz, O. (2007). Modular ontology languages revisited. In Proceedings
of the Workshop on Semantic Web for Collaborative Knowledge Acquisition, Hyderabad, India, January 5, 2007.
Cuenca Grau, B., Parsia, B., & Sirin, E. (2006a). Combining OWL ontologies using Econnections. J. Web Sem., 4 (1), 40â€“59.
Cuenca Grau, B., Parsia, B., Sirin, E., & Kalyanpur, A. (2006b). Modularity and web ontologies. In Proceedings of the Tenth International Conference on Principles of Knowledge
316

Modular Reuse of Ontologies: Theory and Practice

Representation and Reasoning (KR-2006), Lake District of the United Kingdom, June
2-5, 2006, pp. 198â€“209. AAAI Press.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2007). Just the right amount:
extracting modules from ontologies. In Proceedings of the 16th International Conference on World Wide Web (WWW-2007), Banff, Alberta, Canada, May 8-12, 2007,
pp. 717â€“726. ACM.
Cuenca Grau, B., Horrocks, I., Kutz, O., & Sattler, U. (2006). Will my ontologies fit
together?. In Proceedings of the 2006 International Workshop on Description Logics
(DL-2006), Windermere, Lake District, UK, May 30 - June 1, 2006, Vol. 189 of CEUR
Workshop Proceedings. CEUR-WS.org.
Gardiner, T., Tsarkov, D., & Horrocks, I. (2006). Framework for an automated comparison of description logic reasoners. In Proceedings of the 5th International Semantic
Web Conference (ISWC-2006), Athens, GA, USA, November 5-9, 2006, Vol. 4273 of
Lecture Notes in Computer Science, pp. 654â€“667. Springer.
Ghilardi, S., Lutz, C., & Wolter, F. (2006). Did I damage my ontology? a case for conservative extensions in description logics. In Proceedings of the Tenth International
Conference on Principles of Knowledge Representation and Reasoning (KR-2006),
Lake District of the United Kingdom, June 2-5, 2006, pp. 187â€“197. AAAI Press.
Horrocks, I., Patel-Schneider, P. F., & van Harmelen, F. (2003). From SHIQ and RDF to
OWL: the making of a web ontology language. J. Web Sem., 1 (1), 7â€“26.
Horrocks, I., & Sattler, U. (2005). A tableaux decision procedure for SHOIQ. In Proceedings
of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05),
Edinburgh, Scotland, UK, July 30-August 5, 2005, pp. 448â€“453. Professional Book
Center.
Kalfoglou, Y., & Schorlemmer, M. (2003). Ontology mapping: The state of the art. The
Knowledge Engineering Review, 18, 1â€“31.
Kalyanpur, A., Parsia, B., Sirin, E., Cuenca Grau, B., & Hendler, J. A. (2006). Swoop: A
web ontology editing browser. J. Web Sem., 4 (2), 144â€“153.
Lutz, C., Walther, D., & Wolter, F. (2007). Conservative extensions in expressive description
logics. In Proceedings of the Twentieth International Joint Conference on Artificial
Intelligence (IJCAI-07), Hyderabad, India, January 2007, pp. 453â€“459. AAAI.
Lutz, C., & Wolter, F. (2007). Conservative extensions in the lightweight description logic
EL. In Proceedings of the 21st International Conference on Automated Deduction
(CADE-21), Bremen, Germany, July 17-20, 2007, Vol. 4603 of Lecture Notes in Computer Science, pp. 84â€“99. Springer.
MoÌˆller, R., & Haarslev, V. (2003). Description logic systems. In The Description Logic
Handbook, chap. 8, pp. 282â€“305. Cambridge University Press.
Motik, B. (2006). Reasoning in Description Logics using Resolution and Deductive
Databases. Ph.D. thesis, UnivesitaÌˆt Karlsruhe (TH), Karlsruhe, Germany.
Noy, N. F. (2004a). Semantic integration: A survey of ontology-based approaches. SIGMOD
Record, 33 (4), 65â€“70.
317

Cuenca Grau, Horrocks, Kazakov, & Sattler

Noy, N. F. (2004b). Tools for mapping and merging ontologies. In Staab, & Studer (Staab
& Studer, 2004), pp. 365â€“384.
Noy, N., & Musen, M. (2003). The PROMPT suite: Interactive tools for ontology mapping
and merging. Int. Journal of Human-Computer Studies, Elsevier, 6 (59).
Patel-Schneider, P., Hayes, P., & Horrocks, I. (2004). Web ontology language OWL Abstract
Syntax and Semantics. W3C Recommendation.
Rector, A., & Rogers, J. (1999). Ontological issues in using a description logic to represent
medical concepts: Experience from GALEN. In IMIA WG6 Workshop, Proceedings.
Schmidt-SchauÃŸ, M., & Smolka, G. (1991). Attributive concept descriptions with complements. Artificial Intelligence, Elsevier, 48 (1), 1â€“26.
Seidenberg, J., & Rector, A. L. (2006). Web ontology segmentation: analysis, classification
and use. In Proceedings of the 15th international conference on World Wide Web
(WWW-2006), Edinburgh, Scotland, UK, May 23-26, 2006, pp. 13â€“22. ACM.
Sirin, E., & Parsia, B. (2004). Pellet system description. In Proceedings of the 2004 International Workshop on Description Logics (DL2004), Whistler, British Columbia,
Canada, June 6-8, 2004, Vol. 104 of CEUR Workshop Proceedings. CEUR-WS.org.
Staab, S., & Studer, R. (Eds.). (2004). Handbook on Ontologies. International Handbooks
on Information Systems. Springer.
Stuckenschmidt, H., & Klein, M. (2004). Structure-based partitioning of large class hierarchies. In Proceedings of the Third International Semantic Web Conference (ISWC2004), Hiroshima, Japan, November 7-11, 2004, Vol. 3298 of Lecture Notes in Computer Science, pp. 289â€“303. Springer.
Tobies, S. (2000). The complexity of reasoning with cardinality restrictions and nominals
in expressive description logics. J. Artif. Intell. Res. (JAIR), 12, 199â€“217.
Tsarkov, D., & Horrocks, I. (2006). FaCT++ description logic reasoner: System description.
In Proceedings of the Third International Joint Conference on Automated Reasoning
(IJCAR 2006), Seattle, WA, USA, August 17-20, 2006, Vol. 4130 of Lecture Notes in
Computer Science, pp. 292â€“297. Springer.

318

Journal of Artificial Intelligence Research 31 (2008) 83-112

Submitted 06/07; published 01/08

CUI Networks: A Graphical Representation for Conditional
Utility Independence
Yagil Engel
Michael P. Wellman

yagil@umich.edu
wellman@umich.edu

University of Michigan, Computer Science & Engineering
2260 Hayward St, Ann Arbor, MI 48109-2121, USA

Abstract
We introduce CUI networks, a compact graphical representation of utility functions
over multiple attributes. CUI networks model multiattribute utility functions using the
well-studied and widely applicable utility independence concept. We show how conditional
utility independence leads to an effective functional decomposition that can be exhibited
graphically, and how local, compact data at the graph nodes can be used to calculate
joint utility. We discuss aspects of elicitation, network construction, and optimization, and
contrast our new representation with previous graphical preference modeling.

1. Introduction
Modern AI decision making is based on the notion of expected utility, in which probability distributions are used to weigh the utility values for each of the possible outcomes.
The representation of probability distribution functions by Markov or Bayesian networks
(Pearl, 1988)â€”exploiting conditional independence to achieve compactness and computational efficiencyâ€”has led to a plethora of new techniques and applications. Despite their
equal importance to decision making, preferences and utilities have generally not received
the level of attention AI researchers have devoted to beliefs and probabilities. Nor have the
(increasing) efforts to develop representations and inference methods for utility achieved a
degree of success comparable to the impact of graphical models on probabilistic reasoning.
Recognizing that utility functions over multidimensional domains may also be amenable to
factoring based on independence (Keeney & Raiffa, 1976), several have aimed to develop
models with analogous benefits (Bacchus & Grove, 1995; Boutilier, Bacchus, & Brafman,
2001; La Mura & Shoham, 1999; Wellman & Doyle, 1992). This is our goal as well, and we
compare our approach to these and other methods in the Related Work section (2.2).
The development of compact representations for multiattribute utility begins with the
notion of preferential independence (PI), or separability of subdomains in the outcome space.
A subdomain of outcomes is separable in the PI sense if the preference order over this subdomain does not depend on the rest of the domain. When all subsets of attributes induce
separable subdomains, the ordinal utility (value) function decomposes additively over its
variables (Debreu, 1959; Fishburn, 1965; Gorman, 1968). A cardinal utility function represents not only preferences over outcomes but also a notion of strength of preferences, most
notably to represent preferences over actions with uncertain outcomes, or lotteries. Direct
adaptation of the PI concept to cardinal utility requires a generalization of this notion:
a set of attributes is utility independent (UI) if the preference order over lotteries on the

c
2008
AI Access Foundation. All rights reserved.

Engel & Wellman

induced subdomain does not depend on the values of the rest of the attributes. A stronger
judgement is to assert that the preference order over the joint domain depends only on its
margins over some attribute subsets. The latter leads to powerful additive decompositions,
either fully additive (when the subsets of attributes are disjoint), or generalized, which is an
additive decomposition over overlapping subsets (Fishburn, 1967; Bacchus & Grove, 1995).
Utility independence leads to less convenient decompositions, such as multilinear (Keeney
& Raiffa, 1976) or hierarchical (Von Stengel, 1988; Wellman & Doyle, 1992). Most previous
efforts in the AI community to adapt modern graphical modeling to utility functions employ the generalized additive decomposition (Bacchus & Grove, 1995; Boutilier et al., 2001;
Gonzales & Perny, 2004). In contrast, our work continues the other thread, based on the
weaker utility independence assumption. We elaborate on the difference between the types
of independence following the presentation of formal definitions.

2. Background
Our utility-theoretic terminology follows the definitive text by Keeney and Raiffa (1976).
In the multiattribute utility framework, an outcome is represented by a vector of values
for n variables, called attributes. The decision makerâ€™s preferences are represented by a
total pre-order, , over the set of outcomes. In common applications decision makers do
not have the ability to choose a certain outcome, but rather an action that results in a
probability distribution over outcomes, also called a lottery. The decision maker is hence
Ëœ over the set of possible lotteries. Given a standard set
assumed to have a preference order 
Ëœ
of axioms,  can be represented by a real-valued utility function over outcomes, U (Â·), such
that numeric ranking of probabilistic outcomes by expected utility respects the ordering by
Ëœ The utility function is unique up to positive affine transformations. A positive linear
.
transform of U (Â·) represents the same preferences, and is thus strategically equivalent.
The ability to represent utility over probability distributions by a function over outcomes
provides some structure, but in multiattribute settings the outcome space is n-dimensional.
Unless n is quite small, therefore, an explicit (e.g., tabular) representation of U (Â·) will
generally not be practical. Much of the research in multiattribute utility theory aims to
identify structural patterns that enable more compact representations. In particular, when
subsets of attributes respect various independence relationships, the utility function may
be decomposed into combinations of modular subutility functions of smaller dimension.
Let S = {x1 , . . . , xn } be a set of attributes. In the following definitions (and the rest of
the work) capital letters denote subsets of attributes, small letters (with or without numeric
subscripts) denote specific attributes, and X denotes the complement of X with respect to
S. We denote the (joint) domain of X by D(X), and indicate specific attribute assignments
with prime signs or superscripts. To represent an instantiation of subsets X and Y at the
same time we use a sequence of instantiation symbols, as in X 0 Y 0 .
In order to meaningfully discuss preferences over subsets of attributes, we need a notion
of preferences over a subset given fixed values for the rest of the attributes.
0

0

Definition 1. Outcome Y 0 is conditionally preferred to outcome Y 00 given Y , if Y 0 Y 
0
0
Y 00 Y . We denote the conditional preference order over Y given Y by Y 0 .

84

CUI networks

Ëœ 0
Similarly we define conditional preference order over lotteries. The preference order 
Y
0
over lotteries on Y is represented by a conditional utility function, U (Y, Y ).
Definition 2. Y is Preferential Independent (PI) of Y if Y 0 does not depend on the value
0
chosen for Y .
Preferential independence can be very useful for qualitative preference assessment. Firstorder preferential independence (i.e., independence of a single attribute from the rest) is a
natural assumption in many domains. For example, in typical purchase decisions greater
quantity or higher quality is more desirable regardless of the values of other attributes. Preferential independence of higher order, however, requires invariance of the tradeoffs among
some attributes with respect to variation in others, a more stringentâ€”though still often
satisfiableâ€”independence condition. The standard PI condition applies to a subset with respect to the full complement of remaining attributes. The conditional version of PI specifies
independence with respect to a subset of the complement, holding the remaining attributes
fixed.
Definition 3. Y is Conditionally Preferential Independent (CPI) of X given Z (Z = XY ),
if for any Z 0 , X 0 Z 0 does not depend on the value chosen for X 0 . We denote this relationship
by CPI(Y, X | Z).
The counterpart of preferential independence that considers probability distributions
over outcomes is called utility independence.
Definition 4. Y is Utility Independent (UI) of Y , if the conditional preference order for
Ëœ 0 , does not depend on value chosen for Y 0 .
lotteries over Y , 
Y
In our notations, we apply UI and the conditions defined below to sets of attributes or
to specific attributes.
Given UI(Y, X), taking X = Y , the conditional utility function over Y given X 0 is
invariant up to positive affine transformations, for any fixed value X 0 . This fact can be
expressed by the decomposition
U (X, Y ) = f (X) + g(X)U (X 0 , Y ),

g(Â·) > 0.

Note that the functions f (Â·) and g(Â·) may be different for each particular choice of X 0 . Since
U (X 0 , Y ) is a function only of Y , we sometimes use the notation UX 0 (Y ).
Utility independence has a conditional version as well.
Definition 5. Y is Conditionally Utility Independent (CUI) of X given Z (Z = XY ) if for
Ëœ X 0 Z 0 does not depend on the value chosen for X 0 . We denote this relationship by
any Z 0 , 
CUI(Y, X | Z).
CUI also supports functional decomposition. For any Z 0 , the conditional utility function
over Y given X 0 Z 0 is strategically equivalent to this function given a different instantiation
of X. However, the transformation depends not only on X, but also on Z 0 . Hence we can
write:
U (X, Y, Z) = f (X, Z) + g(X, Z)U (X 0 , Y, Z), g(Â·) > 0.
(1)
85

Engel & Wellman

That is, we can fix X on some arbitrary level X 0 and use two transformation functions f and
g to get the value of U (Â·) for other levels of X. A stronger, symmetric form of independence
which leads to additive decomposition of the utility function is called additive independence.
We provide the definition for its conditional version.
Definition 6. X and Y are Conditionally Additive Independent given Z, CAI(X, Y | Z),
Ëœ Z 0 depends only on the marginal conditional probability disif for any instantiation Z 0 , 
0
tributions over XZ and Y Z 0 .
This means that for any value Z 0 , and for any two probability distributions p, q such
that p(X, Â·, Z 0 ) â‰¡ q(X, Â·, Z 0 ), and p(Â·, Y, Z 0 ) â‰¡ q(Â·, Y, Z 0 ), the decision maker is indifferent
between p and q. A necessary (but not always sufficient) condition for this to hold is that
the utility differences U (X 0 , Y, Z 0 ) âˆ’ U (X 00 , Y, Z 0 ) (for any X 0 , X 00 ) do not depend on the
value of Y .
CAI leads to the following decomposition (Keeney & Raiffa, 1976):
U (X, Y, Z) = f (X, Z) + g(Y, Z).
Other variations of utility independence were considered in the theoretical literature,
leading to various decomposition results (Fishburn, 1975; Krantz, Luce, Suppes, & Tversky,
1971; Fuhrken & Richter, 1991).
2.1 Motivation
The most obvious benefit of a model based on (conditional) utility independence is the
generality admitted by a weaker independence condition, in comparison to additive independence. Whereas additivity practically excludes any interaction between utility of one
attribute or subset (X in Definition 6) to the value of another (Y ), utility independence
allows substitutivity and complementarity relationships, as long as the risk attitude towards one variable is not affected by the value of another. One could also argue that UI is
particularly intuitive, based as it is on an invariance condition on the preference order. In
contrast, (conditional) additive independence requires a judgment about the effects of joint
versus marginal probability distributions. Moreover, additive independence is symmetric,
whereas the condition U I(X, Y ) does allow the preference order over Y to depend on X.
Bacchus and Grove exemplify the difference between additive and utility independence
on a simple state space of two boolean attributes: Health and Wealth. In their example,
shown in Table 1, the attributes are not additive independent (it can be immediately seen
using preference differences), because H and W are complements: having both is worth
more than the sum of having each one without the other. We would have considered the
two attributes substitutes if, for example, U (W, H) = 4 and U (W, Â¬H) = 3. In both cases
H and W are nonetheless preferential independent, since we always prefer to be richer (all
else being equal) and healthier (all else being equal). For boolean variables, preferential and
utility independence are equivalent (we always prefer lotteries that give higher probability
to the preferred level) and therefore Health and Wealth are also UI of each other.
(Conditional) additive independence and its resulting additive decomposition can be
generalized to multiple subsets that are not necessarily disjoint. This condition is called

86

CUI networks

W
Â¬W

H
5
2

Â¬H
1
0

Table 1: Utility values for the Health and Wealth example (Bacchus & Grove, 1995).
generalized additive independence (GAI). If GAI holds, U (Â·) decomposes to a sum of independent functions fi (Â·) over the GAI subsets Xi . As shown by Bacchus and Grove, CAI
conditions can be accumulated to a global GAI decomposition (see Section 2.2). The latter
may also exist without any CAI conditions leading to it, but such a GAI condition is hard
to identify: whereas each CAI condition corresponds to the independence of two attributes
or two subsets, a global GAI condition does not have such an intuitive interpretation.
In the next example, no cardinal independence condition exists, except for a non symmetric CUI. The example also shows the difference between PI and UI, and hence requires
the domains of H and W to include at least three values each. We also add a third attribute to the outcome space, location (L), indicating whether we live in the city or in the
countryside (Table 2). In order to show that U I(H, {W, L}) does not hold it is enough
to find that it is violated for one pair of lotteries. Given the partial outcome Wr , Lci we
prefer the equal chance lottery over < Hf , Hs >, whose expected utility is 12+5
2 , to the sure
outcome Hg (value 8), whereas given Wp , Lci we are indifferent (expected utility of 2 to
both lotteries). Intuitively, it may be the case that the additional value we get from fitness
(over good health) is higher if we are also rich, making it more significant than the value
Hg adds over Hs . Similarly, U I(W, {H, L}) does not hold, by comparing the even-chance
gamble over < Wr , Wp > and the sure outcome Wm , first given Hf , Lci and then given
Hs , Lci .
W and H are therefore not utility independent, but they are preferential independent.
L, however, is not: when we are rich we would rather live in the city, and the other way
round when we are poor, except for the case of being poor and sick under which we prefer
the city.

Wr
Wm
Wp

Hf
12
6
3

Lci
Hg
8
4
2

Hs
5
3
1

Hf
10
6
4

Lco
Hg
6
3
1.5

Hs
4
2
0

Table 2: Utility values for the Health, Wealth and Location example. Wr means rich, Wm is
medium income, Wp means poor. Hf is healthy and at top fitness, Hg means good health,
and Hs means sick. Lci stands for city location, and Lco means countryside location.
Therefore, no symmetric independence condition exists here, and that rules out any additive or multiplicative independence, conditional or not, between any subsets of attributes.
Also, since no single variable is unconditionally UI, then no subset can be unconditionally
UI. Further, the fact that preferences over L depend on the combination of H and W rules
out a GAI decomposition of the form {W, L}, {W, H}, {H, L}.
87

Engel & Wellman

We can, however, achieve decomposition using CUI. It is the case that CUI(W, L|H),
since each column on the left matrix (Lci ) is an affine transformation of its counterpart on
the right side (Lco ). For example, to transform the first column (Hf ), multiply by 23 and
add 2.
This example illustrates the subtlety of utility independence. In particular, whereas
preferences over L depend on W , W may still be (conditionally) UI of L. A CAI assumption for the same attributes must inevitably ignore the reversal of preferences over L for
different values of W , hence a decision maker that will be queried for preferences under this
assumption may not be able to provide meaningful answers.
The interaction with a system that requires preference representation normally requires
the identification of structure, and then the population of the utility values that are required
by the compact representation. It is therefore most important that these two aspects are
simplified as possible, whereas the functional form handled by the system may be more
sophisticated. This is exactly the tradeoff made by CUI nets, compared to a GAI-based
representation: if the GAI condition is based on CAI, CUI nets achieve lower dimensionality
(Section 7), and therefore easier elicitation. If a GAI condition is not based on a collection
of CAI conditions, it is hard to identify. CUI nets simplify these bottleneck aspects, by
driving the complexity into the algorithms and into the functional form that is handled
behind the scenes.
2.2 Related Work
Perhaps the earliest effort to exploit separable preferences in a graphical model was the extension of influence diagrams by Tatman and Shachter (1990) to decompose value functions
into sums and products of multiple value nodes. This structure provided computational
advantages, enabling the use of dynamic programming techniques exploiting value separability.
Bacchus and Grove (1995) were first to develop a graphical model based on conditional
independence structure. In particular, they establish that the CAI condition has a perfect
map (Pearl & Paz, 1989); that is, a graph with attribute nodes S such that node separation
reflects exactly the set of CAI conditions on S. More specifically, for any two sets of nodes
X, Y âŠ† S, CAI(X, Y |XY ) holds if and only if there is no direct edge between a node in X
and a node in Y . We use the term CAI map of S when referring to the graph which reflects
the perfect map of CAI conditions, in the context of a preference order over D(S). Bacchus
and Grove go on to show that the utility function has a GAI decomposition over the set of
maximal cliques of the CAI map. As we show in Section 7, the CUI network representation
developed here achieves weakly better dimensionality than CAI maps due to the greater
generality of the independence assumption.
Initiating another important line of work, Boutilier et al. (1999) introduced CP networks, an efficient representation for ordinal preferences over multiple attributes. In a
CP network, each variable is conditionally PI of the rest given its parents. Ordinal multiattribute preference representation schemes (for decision making under certainty), and
especially CP networks, can dramatically simplify the preference elicitation process, based
as they are on intuitive relative preference statements that avoid magnitude considerations.
However, the limited expressive power of CP networks may not suffice for complex decision

88

CUI networks

problems, in which tradeoff resolution may hinge in a complicated way on attribute settings
over rich domains. This problem is particularly acute when continuous or almost continuous
attributes are involved, such as money or time.
Boutilier et al. (2001) subsequently extended this approach to numeric, cardinal utility
in UCP networks, a graphical model that utilizes the GAI decomposition combined with
a CP-net topology. This requires dominance relations between parents and their children,
somewhat limiting the applicability of the representation. The GAI structure was also
applied for graphical models by Gonzales and Perny (2004), who employ the clique graph
of the CAI map (the GAI network ) for elicitation purposes.
In earlier work, La Mura and Shoham (1999) redefine utility independence as a symmetric multiplicative condition, taking it closer to its probability analog, and supporting a
Bayes-net like representation. Although multiplicative independence is different from additive independence, it is not necessarily weaker. Recent work by Abbas (2005) defines
a subclass of utility functions on which a multiplicative notion of UI obeys an analog of
Bayesâ€™s rule.
The only graphical decomposition suggested in the past for utility functions that is based
on the original, non-symmetric notion of utility independence is the utility tree (Von Stengel,
1988, see also Wellman and Doyle, 1992, for discussion in an AI context). The utility tree
decomposes the utility function using multilinear or multiplicative decomposition (Keeney
& Raiffa, 1976), and then further tries to decompose each subset similarly. Using these
hierarchical steps the utility function becomes a nested expression over functions of its
smallest separable subsets and their complements.
2.3 Graphical Models of CUI
In their concluding remarks, Bacchus and Grove (1995) suggest investigating graphical
models of other independence concepts, in particular utility independence. Founding a
graphical model on UI is more difficult, however, as utility independence does not decompose
as effectively as does additive independence. In particular, the condition U I(Y, X) ensures
that Y has a subutility function, but since X does not have one it is harder to carry on
the decomposition into X. Hence in the case that X is large the dimensionality of the
representation may remain too high. Our approach therefore employs CUI conditions on
large subsets Y , in which case the decomposition can be driven further by decomposing the
conditional utility function of Y using more CUI conditions.
In the sequel we show how serial application of CUI leads to functional decomposition.
The corresponding graphical model, a CUI network, provides a lower-dimension representation of the utility function in which the function for any vertex depends only on the node
and its parents. We demonstrate the use of CUI networks by constructing an example
for a relatively complex domain. Next we elaborate on the technical and semantic properties of the model and knowledge required to construct it. Subsequent technical sections
present optimization algorithms and techniques for further reducing the complexity of the
representation.

89

Engel & Wellman

3. CUI Networks
We begin by constructing a DAG representing a set of CUI conditions, followed by a derivation of the functional decomposition over the nodes of the DAG.
3.1 CUI DAG
Suppose that we obtain a set Ïƒ of CUI conditions on the variable set S = {x1 , . . . , xn }, such
that for each x âˆˆ S, Ïƒ contains a condition of the form
CUI(S \ ({x} âˆª P (x)) , x | P (x)).
In other words, there exists a set P (x) that separates the rest of the variables from x. Such
P (x) always exists, because for P (x) = S \ {x} the condition above trivially holds. The set
Ïƒ can be represented graphically by the following procedure, which we name procedure C.
1. Define an order on the set S (for convenience we assume the ordering x1 , . . . , xn ).
2. Define the set of parents of x1 as P a(x1 ) = P (x1 ).
3. For each i = 2, . . . , n
Ëœ i ), as the set of nodes in
â€¢ Define the set of intermediate descendants of xi , Dn(x
x1 , . . . , xiâˆ’1 that turned out to be descendants of xi , that is those for which xi is
Ëœ i ) is the smallest
a parent or another descendant of xi is a parent. Formally, Dn(x
set that satisfies the following condition:
Ëœ i ) âˆ© P a(xj )
âˆ€j âˆˆ {1, . . . , i âˆ’ 1}, [xi âˆˆ P a(xj ), or âˆƒk âˆˆ {1, . . . , i âˆ’ 1}.xk âˆˆ Dn(x
Ëœ i ).] (2)
â‡’ xj âˆˆ Dn(x
â€¢ Define the parents of xi to be the nodes in P (xi ) which are not already descendants of xi ,
Ëœ i ).
P a(xi ) = P (xi ) \ Dn(x
This procedure defines a DAG. We denote Dn(x) as the final set of descendants of x. It
is the set defined by Equation (2), when replacing {1, . . . , i âˆ’ 1} with {1, . . . , n}). By their
Ëœ
definitions, Dn(x) âŠ‡ Dn(x),
hence
Ëœ
P a(x) âˆª Dn(x) âŠ‡ P a(x) âˆª Dn(x)
= P (x).

(3)

Proposition 1. Consider the DAG defined by procedure C for a set of attributes S. For
any x âˆˆ S,
CUI(S \ ({x} âˆª P a(x) âˆª Dn(x)) , x | P a(x) âˆª Dn(x)).
(4)
Ëœ
Proof. By the definitions of P a(x) and P (x), (4) holds when replacing Dn(x) with Dn(x).
From the definition of CUI, it is straightforward that
CUI(S \ (Y âˆª W ) , Y | W ) â‡’ CUI(S \ (Y âˆª W âˆª Z) , Y | W âˆª Z),
because invariance of preference order over S \ (Y âˆª W ) implies invariance of preference
order over its subset S \ (Y âˆª W âˆª Z), when the difference set Z is fixed. Given (3), and
Ëœ
Ëœ
taking W = P a(x) âˆª Dn(x)
and Z = Dn(x) \ Dn(x),
we get (4).
90

CUI networks

As an example, we show the construction of the structure on a small set of variables
S = {x1 , x2 , x3 , x4 , x5 , x6 }, for which we are given the following set of CUI conditions:
Ïƒ = {CUI({x4 , x5 , x6 }, x1 | {x2 , x3 }), CUI({x4 , x3 , x6 }, x2 | {x1 , x5 }),
CUI({x2 , x4 , x6 }, x3 | {x1 , x5 }), CUI({x1 , x3 , x5 }, x4 | {x2 , x6 }),
CUI(x6 , x5 | {x1 , x2 , x3 , x4 }), CUI({x1 , x2 , x3 , x5 }, x6 | x4 )}.
Construction of the network using the order implied by the indices results in the CUI
DAG illustrated in Figure 1. The minimal separating set for x1 is {x2 , x3 }. For x2 , we get
Ëœ 2 ) = {x1 }, and the only non-descendant variable that is required to separate it from
Dn(x
the rest is x5 , which is therefore its only parent. The rest of the graph is constructed in
a similar way. When x4 is placed, we find that P (x4 ) = {x2 , x6 }. Therefore, x4 becomes
Ëœ 2 ) âˆª {x4 } = {x1 , x4 }.
descendant of x2 after x2 is placed, in other words Dn(x2 ) = Dn(x
ix6

ix5
 Z

Z
=x

~ ix
Z
i
2



?
=x

i
4

3

Z

Z

~i
Z
=x

1

Figure 1: CUI DAG given Ïƒ and order x1 ,. . . ,x6 .

Definition 7. Let U (S) be a utility function representing cardinal preferences over D(S).
A CUI DAG for U (Â·) is a DAG, such that for any x âˆˆ S, (4) holds.
Procedure C yields a CUI DAG by Proposition 1. As the other direction, any given CUI
DAG G (in which parents and descendants are denoted by P aG (Â·), DnG (Â·), respectively)
can be constructed using C, as follows. Define P (x) = P aG (x) âˆª DnG (x) and a variable
ordering according to the reverse topological order of G, and complete the execution of C.
It is straightforward to show that the set of parents selected for each xi is exactly P aG (xi ),
hence the result is a DAG which is identical to G.
3.2 CUI Decomposition
We now show how the CUI conditions, guaranteed by Proposition 1, can be applied iteratively to decompose U (Â·) to lower dimensional functions. We first pick a variable ordering
that agrees with the reverse topological order of the CUI DAG. To simplify the presentation,
we rename the variables so the ordering is again x1 , . . . , xn . The CUI condition (4) on x1
implies the following decomposition, according to (1):
U (S) = f1 (x1 , P a(x1 ), Dn(x1 )) + g1 (x1 , P a(x1 ), Dn(x1 ))Ux01 (S \ {x1 }).

(5)

Note that Dn(x1 ) = âˆ….
We assume that we have specified a reference point S 0 , which is an arbitrary value chosen
for each attribute x âˆˆ S, denoted by x0 . Ux01 (Â·) on the right hand side is the conditional
91

Engel & Wellman

utility function on S given that x1 is fixed at a reference point x01 . For convenience we omit
attributes whose values are fixed from the list of arguments.
By applying the decomposition based on the CUI condition of x2 on the conditional
utility function Ux01 (Â·), we get
Ux01 (S \ {x1 }) = f2 (x, P a(x2 ), Dn(x2 )) + g2 (x2 , P a(x2 ), Dn(x2 ))Ux01 ,x02 (S \ {x1 , x2 }). (6)
Note that Dn(x2 ) âŠ† {x1 }, and x1 is fixed to x01 , hence f2 and g2 effectively depend only on
x2 and P a(x2 ). This point is exploited below.
Substituting Ux01 (Â·) in (5) according to (6) yields:
U (S) = f1 + g1 (f2 + g2 Ux01 ,x02 (S \ {x1 , x2 })) = f1 + g1 f2 + g1 g2 Ux01 ,x02 (S \ {x1 , x2 }).
The list of arguments to the functions fj , gj are always (xj , P a(xj ), Dn(xj )), and we omit
it for readability.
We continue in this fashion and get
U (S) =

iâˆ’1
X

kâˆ’1
Y

(fk

j=1

k=1

gj ) +

i
Y

gj Ux01 ,...,x0 (xi , . . . , xn ),
iâˆ’1

j=1

and apply the CUI condition of xi ,
Ux01 ,...,x0 (xi , xi+1 , . . . xn ) =
iâˆ’1

fi (xi , P a(xi ), Dn(xi )) + gi (xi , P a(xi ), Dn(xi ))Ux01 ,...,x0 (xi+1 , . . . , xn ). (7)
i

For convenience, we define the constant function fn+1 â‰¡ Ux01 ,...,x0n (). Ultimately we obtain
U (S) =

n+1
X

iâˆ’1
Y

i=1

j=1

(fi (xi , P a(xi ), Dn(xi ))

gj (xj , P a(xj )), Dn(xj )).

(8)

The variable ordering is restricted to agree with the reverse topological order of the graph,
hence in (7), Dn(xi ) âŠ† {x1 , . . . , xiâˆ’1 }. Therefore, all the variables in Dn(xi ) on the righthand side of (7) are fixed on their reference points, so fi and gi only depend on xi and
P a(xi ). Formally, let y1 , . . . , yk be the variables in Dn(xi ). With some abuse of notation,
we define:
fi (xi , P a(xi )) = fi (xi , P a(xi ), y10 , . . . , yk0 ),
gi (xi , P a(xi )) = gi (xi , P a(xi ), y10 , . . . , yk0 ).

(9)

Now (8) becomes
U (S) =

n+1
X

iâˆ’1
Y

i=1

j=1

(fi (xi , P a(xi ))

gj (xj , P a(xj ))).

(10)

This term is a decomposition of the multiattribute utility function to lower dimensional
functions, whose dimensions depend on the number of variables of P a(x). As a result, the
92

CUI networks

dimensionality of the representation is reduced (as in Bayesian networks) to the maximal
number of parents of a node plus one.
We illustrate how the utility function is decomposed in the example of Figure 1. We
pick the ordering x4 , x1 , x6 , x3 , x2 , x5 that agrees with the reverse topological order of
the graph (note that we are not renaming the variables here). To simplify notation we
denote the conditional utility function in which xi is fixed on the reference point by adding
a subscript i to U (Â·).
U (S) = f4 (x4 x2 x6 ) + g4 (x4 x2 x6 )U4 (S \ {x4 })
U4 (S \ {x4 }) = f1 (x1 x2 x3 ) + g1 (x1 x2 x3 )U1,4 (S \ {x4 x1 })
U1,4 (S \ {x4 x1 }) = f6 (x6 ) + g6 (x6 )U1,4,6 (x2 x3 x5 )
U1,4,6 (x2 x3 x5 ) = f3 (x3 x5 ) + g3 (x3 x5 )U1,3,4,6 (x2 x5 )
U1,3,4,6 (x2 x5 ) = f2 (x2 x5 ) + g2 (x2 x5 )U1,2,3,4,6 (x5 )
U1,2,3,4,6 (x5 ) = f5 (x5 ) + g5 (x5 )U1,2,3,4,5,6 ()
Note that each fi and gi depends on xi and its parents. Merging the above equations, and
using the definition f7 â‰¡ U1,2,3,4,5,6 () produces
U (S) = f4 + g4 f1 + g4 g1 f6 + g4 g1 g6 f3 + g4 g1 g6 g3 f2 + g4 g1 g6 g3 g2 f5 + g4 g1 g6 g3 g2 g5 f7 . (11)
We established that U (S) can be represented using a set of functions F, that includes,
for any x âˆˆ S, the functions (fx , gx ) resulting from the decomposition (1) based on the CUI
condition (4). This means that to fully specify U (S) it is sufficient to obtain the data for
functions in F (this aspect is discussed in Section 5).
Definition 8. Let U (S) be a utility function representing cardinal preferences over D(S).
A CUI network for U (Â·) is a triplet (G, F, S 0 ). G = (S, E) is a CUI DAG for U (S), S 0 is
a reference point, and F is the set of functions {fi (xi , P a(xi )), gi (xi , P a(xi )) | i = 1 . . . , n}
defined above.
The utility value for any assignment to S can be calculated from the CUI network
according to (10), using any variable ordering that agrees with the reverse topological order
of the DAG. In our example, we can choose a different variable ordering than the one used
above, such as x1 , x3 , x4 , x2 , x5 , x6 , leading to the following expression.
U (S) = f1 + g1 f3 + g1 g3 f4 + g1 g3 g4 f2 + g1 g3 g4 g2 f5 + g1 g3 g4 g2 g5 f6 + g1 g3 g4 g2 g5 g6 f7 .
This sum of product is different than the one in (11). However, it is based on the same CUI
decompositions and therefore the same functions (fi , gi ).
3.3 Properties of CUI Networks
Based on Procedure C and the decomposition following it, we conclude the following.
Proposition 2. Let S be a set of attributes, and Ïƒ a set of CUI conditions on S. If Ïƒ
includes a condition of the form CUI(S \ (x âˆª Zx ), x | Zx ) for each x âˆˆ S, then Ïƒ can be
represented by a CUI network whose dimensionality does not exceed maxx (|Zx | + 1).
93

Engel & Wellman

Note that Zx denotes here a minimal set of attributes (variables) that renders the rest
CUI of x. This bound on the dimensionality will be obtained regardless of the variable
ordering. We can expect the maximal dimension to be lower if the network is constructed
using a good variable ordering. A good heuristic in determining the ordering would be to
use attributes with smaller dependent sets first, so that the attributes with more dependents
would have some of them as descendants. Based on such an ordering we would expect the
less important attributes to be lower in the topology, while the more crucial attributes
would either be present higher or have a larger number of parents.
From this point we usually omit the third argument when referring to a CUI condition,
as in CUI(X, Y ), which is taken equivalent to CUI(X, Y | S \ (X âˆª Y )).
In order to achieve a low dimensional CUI networks, we are required to detect CUI
conditions over large sets. This may be a difficult task, and we address it through an
example in Section 4. The task is made somewhat easier by the fact that the set has to be
CUI of a single variable; note that the condition CU I(Y, x) is weaker than the condition
CU I(Y, X) when x âˆˆ X. Furthermore, Section 7 shows how the dimensionality can be
reduced if the initial CUI decomposition is not sufficiently effective.
Based on properties of CUI, we can read additional independence conditions off the
graph. First, we observe that CUI has a composition property at the second argument.
Lemma 3. Let CUI(X, Y ) [X, Y âŠ‚ S], and CUI(A, B) [A, B âŠ‚ S]. Then
CUI(A âˆ© X , Y âˆª B).
This property leads to the following claim, which allows us to derive additional CUI
conditions once the graph is constructed.
Proposition
4. Consider S
a CUI network for a set of attributes S. Define P a(X) =
S
P
a(x)
and
Dn(X)
=
xâˆˆX Dn(x). Then for any X âŠ‚ S,
xâˆˆX
CUI(S \ (X âˆª P a(X) âˆª Dn(X)) , X).
Proof. By recursion on X, using Lemma 3 and Proposition 1.
We also consider the other direction, by defining the set of nodes that renders a set CUI
of the rest. This dual perspective becomes particularly useful for optimization (Section 6),
because optimization based on the preference order over an attribute is meaningful only
when holding enough other attributes fixed to make it CPI or CUI of the rest. Let Ch(X)
denote the union of children of nodes in X, and let An(X) denote all of the ancestors of
nodes in X, in both cases excluding nodes which are themselves in X.
Proposition 5. Consider a CUI network for a set of attributes S. CUI(X, S \(X âˆªAn(X)âˆª
Ch(X))) for any X âŠ† S.
Proof. Let y âˆˆ
/ X âˆª Ch(X) âˆª An(X). Then clearly âˆ€x âˆˆ X, x âˆˆ
/ P a(y) âˆª Dn(y). Hence from
Proposition 1, CUI(X, y). We apply Lemma 3 iteratively for each y âˆˆ
/ X âˆª Ch(X) âˆª An(X)
(note that the first argument is X for each CUI condition, so it is X in the result as well),
and get the desired result.
We conclude this section by relating CUI networks to CAI maps.
94

CUI networks

Proposition 6. Let G = (X, E) be a CAI map, and x1 , . . . , xn an ordering over the nodes
in X. Let G0 = (X, E 0 ) be the DAG such that there is a directed arc (xi , xj ) in E 0 iff i < j
and (xi , xj ) âˆˆ E. Then G0 is a CUI network.
We note, however, that CAI maps decompose the utility function over the maximal
cliques, whereas CUI networks decompose over nodes and their parents. Section 7 bridges
this gap. In addition, this result is used in Section 6.3.

4. CUI Modeling Example
To demonstrate the potential representational advantage of CUI networks we require a domain that is difficult to simplify otherwise. The example we use is the choice of a software
package by an enterprise that wishes to automate its sourcing (strategic procurement) process. We focus on the softwareâ€™s facilities for running auction or RFQ (request for quotes)
events, and tools to select winning suppliers either manually or automatically.
We identified nine key features of these kinds of software packages. In our choice scenario,
the buyer evaluates each package on these nine features, graded on a discrete scale (e.g.,
one to five). The features are, in brief:
Interactive Negotiations (IN ) allows a separate bargaining procedure with each supplier.
Multi-Stage (MS ) allows a procurement event to be comprised of separate stages of different types.
Cost Formula (CF ) buyers can formulate their total cost of doing business with each
supplier.
Supplier Tracking (ST ) allows long-term tracking of supplier performance.
MultiAttribute (MA) bidding over multiattribute items, potentially using a scoring function.1
Event Monitoring (EM ) provides an interface to running events and real-time graphical
views.
Bundle Bidding (BB ) bidding for bundles of goods.
Grid Bidding (GB ) adds a bidding dimension corresponding to an aspect such as time
or region.
Decision Support (DS ) tools for optimization and for aiding in the choice of the best
supplier(s).
We observe first that additive independence does not widely apply in this domain. For
example, Multi-Stage makes several other features more useful or important: Interactive
Negotiations (often useful as a last stage), Decision Support (to choose which suppliers
1. We hope the fact that the software itself may include facilities for multiattribute decision making does
not cause undue confusion. Naturally, we consider this an important feature.

95

Engel & Wellman

proceed to the next stage), and Event Monitoring (helps keep track of how useful was each
stage in reducing costs). Conversely, in some circumstances Multi-Stage can substitute for
the functionality of other features: MultiAttribute (by bidding on different attributes in different stages), Bundle Bidding (bidding on separate items in different stages), Grid Bidding
(bidding on different time/regions in different stages) and Supplier Tracking (by extracting
supplier information in a â€œRequest for Informationâ€ stage). The potential dependencies for
each attribute are shown in Table 3.
Attr
EM
IN
CF
ST
MA
MS
DS
GB
BB

Complements
CF ST MS
ST MS MA
EM MS DS MA GB BB
EM MS IN DS
IN DS CF
DS EM IN ST
CF MA GB ST BB MS
CF DS
CF DS

Substitutes

DS
MA
MS BB ST GB
GB BB MA CF
MA MS BB
MA MS GB

CUI set
IN,DS,MA,GB,BB
EM,CF,ST,DS,GB,BB
MA,GB,BB
IN,CF,GB,BB
GB,BB
MA,GB,BB
IN,EM
MA,BB
MA,GB

Table 3: Dependent and independent sets for each attribute.
The presence of a complement or substitute relation precludes additive independence.
From this fact we can identify a set of six attributes that must be mutually (additive) dependent: {BB , GB , DS , MA, MS , CF }. In consequence, the best-case dimensionality achieved
by a CAI map (and other CAI-based representations, see Section 2.2), for this domain would
be six, the size of the largest maximal clique.
In order to construct a CUI network we first identify, for each attribute x, a set Y that is
CUI of it. We can first guess such a set according to the complement/substitute information
in Table 3; typically, the set of attributes that are neither complements nor substitutes would
be CUI. This is the approach taken for the attributes EM and DS . However, attributes that
are complements or substitutes may still be CUI of each other, and we therefore attempt
to detect and verify potentially larger CUI sets. Keeney and Raiffa (1976) provide several
useful results that can help in detection of UI, and those results can be generalized to CUI.
In particular they show that we can first detect a conditional preferential independence
(CPI) condition in which one element is also CUI. Based on this result, in order to verify
for example that
CUI({BB , GB , MA}, CF | S \ {BB , GB , MA, CF }),

(12)

the following two conditions are sufficient:
CPI({BB , GB , MA}, CF | S \ {BB , GB , MA, CF }),

(13)

CUI(BB , {GB , MA, CF } | S \ {BB , GB , MA, CF }).

(14)

Detection and verification of these conditions are also discussed by Keeney and Raiffa (1976).
For our example, we observe that the features BB , GB , and MA each add a qualitative
96

CUI networks

element to the bidding. Each bidding element is best exploited when cost formulation
is available, so complements CF . The complementarity is similar for each feature, thus
implying (13). Moreover, BB is a crucial feature and therefore the risk attitude towards it
is not expected to vary with the level of CF , MA, and GB , and that implies (14), together
leading to (12).
In a similar fashion, we observe that the nature of the substitutivity of the three
mechanisms BB , GB , MA in MS is similar: each can be simulated using multiple stages.
That means that the tradeoffs among the three do not depend on MS , meaning that
CPI({BB , GB , MA}, MS ) holds. Next, the dependency among the triplet {BB , GB , MA} is
also a result of the option to substitute one by another. As a result, each pair is CPI of the
third. Finally, we find that the complementarity of ST and IN is marginal and does not
affect the tradeoffs with other attributes. We can therefore verify the following conditions:
CUI({BB , GB , MA}, MS ), CUI({BB , GB }, MA), CUI({ST , EM , CF , DS , GB , BB }, IN ),
and CUI({GB , BB , CF , IN }, ST ). The resulting maximal CUI sets for each attribute are
shown in Table 3.
To construct the network we start with the variable with the largest CUI set, IN , which
needs only MS and MA as parents, after which it is EM that gets CF , MS , and ST as
parents. Next, we consider ST which needs four attributes in its conditional set, but EM is
a descendant, therefore only DS , MS , and MA are needed as parents. The next variable to
choose is MS , which needs only CF and DS as parents since the other dependant variables
are descendants. Had we chosen CF before MS it would have needed four parents: IN , MS ,
ST , and DS (note that although IN is CUI of CF and so is the set {BB , GB , MA}, this
is not the case for the union {BB , GB , MA, IN }). Now that we choose CF after MS it has
MS , ST , and IN as descendants and therefore only DS is a parent. The complete variable
ordering is IN , EM , ST , MS , CF , DS , MA, GB , BB , and the resulting CUI network is
depicted in Figure 2. The maximal dimension is four.
The structure we obtained over the utility function in the above example is based largely
on objective domain knowledge, and may be common to various sourcing departments.
This demonstrates an important aspect of graphical modeling captured by CUI networks:
encoding qualitative information about the domain, thus making the process of extracting
the numeric information easier. This structure in some cases differs among decision makers,
but in other cases (as above) it makes sense to extract such data from domain experts and
reuse this structure across decision makers.

5. Representation and Elicitation
In this section, we derive an expression for local node data in terms of conditional utility functions, and discuss how to elicit utility information from judgments about relative
preference differences.
5.1 Node Data Representation
Representing U by a CUI network requires that we determine the f and g functions for each
CUI condition. At any node y the functions f, g represent the affine transformation of the
conditional utility function U (x0 , Y, Z) (here Z = P a(x)) to strategically equivalent utility
functions for other values of x. Like the transformation functions for UI (Keeney & Raiffa,
97

Engel & Wellman

Figure 2: CUI network for the example. The maximal number of parents is 3, leading to
dimension 4.

1976), the transformation functions for CUI can be represented in terms of the conditional
utility functions U (x, Y 1 , Z) and U (x, Y 2 , Z) for suitable values Y 1 and Y 2 (see below).
We can determine f and g by solving the system of two equations below, both based on
applying (1) for these specific values of Y :
U (x, Y 1 , Z) = f (x, Z) + g(x, Z)U (x0 , Y 1 , Z),
U (x, Y 2 , Z) = f (x, Z) + g(x, Z)U (x0 , Y 2 , Z),
yielding
U (x, Y 2 , Z) âˆ’ U (x, Y 1 , Z)
,
U (x0 , Y 2 , Z) âˆ’ U (x0 , Y 1 , Z)
f (x, Z) = U (x, Y 1 , Z) âˆ’ g(x, Z)U (x0 , Y 1 , Z).
g(x, Z) =

(15)
(16)

The only restriction on the choice of Y 1 , Y 2 is that the decision maker must not be
indifferent between them given x0 and the current assignment to Z. For example, Y 1 , Y 2
may differ on any single attribute y âˆˆ Y that is strictly essential.
5.2 Elicitation of Measurable Value Functions
A utility function that is a used for choosing an action that leads to a known probability
distribution over the outcomes, should be obtained through elicitation of preferences over
lotteries, for example using even-chance gambles and their certainty equivalents (Keeney &
Raiffa, 1976). Based on the preceding discussion, to fully specify U (Â·) via a CUI network,
we need to obtain the numeric values for the conditional utility functions U (x, Y 1 , P a(x))
and U (x, Y 2 , P a(x)) for each node x. This is significantly easier than obtaining the full
n-dimensional function, and in general can be done using methods described in preference
98

CUI networks

elicitation literature (Keeney & Raiffa, 1976). In this section we show how elicitation can
be conducted in cases when the choice is assumed to be done over certain outcomes, but a
cardinal representation is nevertheless useful.
For particular applications we can point out specific attributes that can be used as a
measurement for others. The most common example is preferences that are quasi-linear in
a special attribute such as money or time. These kind of preferences can be represented by
a measurable value function, or MVF (Krantz et al., 1971; Dyer & Sarin, 1979). An MVF
is a cardinal utility function defined under certainty and represents preference differences.
It has been shown (Dyer & Sarin, 1979) that UI has an analogous interpretation for MVF
with similar resulting decomposition. The extension to CUI is straightforward.
For the case of monetary scaling, the preference difference over a pair of outcomes
represents the difference in willingness to pay (wtp) for each. A potential way to elicit the
MVF is by asking the decision maker to provide her wtp to improve from one outcome to
another, particularly when these outcomes differ over a single attribute.
Under this interpretation, we first observe from (15) that g(x, Z) can be elicited in terms
of preference differences, between outcomes that possibly differ over a single attribute. The
result can convey qualitative preference information. Assume Y 2  Y 1 and that âˆ€x.x0  x.
Then g(x, Z) is the ratio of the preference difference between Y 1 and Y 2 given x to the
same difference given x0 (Z is fixed in all outcomes). Hence, if Y and x are complements
then g(x, Z) > 1 and increasing in x. If Y and x are substitutes, g(x, Z) < 1 and decreasing
in x. This holds regardless of the choice for Y 1 , Y 2 , since by CUI(Y, x | Z) all attributes in
Y maintain the same complementarity or substitutivity relationship to x. Note also that
g(x, Z) = 1 iff CAI(Y, x | Z). Another important observation is that though both Y and x
may depend on Z, in practice we do not expect the level of dependency between Y and x to
depend on the particular value of Z. In that case g becomes a single-dimensional function,
independent of Z.
f (x, Z), intuitively speaking, is a measurement of wtp to improve from x0 to x. The
value U (x0 , Y 1 , Z) is multiplied by g(x, Z) to compensate for the interaction between Y
and x, allowing f (Â·) to be independent of Y . If we perform the elicitation obeying the
topological order of the graph, the function U (x0 , Y 1 , Z) can be readily calculated for each
new node from data stored at its predecessors. Choose Y 1 = Y 0 , and let Z = {z1 , . . . , zk },
ordered such that children precede parents. Since Y, x are fixed on the reference point,
k
iâˆ’1
X
Y
U (x , Y , Z) =
(fzi
gzj )fn+1 ().
0

0

i=1

j=1

Now we can obtain f (x, Z) as follows: first we elicit the preference difference function
e(x, Z) = U (x, Y 1 , Z) âˆ’ U (x0 , Y 1 , Z). Then, assuming g(x, Z) was already obtained, calculate:
f (x, Z) = e(x, Z) âˆ’ (g(x, Z) âˆ’ 1)U (x0 , Y 1 , Z).

6. Optimization
One of the primary uses of utility functions is to support optimal choices, as in selecting an
outcome or action. The complexity of the choice depends on the specific properties of the
99

Engel & Wellman

environment. When the choice is among a limited set of definite outcomes, we can recover
the utility of each outcome using the compact representation and choose the one with the
highest value. For instance, in the software example of Section 4 we would normally choose
among an enumerated set of vendors or packages. In this procurement scenario we assume
the utility is an MVF, and we usually choose the outcome that yields the highest utility
net of price. In case of decision under uncertainty, when the choice is among actions that
lead to probability distributions over outcomes, the optimal choice is selected by computing
the expected utility of each action. If each action involves a reasonably bounded number of
outcomes with non-zero probability, this again can be done by exhaustive computation.
Nevertheless, it is often useful to directly identify the maximal utility outcome given a
quantitative representation of utility. In case of a direct choice over a constrained outcome
space, the optimization algorithm serves as a subroutine for systematic optimization procedures, and such can be adapted from the probabilistic reasoning literature (Nilsson, 1998).
The algorithm may also be useful as a heuristic aid for optimization of expected utility or
net utility mentioned above, when the set of possible outcomes is too large for an explicit,
exhaustive choice.
In this section, we develop optimization algorithms for discrete domains, and show how
in many cases CUI networks can provide leverage for optimization of CAI maps. As is
typical for graphical models, our optimization algorithm is particularly efficient when the
graph is restricted to a tree.
6.1 Optimization Over CUI Trees
Definition 9. A CUI tree is a CUI network in which no node has more than one child.
Note that this type of graph corresponds to an upside-down version of a standard directed tree (or a forest).
Let T be a CUI tree. We assume WLOG that T is connected (a forest can be turned
into a tree by adding arcs). As an upside-down sort of tree, it has any number of roots, and
a single leaf. We denote the root nodes by ai âˆˆ {a1 , . . . , ak }, the child of ai by bi , and so
on. For each root node ai , we define the function
hai (bi ) = arg 0 max U (bi , a0i ),
ai âˆˆD(ai )

denoting the selection of an optimal value of ai corresponding to a given value of its child.
From Proposition 5, hai does not depend on the reference values chosen for S \ {ai , bi }. The
function hai (Â·), which we call the optimal value function (OVF) of ai , is stored at node ai
since it is used by its descendants as described below.
Next, each bi has no children or a single child ci , and any number of parents. For simplicity of exposition we present the case that bi has two parents, ai and aj . The maximization
function for bi is defined as
hbi (ci ) = arg 0 max U (ci , b0i , hai (b0i ), haj (b0i )).
bi âˆˆD(bi )

In words, we pick the optimal value of bi for each assignment to its child and its parents.
But since we already know the optimum of the parents for each value of bi , we need only
consider this optimum for each evaluation on the domain of bi .
100

CUI networks

(a)

(b)

Figure 3: CUI networks in optimization examples: (a) Tree (b) Non-tree
The only external child of the set {ai , aj , bi } is ci , and it has no external ancestors,
hence {ai , aj , bi } is CUI of the rest given ci , therefore the maximization above again does
not depend on the reference values of the rest of the attributes. Similarly, when computing
hci (di ) for the child ci of bi , each value for ci fixes bi (and any other parents of ci ), and that
fixes ai and aj (and the other ancestors of ci ). The last computation, at the leaf x, evaluates
each value of x. Each value x0 causes this cascade of fixed values to all of the ancestors,
meaning we finally get the optimal choice by comparing |D(x)| complete assignments.
We illustrate the execution of the algorithm on the CUI tree of Figure 3a. We compute
ha (c) which is the optimal value of a for each value of c, and similarly hb (c). Next, to
compute hc (e), for each value e0 of e we compare all outcomes (e0 , c0 , ha (c0 ), hb (c0 )), c0 âˆˆ D(c).
At node d we compute hd (f ), which is independent of the other nodes. At node e we compute
he (f ) = arg maxe0 U (f, e0 , hc (e0 ), hb (hc (e0 )), ha (hc (e0 )) (node d can be ignored here) and at
node f it is
hf () = arg max U (f 0 , he (f 0 ), hd (f 0 ), hc (he (f 0 )), hb (hc (he (f 0 ))), ha (hc (he (f 0 ))).
f 0 âˆˆD(f )

Note how each candidate value of f causes the cascade of optimal values to all of its
ancestors. The solution is then hf () and the resulting values of all the ancestors.
This optimization algorithm iterates over the nodes in topological order, and for each xi
it calculates the OVF hxi (xj ), where xj is the child of xi . This calculation uses the values
of the OVF stored for its parents, and therefore involves comparison of |D(xi )||D(xj )|
outcomes. In case the numeric data at the nodes is available, factoring in the time it takes
to recover the utility value for each outcome (which is O(n)), the algorithm runs in time
O(n2 maxi |D(xi )|2 ).
6.2 Optimization Over General DAGs
A common way in graphical models to apply tree algorithms to non-trees is by using the
junction graph. However, the common notion of a junction graph for DAG is a polytree,

101

Engel & Wellman

whereas our algorithm above is specialized to a (unit) tree. Instead, we optimize the CUI
network directly by generalizing the tree algorithm.
In the tree case, fixing the value of the child of a node x is sufficient in order to separate
x from the rest of the graph, excluding ancestors. We consider each value of the child at a
time, so it also determines the values for all the ancestors. In a general DAG it is no longer
sufficient for the OVF to depend on the children, because they do not provide sufficient
information to determine the values of An(x). Hence we generalize this notion to be the
scope of x (Sc(x), defined below), which is a set of nodes on which the OVF of x must
depend, in order for an iterative computation of the OVF to be sound.
With this generalization, the DAG algorithm is similar to the tree algorithm. Let G be
a CUI network, and x1 , . . . , xn a variable ordering that agrees with the topological order of
G (parents precede children). For each xi (according to the ordering), compute hxi (Sc(xi ))
for any instantiation of Sc(xi ). The optimal instantiation can now be selected backwards
from hxn (), since for each node xi that is reached the values for Sc(xi ) are already selected.
Sc(xi ) is computed as follows: scan variables xi+1 , . . . , xn in this order. When scanning
xj , add xj to Sc(xi ) if the following conditions hold:
1. There is an undirected path between xj and xi .
2. The path is not blocked by a node already in Sc(xi ).
By these conditions, Sc(xi ) includes all the children of xi , but non of xi â€™s ancestor since
they precede xi in the ordering. In addition, Sc(xi ) includes all nodes that are needed to
block the paths that reach xi through its ancestors. For example, if xk , xj are children of
an ancestor xa of xi , and k < i < j, then xj must be in Sc(xi ), because of the path through
xa . The children of xj are blocked by xj , so unless they have another path to xi they will
not be in Sc(xi ). The children of xk , if ordered later than xi , will be in Sc(xi ) (but their
children will not), and so on.
Figure 3b is an example of a CUI network that is not a tree. We consider the scopes
under the variable ordering a, b, . . . , j. The scope of roots always equals their set of children
(because there is no other path reaching them), meaning Sc(a) = {d, e}, Sc(b) = {d, e, f },
Sc(c) = {e, f, h}, Sc(i) = {j}. The scope of d must include its child g and its siblings e
and f . All paths of h, j, and i to d are blocked by g, e, f therefore Sc(d) = {g, e, f }. For e,
we must include its child g, and its â€œyoungerâ€ sibling f . h has a blocked path to e through
f âˆˆ Sc(e), but also a non-blocked one through c âˆˆ
/ Sc(e), therefore Sc(e) = {g, f, h}.
Similarly, g and h are in the scope of f due to paths through b and c respectively, hence
Sc(f ) = {g, h, j}. For g, in addition to its child h we add j whose path to g through f, b, e
is not blocked (Sc(g) = {h, j}) and finally Sc(h) = Sc(i) = {j} and Sc(j) = {}.
The next step, computing the OVF, requires that we compare a set of outcomes that
differ on xi âˆª Co(xi ), where Co(xi ) is a set of nodes whose OVF can be determined by
xi âˆª Sc(xi ) (hence they are covered by xi ). For this maximization to be valid, the condition
CUI(xi âˆª Co(xi ), S \ (xi âˆª Co(xi ) âˆª Sc(xi ))) must hold. We formally define Co(xi ), and
establish this result which is proved in the appendix.
Definition 10. Co(xi ) is the smallest set of nodes that satisfied the following condition
âˆ€j < i, Sc(xj ) âŠ† ({xi } âˆª Sc(xi ) âˆª Co(xi )) â†’ xj âˆˆ Co(xi ).
102

(17)

CUI networks

Intuitively, xj is covered by xi if each node xk 6= xi in its scope, is either in the scope of xi
or was determined (according to its own scope) to be covered by xi . In Figure 3b, f âˆˆ Co(g)
because Sc(f ) = {g} âˆª Sc(g). e âˆˆ Co(g) because Sc(e) âŠ‚ {g} âˆª Sc(g) âˆª {f }. Moreover,
Sc(d) = {g, e, f } hence d âˆˆ Co(g) as well, and similarly we find that a, b âˆˆ Co(g). In this
example all the nodes preceding g in the ordering are covered, but this is not necessarily
always the case.
Lemma 7. An assignment to xi and Sc(xi ) is sufficient to determine hxj (Â·) for each xj âˆˆ
Co(xi ).
Lemma 8. For any node xi , CUI({xi } âˆª Co(xi ), S \ ({xi } âˆª Co(xi ) âˆª Sc(xi ))). Meaning
that xi and the nodes it covers are CUI of the rest given Sc(xi ).
When the algorithm reaches node xi , every choice of assignment to Sc(xi ) âˆª {xi } determines optimal values for Co(xi ) (Lemma 7). We compare the |D(xi )| assignments which
differ over the values of xi and Co(xi ), and select an optimal one as the value of hxi (Sc(xi )).
This optimum does not depend on the nodes in S \({xi }âˆªCo(xi )âˆªSc(xi ))) due to Lemma 8.
To illustrate, we examine what happens when the algorithm reaches node g in Figure 3b.
At this point hx (Sc(x)) is known for any x that precedes g. As showed, all these nodes
are in Co(g). Indeed, the assignment to Sc(g) = {g, h, j} directly determines the value for
hf (Â·), and then together with hf (Â·) it determines the value for he (Â·), and further it cascades
to the rest of the nodes. The CUI network shows that CUI({a, b, c, d, e, f, g}, {i}) (given
{h, j}) and therefore the maximization operation (over the choice of value for g) is valid
regardless of the value of i.
The performance of the optimization algorithm is exponential in the size of the largest
scope (plus one). Note that this would be seriously affected by the choice of variable ordering. Also note, that in the case of a tree this algorithm specializes to the tree optimization
above, since there is no node that has a path to an ancestor of xi , except for other ancestors of xi which must precede xi in the ordering. Therefore it is always the case that
Sc(xi ) = Ch(xi ), meaning that hxi (Â·) is a function of its single child. Based on that, we
expect the algorithm to perform better the more similar the CUI network is to a tree.
6.3 CUI Tree for Optimization of CAI Maps
The optimization procedure for CUI trees is particularly attractive due to the relatively
low amount of preference information it requires. In some cases the comparison can be
done directly, without even having the data that comprises the utility function. Aside
from the direct benefit to CUI networks, we are interested in applying this structure to the
optimization of CAI maps. In some domains a CAI map is a simple and effective way to
decompose the utility function. However, the optimization of CAI maps is exponential in
the size of its tree width, and it requires the full data in terms of utility functions over its
maximal cliques. If a CAI map happens to have a simple structure, such as a tree, or the
CP condition, faster optimization algorithms can be used. However, it could be the case
that a CAI map is not a tree, but more subtle CUI conditions might exist which cannot be
captured by CAI conditions. If enough such conditions could be detected to turn the CAI
map into a CUI tree (or close enough to a tree), we could take advantage of our simple
optimization procedure.
103

Engel & Wellman

(a)

(b)

(c)

Figure 4: (a) A CAI map containing a cycle. (b) Enhanced CAI map, expressing CUI of
{a, d, f } in b. (c) An equivalent CUI tree.
Definition 11. Let G = (V, E) be a CAI map. An enhanced CAI map is a directed graph
G0 = (V, A), in which a pair of arcs (u, v), (v, u) âˆˆ A implies the same dependency as an
edge (u, v) âˆˆ E, and in addition for any node x, CUI(S \ ({x} âˆª In(x)), x) (In(x) denoting
the set of nodes y for which (y, x) âˆˆ A). We call the pair of arcs (u, v), (v, u) âˆˆ A a hard
link and an arc (u, v) âˆˆ A s.t. (v, u) âˆˆ
/ A a weak link.
For any CAI map, an enhanced CAI map can be generated by replacing each edge (u, v)
with the arcs (u, v) and (v, u). This does not require any additional CUI conditions because
these are entailed by the CAI map. However, if additional CUI conditions as above can be
detected, we might be able to remove one (or both) of the directions. Figure 4a shows a
CAI map which contains a cycle. If we could detect that CUI({a, d, f }, b), we could remove
the direction (a, b) and get the enhanced CAI map in Figure 4b. The set of CUI conditions
implied by the enhanced CAI map can now be expressed by a CUI tree, as in Figure 4c.
Proposition 9. Consider an enhanced CAI map G. Let Ï‰ be an ordering on the nodes of
G, and G0 a DAG which is the result of removing all arcs (u, v) whose direction does not
agree with Ï‰. If for any such removed arc, v is an ancestor of u in G0 , then G0 is a CUI
network.
For hard links, the removal of (u, v) leaves v as a parent of u, so the condition trivially
holds. To obtain a CUI tree, the key is therefore to find a variable ordering under which
enough weak links can be removed to turn the graph into a tree, maintaining the condition of
Proposition 9. For a large number of variables, an exhaustive search over variable orderings
may not be feasible. However in many cases it can be effectively constrained, restricting
the number of orderings that we need to consider. For example, in order to break the cycle
in Figure 4b it is clear that the weak link (b, a) must be implied by the ordering, so that a
could be an ancestor of b. The only way for this to happen (given the existing hard links),
is that c is a parent of b, d is a parent of c, and a a parent of d.
Proposition 10. Let c = (y1 , . . . , yk ) be a cycle in an enhanced CAI map G. Assume that
c contains exactly one weak link: (yi , yi+1 ) for some i < k, or (yk , y1 ). Let Ï‰ be a variable
104

CUI networks

ordering that does not agree with the order of the path p = (yi+1 , yi+2 , . . . , yk , y1 , . . . , yi ).
Then any CUI network constructed from G and Ï‰ (by Proposition 9), is not a tree.
Therefore any cycle that contains one weak link leads to a constraint on the variable
ordering. Cycles with more than one weak link also lead to constraints. If c above has
another weak link (yj , yj+1 ), one of the two links must be removed, and the ordering must
agree with either the path p above or the path p0 = (yj+1 , yj+2 , . . . , yk , y1 , . . . , yj ). Assuming
WLOG that j > i, the paths (yi+1 , . . . , yj ) and (yj+1 , . . . , yi ) are required for both p and
p0 , and therefore can be used as constraints. Similarly we can find the intersection of the
paths implied by any number of weak links in a cycle.
Sometimes the constraint set can lead to an immediate contradiction, and in such case
search is redundant. If it does not, it can significantly reduce the search space. However,
the major bottleneck in preference handling is usually elicitation, rather than computation.
Therefore, given that a good variable ordering may lead to the reduction of the optimization
problem to a simpler, qualitative task, eliminating the need for a full utility elicitation, it
would be worthwhile to invest the required computation time.

7. Nested Representation
From Section 5.1 we conclude that node data can be represented by conditional utility functions depending on the node and its parents. But this may not be the best dimensionality
that can be achieved by a network. Perhaps the set Z = P a(x) has some internal structure,
in the sense that the subgraph induced by Z has maximal dimension lower than |Z|. In such
a case we could recursively apply CUI decomposition to the conditional utility functions for
this subgraph. This approach somewhat resembles the hierarchical decomposition done for
the utility trees (Keeney & Raiffa, 1976; Von Stengel, 1988). For example, to represent f1 for
the network of Figure 1, we require the conditional utility function U (x1 , x14 , x15 , x16 , x2 , x3 ).
However from the network we can see that CUI(x3 , x2 | x1 , x4 , x5 , x6 ). Hence we can decompose this conditional utility:
U (x1 , x14 , x15 , x16 , x2 , x3 ) = f 0 (x1 , x2 ) + g 0 (x1 , x2 )U (x1 , x3 , x02 , x14 , x15 , x16 ).
We use the notation f 0 and g 0 since these are not the same as the f and g functions of the
top level decomposition.
A nested representation can be generated systematically (Algorithm 1), by decomposing
each local function at node x (xâ€™s utility factors) whose argument set Z âŠ† P a(x) does not
form a clique. We do that by performing a complete CUI decomposition over the subgraph
induced by Z (keeping in mind that all the resulting factors depend also on x).
Proposition 11. Let G be a CUI network for utility function U (S). Then U (S) can be
represented by a set of conditional utility functions, each depending on a set of attributes
corresponding to (undirected) cliques in G.
7.1 Discussion
This result reduces the maximal dimensionality of the representation to the size of the
largest maximal clique of the CUI network. For instance, applying it to the example in
105

Engel & Wellman

Data: CUI Utility factors U (x, P a(x), YÌ‚ ), U (x, P a(x), YÌƒ ) at each node x
/* note: YÌ‚ , YÌƒ âˆˆ D(Y ) */
Determine order x1 , . . . , xn ;
for j = 1, . . . , n do /* initialization */
Kj1 = {xj } âˆª P a(xj ) /* scope of utility factors */ ;
Yj1 = S \ Kj1 /* rest of variables */ ;
Q1j = P a(xj );
A1j = âˆ…, dj = 1;
end
for j = 1, . . . , n do
for i = 1, . . . , dj do /* loop on factors in node j*/
if Qij 6= âˆ… and Kji is not a clique then
Let Gij be the subgraph induced by Qij ;
Decompose Uji (Kji ) according the CUI network on Gij ;
foreach xr âˆˆ Qij do
Let dr = dr + 1 (current num. of factors at xr ) and denote d = dr ;
Adr = Aij âˆª {xj }, Qdr = P a(xr ) âˆ© Qij ;
Krd = Adr âˆª {xr } âˆª Qdr , Yrd = S \ Krd ;
Store new CUI factors of xr : U (Krd , YÌ‚rd ), U (Krd , YÌƒrd );
/*YÌ‚rd , YÌƒrd are fixed assignments to Yrd */
end
Remove factors U (Kji , YÌ‚ji ), (Kji , YÌƒji );
end
end
end
Algorithm 1: Recursive CUI decomposition. Process node in reverse topological
order (outermost loop). Decompose each factor stored at current node, whose parents
do not form a clique. At each such parent xr (innermost loop) store resulting new
factors. These are defined over xr , those of xr â€™s parents that are also in P a(xi ) (this
is Qdr ), and a clique Adr on which the original factor depends. Each time a factor is
decomposed its set Q shrinks. When it is empty, K is a clique.

106

CUI networks

Section 4 reduces dimensionality from four to three. An important implication is that we
can somewhat relax the requirement to find very large CUI sets. If some variables end up
with many parents, we can reduce dimensionality using this technique. As the example
below illustrates, this technique aggregates lower order CUI conditions to a more effective
decomposition.
The procedure may generate a complex functional form, decomposing a function multiple
times before the factors become restricted to a clique. The ultimate number of factors
required to represent U (S) is exponential in the number of such nesting levels. However,
each decomposition is based on a CUI network on a subgraph, and therefore typically
reduces the number of entries that are maintained.
We expect the typical application of this technique to be for composition rather than
decomposition. We execute Algorithm 1 without the actual data, resulting in a list of factors
per node (that are conditional utility functions over cliques of the graph). That means
that for elicitation purposes we can restrict attention to conditional utility functions over
maximal cliques. Once these are obtained, we have sufficient data for all the factors. We can
then recover the original, more convenient CUI-network representation of the function and
store it as such (more on that in the example below). Therefore, the effective dimensionality
for elicitation is that of the maximal cliques. The storage for efficient usage requires the
potentially higher dimension of the original CUI network, but typically this is less of a
concern.
With this result and Proposition 6, CUI networks are shown to always achieve weakly
better dimensionality than CAI maps, since both representations reduce the dimensionality
to the size of the maximal clique.
7.2 Example
We illustrate this result using a simple example. Consider a domain with four attributes
(a, b, c, d), and the following CUI conditions:
CUI(b, c), CUI(c, b), CUI(d, a)
The CUI network corresponding to the variable ordering a, b, c, d is depicted in Figure 5.
Since the CUI sets are small (a single variable each), for any variable ordering there must
be a node with two parents, meaning dimensionality of three. The nesting operation below
combines these lower order conditions to reduce the dimensionality to two.
Initially, the utility function is represented using the conditional utility functions listed
according to their corresponding nodes in the column â€œLevel 0â€ in Table 4. To remove the
three-dimensional factors, we need to decompose the functions of node a according to the
CUI network on {b, c}, which contains no arcs. This proceeds as follows:
U (a, b, c, d1 ) =
fb1 (a, c) + gb1 (a, c)U (a, b, c0 , d1 ) = fb1 (a, c) + gb1 (a, c)(fc1 (a, b) + gc1 (a, b)U (a, b0 , c1 , d1 ))
U (a, b, c, d2 ) =
fb2 (a, c) + gb2 (a, c)U (abc0 d2 ) = fb2 (a, c) + gb2 (a, c)(fc2 (a, b) + gc2 (a, b)U (a, b0 , c0 , d2 ))
107

Engel & Wellman

Figure 5: Nesting example

The resulting functions are fbi (a, c), gbi (a, c), fci (a, b), gci (a, b), i = 1, 2. The functions
and gbi (a, c) can be represented using the conditional utility functions U (a, b1 , c, di )
and U (a, b2 , c, di ), and similarly the other two functions. We can delete the factors of a,
U (a, b, c, di ), and add the new lower dimensional factors as a second column to aâ€™s parents
b and c. Though we had to multiply the number of factors we store by four, all the new
factors are conditional utility functions over subdomains of the (deleted) higher dimensional
factors. The algorithm continues to node b, and loops over its six factors. If there are factors
that are defined over a set of parents of b that are not a clique it decomposes them and store
the new factors in the next table column. In case a factor from column â€œlevel 1â€ could be
decomposed, we would add a â€œlevel 2â€ column to store the result. In our simple example
no further decomposition is possible.
fbi (a, c)

Attr
a
b
c
d

Level 0 (CUI net)
U (a, b, c, d1 ), U (a, b, c, d1 )
U (a0 , b, c1 , d),
U (a0 , b, c2 , d)
U (a0 , b1 , c, d),
U (a0 , b2 , c, d)
U (a0 , b0 , c0 , d)

Level 1
U (a, b, c1 , d1 ),
U (a, b, c1 , d2 ),
U (a, b1 , c, d1 ),
U (a, b1 , c, d2 ),

U (a, b, c2 , d1 )
U (a, b, c2 , d2 )
U (a, b2 , c, d1 )
U (a, b2 , c, d2 )

Table 4: Nested CUI decomposition
The reverse direction mentioned above is done as follows: we run Algorithm 1 without
any data, resulting in a table such as Table 4 (without the actual utility values). We then
elicit the data for the non deleted factors (all are limited to maximal cliques). Next, we
recover the more convenient â€œlevel 0â€ CUI representation using the table, by computing
each deleted factor (going from rightmost columns to the left) as a function of the factors
stored at its parents.

8. Conclusions
We present a graphical representation for multiattribute utility functions, based on conditional utility independence. CUI networks provide a potentially compact representation of
the multiattribute utility function, via functional decomposition to lower-dimensional functions that depend on a node and its parents. CUI is a weaker independence condition than
108

CUI networks

those previously employed as a basis for graphical utility representations, allowing common
patterns of complementarity and substitutivity relations disallowed by additive models.
We proposed techniques to obtain and verify structural information, and use it to construct the network and elicit the numeric data. In addition, we developed an optimization
algorithm that performs particularly well for the special case of CUI trees. In some cases it
can also be leveraged for efficient optimization of CAI maps. Finally, we show how functions
can be further decomposed over the set of maximal cliques of the CUI network. With this
technique, CUI networks can achieve the same dimensionality of graphical models based on
CAI and GAI decompositions, yet with more broadly applicable independence conditions.

Acknowledgments
A preliminary version of this paper was published in the proceedings of AAAI-06. The
work was supported in part by NSF grant IIS-0205435, and the STIET program under NSF
IGERT grant 0114368. We are grateful to the thorough work of the anonymous reviewers,
whose suggestions provided valued help in finalizing this paper.

Appendix A. Proofs
A.1 Lemma 3
Proof. Let Z = S \ (X âˆª Y ) and C = S \ (A âˆª B). We simply apply the two independence
conditions consequentially, and we can define fË†, gÌ‚ such that:
U (S) = U (XY Z) = f (Y Z) + g(Y Z)UY (S \ Y ) = f (Y Z) + g(Y Z)(f 0 ((BC) \ Y )
+ g 0 ((BC) \ Y )UY B (S \ (Y B))) = fË†(ZBY C) + gÌ‚(ZBY C)U (S \ (Y B)).
Since Z âˆªY âˆªB âˆªC = S \(Aâˆ©X), the last decomposition is equivalent to the decomposition
(1) for the condition CUI(A âˆ© X , Y âˆª B).
A.2 Proposition 6
Proof. A CAI condition is stronger than a CUI condition, in that CAI(x, y) â‡’ CUI(x, y) âˆ§
CUI(y, x). To be a CUI network, for each node xi it must be the case that all other nodes
are CUI of it given its parents and descendants. This is obvious since xi is CAI of all other
nodes given its parents and children.
A.3 Lemma 7
Proof. To determine hxj (Â·), any y âˆˆ Sc(xj ) needs to be determined. If y âˆˆ {xi } âˆª Sc(xi )
we are done, if not its own scope is covered and therefore recursively determined by the
assignment to {xi } âˆª Sc(xi ).
A.4 Lemma 8
We first introduce two additional lemmas.
Lemma 12. Ch({xi } âˆª Co(xi )) âŠ† ({xi } âˆª Sc(xi ) âˆª Co(xi ))
109

Engel & Wellman

Proof. Let xj âˆˆ {xi } âˆª Co(xi ), and y âˆˆ Ch(xj ). If xj = xi the proof is immediate because
Ch(xi ) âŠ† Sc(xi ). Assume xj âˆˆ Co(xi ). We know from Definition 10 that Ch(xj ) âŠ†
Sc(xj ) âŠ† ({xi } âˆª Sc(xi ) âˆª Co(xi )), and this proves the lemma.
Lemma 13. An({xi } âˆª Co(xi )) âŠ† Co(xi )
Proof. Let xj âˆˆ An(xi ) (clearly j < i, therefore xj âˆˆ
/ Sc(xi )). Let xj1 âˆˆ Sc(xj ). Then
j1 > j and there is an undirected path from xj1 to xj , not blocked by Sc(xj ). If j1 â‰¥ i, then
xj1 âˆˆ Sc(xi )âˆª{xi } because it has an unblocked path to xj (and from there to xi ). Otherwise,
let xj2 âˆˆ Sc(xj1 ), and apply the same argument to xj2 . We continue until xjk such that
âˆ€xy âˆˆ Sc(xjk ), y > i at which point xy âˆˆ Sc(xi ) âˆª {xi } by the path xy , xjk , . . . , xj1 , xj , xi
and the recursion halts (note that it includes empty scopes), proving that xj âˆˆ Co(xi ).
It is left to prove that An(Co(xi )) âŠ† Co(xi ). Let xj âˆˆ Co(xi ), y âˆˆ An(xj ). Applying
the first part of the proof on xj , we get that y âˆˆ Co(xj ). From Definition of Co(xj ), we get
y < j and âˆ€w âˆˆ Sc(y), either w = xj , w âˆˆ Sc(xj ) or w âˆˆ Co(xj ). To show that y âˆˆ Co(xi ),
we need to prove for each of the cases that w âˆˆ {xi } âˆª Sc(xi ) âˆª Co(xi ).
1. If w = xj immediately w âˆˆ Co(xi ).
2. If w âˆˆ Sc(xj ), from xj âˆˆ Co(xi ) we get that either w = xi , w âˆˆ Sc(xi ) or w âˆˆ Co(xi ).
3. If w âˆˆ Co(xj ), we repeat the argument recursively âˆ€z âˆˆ Sc(w). Note that z precedes
w therefore the recursion will halt at some point.

Lemma 8. Let X = {xi } âˆª Co(xi ). From Lemma 13, X has no external ancestors. From
Lemma 12, all external children of X are in Sc(xi ). Therefore S \ (X âˆª An(X) âˆª Ch(X)) =
S \ (X âˆª Sc(xi )) and the result is immediate from Proposition 5.
A.5 Proposition 9
Proof. Let x be a node in G0 . Let Y = S \ (x âˆª In(x)) in G and YÌ‚ = S \ (x âˆª P a(x) âˆª Dn(x))
in G0 . By definition of G, we know that CAI(Y, x), so also CUI(Y, x). Let y âˆˆ
/ Y, y 6= x (so
0
y âˆˆ In(x) in G). If y âˆˆ YÌ‚ , then y âˆˆ
/ P a(x) = In(x) in G . Then the arc (y, x) was removed,
meaning that y âˆˆ Dn(x). It therefore must be the case that y âˆˆ
/ YÌ‚ . Therefore YÌ‚ âŠ† Y hence
CUI(YÌ‚ , x).
A.6 Proposition 10
Proof. For G to become a CUI tree, for each cycle at least one weak link must be removed.
Since (yi , yi+1 ) is the only weak link for c, it must be removed. By Proposition 9, the
variable ordering must ensure that yi+1 is an ancestor of yi . This can be done through the
path according to the order of p, or there might be another path from yi+1 to yi . Let p1
be such path. Then the combination of p1 and p is another cycle c1 , which therefore must
be broken. Since p comprises of strong links, there must be at least one weak link (u, v) in
p1 . For (u, v) to be removed, v must be an ancestor of u. This can be done through the
path in the cycle c1 , and this path includes p, or through another path if such exists, for
which we can repeat the argument. At each stage we get a larger cycle ci , and a larger path
110

CUI networks

pi âŠƒ piâˆ’1 . Therefore at some point there will be just one path pi that must be guaranteed
by the variable ordering, and this path includes p.
A.7 Proposition 11
Proof. We show that Algorithm 1 leads to a functional decomposition over cliques. The
outer loop in the algorithm maintains the following iteration properties:
1. âˆ€a âˆˆ Aij , Qij âŠ† P a(a)
2. Uij is defined over Kji
3. Aij âˆª xj is a clique
These properties hold trivially after initialization. Assume they are valid for all factors
stored in the network until outer iteration j and inner iteration i, we next show that they
remain valid for each factor Urd that is created in iteration j, i:
1. By definition Adr = Aij âˆª xj . From previous iteration and definition of Qdr , âˆ€a âˆˆ
Aij , Qdr âŠ† Qij âŠ† P a(a). From definitions of Qij and Qdr we get P a(xj ) âŠ‡ Qij âŠ‡ Qdr , and
together it yields the result.
2. Urd is a factor in the CUI decomposition of Uji (Kji ) over Gij . Its scope contains: (i)
the nodes that are not affected by the last CUI decomposition, i.e. in Kji \ Qij =
Aij âˆª xj = Adr , (ii) its node xr , and (iii) the parents P a(xr ) which were not fixed
in Uji (i.e. P a(xr âˆ© Kji )). We know Kji = Aij âˆª xj âˆª Qij , and xj âˆˆ
/ P a(xr ) (because
i
xr âˆˆ P a(xj )), and also P a(xr ) âˆ© Aj = âˆ… (using a similar argument and property 1).
Therefore (P a(xr ) âˆ© Kji ) âŠ‚ Qij , and from (i),(ii),(iii) we get that Krd = Adr âˆª xr âˆª Qdr .
3. Adr is a clique by its definition and the same property of previous iteration. xr âˆˆ Qij ,
therefore from property 1 of previous iteration xr âˆˆ P a(a) for each a âˆˆ Aij . Also xr âˆˆ
Qij âŠ† P a(xj ) (the last containment is immediate from definition of Qij ). Therefore xr
is a parent of all members of Adr , and as a result Adr âˆª xr is a clique.
By the iteration properties, either Krd is a clique, or Qdr is non empty and decomposition
can be applied once we reach node r in the outer loop. At the end of the process all factors
which are not defined on cliques where removed. All the factors that remained are defined
on cliques. U (S) can be still represented by the new set of factors since we only applied
valid decompositions to its factors.

References
Abbas, A. (2005). Attribute dominance utility. Decision Analysis, 2, 185â€“206.
Bacchus, F., & Grove, A. (1995). Graphical models for preference and utility. In Eleventh
Conference on Uncertainty in Artificial Intelligence, pp. 3â€“10, Montreal.
Boutilier, C., Bacchus, F., & Brafman, R. I. (2001). UCP-networks: A directed graphical
representation of conditional utilities. In Seventeenth Conference on Uncertainty in
Artificial Intelligence, pp. 56â€“64, Seattle.
111

Engel & Wellman

Boutilier, C., Brafman, R. I., Hoos, H. H., & Poole, D. (1999). Reasoning with conditional ceteris paribus preference statements. In Fifteenth Conference on Uncertainty
in Artificial Intelligence, pp. 71â€“80, Stockholm.
Debreu, G. (1959). Topological methods in cardinal utility theory. In Arrow, K., Karlin, S.,
& Suppes, P. (Eds.), Mathematical Methods in the Social Sciences. Stanford University
Press.
Dyer, J. S., & Sarin, R. K. (1979). Measurable multiattribute value functions. Operations
Research, 27, 810â€“822.
Fishburn, P. C. (1965). Independence in utility theory with whole product sets. Operations
Research, 13, 28â€“45.
Fishburn, P. C. (1967). Interdependence and additivity in multivariate, unidimensional
expected utility theory. International Economic Review, 8, 335â€“342.
Fishburn, P. C. (1975). Nondecomposable conjoint measurement for bisymmetric structures.
Journal of Mathematical Psychology, 12, 75â€“89.
Fuhrken, G., & Richter, M. K. (1991). Polynomial utility. Economic Theory, 1 (3), 231â€“249.
Gonzales, C., & Perny, P. (2004). GAI networks for utility elicitation. In Ninth International
Conference on Principles of Knowledge Representation and Reasoning, pp. 224â€“234,
Whistler, BC, Canada.
Gorman, W. M. (1968). The structure of utility functions. Review of Economic Studies,
35, 367â€“390.
Keeney, R. L., & Raiffa, H. (1976). Decisions with Multiple Objectives: Preferences and
Value Tradeoffs. Wiley.
Krantz, D. H., Luce, R. D., Suppes, P., & Tversky, A. (1971). Foundations of Measurement,
Vol. 1. Academic Press, New York.
La Mura, P., & Shoham, Y. (1999). Expected utility networks. In Fifteenth Conference on
Uncertainty in Artificial Intelligence, pp. 366â€“373, Stockholm.
Nilsson, D. (1998). An efficient algorithm for finding the M most probable configurations
in probabilistic expert systems. Statistics and Computing, 8 (2), 159â€“173.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann.
Pearl, J., & Paz, A. (1989). Graphoids: A graph based logic for reasoning about relevance
relations. In Du Boulay, B. (Ed.), Advances in Artificial Intelligence II. North-Holland,
New York.
Tatman, J. A., & Shachter, R. D. (1990). Dynamic programming and influence diagrams..
20, 365â€“379.
Von Stengel, B. (1988). Decomposition of multiattribute expected utility functions. Annals
of Operations Research, 16, 161â€“184.
Wellman, M. P., & Doyle, J. (1992). Modular utility representation for decision-theoretic
planning. In First International Conference on Artificial Intelligence Planning Systems, pp. 236â€“242, College Park, MD.

112

Journal of Artificial Intelligence Research 31 (2008) 205â€“216

Submitted 10/07; published 01/08

Sound and Complete Inference Rules for SE-Consequence
Ka-Shu Wong

KSWONG @ CSE . UNSW. EDU . AU

University of New South Wales and National ICT Australia
Sydney, NSW 2052, Australia

Abstract
The notion of strong equivalence on logic programs with answer set semantics gives rise to a consequence relation on logic program rules, called SE-consequence. We present a sound and complete
set of inference rules for SE-consequence on disjunctive logic programs.

1. Introduction
In recent years there has been much research on various notions of equivalence between two logic
programs. In particular, the notion of strong equivalence of logic programs with answer set semantics (Lifschitz, Pearce, & Valverde, 2001; Turner, 2001, 2003; Cabalar, 2002; Lin, 2002) has
received much attention. We say that two logic programs P and Q are strongly equivalent iff for
any set of rules R, P âˆª R and Q âˆª R have the same answer sets.
Recent work in this area (Eiter, Fink, Tompits, & Woltran, 2004; Turner, 2003; Osorio, Navarro,
& Arrazola, 2001) has focused on the simplification of logic programs under strong equivalence.
This has resulted in a number of logic program transformation rules which preserve strong equivalence. In these transformations, logic program rules are identified which can be removed while
maintaining strong equivalence with the original program.
In this paper we look at a different but related aspect of strong equivalence. The notion of
strong equivalence on logic programs gives rise to a consequence relation |=s on logic program
rules, called SE-consequence (Eiter et al., 2004), which can be defined by saying that a rule r is
a consequence of a logic program P iff P and P âˆª r are strongly equivalent1 . This consequence
relation is useful in testing for strong equivalence, as well as in identifying redundant rules for logic
program simplification.
In this paper, we present a set of inference rules on logic program rules and show that they
are sound and complete for SE-consequence. Our set of inference rules consists of adaptations of
several well-known logic program simplification rules, together with a new rule which we call SHYP. The main contribution of this paper is the new inference rule S-HYP and a completeness result.
The completeness proof makes use of the construction used in the reduction of strong equivalence
testing to classical logic by Lin (2002), and applies to it a restricted form of resolution called lock
resolution by Boyer (1971).

1. Eiter et al. (2004) uses a different definition of SE-consequence based on Turnerâ€™s SE-models (Turner, 2001, 2003).
The equivalence of the two definitions is proved in Section 3.
c
2008
AI Access Foundation. All rights reserved.

W ONG

2. Definitions
We deal with propositional disjunctive logic programs with negation-as-failure, where each rule is
of the form
a1 ; a2 ; Â· Â· Â· ; ak â† b1 , b2 , Â· Â· Â· , bm , not c1 , not c2 , Â· Â· Â· , not cn .
where a1 , Â· Â· Â· , ak , b1 , Â· Â· Â· , bm and c1 , Â· Â· Â· , cn are from a set A of atoms, We assume that the set
of atoms A is fixed. Given a rule r in this form, we denote H(r) = {a1 , Â· Â· Â· , ak } (head of r),
B + (r) = {b1 , Â· Â· Â· , bm } (positive part of r), and B âˆ’ (r) = {c1 , Â· Â· Â· , cn } (negative part of r).
We ignore the order of atoms within a rule; therefore, a rule can be considered as a triple of atom
sets. As an abbreviation, when we include atom sets in a rule, it means that the atoms in the set are
in the corresponding part of the rule. In particular, if X = {x1 , Â· Â· Â· , xk }, then not X in the body
of a rule is an abbreviation for not x1 , Â· Â· Â· , not xk . Applied to the rule r from above, if A = H(r),
B = B + (r) and C = B âˆ’ (r), then the rule can be abbreviated as
A â† B, not C.
For a set X of atoms and a logic program P , we use the notation X |= P to mean that X is a model
of P in the classical sense: For each r âˆˆ P , if B + (r) âŠ† X and B âˆ’ (r) âˆ© X = âˆ…, then H(r) âˆ© X is
non-empty. We say that X is a minimal model of P if X is minimal by set inclusion among all the
models of P , i.e. X |= P and there is no X 0 such that X 0 âŠ‚ X and X 0 |= P .
The Gelfond-Lifschitz reduct (1988) P X of a program P with respect to a set of atoms X is
defined by P X = {H(r) â† B + (r) | r âˆˆ P and X âˆ© B âˆ’ (r) = âˆ…}. We say that X is an answer set
of P if X is a minimal model of P X .

3. Strong Equivalence
The notion of strong equivalence (Lifschitz et al., 2001) describes the property that two programs
remain equivalent regardless of what additional rules are added, and is defined as follows:
Definition 1. Logic programs P and Q are strongly equivalent, iff for all sets R of rules, the
programs P âˆª R and Q âˆª R have the same answer sets.
Lifschitz et al. (2001) showed that strong equivalence can be reduced to equivalence in the logic
of here-and-there. Based on this result, Turner (2003) gave the following definition of SE-models,
which characterises strong equivalence in the sense that two programs are strongly equivalent iff
they have the same SE-models:
Definition 2. Let P be a logic program, and let X, Y âŠ† A be sets of atoms. We say the pair (X, Y )
is a SE-model of P , written (X, Y ) |= P , if X âŠ† Y , Y |= P and X |= P Y . For a set M of
SE-models, we write M |= P to mean (X, Y ) |= P for all (X, Y ) âˆˆ M . Let Ms (P ) denote the set
of all SE-models of P .
SE-models have the property that a pair (X, Y ) is a SE-model of P iff it is a SE-model of every rule
r âˆˆ P . This implies Ms (P âˆª Q) = Ms (P ) âˆ© Ms (Q).
The notion of strong equivalence gives rise to a consequence relation on logic program rules,
called SE-consequence and denoted by |=s . SE-consequence is defined by:
206

S OUND AND C OMPLETE I NFERENCE RULES FOR SE-C ONSEQUENCE

Definition 3. Let P, Q be logic programs, and r be a logic program rule. We say P |=s r iff
Ms (P ) |= r, i.e. every (X, Y ) âˆˆ Ms (P ) is a SE-model of r. Furthermore, we write P |=s Q iff
P |=s r for every r âˆˆ Q.
There is an equivalent definition of SE-consequence which does not make use of SE-models:
Proposition 1. Let P be a logic program and r be a logic program rule. Then P |=s r iff P and
P âˆª {r} are strongly equivalent.
Proof. P and P âˆª {r} are strongly equivalent iff Ms (P ) = Ms (P âˆª {r}) (= Ms (P ) âˆ© Ms (r)). This
holds iff Ms (P ) âŠ† Ms (r), i.e. every (X, Y ) âˆˆ Ms (P ) is a SE-model of r.
The relation |=s has the properties of a consequence relation:
Proposition 2. Let P, Q be logic programs, and r be a logic program rule.
â€¢ If r âˆˆ P , then P |=s r
â€¢ If P âŠ† Q and P |=s r then Q |=s r
â€¢ If P |=s r and Q |=s P then Q |=s r
The proofs follow easily from the fact that P |=s Q iff Ms (P ) âŠ† Ms (Q).
There exist binary resolution-style calculi for the logic of here-and-there (also known as GoÌˆdelâ€™s
3-valued logic). However, Example 1 suggests that this cannot be applied to SE-consequence, seemingly because it takes one outside the logic fragment corresponding to disjunctive logic programs.
This is supported by the fact that the construction in Section 6.1 may produce clauses which do not
correspond to logic program rules. This is currently being investigated.

4. Inference Rules for Strong Equivalence
The consequence relation `s is defined by the following rules of inference:
(TAUT)

x â† x.

(NONMIN)

(WGPPE)

(CONTRA)

â† x, not x.

A â† B, not C.
A; X â† B, Y, not C, not Z.

A1 â† B1 , x, not C1 .
A2 ; x â† B2 , not C2 .
A1 ; A2 â† B1 , B2 , not C1 , not C2 .
A1 â† B1 , not x1 , not C1 .
..
.

An â† Bn , not xn , not Cn .
A â† x1 , Â· Â· Â· , xn , not C.
(S-HYP)
A1 ; Â· Â· Â· ; An â† B1 , Â· Â· Â· , Bn , not C1 , Â· Â· Â· , not Cn , not A, not C.
207

W ONG

Many of these rules are well-known: tautological rules (TAUT), contradiction (CONTRA), nonminimal rules (NONMIN), and weak partial evaluation (WGPPE) (also called partial deduction,
Sakama & Seki, 1997). These have been shown to be strong equivalence preserving (Brass & Dix,
1999; Osorio et al., 2001; Eiter et al., 2004). The new rule S-HYP can be thought of as a form of
hyper-resolution. To our knowledge it has not been considered before in the literature.
Instead of S-HYP, one might expect a more general rule S-HYP+ which allows additional positive atoms B in the final rule:
A1 â† B1 , not x1 , not C1 .
..
.
An â† Bn , not xn , not Cn .
A â† x1 , Â· Â· Â· , xn , B, not C.
(S-HYP+)
A1 ; Â· Â· Â· ; An â† B, B1 , Â· Â· Â· , Bn , not C1 , Â· Â· Â· , not Cn , not A, not C.
However, it can be shown that replacing S-HYP with S-HYP+ does not change the consequence
relation:
Proposition 3. Let ` be a consequence relation satisfying CONTRA. Then S-HYP and S-HYP+ are
interchangeable.
Proof. Since S-HYP+ is a more general form of S-HYP, it suffices to show that S-HYP+ can be
simulated using S-HYP and CONTRA. Suppose we have
A1 â† B1 , not x1 , not C1 .
..
.
An â† Bn , not xn , not Cn .
A â† x1 , Â· Â· Â· , xn , b1 , Â· Â· Â· , bk , not C.
For each bi , CONTRA gives us â† bi , not bi . By using S-HYP on these rules, plus the above, we
get
A1 ; Â· Â· Â· ; An â† B1 , Â· Â· Â· , Bn , b1 , Â· Â· Â· , bk , not C1 , Â· Â· Â· , not Cn , not A, not C.
This is the result of applying S-HYP+ to our initial set of rules.
Example 1. We now consider the possibility of using only binary inference rules on the logic program P :
r1 : a â† not x.
r2 : a â† not y.
r3 :
â† x, y.
The following rule is an SE-consequence of P , and can be derived using S-HYP on r1 , r2 and r3 :
s:

aâ†.

Now suppose we restrict ourselves to binary inference rules by replacing S-HYP with the binary
variant of S-HYP+. Applying S-HYP+ to r1 and r3 gives:
r4 :

a â† y.
208

S OUND AND C OMPLETE I NFERENCE RULES FOR SE-C ONSEQUENCE

and then using S-HYP+ on r2 and r4 gives:
t:

a â† not a.

We observe that t is weaker than s. This suggests that it may not be possible to derive s using only
binary inference rules. However, it is still an open question as to whether n-ary rules are indeed
required.
Observe that the rule CONTRA can be replaced by s-implication (S-IMP) (Wang & Zhou, 2005):
Proposition 4. Let ` be a consequence relation satisfying TAUT and WGPPE. Then CONTRA can
be replaced by the following inference rule:
(S-IMP)

A; X â† B, not C.
A â† B, not C, not X.

Proof. (S-IMP â‡’ CONTRA) The rule â† x, not x. can be formed by applying TAUT followed by
S-IMP.
(CONTRA â‡’ S-IMP) Suppose we have the rule
A; x â† B, not C.
By applying CONTRA to get â† x, not x. followed by WGPPE on these two rules, we get
A â† B, not C, not x.
By repeating these steps we can derive new rules by moving any set of atoms from the head to the
negative part of the rule.
We note that S-IMP is a special case of the solution of the 1-1-0 problem of Lin and Chen (2007).
In addition, WGPPE as well as the binary variant of S-HYP+ are contained in the solution to Lin
and Chenâ€™s 2-1-0 problem.
It can be shown that the inference rules presented above are sound and complete for SEconsequence:
Theorem 1. P |=s r iff P `s r.
Proof (Soundness). Here we prove soundness only for the inference rule S-HYP, as the soundness
of the other rules are already known.
The proof proceeds by contradiction. Assume the rule is not sound. Then there is a program P
A1 â† B1 , not x1 , not C1 .
..
.
An â† Bn , not xn , not Cn .
A â† x1 , Â· Â· Â· , xn , not C.
and a rule r
A1 ; Â· Â· Â· ; An â† B1 , Â· Â· Â· , Bn , not C1 , Â· Â· Â· , not Cn , not A, not C.
209

W ONG

for which P `s r but P 6|=s r. This means Ms (P ) 6âŠ† Ms (r), so P has a SE-model (X, Y ) which is
not a SE-model of r.
(X, Y ) not being a SE-model of r means either Y 6|= r or X 6|= rY . We can exclude the first
case since it is clear that r is a classical consequence of P . Therefore assume X 6|= rY . For each
1 â‰¤ i â‰¤ n we have Ai âˆ©X = âˆ…, Bi âŠ† X, and Ci âˆ©Y = âˆ…. Furthermore we have Aâˆ©Y = Câˆ©Y = âˆ….
But (X, Y ) is a SE-model of P , hence X |= P Y . For each 1 â‰¤ i â‰¤ n, we have the following
rule in P :
Ai â† Bi , not xi , not Ci .
Since Ai âˆ© X = âˆ…, the body must not hold, or the rule must be eliminated in the reduct. But we
know Bi âŠ† X and Ci âˆ© Y = âˆ…. Therefore we must have xi âˆˆ Y so that the rule is eliminated in the
reduct.
We have A âˆ© Y = C âˆ© Y = âˆ… and x1 , Â· Â· Â· , xn âˆˆ Y , so Y is not a classical model of
A â† x1 , Â· Â· Â· , xn , not C.
and hence Y 6|= P , which contradicts (X, Y ) being a SE-model of P .

5. Some Background for the Completeness Proof
In this section we introduce two results which will be used in the completeness proof.
5.1 Linâ€™s Construction
Lin (2002) presented a method of reducing strong equivalence to equivalence in classical logic.
Given a logic program, this construction produces a set of clauses such that two logic programs are
strongly equivalent iff the two sets of clauses are equivalent in classical logic.
Let {x1 , Â· Â· Â· , xn } be the set of atoms. In the construction, each atom xi is represented by two
propositional letters xi and x0i . The logic program P consists of a set of rules of the following form:
a1 ; a2 ; Â· Â· Â· ; ak â† b1 , b2 , Â· Â· Â· , bm , not c1 , not c2 , Â· Â· Â· , not cn .
For each such rule r, we construct two clauses Î³(r) and Î³ 0 (r):
Î³(r) := a1 âˆ¨ Â· Â· Â· âˆ¨ ak âˆ¨ Â¬b1 âˆ¨ Â· Â· Â· âˆ¨ Â¬bm âˆ¨ c01 âˆ¨ Â· Â· Â· âˆ¨ c0n
Î³ 0 (r) := a01 âˆ¨ Â· Â· Â· âˆ¨ a0k âˆ¨ Â¬b01 âˆ¨ Â· Â· Â· âˆ¨ Â¬b0m âˆ¨ c01 âˆ¨ Â· Â· Â· âˆ¨ c0n
Let Î“(P ) := {Î³(r) | r âˆˆ P } and Î“0 (P ) := {Î³ 0 (r) | r âˆˆ P }. Furthermore for each atom xi we add
the clause Â¬xi âˆ¨ x0i . Let âˆ† denote the set of all such clauses. Linâ€™s result showed that P and Q are
strongly equivalent iff
^
^
(Î“(P ) âˆª Î“0 (P ) âˆª âˆ†) â‰¡ (Î“(Q) âˆª Î“0 (Q) âˆª âˆ†)
An immediate corollary of this result is:
Proposition 5. P |=s r iff
^

(Î“(P ) âˆª Î“0 (P ) âˆª âˆ†) |= Î³(r) âˆ§ Î³ 0 (r)

Observe that given a clause Î±, we can find a corresponding rule r such that Î³(r) = Î± if and only if
there are no literals of the form Â¬x0 in Î±.
210

S OUND AND C OMPLETE I NFERENCE RULES FOR SE-C ONSEQUENCE

5.2 Boyerâ€™s Lock Resolution
Resolution is the following inference rule: given two clauses x âˆ¨ C1 and Â¬x âˆ¨ C2 , derive the clause
C1 âˆ¨ C2 . We say that x and Â¬x are the literals resolved on, and the clause C1 âˆ¨ C2 is the resolvent. It
is well-known that resolution is refutation-complete, that is, if a set of clauses is unsatisfiable, then
the empty clause can be derived using resolution.
Definition 4. A deduction of the clause C from a set S of clauses is a sequence of clauses C1 , Â· Â· Â· , Cn
such that Cn = C and each Ci is either a clause in S or a resolvent of clauses preceding Ci . If such
a deduction exists, we say that C can be derived from S.
Lock resolution is a restricted form of resolution introduced by Boyer (1971). A numeric label is
given to each literal in each clause. Resolution is permitted only on literals with the lowest valued
label in their clause. Note that in a clause there can be more than one literal with the same label:
if there are many literals with the lowest valued label, then resolution on any of them is allowed.
Literals in the resolvent inherit their labels from the parent clauses. If a literal in the resolvent has
two possible labels, the lower value is used. A deduction which follows these restrictions is called
a lock deduction.
Example 2. Consider the following clauses:
C1 : a(1) âˆ¨ b(2)

C2 : Â¬a(2) âˆ¨ b(3)

C3 : Â¬b(1) âˆ¨ c(2)

We can resolve C1 and C2 on a(1) and Â¬a(2) to form the following clause:
b(2)
Note that b is labelled 2 in C1 and 3 in C2 , so the lower value is used. However we cannot resolve
C2 and C3 on b(3) and Â¬b(1) since 3 is not the minimum label in C2 .
Boyer showed that lock resolution is refutation-complete.

6. The Completeness Proof
Proof of Theorem 1 (Completeness). To prove completeness, we need to show that P |=s r implies
P `s r. We do this by showing the existence of a lock deduction of Î³(r0 ) where r0 is a subset of
r (in the sense that H(r0 ) âŠ† H(r), B + (r0 ) âŠ† B + (r), and B âˆ’ (r0 ) âŠ† B âˆ’ (r)) from which we can
construct a deduction of r from P using the inference rules.
6.1 Lock Deduction of Î³(r0 ) from Î“(P ) âˆª Î“0 (P ) âˆª âˆ†
V
From Proposition 5 we know that Î³(r) is a logical consequence of (Î“(P ) âˆª Î“0 (P ) âˆª âˆ†). Ideally,
we want a lock deduction of Î³(r) from Î“(P ) âˆª Î“0 (P ) âˆª âˆ†. However, this may not be possible as
resolution is only refutation-complete. But in fact we can show that a lock deduction of Î³(r0 ) does
exist for some r0 , provided that r does not contain the same atom in its head and positive body. We
do this by first obtaining a lock deduction D0 of the empty clause from Î“(P ) âˆª Î“0 (P ) âˆª âˆ† and the
negation of Î³(r). We then modify this to form the deduction D of Î³(r0 ) from Î“(P ) âˆª Î“0 (P ) âˆª âˆ†,
in such a way that the restrictions of lock deduction are preserved.
211

W ONG

We label the literals in Î“(P ) âˆª Î“0 (P ) âˆª âˆ† with either 1 or 0: if the literal is of the form Â¬x0 , we
give it the label 0, otherwise we give it the label 1. For example, Î³(a â† b, not c) becomes
a(1) âˆ¨ Â¬b(1) âˆ¨ c0(1)
and Î³ 0 (a â† b, not c) becomes
a0(1) âˆ¨ Â¬b0(0) âˆ¨ c0(1)
Let r be the rule
a1 ; a2 ; Â· Â· Â· ; ak â† b1 , b2 , Â· Â· Â· , bm , not c1 , not c2 , Â· Â· Â· , not cn .
Then Î³(r) is
a1 âˆ¨ Â· Â· Â· âˆ¨ ak âˆ¨ Â¬b1 âˆ¨ Â· Â· Â· âˆ¨ Â¬bm âˆ¨ c01 âˆ¨ Â· Â· Â· âˆ¨ c0n
Negating Î³(r) gives us the following set of clauses, which we will call N (r):
Â¬a1 , Â· Â· Â· , Â¬ak , b1 , Â· Â· Â· , bm , Â¬c01 , Â· Â· Â· , Â¬c0n
We label these clauses in the same way as above. Note that Î³(r) contain only literals with label
1, while N (r) is a set ofV
single-literal clauses, where some of them may also have label 0. Since
Î³(r) is a consequence of (Î“(P ) âˆª Î“0 (P ) âˆª âˆ†), adding the negation of Î³(r) makes it unsatisfiable.
Therefore there is a lock deduction D0 of the empty clause from Î“(P ) âˆª Î“0 (P ) âˆª âˆ† plus N (r).
In the next step, we construct a new lock deduction D which does not contain any clauses from
N (r). Let C10 , Â· Â· Â· , Cn0 be the clauses in D0 . We construct inductively the clauses C1 , Â· Â· Â· , Cn :
â€¢ Ci0 is not a resolvent. In this case we set Ci := Ci0 . Note that if Ci0 is from N (r), it will be
removed in the next step of the construction.
â€¢ Ci0 is a resolvent of Cj0 and Ck0 on the literals x and Â¬x, where neither Cj0 or Ck0 is from N (r).
We set Ci to be the resolvent of Cj and Ck on x and Â¬x.
â€¢ Ci0 is a resolvent of Cj0 and Ck0 , one of which is from N (r). Without loss of generality, assume
Cj0 is from N (r). In this case we set Ci := Ck .
To complete the construction, we remove every Ci which is from N (r) and is not a resolvent. The
remaining clauses form the deduction D. Note that it is not possible for Ci0 to be a resolvent of
two clauses from N (r). This is because r does not contain the same atom in both its head and
positive body, and hence N (r) cannot contain a pair of complementary literals. Note also that the
final clause Cn is never removed, since Cn0 is the empty clause, which is not in N (r).
Example 3. Suppose P is the program consisting of the single rule
a â† b.
and r is the rule
â† b, not a.
Then Î“(P ) âˆª Î“0 (P ) âˆª âˆ† consists of the clauses
a(1) âˆ¨ Â¬b(1)

a0(1) âˆ¨ Â¬b0(0)

Â¬a(1) âˆ¨ a0(1)
212

Â¬b(1) âˆ¨ b0(1)

S OUND AND C OMPLETE I NFERENCE RULES FOR SE-C ONSEQUENCE

Î³(r) is Â¬b(1) âˆ¨ a0(1) (after labelling). The negation of Î³(r), denoted N (r), consists of the clauses
b(1)

Â¬a0(0)

Here is an example of a lock deduction D0 for the empty clause from Î“(P ) âˆª Î“0 (P ) âˆª âˆ† âˆª N (r):
(1)
(2)
(3)
(4)
(5)
(6)
(7)

b(1)
Â¬b(1) âˆ¨ b0(1)
b0(1)
a0(1) âˆ¨ Â¬b0(0)
a0(1)
Â¬a0(0)
âŠ¥

from N (r)
from âˆ†
resolvent of (1), (2)
from Î“0 (P )
resolvent of (3), (4)
from N(r)
resolvent of (5), (6)

The construction produces the following sequence of clauses:
(1)âˆ—
(2)
(3)
(4)
(5)
(6)âˆ—
(7)

b(1)
Â¬b(1) âˆ¨ b0(1)
Â¬b(1) âˆ¨ b0(1)
a0(1) âˆ¨ Â¬b0(0)
a0(1) âˆ¨ Â¬b(1)
Â¬a0(0)
a0(1) âˆ¨ Â¬b(1)

from âˆ†
from âˆ†â€”copy of (2)
from Î“0 (P )
resolvent of (3), (4)
resolvent of (3), (4)â€”copy of (5)

The clauses marked with âˆ— are removed, and the resulting deduction D is formed by the remaining
clauses.
By construction, D is a deduction. We need to show that D satisfies the restrictions of lock deduction. In addition, we show that each clause Ci in D consists of Ci0 with zero or more literals from
Î³(r) added, i.e. Ci = Ci0 âˆ¨ Î±i where Î±i is a disjunction of zero or more literals from Î³(r). The
proof is by induction.
â€¢ Ci0 is not a resolvent. In this case Ci is the same as Ci0 .
â€¢ Ci0 is a resolvent of clauses Cj0 and Ck0 on the literals x and Â¬x, with neither being from N (r).
Then Ci is the resolvent of Cj and Ck on the literals x and Â¬x. By induction, Cj = Cj0 âˆ¨ Î±j
and Ck = Ck0 âˆ¨ Î±k . If x does not occur in Î±j and Î±k , then Ci = Ci0 âˆ¨ Î±j âˆ¨ Î±k . Otherwise
Ci = Ci0 âˆ¨ Î±i where Î±i contains the literals in Î±j âˆ¨ Î±k except possibly for x or Â¬x. In both
cases, Ci consists of Ci0 plus zero or more literals from Î³(r).
This resolution step satisfies the restriction of lock deduction because the added literals are all
labelled 1, which is the highest label value that we use. Thus if x has the lowest label value
in Cj0 and Â¬x in Ck0 , the same must hold for x in Cj and Â¬x in Ck .
â€¢ Ci0 is a resolvent of clauses Cj0 and Ck0 , and Cj0 is from N (r). Since each clause in N (r) is
the negation of a literal found in Î³(r) (note they might carry different labels), there must be
some literal Î± in Î³(r) such that Cj0 = Â¬Î± and Ck0 = Ci0 âˆ¨ Î±. The construction of Ci gives us
Ci = Ck , and by induction Ck = Ck0 âˆ¨ Î±k . Therefore Ci = Ci0 âˆ¨ Î± âˆ¨ Î±k .
213

W ONG

We have shown that D is a lock deduction, and that each clause Ci in D consists of Ci0 with zero
or more literals from Î³(r) added. Recall that the final clause in D0 is the empty clause. Therefore
the final clause in D is a clause which contains some subset of the literals of Î³(r), and hence D is a
lock deduction for some Î³(r0 ) where r0 is a subset of r.
6.2 Existence of a Deduction of r from P
Suppose we have a lock deduction of Î³(r) from Î“(P ) âˆª Î“0 (P ) âˆª âˆ† with the labelling described
above. We prove by induction that P `s r.
BASE C ASE
Î³(r) is either in Î“(P ) or Î“0 (P ) or âˆ†.
â€¢ Î³(r) is in Î“(P ). Then r âˆˆ P , therefore P `s r.
â€¢ Î³(r) is in Î“0 (P ). This means Î³(r) = Î³ 0 (s) for some s âˆˆ P . B + (s) must be empty since
there can be no literals of the form Â¬x0 in Î³(r). Hence we can write s as
a1 ; Â· Â· Â· ; ak â† not c1 , Â· Â· Â· not cn .
and r is
â† not a1 , Â· Â· Â· , not ak , not c1 , Â· Â· Â· not cn .
Since `s â† ai , not ai , we can â€œmoveâ€ atoms from the head to the negative part using WGPPE.
Therefore P `s r.
â€¢ Î³(r) is in âˆ†. In this case r is
â† x, not x.
for some atom x, and `s r by applying CONTRA.
I NDUCTION S TEP
Î³(r) is the resolvent of clauses Î± and Î². The literal resolved on is either a and Â¬a or a0 and Â¬a0
for some atom a. Assume without loss of generality that the positive literal is in Î± and the negative
literal is in Î².
â€¢ a in Î± and Â¬a in Î² is the literal resolved on. Since there is no literal of the form Â¬x0 in
the resolvent, there cannot be any literal of that form in Î± or Î². Therefore we can find logic
program rules s and t such that Î± = Î³(s) and Î² = Î³(t). The inference rule WGPPE gives us
s, t `s r
and P `s s, t by induction. Therefore P `s r.
â€¢ a0 in Î± and Â¬a0 in Î² is the literal resolved on. Because Â¬a0 is in Î², there is no logic program
rule t such that Î² = Î³(t). However, we can find a logic program rule s such that Î± = Î³(s),
because of the lock resolution property: a0 is labelled 1 so there can be no literal of the form
Â¬x0 , which is labelled 0, in Î±.
214

S OUND AND C OMPLETE I NFERENCE RULES FOR SE-C ONSEQUENCE

If Î² is a resolvent, then the literal resolved on must be of the form x0 and Â¬x0 , with Â¬a0
being from the parent clause that contains Â¬x0 . Again, this is because of the lock resolution
property: the presence of Â¬a0 in that clause prevents resolution on any literal that is not
labelled 0. Let Î²2 be the parent clause containing Â¬x0 , and let Î±2 be the other parent clause.
Now Î±2 only contains literals labelled 1, so we can find a logic program rule s2 such that
Î±2 = Î³(s2 ).
By repeating this, we form a chain of resolvents Î±1 (= Î±), Î±2 , Â· Â· Â· , Î±n and Î²1 (= Î²), Î²2 , Â· Â· Â· , Î²n .
Each Î²i is the resolvent of Î±i+1 and Î²i+1 on the literal a0i in Î±i+1 and Â¬a0i in Î²i+1 . There is a
logic program rule si corresponding to each Î±i such that Î³(si ) = Î±i .
We extend this chain as far as possible, until Î²n is not a resolvent. Î²n contains literals of the
form Â¬x0 , so it can only come from Î“0 (P ). Therefore there is a t âˆˆ P such that Î³ 0 (t) = Î²n .
Observe that t is the rule
X â† a1 , Â· Â· Â· , an , not Y.
for some sets of atoms X, Y . There cannot be additional positive atoms in the body, because
they correspond to literals of the form Â¬x0 in Î²n , and there are no such literals remaining the
result of this chain of resolution steps, which is Î³(r).
The inference rule S-HYP gives us
s1 , Â· Â· Â· , sn , t `s r
Now P `s s1 , Â· Â· Â· , sn by induction, and P `s t because t âˆˆ P . Therefore P `s r.
6.3 The Final Step
We have shown that if P |=s r, then we can find r0 which is a â€œsubsetâ€ of r such that P `s r0 , apart
from some special cases. The final step of the proof is given by applying NONMIN, which allows
us the deduction r0 `s r when r0 is a â€œsubsetâ€ of r.
The special case where r contains the same atom in its head and positive body is handled by
observing that r can be produced using the rules TAUT followed by NONMIN, which shows `s r.
Therefore P |=s r implies P `s r.

7. Conclusion
In this paper we presented a sound and complete set of inference rules for SE-consequence on
disjunctive logic programs, consisting of a number of well-known logic program transformation
rules, TAUT, CONTRA, NONMIN, and WGPPE, plus a new rule which we call S-HYP. We proved
that this set of rules is complete for SE-consequence by using a reduction of logic programs to
propositional clauses on which we apply a restricted form of resolution. This result leads to a
syntactic definition of the closure operator for logic programs under strong equivalence. Future work
involves applying this to construct logic program update operators that respect strong equivalence,
as well as finding similar results for other notions of equivalence on logic programs.

Acknowledgments
We thank the anonymous reviewers for their many helpful suggestions which we used in revising
the paper. This work was partially supported by a scholarship from National ICT Australia. NICTA
215

W ONG

is funded by the Australian Governmentâ€™s Backing Australiaâ€™s Ability initiative, in part through the
Australian Research Council.

References
Boyer, R. (1971). Locking: A Restriction of Resolution. Ph.D. thesis, University of Texas, Austin.
Brass, S., & Dix, J. (1999). Semantics of (disjunctive) logic programs based on partial evaluation.
Journal of Logic Programming, 38(3), 167â€“213.
Cabalar, P. (2002). A three-valued characterization for strong equivalence of logic programs. In
Proceedings of the 18th National Conference on Artificial Intelligence (AAAI-2002), pp. 106â€“
111.
Eiter, T., Fink, M., Tompits, H., & Woltran, S. (2004). Simplifying logic programs under uniform
and strong equivalence. In Proceedings of the 7th International Conference on Logic Programming and Nonmonotonic Reasoning, pp. 87â€“99.
Gelfond, M., & Lifschitz, V. (1988). The stable model semantics for logic programming. In Proceedings of the 5th International Conference on Logic Programming, pp. 1070â€“1080.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. Computational
Logic, 2(4), 526â€“541.
Lin, F. (2002). Reducing strong equivalence of logic programs to entailment in classical propositional logic. In Proceedings of the 8th International Conference on Principles of Knowledge
Representation and Reasoning, pp. 170â€“176.
Lin, F., & Chen, Y. (2007). Discovering classes of strongly equivalent logic programs. Journal of
Artificial Intelligence Research, 28, 431â€“451.
Osorio, M., Navarro, J. A., & Arrazola, J. (2001). Equivalence in answer set programming. In Proceedings of the 11th International Workshop on Logic Based Program Synthesis and Transformation, pp. 57â€“75.
Sakama, C., & Seki, H. (1997). Partial deduction in disjunctive logic programming. Journal of
Logic Programming, 32(3), 229â€“245.
Turner, H. (2001). Strong equivalence for logic programs and default theories (made easy). In
Proceedings of the 6th International Conference on Logic Programming and Nonmonotonic
Reasoning, pp. 81â€“92.
Turner, H. (2003). Strong equivalence made easy: nested expressions and weight constraints. Theory
and Practice of Logic Programming, 3(4-5), 609â€“622.
Wang, K., & Zhou, L. (2005). Comparisons and computation of well-founded semantics for disjunctive logic programs. ACM Transactions on Computational Logic, 6(2), 295â€“327.

216

Journal of Artificial Intelligence Research 31 (2008) 399-429

Submitted 09/07; published 03/08

Global Inference for Sentence Compression
An Integer Linear Programming Approach
James Clarke

jclarke@ed.ac.uk

Mirella Lapata

mlap@inf.ed.ac.uk

School of Informatics
University of Edinburgh
2 Buccleuch Place
Edinburgh EH8 9LW, UK

Abstract
Sentence compression holds promise for many applications ranging from summarization
to subtitle generation. Our work views sentence compression as an optimization problem
and uses integer linear programming (ILP) to infer globally optimal compressions in the
presence of linguistically motivated constraints. We show how previous formulations of
sentence compression can be recast as ILPs and extend these models with novel global
constraints. Experimental results on written and spoken texts demonstrate improvements
over state-of-the-art models.

1. Introduction
The computational treatment of sentence compression has recently attracted much attention
in the literature. The task can be viewed as producing a summary of a single sentence that
retains the most important information and remains grammatical (Jing, 2000). A sentence
compression mechanism would greatly benefit a wide range of applications. For example,
in summarization, it could improve the conciseness of the generated summaries (Jing, 2000;
Lin, 2003; Zajic, Door, Lin, & Schwartz, 2007). Other examples include compressing text
to be displayed on small screens such as mobile phones or PDAs (Corston-Oliver, 2001),
subtitle generation from spoken transcripts (Vandeghinste & Pan, 2004), and producing
audio scanning devices for the blind (Grefenstette, 1998).
Sentence compression is commonly expressed as a word deletion problem: given an input source sentence of words x = x1 , x2 , . . . , xn , the aim is to produce a target compression
by removing any subset of these words (Knight & Marcu, 2002). The compression problem has been extensively studied across different modeling paradigms, both supervised and
unsupervised. Supervised models are typically trained on a parallel corpus of source sentences and target compressions and come in many flavors. Generative models aim to model
the probability of a target compression given the source sentence either directly (Galley
& McKeown, 2007) or indirectly using the noisy-channel model (Knight & Marcu, 2002;
Turner & Charniak, 2005), whereas discriminative formulations attempt to minimize error
rate on a training set. These include decision-tree learning (Knight & Marcu, 2002), maximum entropy (Riezler, King, Crouch, & Zaenen, 2003), support vector machines (Nguyen,
Shimazu, Horiguchi, Ho, & Fukushi, 2004), and large-margin learning (McDonald, 2006).
c
2008
AI Access Foundation. All rights reserved.

Clarke & Lapata

Unsupervised methods dispense with the parallel corpus and generate compressions either
using rules (Turner & Charniak, 2005) or a language model (Hori & Furui, 2004).
Despite differences in formulation, all these approaches model the compression process
using local information. For instance, in order to decide which words to drop, they exploit
information about adjacent words or constituents. Local models can do a good job at
producing grammatical compressions, however they are somewhat limited in scope since
they cannot incorporate global constraints on the compression output. Such constraints
consider the sentence as a whole instead of isolated linguistic units (words or constituents).
To give a concrete example we may want to ensure that each target compression has a verb,
provided that the source had one in the first place. Or that verbal arguments are present in
the compression. Or that pronouns are retained. Such constraints are fairly intuitive and
can be used to instill not only linguistic but also task specific information into the model.
For instance, an application which compresses text to be displayed on small screens would
presumably have a higher compression rate than a system generating subtitles from spoken
text. A global constraint could force the former system to generate compressions with a
fixed rate or a fixed number of words.
Existing approaches do not model global properties of the compression problem for a
good reason. Finding the best compression for a source sentence given the space of all
possible compressions1 (this search process is often referred to as decoding or inference)
can become intractable for too many constraints and overly long sentences. Typically, the
decoding problem is solved efficiently using dynamic programming often in conjunction
with heuristics that reduce the search space (e.g., Turner & Charniak, 2005). Dynamic
programming guarantees we will find the global optimum provided the principle of optimality holds. This principle states that given the current state, the optimal decision for each
of the remaining stages does not depend on previously reached stages or previously made
decisions (Winston & Venkataramanan, 2003). However, we know this to be false in the
case of sentence compression. For example, if we have included modifiers to the left of a
noun in a compression then we should probably include the noun too or if we include a verb
we should also include its arguments. With a dynamic programming approach we cannot
easily guarantee such constraints hold.
In this paper we propose a novel framework for sentence compression that incorporates
constraints on the compression output and allows us to find an optimal solution. Our
formulation uses integer linear programming (ILP), a general-purpose exact framework for
NP-hard problems. Specifically, we show how previously proposed models can be recast
as integer linear programs. We extend these models with constraints which we express as
linear inequalities. Decoding in this framework amounts to finding the best solution given
a linear (scoring) function and a set of linear constraints that can be either global or local.
Although ILP has been previously used for sequence labeling tasks (Roth & Yih, 2004;
Punyakanok, Roth, Yih, & Zimak, 2004), its application to natural language generation
is less widespread. We present three compression models within the ILP framework, each
representative of an unsupervised (Knight & Marcu, 2002), semi-supervised (Hori & Furui,
2004), and fully supervised modeling approach (McDonald, 2006). We propose a small
number of constraints ensuring that the compressions are structurally and semantically
1. There are 2n possible compressions where n is the number of words in a sentence.

400

Global Inference for Sentence Compression

valid and experimentally evaluate their impact on the compression task. In all cases, we
show that the added constraints yield performance improvements.
The remainder of this paper is organized as follows. Section 2 provides an overview
of related work. In Section 3 we present the ILP framework and the compression models
we employ in our experiments. Our constraints are introduced in Section 3.5. Section 4.3
discusses our experimental set-up and Section 5 presents our results. Discussion of future
work concludes the paper.

2. Related Work
In this paper we develop several ILP-based compression models. Before presenting these
models, we briefly summarize previous work addressing sentence compression with an emphasis on data-driven approaches. Next, we describe how ILP techniques have been used
in the past to solve other inference problems in natural language processing (NLP).
2.1 Sentence Compression
Jing (2000) was perhaps the first to tackle the sentence compression problem. Her approach
uses multiple knowledge sources to determine which phrases in a sentence to remove. Central
to her system is a grammar checking module that specifies which sentential constituents
are grammatically obligatory and should therefore be present in the compression. This
is achieved using simple rules and a large-scale lexicon. Other knowledge sources include
WordNet and corpus evidence gathered from a parallel corpus of source-target sentence
pairs. A phrase is removed only if it is not grammatically obligatory, not the focus of the
local context and has a reasonable deletion probability (estimated from a parallel corpus).
In contrast to Jing (2000), the bulk of the research on sentence compression relies exclusively on corpus data for modeling the compression process without recourse to extensive knowledge sources (e.g., WordNet). A large number of approaches are based on the
noisy-channel model (Knight & Marcu, 2002). These approaches consist of a language
model P (y) (whose role is to guarantee that compression output is grammatical), a channel
model P (x|y) (capturing the probability that the source sentence x is an expansion of the
target compression y), and a decoder (which searches for the compression y that maximizes
P (y)P (x|y)). The channel model is acquired from a parsed version of a parallel corpus; it
is essentially a stochastic synchronous context-free grammar (Aho & Ullman, 1969) whose
rule probabilities are estimated using maximum likelihood. Modifications of this model are
presented by Turner and Charniak (2005) and Galley and McKeown (2007) with improved
results.
In discriminative models (Knight & Marcu, 2002; Riezler et al., 2003; McDonald, 2006;
Nguyen et al., 2004) sentences are represented by a rich feature space (also induced from
parse trees) and the goal is to learn which words or word spans should be deleted in a given
context. For instance, in Knight and Marcuâ€™s (2002) decision-tree model, compression is
performed deterministically through a tree rewriting process inspired by the shift-reduce
parsing paradigm. Nguyen et al. (2004) render this model probabilistic through the use
of support vector machines. McDonald (2006) formalizes sentence compression in a largemargin learning framework without making reference to shift-reduce parsing. In his model
compression is a classification task: pairs of words from the source sentence are classified
401

Clarke & Lapata

as being adjacent or not in the target compression. A large number of features are defined
over words, parts-of-speech, phrase structure trees and dependencies. These features are
gathered over adjacent words in the compression and the words in-between which were
dropped (see Section 3.4.3 for a more detailed account).
While most compression models have been developed with written text in mind, Hori
and Furui (2004) propose a model for automatically transcribed spoken text. Their model
generates compressions through word deletion without using parallel data or syntactic information in any way. Assuming a fixed compression rate, it searches for the compression
with the highest score using a dynamic programming algorithm. The scoring function consists of a language model responsible for producing grammatical output, a significance score
indicating whether a word is topical or not, and a score representing the speech recognizerâ€™s
confidence in transcribing a given word correctly.
2.2 Integer Linear Programming in NLP
ILPs are constrained optimization problems where both the objective function and the
constraints are linear equations with integer variables (see Section 3.1 for more details). ILP
techniques have been recently applied to several NLP tasks, including relation extraction
(Roth & Yih, 2004), semantic role labeling (Punyakanok et al., 2004), the generation of
route directions (Marciniak & Strube, 2005), temporal link analysis (Bramsen, Deshpande,
Lee, & Barzilay, 2006), set partitioning (Barzilay & Lapata, 2006), syntactic parsing (Riedel
& Clarke, 2006), and coreference resolution (Denis & Baldridge, 2007).
Most of these approaches combine a local classifier with an inference procedure based
on ILP. The classifier proposes possible answers which are assessed in the presence of global
constraints. ILP is used to make a final decision that is consistent with the constraints
and likely according to the classifier. For example, the semantic role labeling task involves
identifying the verb-argument structure for a given sentence. Punyakanok et al. (2004) first
use SNOW, a multi-class classifier2 (Roth, 1998), to identify and label candidate arguments.
They observe that the labels assigned to arguments in a sentence often contradict each other.
To resolve these conflicts they propose global constraints (e.g., each argument should be
instantiated once for a given verb, every verb should have at least one argument) and use
ILP to reclassify the output of SNOW.
Dras (1999) develops a document paraphrasing model using ILP. The key premise of
his work is that in some cases one may want to rewrite a document so as to conform to
some global constraints such as length, readability, or style. The proposed model has three
ingredients: a set of sentence-level paraphrases for rewriting the text, a set of global constraints, and an objective function which quantifies the effect incurred by the paraphrases.
Under this formulation, ILP can be used to select which paraphrases to apply so that the
global constraints are satisfied. Paraphrase generation falls outside the scope of the ILP
model â€“ sentence rewrite operations are mainly syntactic and provided by a module based
on synchronous tree adjoining grammar (S-TAG, Shieber & Schabes, 1990). Unfortunately,
only a proof-of-concept is presented; implementation and evaluation of this module are left
to future work.
2. SNOWâ€™s learning algorithm is a variation of the Winnow update rule.

402

Global Inference for Sentence Compression

Our work models sentence compression as an optimization problem. We show how previously proposed models can be reformulated in the context of integer linear programming
which allows us to easily incorporate constraints during the decoding process. Our constraints are linguistically and semantically motivated and are designed to bring less local
syntactic knowledge into the model and help preserve the meaning of the source sentence.
Previous work has identified several important features for the compression task (Knight
& Marcu, 2002; McDonald, 2006); however, the use of global constraints is novel to our
knowledge. Although sentence compression has not been explicitly formulated in terms of
optimization, previous approaches rely on some optimization procedure for generating the
best compression. The decoding process in the noisy-channel model searches for the best
compression given the source and channel models. However, the compression found is usually sub-optimal as heuristics are used to reduce the search space or is only locally optimal
due to the search method employed. For example, in the work of Turner and Charniak
(2005) the decoder first searches for the best combination of rules to apply. As it traverses
the list of compression rules, it removes sentences outside the 100 best compressions (according to the channel model). This list is eventually truncated to 25 compressions. In
other models (Hori & Furui, 2004; McDonald, 2006) the compression score is maximized
using dynamic programming which however can yield suboptimal results (see the discussion
in Section 1).
Contrary to most other NLP work using ILP (a notable exception is Roth & Yih, 2005),
we do not view compression generation as a two stage process where learning and inference
are carried out sequentially (i.e., first a local classifier hypothesizes a list of possible answers and then the best answer is selected using global constraints). Our models integrate
learning with inference in a unified framework where decoding takes place in the presence
of all available constraints, both local and global. Moreover, we investigate the influence
of our constraint set across models and learning paradigms. Previous work typically formulates constraints for a single model (e.g., the SNOW classifier) and learning paradigm
(e.g., supervised). We therefore assess how the constraint-based framework advocated in
this article influences the performance of expressive models (which require large amounts of
parallel data) and non-expressive ones (which use very little parallel data or none at all). In
other words, we are able to pose and answer the following question: what kinds of models
benefit most from constraint-based inference?
Our work is close in spirit but rather different in content to Dras (1999). We concentrate
on compression, a specific paraphrase type, and apply our models on the sentence-level. Our
constraints thus do not affect the document as a whole but individual sentences. Furthermore, compression generation is an integral part of our ILP models, whereas Dras assumes
that paraphrases are generated by a separate process.

3. Framework
In this section we present the details of the proposed framework for sentence compression.
As mentioned earlier, our work models sentence compression directly as an optimization
problem. There are 2n possible compressions for each source sentence and while many
of these will be unreasonable, it is unlikely that only one compression will be satisfactory (Knight & Marcu, 2002). Ideally, we require a function that captures the operations
403

Clarke & Lapata

(or rules) that can be performed on a sentence to create a compression while at the same
time factoring how desirable each operation makes the resulting compression. We can then
perform a search over all possible compressions and select the best one, as determined by
how desirable it is. A wide range of models can be expressed under this framework. The
prerequisites for implementing these are fairly low, we only require that the decoding process be expressed as a linear function with a set of linear constraints. In practice, many
models rely on a Markov assumption for factorization which is usually solved with a dynamic programming-based decoding process. Such algorithms can be formulated as integer
linear programs with little effort.
We first give a brief introduction into integer linear programming, an extension of linear
programming for readers unfamiliar with mathematical programming. Our compression
models are next described in Section 3.4 and constraints in Section 3.5.
3.1 Linear Programming
Linear programming (LP) problems are optimization problems with constraints. They
consist of three parts:
â€¢ Decision variables. These are variables under our control which we wish to assign
optimal values to.
â€¢ A linear function (the objective function). This is the function we wish to minimize or
maximize. This function is influences by the values assigned to the decision variables.
â€¢ Constraints. Most problems will only allow the decision variables to take certain
values. These restrictions are the constraints.
These terms are best demonstrated with a simple example taken from Winston and
Venkataramanan (2003). Imagine a manufacturer of tables and chairs which we shall call
the Telfa Corporation. To produce a table, 1 hour of labor and 9 square board feet of wood
is required. Chairs require 1 hour of labor and 5 square board feet of wood. Telfa have
6 hours of labor and 45 square board feet of wood available. The profit made from each
table is 8 GBP and 5 GBP for chairs. We wish to determine the number of tables and
chairs that should be manufactured to maximize Telfaâ€™s profit.
First, we must determine the decision variables. In our case we define:
x1 = number of tables manufactured
x2 = number of chairs manufactured
Our objective function is the value we wish to maximize, namely the profit.
Profit = 8x1 + 5x2
There are two constraints in this problem: we must not exceed 6 hours of labor and no
more than 45 square board feet of wood must be used. Also, we cannot create a negative
amount of chairs or tables:
404

Global Inference for Sentence Compression

Labor constraint
x 1 + x2
Wood constraint
9x1 + 5x2
Variable constraints
x1
x2

â‰¤ 6
â‰¤ 45
â‰¥ 0
â‰¥ 0

Once the decision variables, objective function and constraints have been determined we
can express the LP model:
max z = 8x1 + 5x2 (Objective function)
subject to (s.t.)
x1 + x2
9x1 + 5x2
x1
x2

â‰¤ 6 (Labor constraint)
â‰¤ 45 (Wood constraint)
â‰¥ 0
â‰¥ 0

Two of the most basic concepts involved in solving LP problems are the feasibility region
and optimal solution. The optimal solution is one in which all constraints are satisfied
and the objective function is minimized or maximized. A specification of the value for
each decision variable is referred to as a point. The feasibility region for a LP is a region
consisting of the set of all points that satisfy all the LPâ€™s constraints. The optimal solution
lies within this feasibility region, it is the point with the minimum or maximum objective
function value.
A set of points satisfying a single linear inequality is a half-space. The feasibility region
is defined by a the intersection of m half-spaces (for m linear inequalities) and forms a
polyhedron. Our Telfa example forms a polyhedral set (a polyhedral convex set) from
the intersection of our four constraints. Figure 1a shows the feasible region for the Telfa
example. To find the optimal solution we graph a line (or hyperplane) on which all points
have the same objective function value. In maximization problems it is called the isoprofit
line and in minimization problems the isocost line. One isoprofit line is represented by the
dashed black line in Figure 1a. Once we have one isoprofit line we can find all other isoprofit
lines by moving parallel to the original isoprofit line.
The extreme points of the polyhedral set are defined as the intersections of the lines
that form the boundaries of the polyhedral set (points A B C and D in Figure 1a). It can
be shown that any LP that has an optimal solution, has an extreme point that is globally
optimal. This reduces the search space of the optimization problem to finding the extreme
point with the highest or lowest value. The simplex algorithm (Dantzig, 1963) solves LPs
by exploring the extreme points of a polyhedral set. Specifically, it moves from one extreme
point to an adjacent extreme point (extreme points that lie on the same line segment) until
an optimal extreme point is found. Although the simplex algorithm has an exponential
worst-case complexity, in practice the algorithm is very efficient.
15
9
The optimal solution for the Telfa example is z = 165
4 , x1 = 4 , x2 = 4 . Thus, to
achieve a maximum profit of 41.25 GBP they must build 3.75 tables and 2.25 chairs. This
is obviously impossible as we would not expect people to buy fractions of tables and chairs.
Here, we want to be able to constrain the problem such that the decision variables can only
take integer values. This can be done with Integer Linear Programming.
405

Clarke & Lapata

a.

b.

10

10

9

9

= LPâ€™s feasible region

9x1 + 5x2 = 45

9x1+ 5x2 = 45

8

8

7

7

6 B

6

x2 5

x2 5

4

4

= IP feasible point
= IP relaxationâ€™s feasible region

3

3

Optimal LP solution

Optimal LP solution
2

C

2

x 1 + x2 = 6

1
0

A

0

1

2

3

x1

4

D
5

6

x 1 + x2 = 6

11

7

0

0

1

2

3

x1

4

5

6

7

Figure 1: Feasible region for the Telfa example using linear (graph (a)) and integer linear
(graph (b)) programming

3.2 Integer Linear Programming
Integer linear programming (ILP) problems are LP problems in which some or all of the
variables are required to be non-negative integers. They are formulated in a similar manner
to LP problems with the added constraint that all decision variables must take non-negative
integer values.
To formulate the Telfa problem as an ILP model we merely add the constraints that x1
and x2 must be integer. This gives:
max z = 8x1 + 5x2 (Objective function)
subject to (s.t.)
x1 + x2
9x1 + 5x2
x1
x2

â‰¤
6 (Labor constraint)
â‰¤
45 (Wood constraint)
â‰¥ 0; x1 integer
â‰¥ 0; x2 integer

For LP models, it can be proved that the optimal solution lies on an extreme point of
the feasible region. In the case of integer linear programs, we only wish to consider points
that are integer values. This is illustrated in Figure 1b for the Telfa problem. In contrast to
linear programming, which can be solved efficiently in the worst case, integer programming
problems are in many practical situations NP-hard (Cormen, Leiserson, & Rivest, 1992).
406

Global Inference for Sentence Compression

Fortunately, ILPs are a well studied optimization problem and a number of techniques have
been developed to find the optimal solution. Two such techniques are the cutting planes
method (Gomory, 1960) and the branch-and-bound method (Land & Doig, 1960). We
briefly discuss these methods here. For a more detailed treatment we refer the interested
reader to Winston and Venkataramanan (2003) or Nemhauser and Wolsey (1988).
The cutting planes method adds extra constraints to slice parts of the feasible region
until it contains only integer extreme points. However, this process can be difficult or
impossible (Nemhauser & Wolsey, 1988). The branch-and-bound method enumerates all
points in the ILPâ€™s feasible region but prunes those sections in the region which are known
to be sub-optimal. It does this by relaxing the integer constraints and solving the resulting
LP problem (known as the LP relaxation). If the solution of the LP relaxation is integral,
then it is the optimal solution. Otherwise, the resulting solution provides an upper bound
on the solution for the ILP. The algorithm proceeds by creating two new sub-problems based
on the non-integer solution for one variable at a time. These are solved and the process
repeats until the optimal integer solution is found.
Using the branch-and-bound method, we find that the optimal solution to the Telfa
problem is z = 40, x1 = 5, x2 = 0; thus, to achieve a maximum profit of 40 GBP, Telfa
must manufacture 5 tables and 0 chairs. This is a relatively simple problem, which could be
solved merely by inspection. Most ILP problems will involve many variables and constraints
resulting in a feasible region with a large number of integer points. The branch-and-bound
procedure can efficiently solve such ILPs in a matter of seconds and forms part of many
commercial ILP solvers. In our experiments we use lp solve 3 , a free optimization package
which relies on the simplex algorithm and brand-and-bound methods for solving ILPs.
Note that under special circumstances other solving methods may be applicable. For
example, implicit enumeration can be used to solve ILPs where all the variables are binary
(also known as pure 0âˆ’1 problems). Implicit enumeration is similar to the branch-andbound method, it systematically evaluates all possible solutions, without however explicitly
solving a (potentially) large number of LPs derived from the relaxation. This removes
much of the computational complexity involved in determining if a sub-problem is infeasible. Furthermore, for a class of ILP problems known as minimum cost network flow
problems (MCNFP), the LP relaxation always yields an integral solution. These problems
can therefore be treated as LP problems.
In general, a model will yield an optimal solution in which all variables are integers if
the constraint matrix has a property known as total unimodularity. A matrix A is totally
unimodular if every square sub-matrix of A has its determinant equal to 0, +1 or âˆ’1.
It is the case that the more the constraint matrix looks totally unimodular, the easier
the problem will be to solve by branch-and-bound methods. In practice it is good to
formulate ILPs where as many variables as possible have coefficients of 0, +1 or âˆ’1 in the
constraints (Winston & Venkataramanan, 2003).
3.3 Constraints and Logical Conditions
Although integer variables in ILP problems may take arbitrary values, these are frequently
are restricted to 0 and 1. Binary variables (0âˆ’1 variables) are particularly useful for rep3. The software is available from http://lpsolve.sourceforge.net/.

407

Clarke & Lapata

Condition
Implication
Iff
Or
Xor
And
Not

Statement
if a then b
a if and only if b
a or b or c
a xor b xor c
a and b
not a

Constraint
bâˆ’aâ‰¥0
aâˆ’b=0
a+b+câ‰¥1
a+b+c=1
a = 1; b = 1
1âˆ’a=1

Table 1: How to represent logical conditions using binary variables and constraints in ILP.

resenting a variety of logical conditions within the ILP framework through the use of constraints. Table 1 lists several logical conditions and their equivalent constraints.
We can also express transitivity, i.e., â€œc if and only if a and bâ€. Although it is often thought that transitivity can only be expressed as a polynomial expression of binary
variables (i.e., ab = c), it is possible to replace the latter by the following linear inequalities (Williams, 1999):

(1 âˆ’ c) + a â‰¥ 1
(1 âˆ’ c) + b â‰¥ 1
c + (1 âˆ’ a) + (1 âˆ’ b) â‰¥ 1
This can be easily extended to model indicator variables representing whether a set of binary
variables can take certain values.
3.4 Compression Models
In this section we describe three compression models which we reformulate as integer linear
programs. Our first model is a simple language model which has been used as a baseline in
previous research (Knight & Marcu, 2002). Our second model is based on the work of Hori
and Furui (2004); it combines a language model with a corpus-based significance scoring
function (we omit here the confidence score derived from the speech recognizer since our
models are applied to text only). This model requires a small amount of parallel data to
learn weights for the language model and the significance score.
Our third model is fully supervised, it uses a discriminative large-margin framework
(McDonald, 2006), and is trained trained on a larger parallel corpus. We chose this model
instead of the more popular noisy-channel or decision-tree models, for two reasons, a practical one and a theoretical one. First, McDonaldâ€™s (2006) model delivers performance superior
to the decision-tree model (which in turn performs comparably to the noisy-channel). Second, the noisy channel is not an entirely appropriate model for sentence compression. It
uses a language model trained on uncompressed sentences even though it represents the
probability of compressed sentences. As a result, the model will consider compressed sentences less likely than uncompressed ones (a further discussion is provided by Turner &
Charniak, 2005).
408

Global Inference for Sentence Compression

3.4.1 Language Model
A language model is perhaps the simplest model that springs to mind. It does not require
a parallel corpus (although a relatively large monolingual corpus is necessary for training),
and will naturally prefer short sentences to longer ones. Furthermore, a language model can
be used to drop words that are either infrequent or unseen in the training corpus. Knight
and Marcu (2002) use a bigram language model as a baseline against their noisy-channel
and decision-tree models.
Let x = x1 , x2 , . . . , xn denote a source sentence for which we wish to generate a target
compression. We introduce a decision variable for each word in the source and constrain it
to be binary; a value of 0 represents a word being dropped, whereas a value of 1 includes
the word in the target compression. Let:
Î´i =

(

1 if xi is in the compression
âˆ€i âˆˆ [1 . . . n]
0 otherwise

If we were using a unigram language model, our objective function would maximize the
overall sum of the decision variables (i.e., words) multiplied by their unigram probabilities
(all probabilities throughout this paper are log-transformed):
max

n
X

Î´i Â· P (xi )

(1)

i=1

Thus, if a word is selected, its corresponding Î´i is given a value of 1, and its probability
P (xi ) according to the language model will be counted in our total score.
A unigram language model will probably generate many ungrammatical compressions.
We therefore use a more context-aware model in our objective function, namely a trigram
model. Dynamic programming would be typically used to decode a language model by
traversing the sentence in a left-to-right manner. Such an algorithm is efficient and provides
all the context required for a conventional language model. However, it can be difficult
or impossible to incorporate global constraints into such a model as decisions on word
inclusion cannot extend beyond a three word window. By formulating the decoding process
for a trigram language model as an integer linear program we are able to take into account
constraints that affect the compressed sentence more globally. This process is a much more
involved task than in the unigram case where there is no context, instead we must now
make decisions based on word sequences rather than isolated words. We first create some
additional decision variables:
Î±i =

(

Î²ij =

ï£±
ï£´
ï£² 1

Î³ijk =

1 if xi starts the compression
âˆ€i âˆˆ [1 . . . n]
0 otherwise

if sequence xi , xj ends
the compression
âˆ€i âˆˆ [0 . . . n âˆ’ 1]
ï£´
ï£³ 0 otherwise
âˆ€j âˆˆ [i + 1 . . . n]

ï£±
ï£´
ï£² 1

if sequence xi , xj , xk âˆ€i âˆˆ [0 . . . n âˆ’ 2]
is in the compression âˆ€j âˆˆ [i + 1 . . . n âˆ’ 1]
ï£´
ï£³ 0 otherwise
âˆ€k âˆˆ [j + 1 . . . n]
409

Clarke & Lapata

Our objective function is given in Equation (2). This is the sum of all possible trigrams
that can occur in all compressions of the source sentence where x0 represents the â€˜startâ€™
token and xi is the ith word in sentence x. Equation (3) constrains the decision variables
to be binary.
max z =

n
X

Î±i Â· P (xi |start)
i=1
nâˆ’2
n
X nâˆ’1
X X

+

Î³ijk Â· P (xk |xi , xj )

i=1 j=i+1 k=j+1

+

nâˆ’1
X

n
X

Î²ij Â· P (end|xi , xj )

(2)

i=0 j=i+1

subject to:

Î´i , Î±i , Î²ij , Î³ijk = 0 or 1

(3)

The objective function in (2) allows any combination of trigrams to be selected. This
means that invalid trigram sequences (e.g., two or more trigrams containing the â€˜endâ€™ token)
could appear in the target compression. We avoid this situation by introducing sequential
constraints (on the decision variables Î´i , Î³ijk , Î±i , and Î²ij ) that restrict the set of allowable
trigram combinations.
Constraint 1

Exactly one word can begin a sentence.
n
X

Î±i = 1

(4)

i=1

Constraint 2 If a word is included in the sentence it must either start the sentence or be
preceded by two other words or one other word and the â€˜startâ€™ token x0 .
Î´k âˆ’ Î±k âˆ’

kâˆ’2
X kâˆ’1
X

Î³ijk = 0

(5)

i=0 j=1

âˆ€k : k âˆˆ [1 . . . n]
Constraint 3 If a word is included in the sentence it must either be preceded by one
word and followed by another or it must be preceded by one word and end the sentence.
Î´j âˆ’

jâˆ’1
X

n
X

Î³ijk âˆ’

i=0 k=j+1

jâˆ’1
X

Î²ij = 0

(6)

i=0

âˆ€j : j âˆˆ [1 . . . n]

Constraint 4 If a word is in the sentence it must be followed by two words or followed
by one word and then the end of the sentence or it must be preceded by one word and end
the sentence.
Î´i âˆ’

nâˆ’1
X

n
X

j=i+1 k=j+1

Î³ijk âˆ’

n
X

j=i+1

410

Î²ij âˆ’

iâˆ’1
X

Î²hi = 0

h=0

âˆ€i : i âˆˆ [1 . . . n]

(7)

Global Inference for Sentence Compression

Constraint 5

Exactly one word pair can end the sentence.
nâˆ’1
X

n
X

Î²ij = 1

(8)

i=0 j=i+1

The sequential constraints described above ensure that the second order factorization (for
trigrams) holds and are different from our compression-specific constraints which are presented in Section 3.5.
Unless normalized by sentence length, a language model will naturally prefer one-word
output. This normalization is however non-linear and cannot be incorporated into our ILP
formulation. Instead, we impose a constraint on the length of the compressed sentence.
Equation (9) below forces the compression to contain at least b tokens.
n
X

Î´i â‰¥ b

(9)

i=1

Alternatively, we could force the compression to be exactly b tokens (by substituting the
inequality with an equality in (9)) or to be less than b tokens (by replacing â‰¥ with â‰¤).4
The constraint in (9) is language model-specific and is not used elsewhere.
3.4.2 Significance Model
The language model just described has no notion of which content words to include in the
compression and thus prefers words it has seen before. But words or constituents will be of
different relative importance in different documents or even sentences.
Inspired by Hori and Furui (2004), we add to our objective function (see Equation (2))
a significance score designed to highlight important content words. In Hori and Furuiâ€™s
original formulation each word is weighted by a score similar to un-normalized tf âˆ— idf . The
significance score is not applied indiscriminately to all words in a sentence but solely to
topic-related words, namely nouns and verbs. Our score differs in one respect. It combines
document-level with sentence-level significance. So in addition to tf âˆ— idf , each word is
weighted by its level of embedding in the syntactic tree.
Intuitively, in a sentence with multiply nested clauses, more deeply embedded clauses
tend to carry more semantic content. This is illustrated in Figure 2 which depicts the
clause embedding for the sentence â€œMr Field has said he will resign if he is not reselected,
a move which could divide the party nationallyâ€. Here, the most important information is
conveyed by clauses S3 (he will resign) and S4 (if he is not reselected) which are embedded.
Accordingly, we should give more weight to words found in these clauses than in the main
clause (S1 in Figure 2). A simple way to enforce this is to give clauses weight proportional
to the level of embedding. Our modified significance score becomes:
I(xi ) =

Fa
l
Â· fi log
N
Fi

(10)

where xi is a topic word, fi and Fi are the frequency of xi in the document and corpus
respectively, Fa is the sum of all topic words in the corpus, l is the number of clause
4. Compression rate can be also limited to a range by including two inequality constraints.

411

Clarke & Lapata

S1
S2
Mr Field has said
S3
he will resign
S4
if he is not reselected
, a move
SBAR
which could divide the party nationally

Figure 2: The clause embedding of the sentence â€œMr Field has said he will resign if he is
not reselected, a move which could divide the party nationallyâ€; nested boxes
correspond to nested clauses.

constituents above xi , and N is the deepest level of clause embedding. Fa and Fi are
estimated from a large document collection, fi is document-specific, whereas Nl is sentencespecific. So, in Figure 2 the term Nl is 1.0 (4/4) for clause S4 , 0.75 (3/4) for clause S3 , and
so on. Individual words inherit their weight from their clauses.
The modified objective function with the significance score is given below:
max z =

n
X

Î´i Â· Î»I(xi ) +

i=1
nâˆ’2
X nâˆ’1
X

+

n
X

Î±i Â· P (xi |start)

i=1

n
X

Î³ijk Â· P (xk |xi , xj )

i=1 j=i+1 k=j+1

+

nâˆ’1
X

n
X

Î²ij Â· P (end|xi , xj )

(11)

i=0 j=i+1

We also add a weighting factor (Î») to the objective, in order to counterbalance the importance of the language model and the significance score. The weight is tuned on a small
parallel corpus. The sequential constraints from Equations (4)â€“(8) are again used to ensure
that the trigrams are combined in a valid way.
3.4.3 Discriminative Model
As a fully supervised model, we used the discriminative model presented by McDonald
(2006). This model uses a large-margin learning framework coupled with a feature set
defined on compression bigrams and syntactic structure.
Let x = x1 , . . . , xn denote a source sentence with a target compression y = y1 , . . . , ym
where each yj occurs in x. The function L(yi ) âˆˆ {1 . . . n} maps word yi in the target com412

Global Inference for Sentence Compression

pression to the index of the word in the source sentence, x. We also include the constraint
that L(yi ) < L(yi+1 ) which forces each word in x to occur at most once in the compression
y. Let the score of a compression y for a sentence x be:
(12)

s(x, y)

This score is factored using a first-order Markov assumption on the words in the target
compression to give:
s(x, y) =

|y|
X

s(x, L(yjâˆ’1 ), L(yj ))

(13)

j=2

The score function is defined to be the dot product between a high dimensional feature
representation and a corresponding weight vector:
s(x, y) =

|y|
X

w Â· f (x, L(yjâˆ’1 ), L(yj ))

(14)

j=2

Decoding in this model amounts to finding the combination of bigrams that maximizes
the scoring function in (14). McDonald (2006) uses a dynamic programming approach
where the maximum score is found in a left-to-right manner. The algorithm is an extension
of Viterbi for the case in which scores factor over dynamic sub-strings (Sarawagi & Cohen,
2004; McDonald, Crammer, & Pereira, 2005a). This allows back-pointers to be used to
reconstruct the highest scoring compression as well as the k-best compressions.
Again this is similar to the trigram language model decoding process (see Section 3.4.1),
except that here a bigram model is used. Consequently, the ILP formulation is slightly
simpler than that of the trigram language model. Let:
Î´i =

(

1 if xi is in the compression
(1 â‰¤ i â‰¤ n)
0 otherwise

We then introduce some more decision variables:
Î±i =
Î²i =
Î³ij =

(

(

(

1 if xi starts the compression
âˆ€i âˆˆ [1 . . . n]
0 otherwise

1 if word xi ends the compression
0 otherwise
âˆ€i âˆˆ [1 . . . n]

1 if sequence xi , xj is in the compression âˆ€i âˆˆ [1 . . . n âˆ’ 1]
0 otherwise
âˆ€j âˆˆ [i + 1 . . . n]

The discriminative model can be now expressed as:
max z =

n
X

Î±i
i=1
nâˆ’1
X

Â· s(x, 0, i)

+

Î²i Â· s(x, i, n + 1)

+

n
X

i=1 j=i+1
n
X
i=1

413

Î³ij Â· s(x, i, j)
(15)

Clarke & Lapata

Constraint 1

Exactly one word can begin a sentence.
n
X

Î±i = 1

(16)

i=1

Constraint 2 If a word is included in the sentence it must either start the compression
or follow another word.

Î´j âˆ’ Î±j âˆ’

j
X

Î³ij = 0

(17)

i=1

âˆ€j : j âˆˆ [1 . . . n]
Constraint 3 If a word is included in the sentence it must be either followed by another
word or end the sentence.

Î´i âˆ’

n
X

Î³ij âˆ’ Î²i = 0

(18)

j=i+1

âˆ€i : i âˆˆ [1 . . . n]

Constraint 4

Exactly one word can end a sentence.
n
X

Î²i = 1

(19)

i=1

Again, the sequential constraints in Equations (16)â€“(19) are necessary to ensure that the
resulting combination of bigrams are valid.
The current formulation provides a single optimal compression given the model. However, McDonaldâ€™s (2006) dynamic programming algorithm is capable of returning the k-best
compressions; this is useful for their learning algorithm described later. In order to produce
k-best compressions, we must rerun the ILP with extra constraints which forbid previous
solutions. In other words, we first formulate the ILP as above, solve it, add its solution to
the k-best list, and then create a set of constraints that forbid the configuration of Î´i decision
variables which form the current solution. The procedure is repeated until k compressions
are found.
The computation of the compression score crucially relies on the dot product between
a high dimensional feature representation and a corresponding weight vector (see Equation (14)). McDonald (2006) employs a rich feature set defined over adjacent words and
individual parts-of-speech, dropped words and phrases from the source sentence, and dependency structures (also of the source sentence). These features are designed to mimic the
information presented in the previous noisy-channel and decision-tree models of Knight and
Marcu (2002). Features over adjacent words are used as a proxy to the language model of
the noisy channel. Unlike other models, which treat the parses as gold standard, McDonald
uses the dependency information as another form of evidence. Faced with parses that are
noisy the learning algorithm can reduce the weighting given to those features if they prove
414

Global Inference for Sentence Compression

poor discriminators on the training data. Thus, the model should be much more robust
and portable across different domains and training corpora.
The weight vector, w is learned using the Margin Infused Relaxed Algorithm (MIRA,
Crammer & Singer, 2003) a discriminative large-margin online learning technique (McDonald, Crammer, & Pereira, 2005b). This algorithm learns by compressing each sentence and
comparing the result with the gold standard. The weights are updated so that the score of
the correct compression (the gold standard) is greater than the score of all other compressions by a margin proportional to their loss. The loss function is the number of words falsely
retained or dropped in the incorrect compression relative to the gold standard. A source
sentence will have exponentially many compressions and thus exponentially many margin
constraints. To render learning computationally tractable, McDonald et al. (2005b) create
constraints only on the k compressions that currently have the highest score, bestk (x; w).
3.5 Constraints
We are now ready to describe our compression-specific constraints. The models presented
in the previous sections contain only sequential constraints and are thus equivalent to their
original formulation. Our constraints are linguistically and semantically motivated in a
similar fashion to the grammar checking component of Jing (2000). However, they do
not rely on any additional knowledge sources (such as a grammar lexicon or WordNet)
beyond the parse and grammatical relations of the source sentence. We obtain these from
RASP (Briscoe & Carroll, 2002), a domain-independent, robust parsing system for English.
However, any other parser with broadly similar output (e.g., Lin, 2001) could also serve our
purposes. Our constraints revolve around modification, argument structure, and discourse
related factors.
Modifier Constraints Modifier constraints ensure that relationships between head words
and their modifiers remain grammatical in the compression:
Î´i âˆ’ Î´j â‰¥ 0

(20)

âˆ€i, j : xj âˆˆ xi â€™s ncmods
Î´i âˆ’ Î´j â‰¥ 0

(21)

âˆ€i, j : xj âˆˆ xi â€™s detmods
Equation (20) guarantees that if we include a non-clausal modifier5 (ncmod) in the compression (such as an adjective or a noun) then the head of the modifier must also be included;
this is repeated for determiners (detmod) in (21). In Table 2 we illustrate how these constraints disallow the deletion of certain words (starred sentences denote compressions that
would not be possible given our constraints). For example, if the modifier word Pasok from
sentence (1a) is in the compression, then its head Party will also included (see (1b)).
We also want to ensure that the meaning of the source sentence is preserved in the
compression, particularly in the face of negation. Equation (22) implements this by forcing
not in the compression when the head is included (see sentence (2b) in Table 2). A similar
constraint is added for possessive modifiers (e.g., his, our), including genitives (e.g., Johnâ€™s
5. Clausal modifiers (cmod) are adjuncts modifying entire clauses. In the example â€œhe ate the cake because
he was hungryâ€, the because-clause is a modifier of the sentence â€œhe ate the cakeâ€.

415

Clarke & Lapata

1a.
1b.
2a.
2b.
2c.
3a.
3b.
3c.
3d.
3e.
3f.

He became a power player in Greek Politics in 1974, when he founded the
socialist Pasok Party.
*He became a power player in Greek Politics in 1974, when he founded the
Pasok.
We took these troubled youth who donâ€™t have fathers, and brought them into
a room to Dads who donâ€™t have their children.
*We took these troubled youth who do have fathers, and brought them into a
room to Dads who do have their children.
*We took these troubled youth who donâ€™t have fathers, and brought them into
a room to Dads who donâ€™t have children.
The chain stretched from Uganda to Grenada and Nicaragua, since the 1970s.
*Stretched from Uganda to Grenada and Nicaragua, since the 1970s.
*The chain from Uganda to Grenada and Nicaragua, since the 1970s.
*The chain stretched Uganda to Grenada and Nicaragua, since the 1970s.
*The chain stretched from to Grenada and Nicaragua, since the 1970s.
*The chain stretched from Uganda to Grenada Nicaragua, since the 1970s.
Table 2: Examples of compressions disallowed by our set of constraints.

gift), as shown in Equation (23). An example of the possessive constraint is given in
sentence (2c) in Table 2.
Î´i âˆ’ Î´j = 0

(22)

âˆ€i, j : xj âˆˆ xi â€™s ncmods âˆ§ xj = not
Î´i âˆ’ Î´j = 0

(23)

âˆ€i, j : xj âˆˆ xi â€™s possessive mods
Argument Structure Constraints We also define a few intuitive constraints that take
the overall sentence structure into account. The first constraint (Equation (24)) ensures
that if a verb is present in the compression then so are its arguments, and if any of the
arguments are included in the compression then the verb must also be included. We thus
force the program to make the same decision on the verb, its subject, and object (see
sentence (3b) in Table 2).
Î´i âˆ’ Î´j = 0

(24)

âˆ€i, j : xj âˆˆ subject/object of verb xi
Our second constraint forces the compression to contain at least one verb provided the
source sentence contains one as well:
X

Î´i â‰¥ 1

(25)

i:xi âˆˆverbs

The constraint entails that it is not possible to drop the main verb stretched from sentence (3a) (see also sentence (3c) in Table 2).
416

Global Inference for Sentence Compression

Other sentential constraints include Equations (26) and (27) which apply to prepositional phrases and subordinate clauses. These constraints force the introducing term
(i.e., the preposition, or subordinator) to be included in the compression if any word from
within the syntactic constituent is also included. By subordinator we mean wh-words
(e.g., who, which, how, where), the word that, and subordinating conjunctions (e.g., after,
although, because). The reverse is also true, i.e., if the introducing term is included, at
least one other word from the syntactic constituent should also be included.
Î´i âˆ’ Î´j â‰¥ 0

(26)

âˆ€i, j : xj âˆˆ PP/SUB
âˆ§xi starts PP/SUB
X

Î´i âˆ’ Î´j â‰¥ 0

(27)

i:xi âˆˆPP/SUB

âˆ€j : xj starts PP/SUB
As an example consider sentence (3d) from Table 2. Here, we cannot drop the preposition
from if Uganda is in the compression. Conversely, we must include from if Uganda is in the
compression (see sentence (3e)).
We also wish to handle coordination. If two head words are conjoined in the source
sentence, then if they are included in the compression the coordinating conjunction must
also be included:
(1 âˆ’ Î´i ) + Î´j â‰¥ 1

(28)

(1 âˆ’ Î´i ) + Î´k â‰¥ 1

(29)

Î´i + (1 âˆ’ Î´j ) + (1 âˆ’ Î´k ) â‰¥ 1

(30)

âˆ€i, j, k : xj âˆ§ xk conjoined by xi
Consider sentence (3f) from Table 2. If both Uganda and Nicaragua are present in the
compression, then we must include the conjunction and.
Finally, Equation (31) disallows anything within brackets in the source sentence from
being included in the compression. This is a somewhat superficial attempt at excluding
parenthetical and potentially unimportant material from the compression.
Î´i = 0

(31)

âˆ€i : xi âˆˆ bracketed words (inc parentheses)
Discourse Constraints Our discourse constraint concerns personal pronouns. Specifically, Equation (32) forces personal pronouns to be included in the compression. The
constraint is admittedly more important for generating coherent documents (as opposed to
individual sentences). It nevertheless has some impact on sentence-level compressions, in
particular when verbal arguments are missed by the parser. When these are pronominal,
constraint (32) will result in more grammatical output since some of the argument structure
of the source sentence will be preserved in the compression.
Î´i = 1
âˆ€i : xi âˆˆ personal pronouns
417

(32)

Clarke & Lapata

We should note that some of the constraints described above would be captured by
models that learn synchronous deletion rules from a corpus. For example, the noisy-channel
model of Knight and Marcu (2002) learns not to drop the head when the latter is modified
by an adjective or a noun, since the transformations DT NN â†’ DT or AJD NN â†’ ADJ are
almost never seen in the data. Similarly, the coordination constraint (Equations (28)â€“(30))
would be enforced using Turner and Charniakâ€™s (2005) special rules â€” they enhance their
parallel grammar with rules modeling more structurally complicated deletions than those
attested in their corpus. In designing our constraints we aimed at capturing appropriate
deletions for many possible models, including those that do not rely on a training corpus
or do not have an explicit notion of a parallel grammar (e.g., McDonald, 2006). The
modification constraints would presumably be redundant for the noisy-channel model, which
could otherwise benefit from more specialized constraints, e.g., targeting sparse rules or
noisy parse trees, however we leave this to future work.
Another feature of the modeling framework presented here is that deletions (or nondeletions) are treated as unconditional decisions. For example, we require not to drop the
noun in adjective-noun sequences if the adjective is not deleted as well. We also require to
always include a verb in the compression if the source sentence has one. These hardwired decisions could in some cases prevent valid compressions from being considered. For instance,
it is not possible to compress the sentence â€œthis is not appropriate behaviorâ€ to â€œthis is
not appropriateâ€ orâ€œBob loves Mary and John loves Susanâ€ to â€œBob loves Mary and John
Susanâ€. Admittedly we lose some expressive power, yet we ensure that the compressions
will be broadly grammatically, even for unsupervised or semi-supervised models. Furthermore, in practice we find that our models consistently outperform non-constraint-based
alternatives, without extensive constraint engineering.
3.6 Solving the ILP
As we mentioned earlier (Section 3.1), solving ILPs is NP-hard. In cases where the coefficient matrix is unimodular, it can be shown that the optimal solution to the linear
program is integral. Although the coefficient matrix in our problems is not unimodular, we
obtained integral solutions for all sentences we experimented with (approximately 3,000,
see Section 4.1 for details). We conjecture that this is due to the fact that all of our variables have 0, +1 or âˆ’1 coefficients in the constraints and therefore our constraint matrix
shares many properties of a unimodular matrix. We generate and solve an ILP for every
sentence we wish to compress. Solve times are less than a second per sentence (including
input-output overheads) for all models presented here.

4. Experimental Set-up
Our evaluation experiments were motivated by three questions: (1) Do the constraintbased compression models deliver performance gains over non-constraint-based ones? We
expect better compressions for the model variants which incorporate compression-specific
constraints. (2) Are there differences among constraint-based models? Here, we would like
to investigate how much modeling power is gained by the addition of the constraints. For
example, it may be the case that a state-of-the-art model like McDonaldâ€™s (2006) does not
benefit much from the addition of constraints. And that their effect is much bigger for less
418

Global Inference for Sentence Compression

sophisticated models. (3) How do the models reported in this paper port across domains?
In particular, we are interested in assessing whether the models and proposed constraints
are general and robust enough to produce good compressions for both written and spoken
texts.
We next describe the data sets on which our models were trained and tested (Section 4.1),
explain how model parameters were estimated (Section 4.2) and present our evaluation setup
(Section 4.3). We discuss our results in Section 5.
4.1 Corpora
Our intent was to assess the performance of the models just described on written and spoken
text. The appeal of written text is understandable since most summarization work today
focuses on this domain. Speech data not only provides a natural test-bed for compression
applications (e.g., subtitle generation) but also poses additional challenges. Spoken utterances can be ungrammatical, incomplete, and often contain artefacts such as false starts,
interjections, hesitations, and disfluencies. Rather than focusing on spontaneous speech
which is abundant in these artefacts, we conduct our study on the less ambitious domain
of broadcast news transcripts. This lies in-between the extremes of written text and spontaneous speech as it has been scripted beforehand and is usually read off on autocue.
Previous work on sentence compression has almost exclusively used the Ziff-Davis corpus
for training and testing purposes. This corpus originates from a collection of news articles
on computer products. It was created automatically by matching sentences that occur in
an article with sentences that occur in an abstract (Knight & Marcu, 2002). The abstract
sentences had to contain a subset of the source sentenceâ€™s words and the word order had
to remain the same. In earlier work (Clarke & Lapata, 2006) we have argued that the
Ziff-Davis corpus is not ideal for studying compression for several reasons. First, we showed
that human-authored compressions differ substantially from the Ziff-Davis which tends to
be more aggressively compressed. Second, humans are more likely to drop individual words
than lengthy constituents. Third, the test portion of the Ziff-Davis contains solely 32 sentences. This is an extremely small data set to reveal any statistically significant differences
among systems. In fact, previous studies relied almost exclusively on human judgments for
assessing the well-formedness of the compressed output, and significance tests are reported
for by-subjects analyses only.
We thus focused in the present study on manually created corpora. Specifically, we
asked annotators to perform sentence compression by removing tokens on a sentence-bysentence basis. Annotators were free to remove any words they deemed superfluous provided
their deletions: (a) preserved the most important information in the source sentence, and
(b) ensured the compressed sentence remained grammatical. If they wished, they could leave
a sentence uncompressed by marking it as inappropriate for compression. They were not
allowed to delete whole sentences even if they believed they contained no information content
with respect to the story as this would blur the task with abstracting. Following these
guidelines, our annotators produced compressions of 82 newspaper articles (1,433 sentences)
from the British National Corpus (BNC) and the American News Text corpus (henceforth
written corpus) and 50 stories (1,370 sentences) from the HUB-4 1996 English Broadcast
News corpus (henceforth spoken corpus). The written corpus contains articles from The LA
419

Clarke & Lapata

Times, Washington Post, Independent, The Guardian and Daily Telegraph. The spoken
corpus contains broadcast news from a variety of networks (CNN, ABC, CSPAN and NPR)
which have been manually transcribed and segmented at the story and sentence level. Both
corpora have been split into training, development and testing sets6 randomly on article
boundaries (with each set containing full stories) and are publicly available from http:
//homepages.inf.ed.ac.uk/s0460084/data/.
4.2 Parameter Estimation
In this work we present three compression models ranging from unsupervised to semisupervised, and fully supervised. The unsupervised model simply relies on a trigram language model for driving compression (see Section 3.4.1). This was estimated from 25 million tokens of the North American corpus using the CMU-Cambridge Language Modeling
Toolkit (Clarkson & Rosenfeld, 1997) with a vocabulary size of 50,000 tokens and GoodTuring discounting. To discourage one-word output we force the ILP to generate compressions whose length is no less than 40% of the source sentence (see the constraint in (9)).
The semi-supervised model is the weighted combination of a word-based significance score
with a language model (see Section 3.4.2). The significance score was calculated using
25 million tokens from the American News Text corpus. We optimized its weight (see
Equation (11)) on a small subset of the training data (three documents in each case) using Powellâ€™s method (Press, Teukolsky, Vetterling, & Flannery, 1992) and a loss function
based on the F-score of the grammatical relations found in the gold standard compression
and the systemâ€™s best compression (see Section 4.3 for details). The optimal weight was
approximately 1.8 for the written corpus and 2.2 for the spoken corpus.
McDonaldâ€™s (2006) supervised model was trained on the written and spoken training
sets. Our implementation used the same feature sets as McDonald, the only difference
being that our phrase structure and dependency features were extracted from the output of
Roarkâ€™s (2001) parser. McDonald uses Charniakâ€™s (2000) parser which performs comparably.
The model was learnt using k-best compressions. On the development data, we found that
k = 10 provided the best performance.
4.3 Evaluation
Previous studies have relied almost exclusively on human judgments for assessing the wellformedness of automatically derived compressions. These are typically rated by naive subjects on two dimensions, grammaticality and importance (Knight & Marcu, 2002). Although
automatic evaluation measures have been proposed (Riezler et al., 2003; Bangalore, Rambow, & Whittaker, 2000) their use is less widespread, we suspect due to the small size of
the test portion of the Ziff-Davis corpus which is commonly used in compression work.
We evaluate the output of our models in two ways. First, we present results using
an automatic evaluation measure put forward by Riezler et al. (2003). They compare
the grammatical relations found in the system compressions against those found in a gold
standard. This allows us to measure the semantic aspects of summarization quality in terms
of grammatical-functional information and can be quantified using F-score. Furthermore,
6. The splits are 908/63/462 sentences for the written corpus and 882/78/410 sentences for the spoken
corpus.

420

Global Inference for Sentence Compression

in Clarke and Lapata (2006) we show that relations-based F-score correlates reliably with
human judgments on compression output. Since our test corpora are larger than ZiffDavis (by more than a factor of ten), differences among systems can be highlighted using
significance testing.
Our implementation of the F-score measure used the grammatical relations annotations
provided by RASP (Briscoe & Carroll, 2002). This parser is particularly appropriate for the
compression task since it provides parses for both full sentences and sentence fragments and
is generally robust enough to analyze semi-grammatical sentences. We calculated F-score
over all the relations provided by RASP (e.g., subject, direct/indirect object, modifier; 15
in total).
In line with previous work we also evaluate our models by eliciting human judgments.
Following the work of Knight and Marcu (2002), we conducted two separate experiments.
In the first experiment participants were presented with a source sentence and its target
compression and asked to rate how well the compression preserved the most important
information from the source sentence. In the second experiment, they were asked to rate
the grammaticality of the compressed outputs. In both cases they used a five point rating
scale where a high number indicates better performance. We randomly selected 21 sentences
from the test portion of each corpus. These sentences were compressed automatically by
the three models presented in this paper with and without constraints. We also included
gold standard compressions. Our materials thus consisted of 294 (21 Ã— 2 Ã— 7) sourcetarget sentences. A Latin square design ensured that subjects did not see two different
compressions of the same sentence. We collected ratings from 42 unpaid volunteers, all self
reported native English speakers. Both studies were conducted over the Internet using a
custom build web interface. Examples of our experimental items are given in Table 3.

5. Results
Let us first discuss our results when compression output is evaluated in terms of F-score.
Tables 4 and 5 illustrate the performance of our models on the written and spoken corpora,
respectively. We also present the compression rate7 for each system. In all cases the
constraint-based models (+Constr) yield better F-scores than the non-constrained ones.
The difference is starker for the semi-supervised model (Sig). The constraints bring an
improvement of 17.2% on the written corpus and 18.3% on the spoken corpus. We further
examined whether performance differences among models are statistically significant, using
the Wilcoxon test. On the written corpus all constraint models significantly outperform the
models without constraints. The same tendency is observed on the spoken corpus except for
the model of McDonald (2006) which performs comparably with and without constraints.
We also wanted to establish which is the best constraint model. On both corpora we
find that the language model performs worst, whereas the significance model and McDonald
perform comparably (i.e., the F-score differences are not statistically significant). To get
a feeling for the difficulty of the task, we calculated how much our annotators agreed in
their compression output. The inter-annotator agreement (F-score) on the written corpus
was 65.8% and on the spoken corpus 73.4%. The agreement is higher on spoken texts since
they consists of many short utterances (e.g., Okay, Thatâ€™s it for now, Good night) that can
7. The term refers to the percentage of words retained from the source sentence in the compression.

421

Clarke & Lapata

Source

The aim is to give councils some control over the future growth of second
homes.
Gold
The aim is to give councils control over the growth of homes.
LM
The aim is to the future.
LM+Constr The aim is to give councils control.
Sig
The aim is to give councils control over the future growth of homes.
Sig+Constr The aim is to give councils control over the future growth of homes.
McD
The aim is to give councils.
McD+Constr The aim is to give councils some control over the growth of homes.
Source
The Clinton administration recently unveiled a new means to encourage
brownfields redevelopment in the form of a tax incentive proposal.
Gold
The Clinton administration unveiled a new means to encourage brownfields redevelopment in a tax incentive proposal.
LM
The Clinton administration in the form of tax.
LM+Constr The Clinton administration unveiled a means to encourage redevelopment in the form.
Sig
The Clinton administration unveiled a encourage brownfields redevelopment form tax proposal.
Sig+Constr The Clinton administration unveiled a means to encourage brownfields
redevelopment in the form of tax proposal.
McD
The Clinton unveiled a means to encourage brownfields redevelopment
in a tax incentive proposal.
McD+Constr The Clinton administration unveiled a means to encourage brownfields
redevelopment in the form of a incentive proposal.
Table 3: Example compressions produced by our systems (Source: source sentence, Gold:
gold-standard compression, LM: language model compression, LM+Constr: language model compression with constraints, Sig: significance model, Sig+Constr:
significance model with constraints, McD: McDonaldâ€™s (2006) compression model,
McD+Constr: McDonaldâ€™s (2006) compression model with constraints).

be compressed only very little or not all. Note that there is a marked difference between the
automatic and human compressions. Our best performing systems are inferior to human
output by more than 20 F-score percentage points.
Differences between the automatic systems and the human output are also observed
with respect to the compression rate. As can be seen the language model compresses most
aggressively, whereas the significance model and McDonald tend to be more conservative
and closer to the gold standard. Interestingly, the constraints do not necessarily increase
the compression rate. The latter increases for the significance model but decreases for
the language model and remains relatively constant for McDonald. It is straightforward to
impose the same compression rate for all constraint-based models (e.g., by forcing the model
P
to retain b tokens ni=1 Î´i = b). However, we refrained from doing this since we wanted our
422

Global Inference for Sentence Compression

Models
LM
Sig
McD
LM+Constr
Sig+Constr
McD+Constr
Gold

CompR
46.2
60.6
60.1
41.2
72.0
63.7
70.3

F-score
18.4
23.3
36.0
28.2âˆ—
40.5âˆ—â€ 
40.8âˆ—â€ 
â€”

Table 4: Results on the written corpus; compression rate (CompR) and grammatical relation F-score (F-score); âˆ— : +Constr model is significantly different from model
without constraints; â€  : significantly different from LM+Constr.
Models
LM
Sig
McD
LM+Constr
Sig+Constr
McD+Constr
Gold

CompR
52.0
60.9
68.6
49.5
78.4
68.5
76.1

F-score
25.4
30.4
47.6
34.8âˆ—
48.7âˆ—â€ 
50.1â€ 
â€”

Table 5: Results on the spoken corpus; compression rate (CompR) and grammatical relation F-score (F-score); âˆ— : +Constr model is significantly different from without
constraints; â€  : significantly different from LM+Constr.

models to regulate the compression rate for each sentence individually according to its
specific information content and structure.
We next consider the results of our human study which assesses in more detail the quality
of the generated compressions on two dimensions, namely grammaticality and information
content. F-score conflates these two dimensions and therefore in theory could unduly reward
a system that produces perfectly grammatical output without any information loss. Tables 6
and 7 show the mean ratings8 for each system (and the gold standard) on the written and
spoken corpora, respectively. We first performed an Analysis of Variance (Anova) to
examine the effect of different system compressions. The Anova revealed a reliable effect
on both grammaticality and importance for each corpus (the effect was significant by both
subjects and items (p < 0.01)).
We next examine the impact of the constraints (+Constr in the tables). In most cases
we observe an increase in ratings for both grammaticality and importance when a model
is supplemented constraints. Post-hoc Tukey tests reveal that the grammaticality and
importance ratings of the language model and significance model significantly improve with
8. All statistical tests reported subsequently were done using the mean ratings.

423

Clarke & Lapata

Models

Grammar
2.25â€ $

Importance

LM
Sig
McD

3.05â€ 

1.82â€ $
2.99â€ $
2.84â€ 

LM+Constr
Sig+Constr
McD+Constr
Gold

3.47âˆ—â€ 
3.76âˆ—
3.50â€ 
4.25

2.37âˆ—â€ $
3.53âˆ—
3.17â€ 
3.98

2.26â€ $

Table 6: Results on the written text corpus; average grammaticality score (Grammar) and
average importance score (Importance) for human judgments; âˆ— : +Constr model
is significantly different from model without constraints; â€  : significantly different
from gold standard; $ : significantly different from McD+Constr.

Models

Grammar
2.20â€ $

Importance

LM
Sig
McD

2.29â€ $
3.33â€ 

1.56â€ 
2.64â€ 
3.32â€ 

LM+Constr
Sig+Constr
McD+Constr
Gold

3.18âˆ—â€ 
3.80âˆ—â€ 
3.60â€ 
4.45

2.49âˆ—â€ $
3.69âˆ—â€ 
3.31â€ 
4.25

Table 7: Results on the spoken text corpus; average grammaticality score (Grammar) and
average importance score (Importance) for human judgments; âˆ— : +Constr model
is significantly different from model without constraints; â€  : significantly different
from gold standard; $ : significantly different from McD+Constr.

the constraints (Î± < 0.01). In contrast, McDonaldâ€™s system sees a numerical improvement
with the additional constraints, but this difference is not statistically significant. These
tendencies are observed on the spoken and written corpus.
Upon closer inspection, we can see that the constraints influence considerably the
grammaticality of the unsupervised and semi-supervised systems. Tukey tests reveal that
LM+Constr and Sig+Constr are as grammatical as McD+Constr. In terms of importance,
Sig+Constr and McD+Constr are significantly better than LM+Constr (Î± < 0.01). This
is not surprising given that LM+Constr is a very simple model without a mechanism for
highlighting important words in a sentence. Interestingly, Sig+Constr performs as well
as McD+Constr in retaining the most important words, despite the fact that it requires
minimal supervision. Although constraint-based models overall perform better than models without constraints, they receive lower ratings (for grammaticality and importance) in
comparison to the gold standard. And the differences are significant in most cases.
424

Global Inference for Sentence Compression

In summary, we observe that the constraints boost performance. This is more pronounced for compression models that are either unsupervised or use small amounts of
parallel data. For example, a simple model like Sig yields performance comparable to
McDonald (2006) when constraints are taken into account. This is an encouraging result
suggesting that ILP can be used to create good compression models with relatively little
effort (i.e., without extensive feature engineering or elaborate knowledge sources). Performance gains are also obtained for competitive models like McDonaldâ€™s that are fully
supervised. But these gains are smaller, presumably because the initial model contains a
rich feature representation consisting of syntactic information and generally does a good job
at producing grammatical output. Finally, our improvements are consistent across corpora
and evaluation paradigms.

6. Conclusions
In this paper we have presented a novel method for automatic sentence compression. A key
aspect of our approach is the use of integer linear programming for inferring globally optimal
compressions in the presence of linguistically motivated constraints. We have shown how
previous formulations of sentence compression can be recast as ILPs and extended these
models with local and global constraints ensuring that the compressed output is structurally
and semantic well-formed. Contrary to previous work that has employed ILP solely for
decoding, our models integrate learning with inference in a unified framework.
Our experiments have demonstrated the advantages of the approach. Constraint-based
models consistently bring performance gains over models without constraints. These improvements are more impressive for models that require little or no supervision. A case
in point here is the significance model discussed above. The no-constraints incarnation of
this model performs poorly and considerably worse than McDonaldâ€™s (2006) state-of-the-art
model. The addition of constraints improves the output of this model so that its performance is indistinguishable from McDonald. Note that the significance model requires a
small amount of training data (50 parallel sentences), whereas McDonald is trained on hundreds of sentences. It also presupposes little feature engineering, whereas McDonald utilizes
thousands of features. Some effort is associated with framing the constraints, however these
are created once and are applied across models and corpora. We have also observed small
performance gains for McDonaldâ€™s system when the latter is supplemented with constraints.
Larger improvements are possible with more sophisticated constraints, however our intent
was to devise a set of general constraints that are not tuned to the mistakes of any specific
system in particular.
Future improvements are many and varied. An obvious extension concerns our constraint set. Currently our constraints are mostly syntactic and consider each sentence in
isolation. By incorporating discourse constraints we could highlight words that are important at the document-level. Presumably words topical in a document should be retained in
the compression. Other constraints could manipulate the compression rate. For example,
we could encourage a higher compression rate for longer sentences. Another interesting
direction includes the development of better objective functions for the compression task.
The objective functions presented so far rely on first or second-order Markov assumptions.
Alternative objectives could take into account the structural similarity between the source
425

Clarke & Lapata

sentence and its target compression; or whether they share the same content which could
be operationalized in terms of entropy.
Beyond the task and systems presented in this paper, we believe the approach holds
promise for other generation applications using decoding algorithms for searching the space
of possible outcomes. Examples include sentence-level paraphrasing, headline generation,
and summarization.

Acknowledgments
We are grateful to our annotators Vasilis Karaiskos, Beata Kouchnir, and Sarah Luger.
Thanks to Jean Carletta, Frank Keller, Steve Renals, and Sebastian Riedel for helpful
comments and suggestions and to the anonymous referees whose feedback helped to substantially improve the present paper. Lapata acknowledges the support of EPSRC (grant
GR/T04540/01). A preliminary version of this work was published in the proceedings of
ACL 2006.

References
Aho, A. V., & Ullman, J. D. (1969). Syntax directed translations and the pushdown assembler. Journal of Computer and System Sciences, 3, 37â€“56.
Bangalore, S., Rambow, O., & Whittaker, S. (2000). Evaluation metrics for generation.
In Proceedings of the first International Conference on Natural Language Generation,
pp. 1â€“8, Mitzpe Ramon, Israel.
Barzilay, R., & Lapata, M. (2006). Aggregation via set partitioning for natural language
generation. In Proceedings of the Human Language Technology Conference of the
North American Chapter of the Association for Computational Linguistics, pp. 359â€“
366, New York, NY, USA.
Bramsen, P., Deshpande, P., Lee, Y. K., & Barzilay, R. (2006). Inducing temporal graphs.
In Proceedings of the 2006 Conference on Empirical Methods in Natural Language
Processing, pp. 189â€“198, Sydney, Australia.
Briscoe, E. J., & Carroll, J. (2002). Robust accurate statistical annotation of general text. In
Proceedings of the Third International Conference on Language Resources and Evaluation, pp. 1499â€“1504, Las Palmas, Gran Canaria.
Charniak, E. (2000). A maximum-entropy-inspired parser. In Proceedings of the 1st North
American Annual Meeting of the Association for Computational Linguistics, pp. 132â€“
139, Seattle, WA, USA.
Clarke, J., & Lapata, M. (2006). Models for sentence compression: A comparison across
domains, training requirements and evaluation measures. In Proceedings of the 21st
International Conference on Computational Linguistics and 44th Annual Meeting of
the Association for Computational Linguistics, pp. 377â€“384, Sydney, Australia.
Clarkson, P., & Rosenfeld, R. (1997). Statistical language modeling using the CMUâ€“
Cambridge toolkit. In Proceedings of Eurospeechâ€™97, pp. 2707â€“2710, Rhodes, Greece.
426

Global Inference for Sentence Compression

Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1992). Intoduction to Algorithms. The
MIT Press.
Corston-Oliver, S. (2001). Text Compaction for Display on Very Small Screens. In Proceedings of the Workshop on Automatic Summarization at the 2nd Meeting of the North
American Chapter of the Association for Computational Linguistics, pp. 89â€“98, Pittsburgh, PA, USA.
Crammer, K., & Singer, Y. (2003). Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Research, 3, 951â€“991.
Dantzig, G. B. (1963). Linear Programming and Extensions. Princeton University Press,
Princeton, NJ, USA.
Denis, P., & Baldridge, J. (2007). Joint determination of anaphoricity and coreference
resolution using integer programming. In Human Language Technologies 2007: The
Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pp. 236â€“243, Rochester, NY.
Dras, M. (1999). Tree Adjoining Grammar and the Reluctant Paraphrasing of Text. Ph.D.
thesis, Macquarie University.
Galley, M., & McKeown, K. (2007). Lexicalized markov grammars for sentence compression.
In In Proceedings of the North American Chapter of the Association for Computational
Linguistics, pp. 180â€“187, Rochester, NY, USA.
Gomory, R. E. (1960). Solving linear programming problems in integers. In Bellman,
R., & Hall, M. (Eds.), Combinatorial analysis, Proceedings of Symposia in Applied
Mathematics, Vol. 10, Providence, RI, USA.
Grefenstette, G. (1998). Producing Intelligent Telegraphic Text Reduction to Provide an
Audio Scanning Service for the Blind. In Hovy, E., & Radev, D. R. (Eds.), Proceedings
of the AAAI Symposium on Intelligent Text Summarization, pp. 111â€“117, Stanford,
CA, USA.
Hori, C., & Furui, S. (2004). Speech summarization: an approach through word extraction
and a method for evaluation. IEICE Transactions on Information and Systems, E87D (1), 15â€“25.
Jing, H. (2000). Sentence reduction for automatic text summarization. In Proceedings of
the 6th Applied Natural Language Processing Conference, pp. 310â€“315, Seattle,WA,
USA.
Knight, K., & Marcu, D. (2002). Summarization beyond sentence extraction: a probabilistic
approach to sentence compression. Artificial Intelligence, 139 (1), 91â€“107.
Land, A. H., & Doig, A. G. (1960). An automatic method for solving discrete programming
problems. Econometrica, 28, 497â€“520.
Lin, C.-Y. (2003). Improving summarization performance by sentence compression â€” a pilot
study. In Proceedings of the 6th International Workshop on Information Retrieval with
Asian Languages, pp. 1â€“8, Sapporo, Japan.
Lin, D. (2001). LaTaT: Language and text analysis tools. In Proceedings of the first Human
Language Technology Conference, pp. 222â€“227, San Francisco, CA, USA.
427

Clarke & Lapata

Marciniak, T., & Strube, M. (2005). Beyond the pipeline: Discrete optimization in NLP. In
Proceedings of the Ninth Conference on Computational Natural Language Learning,
pp. 136â€“143, Ann Arbor, MI, USA.
McDonald, R. (2006). Discriminative sentence compression with soft syntactic constraints.
In Proceedings of the 11th Conference of the European Chapter of the Association for
Computational Linguistics, Trento, Italy.
McDonald, R., Crammer, K., & Pereira, F. (2005a). Flexible text segmentation with structured multilabel classification. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pp.
987â€“994, Vancouver, BC, Canada.
McDonald, R., Crammer, K., & Pereira, F. (2005b). Online large-margin training of dependency parsers. In 43rd Annual Meeting of the Association for Computational
Linguistics, pp. 91â€“98, Ann Arbor, MI, USA.
Nemhauser, G. L., & Wolsey, L. A. (1988). Integer and Combinatorial Optimization. WileyInterscience series in discrete mathematicals and opitmization. Wiley, New York, NY,
USA.
Nguyen, M. L., Shimazu, A., Horiguchi, S., Ho, T. B., & Fukushi, M. (2004). Probabilistic
sentence reduction using support vector machines. In Proceedings of the 20th international conference on Computational Linguistics, pp. 743â€“749, Geneva, Switzerland.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1992). Numerical
Recipes in C: The Art of Scientific Computing. Cambridge University Press, New
York, NY, USA.
Punyakanok, V., Roth, D., Yih, W., & Zimak, D. (2004). Semantic role labeling via integer linear programming inference. In Proceedings of the International Conference on
Computational Linguistics, pp. 1346â€“1352, Geneva, Switzerland.
Riedel, S., & Clarke, J. (2006). Incremental integer linear programming for non-projective
dependency parsing. In Proceedings of the 2006 Conference on Empirical Methods in
Natural Language Processing, pp. 129â€“137, Sydney, Australia.
Riezler, S., King, T. H., Crouch, R., & Zaenen, A. (2003). Statistical sentence condensation
using ambiguity packing and stochastic disambiguation methods for lexical-functional
grammar. In Human Language Technology Conference and the 3rd Meeting of the
North American Chapter of the Association for Computational Linguistics, pp. 118â€“
125, Edmonton, Canada.
Roark, B. (2001). Probabilistic top-down parsing and language modeling. Computational
Linguistics, 27 (2), 249â€“276.
Roth, D. (1998). Learning to resolve natural language ambiguities: A unified approach. In
In Proceedings of the 15th of the American Association for Artificial Intelligence, pp.
806â€“813, Madison, WI, USA.
Roth, D., & Yih, W. (2004). A linear programming formulation for global inference in
natural language tasks. In Proceedings of the Annual Conference on Computational
Natural Language Learning, pp. 1â€“8, Boston, MA, USA.
428

Global Inference for Sentence Compression

Roth, D., & Yih, W. (2005). Integer linear programming inference for conditional random
fields. In Proceedings of the International Conference on Machine Learning, pp. 737â€“
744, Bonn.
Sarawagi, S., & Cohen, W. W. (2004). Semi-markov conditional random fields for information extraction. In Advances in Neural Information Processing Systems, Vancouver,
BC, Canada.
Shieber, S., & Schabes, Y. (1990). Synchronous tree-adjoining grammars. In Proceedings of the 13th International Conference on Computational Linguistics, pp. 253â€“258,
Helsinki, Finland.
Turner, J., & Charniak, E. (2005). Supervised and unsupervised learning for sentence
compression. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pp. 290â€“297, Ann Arbor, MI, USA.
Vandeghinste, V., & Pan, Y. (2004). Sentence compression for automated subtitling: A
hybrid approach. In Marie-Francine Moens, S. S. (Ed.), Text Summarization Branches
Out: Proceedings of the ACL-04 Workshop, pp. 89â€“95, Barcelona, Spain.
Williams, H. P. (1999). Model Building in Mathematical Programming (4th edition). Wiley.
Winston, W. L., & Venkataramanan, M. (2003). Introduction to Mathematical Programming: Applications and Algorithms (4th edition). Duxbury.
Zajic, D., Door, B. J., Lin, J., & Schwartz, R. (2007). Multi-candidate reduction: Sentence
compression as a tool for document summarization tasks. Information Processing
Management Special Issue on Summarization, 43 (6), 1549â€“1570.

429

Journal of Artificial Intelligence Research 31 (2008) 259-272

Submitted 08/07; published 02/08

On the Expressiveness of Levesqueâ€™s Normal Form
Yongmei Liu

ymliu@mail.sysu.edu.cn

Department of Computer Science
Sun Yat-sen University
Guangzhou 510275, China

Gerhard Lakemeyer

gerhard@cs.rwth-aachen.de

Department of Computer Science
RWTH Aachen
52056 Aachen, Germany

Abstract
Levesque proposed a generalization of a database called a proper knowledge base (KB),
which is equivalent to a possibly infinite consistent set of ground literals. In contrast to
databases, proper KBs do not make the closed-world assumption and hence the entailment
problem becomes undecidable. Levesque then proposed a limited but efficient inference
method V for proper KBs, which is sound and, when the query is in a certain normal
form, also logically complete. He conjectured that for every first-order query there is an
equivalent one in normal form. In this note, we show that this conjecture is false. In fact,
we show that any class of formulas for which V is complete must be strictly less expressive
than full first-order logic. Moreover, in the propositional case it is very unlikely that a
formula always has a polynomial-size normal form.

1. Introduction
As argued by Levesque (1998), there is only one deductive technique efficient enough to be
feasible on knowledge bases (KBs) of the size seemingly required for common-sense reasoning: the deduction underlying classical database query evaluation. And yet, databases by
themselves are too restricted to serve as the representational scheme for common-sense reasoning, since they require, among other things, complete knowledge of the domain. Levesque
proposed a generalization of a database called a proper knowledge base, which is equivalent
to a possibly infinite consistent set of ground literals. To illustrate what is meant by a
proper KB consider the following example:
â€¢ Ann likes Bob, and Dan likes Fred.
Likes(ann, bob)
Likes(dan, fred)
â€¢ Ann does not like Dan.
Â¬Likes(ann, dan)
â€¢ Carol likes everyone.
âˆ€x. Likes(carol, x)
â€¢ Eve does not like anyone other than Ann and herself.
âˆ€x. x 6= ann âˆ§ x 6= eve âŠƒ Â¬Likes(eve, x)
c
2008
AI Access Foundation. All rights reserved.

Liu & Lakemeyer

In contrast to databases, proper KBs do not make the closed-world assumption. For
example, while Â¬Likes(eve, fred) follows from the above KB (if we assume unique names),
neither Likes(ann, eve) nor Â¬Likes(ann, eve) does. Sadly, even this very restricted form of
incompleteness renders the entailment problem undecidable, as entailment from an empty
KB reduces to validity in classical logic.
Nevertheless, given KBs like the above many queries seem easy to answer. For example,
consider the formula
Likes(eve, carol) âŠƒ Likes(carol, eve),
which follows from the KB simply because Likes(carol, eve) does. In his work Levesque
devised a limited but efficient inference mechanism V which gets examples like these right
at the expense of being incomplete on others, that is, V sometimes answers â€œdonâ€™t knowâ€
even though the query is logically entailed.
To give a flavor of how V works, consider a sentence Î± in conjunctive normal form
(CNF), that is Î± = c1 âˆ§ c2 âˆ§ . . . âˆ§ cn , where each ci is a disjunction of ground literals. In
order to see whether Î± follows from the KB, V simply checks whether each ci contains a
literal which is an instance of one of the sentences in the KB. Such an evaluation-based
scheme is clearly sound but also easily seen to be incomplete. For example, V would return
â€œdonâ€™t knowâ€ when given the query Likes(ann, eve) âˆ¨ Â¬Likes(ann, eve), as neither literal is
contained in the KB.
In his paper, Levesque introduced a certain normal form (NF) for sentences and proved
that V is logically complete for queries in NF. In the propositional case, examples of
sentences in NF are those in CNF which do not contain tautological clauses and which
are otherwise closed under resolution. Since every propositional sentence is equivalent to
a sentence in this form, it follows immediately that every propositional sentence can be
converted into an equivalent one in NF.
Levesque then conjectured that for every sentence in first-order logic there is also an
equivalent one in NF . In this note, we show that the above conjecture of Levesque is false.
In fact, we can show that any class of formulas for which V is complete must be strictly less
expressive than full first-order logic. Moreover, in the propositional case it is very unlikely
that a formula always has a polynomial-size normal form.
Note that Levesqueâ€™s conjecture is weaker than the statement that there exists an algorithm which converts every first-order sentence into an equivalent one in NF. The latter
statement can be easily refuted since whether a first-order sentence is entailed by a proper
KB is undecidable, but whether a NF sentence is entailed by a proper KB is decidable (V
is such a decision procedure).
In the next section, we briefly review Levesqueâ€™s evaluation-based inference method for
proper KBs. Section 3 contains our main result, that is, we show that not every sentence has
an equivalent normal form. Section 4 considers the size of NF formulas in the propositional
case.

2. Levesqueâ€™s Evaluation-Based Reasoning Procedure V
The underlying language L is a standard first-order dialect with equality. There are countably infinitely many first-order variables and predicate symbols of every arity (including
the binary equality predicate). In addition there is a countably infinite set C = {d1 , d2 , . . .}
260

On the Expressiveness of Levesqueâ€™s Normal Form

of constants (but no other function symbols). The logical connectives are Â¬, âˆ§, and âˆ€. The
atomic formulas of L are predicate symbols with variables or constants as arguments. The
set of formulas of L is the least set which contains the atomic formulas, and if Î± and Î² are
in the set and x is a variable, then Â¬Î±, Î± âˆ§ Î² and âˆ€x.Î± are in the set.
We sometimes refer to the propositional subset of the language, which consists of the
ground atoms of L other than equality and is closed under negation and conjunction.
Some Notation: As usual, equality is written as = using infix notation. We will
freely use the connectives âˆ¨, âŠƒ, â‰¡, and âˆƒ, which are understood as the usual abbreviations.
Formulas without free variables are called sentences. Variables are written as x, y, z with
sub- and superscripts. By ewffs we mean quantifier-free formulas whose only predicate is
equality. For example, (x = y âˆ§ z 6= d1 ) is an ewff. We use âˆ€Ï† to denote the universal
closure of Ï†. For example, âˆ€(x = y âˆ§ x 6= z âŠƒ P (x, y, z)) stands for âˆ€xâˆ€yâˆ€z.x = y âˆ§ x 6= z âŠƒ
P (x, y, z). We write Ï†xd to denote Ï† with all free occurrences of x replaced by constant d. A
clause is a disjunction of literals, which we identify with the set of literals contained in it.
We let the meta-variable c range over clauses and we write c to denote the set {l | l âˆˆ c},
V
where l is the complement of literal l. When Î“ is a finite set of formulas, we write Î“
to denote the conjunction of its elements (and true, when Î“ is empty). We use H(Î“) to
denote the set of constants appearing in the set of formulas Î“ and H + (Î“) to denote the
set of constants appearing in Î“ plus an extra one not occurring in Î“. The set returned by
H + (Î“) can be made unique by assuming that the constants are ordered and letting the new
constant be the least constant not appearing in Î“. When Î“ is a singleton {Ï†} we simply
write H(Ï†) or H + (Ï†).
Levesque considered a special class of Tarskian interpretations called standard interpretations, where equality is interpreted as identity and the set of constants is isomorphic with
the domain of discourse. As shown by the following definition and theorem, the restriction
to standard interpretations can be captured precisely by a set of axioms, provided we limit
ourselves to what is logically implied by finite sets of sentences.
Definition 1 Let the set E consist of the following axioms:
1. âˆ€x.x = x;
2. âˆ€(xi = y âŠƒ (P (x1 , . . . , xi , . . . , xn ) âŠƒ P (x1 , . . . , y, . . . , xn )));
3. {(di 6= dj ) | i 6= j}.
(1) â€“ (2) are a version of the axioms of equality. Here P ranges over all predicate symbols
including equality. (3) asserts the unique names assumption for constants.
Theorem 2 (Levesque) Let Î“ be a finite set of sentences. Then E âˆª Î“ |= Ï† iff every
standard interpretation of Î“ is also a model of Ï†.
From now on we write Î“ |=E Ï† for E âˆª Î“ |= Ï†.
A database can be viewed as a maximally consistent set of ground literals. Levesque
proposed a generalization of a database called a proper KB, which is equivalent to a (possibly
infinite) consistent set of ground literals.
In the following we use e to range over ewffs and Ï to range over atoms (excluding
equality) whose arguments are distinct variables.
261

Liu & Lakemeyer

Definition 3 (Levesque) A set of sentences Î£ is proper if E âˆª Î£ is consistent, Î£ is finite
and every sentence in Î£ has the form âˆ€(e âŠƒ Ï) or âˆ€(e âŠƒ Â¬Ï).
In the propositional case, the definition simplifies to Î£ being a finite consistent set of
ground literals excluding equality. (As equality plays no role in this case, E can be ignored.)
In general, a proper KB Î£ represents the set of ground literals lits(Î£) = {lÎ¸ | âˆ€(e âŠƒ
l) âˆˆ Î£ and E |= eÎ¸}, which is consistent, since E âˆª Î£ is consistent. As a special case, a
database can be represented as a proper KB: each relation R = {d~1 , . . . , d~m } is represented
by âˆ€(e âŠƒ R(~x)) and âˆ€(Â¬e âŠƒ Â¬R(~x)), where e is ~x = d~1 âˆ¨. . .âˆ¨~x = d~m . But more importantly,
a proper KB can represent an incomplete set of literals, by specifying some positive instances
and some negative instances and leaving the status of the rest open.
Here is the example from the introduction formulated as a proper KB. The rephrasing
is needed as the predicates of the right hand sides of the implications may only mention
distinct variables.
â€¢ Ann likes Bob, and Dan likes Fred.
âˆ€xâˆ€y. x = ann âˆ§ y = bob âˆ¨ x = dan âˆ§ y = fred âŠƒ Likes(x, y)
â€¢ Ann does not like Dan.
âˆ€xâˆ€y. x = ann âˆ§ y = dan âŠƒ Â¬Likes(x, y)
â€¢ Carol likes everyone.
âˆ€xâˆ€y. x = carol âŠƒ Likes(x, y)
â€¢ Eve does not like anyone other than Ann and herself.
âˆ€xâˆ€y. x = eve âˆ§ y 6= ann âˆ§ y 6= eve âŠƒ Â¬Likes(x, y)
Again, note that this information cannot be expressed in a traditional database where, for
example, we cannot leave open whether Ann likes Eve.
Levesqueâ€™s evaluation-based inference procedure V for proper KBs is defined as follows.
We use Î¸ to range over substitutions of all variables by constants, and write Ï†Î¸ to mean
the result of applying Î¸ to formula Ï†. We restrict our attention to Boolean queries, that
is, sentences from L. Given a proper KB Î£ and a sentence from L, V returns one of three
values 0 (known to be false), 1 (known to be true), or 12 (unknown). More precisely,
1. V [Î£, ÏÎ¸] =

ï£±
ï£´
ï£² 1

0

ï£´
ï£³

1
2

if there is a âˆ€(e âŠƒ Ï) in Î£ such that V [Î£, eÎ¸] = 1
if there is a âˆ€(e âŠƒ Â¬Ï) in Î£ such that V [Î£, eÎ¸] = 1
otherwise

2. V [Î£, d = dâ€² ] = 1 if d is identical to dâ€² , and 0 otherwise;
3. V [Î£, Â¬Ï†] = 1 âˆ’ V [Î£, Ï†];
4. V [Î£, Ï† âˆ§ Ïˆ] = min{V [Î£, Ï†], V [Î£, Ïˆ]};
5. V [Î£, âˆ€xÏ†] = mindâˆˆH + (Î£âˆª{Ï†}) V [Î£, Ï†xd ].
262

On the Expressiveness of Levesqueâ€™s Normal Form

It is not hard to show that this procedure is logically sound, that is, whenever it returns
1 or 0, either the query or its negation follows from the knowledge base. V is also obviously
decidable as quantification is handled by a finite number of variable substitutions. As shown
by Liu and Levesque (2003), it is also efficient in the sense of database retrieval.
To see why V is incomplete, let Î£ be the set of sentences in our example KB and
Ï† = (Likes(ann, eve) âˆ¨ Â¬Likes(ann, eve)). Then Ï† obviously follows from Î£, yet V [Î£, Ï†] = 12
because V returns 12 for both Likes(ann, eve) and Â¬Likes(ann, eve). The problem is, roughly,
that V requires one of the disjuncts to be derivable in order for the whole disjunction to be
derivable.
For a slightly more complex example, let Ï† = (p âŠƒ q)âˆ§(q âŠƒ r), where p = Likes(ann, bob),
q = Likes(ann, eve), and r = Likes(ann, dan). Then again, V [Î£, Ï†] = 12 , but the correct
answer should be 0 since Î£ |= Â¬Ï† because Î£ |= p and Î£ |= Â¬r. However, notice that the
clauses (p âŠƒ q) and (q âŠƒ r) entail the clause (p âŠƒ r). If we were to conjoin (p âŠƒ r) to Ï†,
logical equivalence would be preserved and V would now return the correct answer 0 since
V [Î£, p] = 1 and V [Î£, r] = 0.
Despite this limitation, Levesque showed that for queries in a certain normal form called
NF, V is actually complete. We first state the result, followed by the definition of NF .
Theorem 4 (Levesque) Let Î£ be proper. Then
for every Ï† âˆˆ NF, V [Î£, Ï†] = 1 iff Î£ |=E Ï†; and V [Î£, Ï†] = 0 iff Î£ |=E Â¬Ï†.
The definition of NF is based on that of logical separability:
Definition 5 (Levesque) A set Î“ of sentences is logically separable iff for every consistent
set of ground literals L, if L âˆª Î“ has no standard interpretation, then L âˆª {Ï†} is inconsistent
for some Ï† âˆˆ Î“.
The intuition behind logical separability is that if a consistent set of literals entails a disjunction, then one of the disjuncts must be entailed. To see this, consider the propositional
case with Î“ = {Â¬p, Â¬q} and L a consistent set of propositional literals. Suppose LâˆªÎ“ has no
standard interpretation, which in the propositional case is the same as L âˆª Î“ is inconsistent
or, equivalently, L |= (p âˆ¨ q). Then L must contain either p or q. Hence either L âˆª {Â¬p} or
L âˆª {Â¬q} is inconsistent, that is, either L |= p or L |= q. In any cases, this proves that Î“ is
logically separable.
The set {p, Â¬p}, on the other hand, is not logically separable. This is because {p, Â¬p} by
itself is already inconsistent and we can let L be the empty set. In this case, both L âˆª {p}
and L âˆª {Â¬p} are consistent.
Definition 6 (Levesque) NF is the least set such that
1. if Ï† is a ground atom or ewff, then Ï† âˆˆ NF;
2. if Ï† âˆˆ NF, then Â¬Ï† âˆˆ NF ;
3. if Î“ âŠ† NF, Î“ is logically separable, and Î“ is finite, then

V

Î“ âˆˆ NF ;

4. if Î“ âŠ† NF, Î“ is logically separable, and for some Ï†, Î“ = {Ï†xd | d âˆˆ C}, then âˆ€xÏ† âˆˆ NF.
263

Liu & Lakemeyer

(1) and (2) say, roughly, that NF contains all ground atoms and is closed under negation.
(3) and (4) say that closure under conjunction and universal generalization is restricted to
formulas which are logically separable.
The idea behind the definition is that a formula in NF , in a sense, does not contain
any logical puzzles. This is the case, for example, for any non-tautologous clause. To see
why, consider any consistent set of literals. Similar to the earlier example of {Â¬p, Â¬q}, it
can be shown that the set is logically separable. Hence the conjunction of the literals and
its negation, which is a clause, are in NF. On the other hand, a tautology like (p âˆ¨ Â¬p) is
not in NF. As shown above, the set {p, Â¬p} is not logically separable. Hence neither p âˆ§ Â¬p
nor its negation, that is, (p âˆ¨ Â¬p) is in NF.
Levesque (1998) showed that in the propositional case, a CNF formula is in NF if its
clauses are non-tautologous and closed under resolution, that is, the resolvent of any two
of the clauses also belongs to the clauses. Consider Î± = (p âŠƒ q) âˆ§ (q âŠƒ r) from our
earlier example. It is not in NF since its clauses are not closed under resolution. However,
(p âŠƒ q) âˆ§ (q âŠƒ r) âˆ§ (p âŠƒ r) is in NF.
In the first-order case, two examples of formulas in NF are âˆ€x(P (x) âˆ§ Q(x)) and
âˆƒx(P (x) âˆ¨ Q(x)). To see why let d be any constant. Just as {p, q} is logically separable, so
is {P (d), Q(d)}. Thus (P (d) âˆ§ Q(d)) is in NF . Now consider Î“ = {(P (d) âˆ§ Q(d)) | d âˆˆ C}.
Let L be any consistent set of literals. If L âˆª Î“ has no standard model, then L must contain
Â¬P (d) or Â¬Q(d) for some d, hence L âˆª {(P (d) âˆ§ Q(d))} is inconsistent for some d. Thus Î“
is logically separable, and so âˆ€x(P (x) âˆ§ Q(x)) is in NF. Similarly, âˆ€x(Â¬P (x) âˆ§ Â¬Q(x)) is
in NF. Therefore, Â¬âˆ€x(Â¬P (x) âˆ§ Â¬Q(x)), that is, âˆƒx(P (x) âˆ¨ Q(x)), is in NF.
Note that the use of the expression normal form is somewhat non-standard. Unlike
traditional normal forms like CNF, it is not even clear whether membership in NF is
decidable. While Levesque pointed out a number of classes of first-order formulas where
membership in NF can be decided syntactically, this is unlikely in general. For example,
he showed that âˆƒx.Â¬R(a, x) âˆ§ R(x, b) is not in NF.
It turns out that Levesqueâ€™s original definition of logical separability (Def. 5) is a little
too strong and rules out certain sentences from being in NF which we definitely would like
to be in. The problem with the definition is that it mixes the use of standard and regular
Tarskian interpretations. This has the peculiar effect that formulas like âˆ€x(x = a âŠƒ P (x)),
which make up proper KBs, are themselves not in NF.1 To see why, by the definition of
NF, for âˆ€x(x = a âŠƒ P (x)), that is, âˆ€xÂ¬(x = a âˆ§ Â¬P (x)), to be in NF, we must have
(d = a âˆ§ Â¬P (d)) âˆˆ NF for every constant d, which requires that {d = a, Â¬P (d)} be logically
separable. However, let b be a constant distinct from a, then {b = a, Â¬P (b)} is not logically
separable. The reason is that {b = a, Â¬P (b)} has no standard model because of the built-in
unique names assumption, but both {b = a} and {Â¬P (b)} are consistent in classical logic.
It turns out that the above anomaly is easy to fix by using the following, slightly weaker
definition of logical separability, which only talk about standard interpretations.
Definition 7 A set Î“ of sentences is logically separable iff for every consistent set of ground
literals L, if LâˆªÎ“ has no standard interpretation, then Lâˆª{Ï†} has no standard interpretation
for some Ï† âˆˆ Î“.
1. This anomaly was first observed by Thomas Eiter (personal communication).

264

On the Expressiveness of Levesqueâ€™s Normal Form

With the new definition, {b = a, Â¬P (b)} is now logically separable, since {b = a} has no
standard model. As a result, we can show that âˆ€x(x = a âŠƒ P (x)) is now in NF. Note that
NF using the new definition of logical separability is strictly bigger than the original NF,
and we will use the new version from now on. Our main result, which says that there are
sentences with no equivalent sentence in NF, then trivially extends to Levesqueâ€™s original
definition.
Before we turn to that, let us briefly recall what NF is good for and point to some related
work. When a user poses a query in NF to a proper KB, then all we need is V to obtain
a correct (sound and complete) answer with respect to logical entailment. Moreover, as we
mentioned earlier, V has been proven to be as efficient as database retrieval (Liu & Levesque,
2003), and standard database technology can be brought to bear for its implementation.
In this regard, there is also an interesting connection to recent work on evaluating certain queries in description logics (Baader, Calvanese, McGuiness, Nardi, & Patel-Schneider,
2003). A description-logic KB consists of two parts, a TBOX with terminological definitions
like â€œa mother is a female person with at least one childâ€ and an ABOX, which is a set
of atomic formulas. An ABOX is just a special case of a proper KB. Most importantly,
an ABOX does not make the closed world assumption, just as proper KBs. Calvanese, de
Giacomo, Lembo, Lenzerini, and Rosati (2006) showed that for conjunctive queries, which
consist of conjunctions of atoms with existentially quantified variables, query answering can
be reduced to database retrieval as well. It is interesting to note that the queries they consider are in NF. While they only consider a small fragment of NF, they go beyond proper
KBs as they also perform terminological reasoning (using the TBOX). We remark that there
have been other extensions of proper KBs by explicitly allowing disjunctions (Lakemeyer
& Levesque, 2002; Liu, Lakemeyer, & Levesque, 2004), but reasoning there goes beyond
database retrieval.

3. First-Order NF Is Not Expressive
Levesque showed that in the propositional case, every formula Ï† can be transformed into
an equivalent one in NF. His transformation is this. Convert the formula to CNF, and run
resolution repeatedly on this set of clauses, deleting any tautologous or subsumed ones until
no new clauses are generated. The resulting set of clauses is the set of prime implicates
of Ï†. The conjunction of these clauses is in NF and it is equivalent to Ï†. However,
this transformation cannot be extended to the first-order case. To see why, consider Ï† =
âˆ€xyz[R(x, y) âˆ§ R(y, z) âŠƒ R(x, z)], which says that R is transitive. If we run the first-order
version of Levesqueâ€™s transformation on Ï†, we would end up with an infinite set of clauses,
each of the format R(x1 , x2 ) âˆ§ . . . âˆ§ R(xn , xn+1 ) âŠƒ R(x1 , xn+1 ), where n â‰¥ 2.
In this section, we will prove that in the first-order case, not every formula is equivalent
to one in NF . For this purpose, we will need a first-order version of prime implicates. In
the propositional case, prime implicates are defined as follows:
Definition 8 Let Î“ be a theory. An implicate of Î“ is a non-tautologous clause c such that
Î“ |= c. A prime implicate of Î“ is an implicate c of Î“ such that for no proper subset câ€² of c
does Î“ |= câ€² .
265

Liu & Lakemeyer

Since we only consider standard interpretations, we can easily generalize prime implicates to the first-order case:
Definition 9 Let Ï† âˆˆ L. An implicate of Ï† is a non-tautologous ground clause c such that
Ï† |=E c. A prime implicate of Ï† is an implicate c of Ï† such that for no proper subset câ€² of c
does Ï† |=E câ€² . We use PI(Ï†) to denote the set of prime implicates of Ï†.
If |=E Ï† â‰¡ Ïˆ, that is, E |= Ï† â‰¡ Ïˆ, then both E âˆª {Ï†} and E âˆª {Ïˆ} entail the same
sentences and, in particular, PI(Ï†) = PI(Ïˆ).
The following is a basic property of prime implicates:
Proposition 10 Let c be a non-tautologous ground clause. Then Ï† |=E c iff there exists a
câ€² âˆˆ PI(Ï†) such that câ€² âŠ† c.
In this note, by the length of a formula, we mean the number of predicate symbols,
variables, constants and logical connectives contained in the formula. By the length of a
clause, we mean the length of the corresponding disjunctive formula. The key property in
this note is defined as follows:
Definition 11 We say that PI(Ï†) is bounded if there exists a number n such that the length
of every member in PI(Ï†) is at most n. If PI(Ï†) is bounded, we use B(Ï†) to denote the
maximum length of a member in PI(Ï†).
We will show that for every Ï† âˆˆ NF, PI(Ï†) is bounded. Then for any Ï† which has an
equivalent Ï†â€² in NF, PI(Ï†) is bounded too. However, there exist formulas Ï† such that PI(Ï†)
is not bounded. Thus not every formula can be transformed into an equivalent one in NF.
The proof that the prime implicates of formulas in NF are bounded will proceed by
induction. The following lemma is useful to establish the induction for conjunctions and
their negations.
Lemma 12 Let Î“ = {Ï†1 , . . . , Ï†n }.
1. If

V

2. PI(Â¬

Î“ âˆˆ NF, then PI( Î“) âŠ†
V

V

Î“) âŠ† {

S

i ci

i PI(Ï†i ).

S

| ci âˆˆ PI(Â¬Ï†i ), i = 1, . . . , n}.

Proof:
1. Let c âˆˆ PI( Î“). Then Î“ |=E c. By Theorem 2, Î“ âˆª c has no standard interpretation.
V
Since Î“ âˆˆ NF, Î“ is logically separable. Since c is non-tautologous, c is consistent.
Thus {Ï†i } âˆª c has no standard interpretation for some i, and so Ï†i |=E c. Let câ€² âŠ† c
V
V
such that Ï†i |=E câ€² . Then Î“ |=E câ€² . Since c âˆˆ PI( Î“), câ€² = c. Thus c âˆˆ PI(Ï†i ).
V

V

2. Let c âˆˆ PI(Â¬ Î“). Then Â¬ Î“ |=E c. Thus Â¬Ï†i |=E c for all i. By Proposition 10,
for each i, there exists ci âˆˆ PI(Â¬Ï†i ) (and hence Â¬Ï†i |=E ci ) such that ci âŠ† c. Then
V
S
S
V
S
Â¬ Î“ |=E i ci and i ci âŠ† c. Since c âˆˆ PI(Â¬ Î“), c = i ci .
2
V

V

266

On the Expressiveness of Levesqueâ€™s Normal Form

Note that, if the prime implicates of the Ï†i are bounded, it follows easily from the lemma
V
V
that the prime implicates of Î“ and Â¬ Î“ are bounded as well. To obtain a similar result
for quantified formulas is more complicated. The obvious generalization of Lemma 12,
V
replacing Î“ by {Ï†xd1 , Ï†xd2 , . . .} and Î“ by âˆ€xÏ† does not work, as this would lead to an
infinite union of sets in the first part and an infinite union of clauses in the second part.
We can get around this by observing the similarity between PI(Ï†xb ) and PI(Ï†xd ), where b and
d are constants not appearing in Ï†, as shown by Proposition 14 below.
We begin with a property that will be useful in the proof. Let âˆ— be a mapping from C
to C. We use Ï†âˆ— to denote Ï† with every constant d replaced by dâˆ— . We use Î“âˆ— to denote
{Ï†âˆ— | Ï† âˆˆ Î“}.
Proposition 13 (Levesque) Let âˆ— be a bijection from C to C. If Î“ |=E Ï†, then Î“âˆ— |=E Ï†âˆ— .
Proposition 14 Let Ï† be a formula with a single free variable x. Let b, d be constants in C
not appearing in Ï†. Let âˆ— be the bijection that swaps b and d and leaves all other constants
unchanged. Then PI(Ï†xd ) = {câˆ— | c âˆˆ PI(Ï†xb )}.
Proof: Let c âˆˆ PI(Ï†xb ). Then Ï†xb |=E c. By Proposition 13, (Ï†xb )âˆ— |=E câˆ— , that is, Ï†xd |=E câˆ— .
Let câ€² âŠ† câˆ— such that Ï†xd |=E câ€² . Then Ï†xb |=E câ€²âˆ— . Since c âˆˆ PI(Ï†xb ) and câ€²âˆ— âŠ† c, câ€²âˆ— = c,
and hence câ€² = câˆ— . Thus câˆ— âˆˆ PI(Ï†xd ). Similarly, if c âˆˆ PI(Ï†xd ), then câˆ— âˆˆ PI(Ï†xb ). Therefore,
PI(Ï†xd ) = {câˆ— | c âˆˆ PI(Ï†xb )}.
2
Basically, the above proposition says that the prime implicates of Ï†xb and Ï†xd are the same
modulo constant renaming.
Lemma 15 Let Ï† be a formula with a single free variable x.
1. If âˆ€xÏ† âˆˆ NF , and for all constants d âˆˆ C, PI(Ï†xd ) is bounded, then PI(âˆ€xÏ†) is also
bounded.
2. If for all constants d âˆˆ C, PI(Â¬Ï†xd ) is bounded, then PI(Â¬âˆ€xÏ†) is also bounded.
Proof:
1. Since for all d âˆˆ C, PI(Ï†xd ) is bounded, we let n = max{B(Ï†xd ) | d âˆˆ H + (Ï†)}. By
Proposition 14, for any d âˆˆ C, PI(Ï†xd ) is a relabeling of PI(Ï†xb ) for some b in H + (Ï†).
Thus for any d âˆˆ C, PI(Ï†xd ) is bounded by n. We will show that PI(âˆ€xÏ†) is also bounded
by this n, by showing that every element of PI(âˆ€xÏ†) is also an element of PI(Ï†xd ), for
some d âˆˆ C.
So suppose that c âˆˆ PI(âˆ€xÏ†). Then âˆ€xÏ† |=E c. Thus {âˆ€xÏ†} âˆª c has no standard
interpretation. So {Ï†xd | d âˆˆ C} âˆª c has no standard interpretation. Since âˆ€xÏ† âˆˆ NF,
{Ï†xd | d âˆˆ C} is logically separable. Thus there exists d âˆˆ C such that {Ï†xd } âˆª c has no
standard interpretation. So Ï†xd |=E c. Let câ€² âŠ† c such that Ï†xd |=E câ€² . Then âˆ€xÏ† |=E câ€² .
Since c âˆˆ PI(âˆ€xÏ†), câ€² = c. Thus c âˆˆ PI(Ï†xd ).
267

Liu & Lakemeyer

2. As in Part 1, we let n = max{B(Â¬Ï†xd ) | d âˆˆ H + (Ï†)}. Then for any d âˆˆ C, PI(Â¬Ï†xd ) is
bounded by n. We will show that PI(Â¬âˆ€xÏ†) is bounded by (m + n + 1) Â· n, where m
is the length of Ï†. This is done by showing that for any c âˆˆ PI(Â¬âˆ€xÏ†), there exists
a set D of no more than (m + n + 1) constants such that for all d âˆˆ D, there exists
S
cd âˆˆ PI(Â¬Ï†xd ) such that c = dâˆˆD cd .

So suppose that c âˆˆ PI(Â¬âˆ€xÏ†). Then Â¬âˆ€xÏ† |=E c, i.e., âˆƒxÂ¬Ï† |=E c. Let d be an
arbitrary constant in C. Then Â¬Ï†xd |=E c because Â¬Ï†xd |=E âˆƒxÂ¬Ï†. By Proposition 10,
there exists cd âˆˆ PI(Â¬Ï†xd ) such that cd âŠ† c. Now let b be a constant that appears
in neither Ï† nor c with cb âˆˆ PI(Â¬Ï†xb ) and cb âŠ† c. Then b does not appear in cb ,
and the length of cb is at most n. Let D = H(Ï†) âˆª H(cb ) âˆª {b}. Then D has no
S
more than (m + n + 1) elements. We will show that c = dâˆˆD cd . To do so, let
a be an arbitrary constant not in D. Let âˆ— be the bijection that swaps b and a
and leaves all other constants unchanged. Since cb âˆˆ PI(Â¬Ï†xb ) we have Â¬Ï†xb |=E cb ,
and, by Proposition 13, (Â¬Ï†xb )âˆ— |=E (cb )âˆ— . Since neither b nor a appears in Ï† or cb ,
(Â¬Ï†xb )âˆ— = Â¬Ï†xa and (cb )âˆ— = cb . Hence Â¬Ï†xa |=E cb . So we have that for all d âˆˆ D,
S
Â¬Ï†xd |=E cd ; and for all a 6âˆˆ D, Â¬Ï†xa |=E cb . Thus âˆƒxÂ¬Ï† |=E dâˆˆD cd , which is a subset
S
2
of c. Since c âˆˆ PI(âˆƒxÂ¬Ï†), c = dâˆˆD cd .

We now have all the pieces in hand to prove the main theorem:
Theorem 16 Let Ïˆ âˆˆ NF . Then PI(Ïˆ) is bounded.
Proof: For technical reasons, it is easier to prove a slightly more general statement, namely
that both PI(Ïˆ) and PI(Â¬Ïˆ) are bounded provided that Ïˆ âˆˆ NF. The proof is by induction
on Ïˆ.
1. Ïˆ is a ground atom or ewff. If Ïˆ is a ground atom, then PI(Ïˆ) = {Ïˆ} and PI(Â¬Ïˆ) =
{Â¬Ïˆ}, hence they are bounded. If Ïˆ is a ground ewff that is true, then Ïˆ does not
entail any ground clause, and hence PI(Ïˆ) is the empty set; if Ïˆ is a ground ewff that
is false, then Ïˆ entails the empty clause, and hence PI(Ïˆ) is the set consisting of the
empty clause. Therefore, if Ïˆ is a ground ewff, both PI(Ïˆ) and PI(Â¬Ïˆ) are bounded.
2. Ïˆ is Â¬Ï†. By induction, PI(Ï†) and PI(Â¬Ï†) are bounded. Since PI(Ï†) = PI(Â¬Â¬Ï†), both
PI(Â¬Ï†) and PI(Â¬Â¬Ï†) are bounded.
3. Ïˆ is Î“. By induction, for all Ï† âˆˆ Î“, PI(Ï†) and PI(Â¬Ï†) are bounded. By Lemma 12,
V
V
PI( Î“) is bounded by max{B(Ï†) | Ï† âˆˆ Î“}, and PI(Â¬ Î“) by the sum of B(Â¬Ï†) for
Ï† âˆˆ Î“.
V

4. Ïˆ is âˆ€xÏ†. By induction, for any constant d, PI(Ï†xd ) and PI(Â¬Ï†xd ) are bounded. By
Lemma 15, both PI(âˆ€xÏ†) and PI(Â¬âˆ€xÏ†) are bounded.
2
As an easy corollary, we have:
Corollary 17 Not every sentence has an equivalent one in NF.
268

On the Expressiveness of Levesqueâ€™s Normal Form

Proof: Let Ï† = âˆ€xyz[R(x, y) âˆ§ R(y, z) âŠƒ R(x, z)], which says that R is transitive. Then for
all n, the following is in PI(Ï†):
R(d1 , d2 ) âˆ§ . . . âˆ§ R(dn , dn+1 ) âŠƒ R(d1 , dn+1 ).
Thus PI(Ï†) is not bounded. Suppose that there exists Ï†â€² âˆˆ NF such that Ï† and Ï†â€² are
equivalent. Then PI(Ï†) = PI(Ï†â€² ). By Theorem 16, PI(Ï†â€² ) is bounded, a contradiction.
2
Moreover, it is easy to generalize our inexpressiveness result:
Theorem 18 There does not exist a class F of sentences with these properties:
1. every formula has an equivalent one in F;
2. V is logically complete for F (i.e., for every proper KB Î£ and every Ï† âˆˆ F, if Î£ |=E Ï†
then V [Î£, Ï†] = 1, and if Î£ |=E Â¬Ï† then V [Î£, Ï†] = 0);
3. if Â¬Ï† âˆˆ F then Ï† âˆˆ F; if
constants d.

V

Î“ âˆˆ F, then Î“ âŠ† F; and if âˆ€xÏ† âˆˆ F, then Ï†xd âˆˆ F for all

Note that the theorem does not require logical separability, only that V be complete
for F. We call any set of formulas that satisfies the third requirement downward saturated,
which, besides being a desirable property of a normal form, is needed for technical reasons.
Proof: Suppose, to the contrary, that there exists a class F of sentences which satisfies
the three properties stated above. As in the case of NF , we can show that PI(Ï†) is bounded
for every Ï† âˆˆ F and use the same sentence as in the proof of Corollary 17 to obtain a
contradiction.
The boundedness proof is almost identical to the argument before for NF , and we
will not repeat it here. Instead we just note the necessary changes. In fact, the only
changes needed are in the proofs of Item 1 in Lemma 12 and 15, where we appeal to logical
separability to show that Ï†i |=E c for some i respectively Ï†xd |=E c for some d. Here we show
that the same conclusions can be drawn using the assumption that V is complete for F.
First, note the following: Let Ï† âˆˆ F, and let c be a non-tautologous ground clause.
Then c is essentially a proper KB. Thus if Ï† |=E c, then c |=E Â¬Ï†, and hence V [c, Ï†] = 0, by
completeness of V for F.
â€¢ Change in Lemma 12, Item 1:
V
V
V
V
Let c âˆˆ PI( Î“). Then Î“ |=E c. Since Î“ âˆˆ F, V [c, Î“] = 0. By the definition of
V , V [c, Ï†i ] = 0 for some Ï†i âˆˆ Î“. By soundness of V , c |=E Â¬Ï†i . Thus Ï†i |=E c.
â€¢ Change in Lemma 15, Item 1:
Let c âˆˆ PI(âˆ€xÏ†). Then âˆ€xÏ† |=E c. Since âˆ€xÏ† âˆˆ F, V [c, âˆ€xÏ†] = 0. By the definition of
V , V [c, Ï†xd ] = 0 for some constant d. By soundness of V , c |=E Â¬Ï†xd . Thus Ï†xd |=E c.
With these small changes the proofs of the two lemmas go through for F instead of NF.
Finally, the proof of Theorem 16 carries over without any change, since the induction works
for any downward-saturated set.
2

269

Liu & Lakemeyer

4. Propositional NF Is Not Succinct
In the propositional case, Levesqueâ€™s transformation to NF, that is, taking the conjunction
of the prime implicates of the formula, may cause an exponential blowup in the size of the
formula. This is because the number of prime implicates of a formula with n propositions is
exponential in n in the worst case (Chandra & Markowsky, 1978). In this section, we show
that in the propositional case, under a certain complexity assumption, not every formula
has a polynomial-size equivalent one in NF. This is done by relating NF to an existing
result in knowledge compilation.
Knowledge compilation (Selman & Kautz, 1996; Darwiche & Marquis, 2002) has been
proposed as one of the main techniques to deal with the computational intractability of
general propositional reasoning. In this approach, a tractable language, which usually
means a language such that whether a clause is entailed by a formula from the language
can be decided in polynomial time, is identified as the target compilation language. A
propositional theory is first compiled off-line into the target language, and the result is then
used on-line to answer multiple queries. The main motivation here is to shift most of the
computational cost into the off-line phase, which is amortized over all on-line queries. As
shown in the following, NF can serve as a knowledge compilation language. The reason
is that in the propositional case, answering an arbitrary query against a proper KB is
equivalent to answering a clausal query against an arbitrary KB. As mentioned in Section 2,
in the propositional case, a proper KB is simply a consistent set of literals.
Proposition 19 Clausal entailment on NF can be decided in polynomial time.
Proof: Let Ï† âˆˆ NF , and let c be a non-tautologous clause. Then c is a proper KB. Thus
Ï† |= c iff c |= Â¬Ï† iff V [c, Ï†] = 0, by soundness and completeness of V for NF. Clearly, in
the propositional case, V runs in polynomial time.
2
The following is a well-known result in knowledge compilation:
Theorem 20 (Selman & Kautz, 1996) Unless NP âŠ† P/poly, there does not exist a class
F of formulas such that every propositional formula has a polynomial-size equivalent one in
F, and clausal entailment on F can be decided in polynomial time.
The complexity class P/poly, also known as non-uniform P , originated in circuit complexity (Boppana & Sipser, 1990). Roughly, a problem is in P/poly if for every integer n
there exists a circuit of size polynomial in n that solves instances of size n. Without going
into further details, NP âŠ† P/poly implies the collapse of the polynomial hierarchy at the
second level, which is considered very unlikely.
As an easy corollary of the above proposition and theorem, we have:
Corollary 21 Unless NP âŠ† P/poly, not every propositional formula has a polynomial-size
equivalent one in NF.
In other words, it is very unlikely that we can obtain compact NF representations for
arbitrary propositional formulas.
270

On the Expressiveness of Levesqueâ€™s Normal Form

5. Conclusion
Levesque remarked in his paper that he did not envision the use of NF in the sense of query
optimization by taking an arbitrary query and converting it into NF before handing it to
V . His main argument was the high computational cost, which usually cannot be afforded
on-line. Besides, except for special cases it is not even clear how to convert a formula into
NF, if one exists. Instead he suggested that NF could be a guideline for users to formulate
â€œgoodâ€ queries which can be evaluated efficiently.
The contribution of this technical note is to point out some of the limits even of this
use of NF . In the propositional case our result says that most likely there will be queries
which cannot be both in NF and compactly representable. In some sense, this is not all
bad news, since in practice queries tend to be very small compared to the knowledge base.
In the first-order case our result is more serious as we showed that there are queries which
do not have a normal form at all. In other words, no matter how ingenious a user might be,
there will always be queries which have no easy-to-answer form, at least if we insist on a
form which is independent of the knowledge base as in NF. Indeed, it may still be possible
to find another notion of normal form which depends in some way on the knowledge base,
for example, the constants it contains. But that is future work.

Acknowledgments
We thank Hector Levesque for many helpful discussions on the topic of this paper and
reading an earlier version of the paper. We also thank the anonymous reviewers for their
detailed comments on improving the presentation of this paper.

References
Baader, F., Calvanese, D., McGuiness, D., Nardi, D., & Patel-Schneider, P. (2003). The
Description Logic Handbook: Theory, Implementation and Applications. Cambridge
University Press.
Boppana, R. B., & Sipser, M. (1990). The complexity of finite functions. In van Leeuwen,
J. (Ed.), Handbook of Theoretical Computer Science, Vol. A, pp. 757â€“804. Elsevier.
Calvanese, D., de Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Data
complexity of query answering in description logics. In Proc. of the Tenth International
Conference on Principles of Knowledge Representation and Reasoning (KR-06), pp.
260â€“270.
Chandra, A. K., & Markowsky, G. (1978). On the number of prime implicants. Discrete
Mathematics, 24, 7â€“11.
Darwiche, A., & Marquis, P. (2002). A knowledge compilation map. Journal of Artificial
Intelligence Research, 17, 229â€“264.
Lakemeyer, G., & Levesque, H. J. (2002). Evaluation-based reasoning with disjunctive information in first-order knowledge bases. In Proc. of the Eighth International Conference
on Principles of Knowledge Representation and Reasoning (KR-02), pp. 73â€“81.
271

Liu & Lakemeyer

Levesque, H. J. (1998). A completeness result for reasoning with incomplete first-order
knowledge bases. In Proc. of the Sixth International Conference on Principles of
Knowledge Representation and Reasoning (KR-98), pp. 14â€“23.
Liu, Y., Lakemeyer, G., & Levesque, H. J. (2004). A logic of limited belief for reasoning with
disjunctive information. In Proc. of the Ninth International Conference on Principles
of Knowledge Representation and Reasoning (KR-04), pp. 587â€“597.
Liu, Y., & Levesque, H. J. (2003). A tractability result for reasoning with incomplete firstorder knowledge bases. In Proc. of the Eighteenth International Joint Conference on
Artificial Intelligence (IJCAI-03), pp. 83â€“88.
Selman, B., & Kautz, H. (1996). Knowledge compilation and theory approximation. Journal
of the ACM, 43 (2), 193â€“224.

272

Journal of Artificial Intelligence Research 31 (2008) 113-155

Submitted 08/07; published 01/08

CTL Model Update for System Modifications
Yan Zhang

yan@scm.uws.edu.au

Intelligent Systems Laboratory
School of Computing and Mathematics
University of Western Sydney, Australia

Yulin Ding

yulin@cs.adelaide.edu.au

Department of Computer Science
University of Adelaide, Australia

Abstract
Model checking is a promising technology, which has been applied for verification of
many hardware and software systems. In this paper, we introduce the concept of model update towards the development of an automatic system modification tool that extends model
checking functions. We define primitive update operations on the models of Computation
Tree Logic (CTL) and formalize the principle of minimal change for CTL model update.
These primitive update operations, together with the underlying minimal change principle, serve as the foundation for CTL model update. Essential semantic and computational
characterizations are provided for our CTL model update approach. We then describe a
formal algorithm that implements this approach. We also illustrate two case studies of CTL
model updates for the well-known microwave oven example and the Andrew File System 1,
from which we further propose a method to optimize the update results in complex system
modifications.

1. Introduction
Model checking is one of the most effective technologies for automatic system verifications.
In the model checking approach, the system behaviours are modeled by a Kripke structure,
and specification properties that we require the system to meet are expressed as formulas
in a propositional temporal logic, e.g., CTL. Then the model checker, e.g., SMV, takes the
Kripke model and a formula as input, and verifies whether the formula is satisfied by the
Kripke model. If the formula is not satisfied in the Kripke model, the system will report
errors, and possibly provides useful information (e.g., counterexamples).
Over the past decade, the model checking technology has been considerably developed,
and many effective model checking tools have been demonstrated through provision of thorough automatic error diagnosis in complex designs e.g., (Amla, Du, Kuehlmann, Kurshan,
& McMillan, 2005; Berard, Bidoit, Finkel, Laroussinie, Petit, Petrucci, & Schnoebelen,
2001; Boyer & Sighireanu, 2003; Chauhan, Clarke, Kukula, Sapra, Veith, & Wang, 2002;
Wing & Vaziri-Farahani, 1995). Some current state-of-the-art model checkers, such as
SMV (Clarke, Grumberg, & Peled, 1999), NuSMV (Cimatti, Clarke, Giunchiglia, & Roveri,
1999) and Cadence SMV (McMillan & Amla, 2002), employ SMV specification language for
both Computational Tree Logic (CTL) and Linear Temporal Logic (LTL) variants (Clarke
et al., 1999; Huth & Ryan, 2004). Other model checkers, such as SPIN (Holzmann, 2003),
use Promela specification language for on-the-fly LTL model checking. Additionally, the
c
2008
AI Access Foundation. All rights reserved.

Zhang & Ding

MCK (Gammie & van der Meyden, 2004) model checker was developed by integrating
a knowledge operator into CTL model checking to verify knowledge-related properties of
security protocols.
Although model checking approaches have been used for verification of problems in large
complex systems, one major limitation of these approaches is that they can only verify the
correctness of a system specification. In other words, if errors are identified in a system
specification by model checking, the task of correcting the system is completely left to the
system designers. That is, model checking is generally used only to verify the correctness of
a system, not to modify it. Although the idea of repair has been indeed proposed for modelbased diagnosis, repairing a system is only possible for specific cases (Dennis, Monroy, &
Nogueira, 2006; Stumptner & Wotawa, 1996).
1.1 Motivation
Since model checking can handle complex system verification problems and as it may be
implemented via fast algorithms, it is quite natural to consider whether we can develop
associated algorithms so that they can handle system modification as well. The idea of
integrating model checking and automatic modification has been investigated in recent
years. Buccafurri, Eiter, Gottlob, and Leone (1999) have proposed an approach whereby
AI techniques are combined with model checking such that the enhanced algorithm can not
only identify errors for a concurrent system, but also provide possible modifications for the
system.
In the above approach, a system is described as a Kripke structure M , and a modification
Î“ for M is a set of state transitions that may be added to or removed from M . If a CTL
formula Ï• is not satisfied in M i.e., the system contains errors with respect to property Ï•,
then M will be repaired by adding new state transitions or removing existing ones specified
in Î“. As a result, the new Kripke structure M 0 will then satisfy formula Ï•. The approach
of Buccafurri et al. (1999) integrates model checking and abductive theory revision to
perform system repairs. They also demonstrate how their approach can be applied to
repair concurrent programs.
It has been observed that this type of system repair is quite restricted, as only relation
elements (i.e., state transitions) in a Kripke model can be changed 1 . This implies that errors
can only be fixed by changing system behaviors. In fact, as we will show in this paper,
allowing change to both states and relation elements in a Kripke structure significantly
enhances the system repair process in most situations. Also, since providing all admissible
modifications (i.e., the set Î“) is a pre-condition of any repair, the approach of Buccafurri
et al. lacks flexibility. Indeed, as stated by the authors themselves, their approach may not
be general enough for other system modifications.
On the other hand, knowledge-base update has been the subject of extensive study in
the AI community since the late 1980s. Winslettâ€™s Possible Model Approach (PMA) is
viewed as pioneering work towards a model-based minimal change approach for knowledgebase update (Winslett, 1988). Many researchers have since proposed different approaches
to knowledge system update (e.g., see references from Eiter & Gottlob, 1992; Herzig &
1. NB: No state changes occur in the specified system repairs (see Definitions 3.2 and 3.3 in Buccafurri
et al., 1999).

114

CTL Model Update for System Modifications

Rifi, 1999). Of these works, Harris and Ryan (2002, 2003) considered using an update
approach for system modification, where they designed update operations to tackle feature
integration, performing theory change and belief revision. However, their study focused
mainly on the theoretical properties of system update, and practical implementation of
their approach in system modification remains unclear.
Baral and Zhang (2005) recently developed a formal approach to knowledge update
based on single-agent S5 Kripke structures observing that system modification is closely
related to knowledge update. From the knowledge dynamics perspective, we can view the
finite transition system, which represents a real time complex system, to be a model of a
knowledge set (i.e., a Kripke model). Thus the problem of system modification is reduced
to the problem of updating this model so that a new updated model satisfies the knowledge
formula.
This observation motivated the initial development of a general approach to updating
Kripke models, which can be integrated into model checking technology, towards a more
general automatic system modification. Ding and Zhangâ€™s work (2005) may be viewed as the
first attempt to apply this idea to LTL model update. The LTL model update modifies the
existing LTL model of an abstracted system to automatically correct the errors occurring
within this model.
Based on the investigation described above, we intend to integrate knowledge update
and CTL model checking to develop a practical model updater, which represents a general
method for automatic system repairs.
1.2 Contributions of This Paper
The overall aim of our work is to design a model updater that improves model checking
function by adding error repair (see schematic in Figure 1). The outcome from the updater
is a corrected Kripke model. The model updaterâ€™s function is to automatically correct
errors reported (possibly as counterexamples) by a model checking compiler. Eventually,
the model updater is intended to be a universal compiler that can be used in certain common
situations for model error detection and correction.

CTL
Kripke Model

System
Design

Model checking
& Updating

Corrected
Kripke Model

Figure 1: CTL model update.

The main contributions of this paper are described as follows:
115

Zhang & Ding

1. We propose a formal framework for CTL model update. Firstly, we define primitive CTL model update operations and, based on these operations, specify a minimal
change principle for the CTL model update. We then study the relationship between
the proposed CTL model update and traditional propositional belief update. Interestingly, we prove that our CTL model update obeys all Katsuno and Mendelzon update
postulates (U1) - (U8). We further provide important characterizations for special
CTL model update formulas such as EXÏ†, AGÏ† and EGÏ†. These characterizations
play an important role in optimization of the update procedure. Finally, we study the
computational properties of CTL model update and show that, in general, the model
checking problem for CTL model update is co-NP-complete. We also classify a useful
subclass of CTL model update problems that can be performed in polynomial time.
2. We develop a formal algorithm for CTL model update. In principle, our algorithm
can perform an update on a given CTL Kripke model with an arbitrary satisfiable
CTL formula and generate a model that satisfies the input formula and has a minimal
change with respect to the original model. The model then can be viewed as a possible
correction on the original system specification. Based on this algorithm, we implement
a system prototype of CTL model updater in C code in Linux.
3. We demonstrate important applications of our CTL model update approach by two
case studies of the well-known microwave oven example (Clarke et al., 1999) and
the Andrew File System 1 (Wing & Vaziri-Farahani, 1995). Through these case
studies, we further propose a new update principle of minimal change with maximal
reachable states, which can significantly improve the update results in complex system
modification scenarios.
In summary, our work presented in this paper is an initial step towards the formal study
of the automatic system modification. This approach may be integrated into existing model
checkers so that we may develop a unified methodology and system for model checking
and model correction. In this sense, our work will enhance the current model checking
technology. Some results presented in this paper were published in ECAI 2006 (Ding &
Zhang, 2006).
The rest of the paper is organized as follows. An overview of CTL syntax and semantics is provided in Section 2.1. Primitive update operations on CTL models are defined
in Section 3, and a minimal change principle for CTL model update is then developed.
Section 4 consists of a study of the relationship between CTL model update and Katsuno
and Mendelzonâ€™s update postulates (U1) - (U8), and various characterizations for some special CTL model updates. In Section 5, a general computational complexity result of CTL
model update is proved, and a useful tractable subclass of CTL model update problems is
identified. A formal algorithm for the proposed CTL model update approach is described
in Section 6. In Section 7, two update case studies are illustrated to demonstrate applications of our CTL model update approach. Section 8 proposes an improved CTL model
update approach which can significantly optimize the update results in complex system
modification scenarios. Finally, the paper concludes with some future work discussions in
Section 9.
116

CTL Model Update for System Modifications

2. Preliminaries
In this section, we briefly review the syntax and semantics of Computation Tree Logic and
basic concepts of belief update, which are the foundation for our CTL model update.
2.1 CTL Syntax and Semantics
To begin with, we briefly review CTL syntax and semantics (refer to Clarke et al., 1999 and
Huth & Ryan, 2004 for details).
Definition 1 Let AP be a set of atomic propositions. A Kripke model M over AP is a
triple M = (S, R, L) where:
1. S is a finite set of states;
2. R âŠ† S Ã— S is a binary relation representing state transitions;
3. L : S â†’ 2AP is a labeling function that assigns each state with a set of atomic
propositions.
An example of a finite Kripke model is represented by the graph in Figure 2, where
each node represents a state in S, which is attached to a set of propositional atoms being
assigned by the labeling function, and an edge represents a state transition - a relation
element in R describing a system transition from one state to another.
S0
p, q

S2
q, r

r
S1

Figure 2: Transition state graph.
Computation Tree Logic (CTL) is a temporal logic allowing us to refer to the future.
It is also a branching-time logic, meaning that its model of time is a tree-like structure in
which the future is not determined but consists of different paths, any one of which might
be the â€˜actualâ€™ path that is eventually realized (Huth & Ryan, 2004).
Definition 2 CTL has the following syntax given in Backus-Naur form:
Ï† ::= > |âŠ¥| p | (Â¬Ï†) | (Ï†1 âˆ§ Ï†2 ) | (Ï†1 âˆ¨ Ï†2 ) | Ï† â†’ Ïˆ | AXÏ† | EXÏ†
| AGÏ† | EGÏ† | AFÏ† | EFÏ† | A[Ï†1 UÏ†2 ] | E[Ï†1 UÏ†2 ]
where p is any propositional atom.
117

Zhang & Ding

A CTL formula is evaluated on a Kripke model. A path in a Kripke model from a state
is a(n) (infinite) sequence of states. Note that for a given path, the same state may occur
an infinite number of times in the path (i.e., the path contains a loop). To simplify our
following discussions, we may identify states in a path with different position subscripts,
although states occurring in different positions in the path may be the same. In this way,
we can say that one state precedes another in a path without much confusion. Now we can
present useful notions in a formal way. Let M = (S, R, L) be a Kripke model and s âˆˆ S. A
path in M starting from s is denoted as Ï€ = [s 0 , s1 , Â· Â· Â· , siâˆ’1 , si , si+1 , Â· Â· Â·], where s0 = s and
(si , si+1 ) âˆˆ R holds for all i â‰¥ 0. We write si âˆˆ Ï€ if si is a state occurring in the path Ï€.
If a path Ï€ = [s0 , s1 , Â· Â· Â· , si , Â· Â· Â· , sj , Â· Â· Â·] and i < j, we also denote si < sj . Furthermore for
a given path Ï€, we use notion s â‰¤ si to denote a state s that is the state s i or s < si . For
simplicity, we may use succ(s) to denote state s 0 if there is a relation element (s, s0 ) in R.
Definition 3 Let M = (S, R, L) be a Kripke model for CTL. Given any s in S, we define
whether a CTL formula Ï† holds in M at state s. We denote this by (M, s) |= Ï†. The
satisfaction relation |= is defined by structural induction on all CTL formulas:
1. (M, s) |= > and (M, s) 6|=âŠ¥ for all s âˆˆ S.
2. (M, s) |= p iff p âˆˆ L(s).
3. (M, s) |= Â¬Ï† iff (M, s) 6|= Ï†.
4. (M, s) |= Ï†1 âˆ§ Ï†2 iff (M, s) |= Ï†1 and (M, s) |= Ï†2 .
5. (M, s) |= Ï†1 âˆ¨ Ï†2 iff (M, s) |= Ï†1 or (M, s) |= Ï†2 .
6. (M, s) |= Ï†1 â†’ Ï†2 iff (M, s) |= Â¬Ï†1 , or (M, s) |= Ï†2 .
7. (M, s) |= AXÏ† iff for all s1 such that (s, s1 ) âˆˆ R, (M, s1 ) |= Ï†.
8. (M, s) |= EXÏ† iff for some s1 such that (s, s1 ) âˆˆ R, (M, s1 ) |= Ï†.
9. (M, s) |= AGÏ† iff for all paths Ï€ = [s0 , s1 , s2 , Â· Â· Â·] where s0 = s and âˆ€si , si âˆˆ Ï€,
(M, si ) |= Ï†.
10. (M, s) |= EGÏ† iff there is a path Ï€ = [s 0 , s1 , s2 , Â· Â· Â·] where s0 = s and âˆ€si , si âˆˆ Ï€,
(M, si ) |= Ï†.
11. (M, s) |= AFÏ† iff for all paths Ï€ = [s 0 , s1 , s2 , Â· Â· Â·] where s0 = s and âˆƒsi , si âˆˆ Ï€,
(M, si ) |= Ï†.
12. (M, s) |= EFÏ† iff there is a path Ï€ = [s 0 , s1 , s2 , Â· Â· Â·] where s0 = s and âˆƒsi , si âˆˆ Ï€,
(M, si ) |= Ï†.
13. (M, s) |= A[Ï†1 UÏ†2 ] iff for all paths Ï€ = [s0 , s1 , s2 , Â· Â· Â·] where s0 = s, âˆƒsi âˆˆ Ï€, (M, si ) |=
Ï†2 and for each j < i, (M, sj ) |= Ï†1 .
14. (M, s) |= E[Ï†1 UÏ†2 ] iff there is a path Ï€ = [s0 , s1 , s2 , Â· Â· Â·] where s0 = s, âˆƒsi âˆˆ Ï€,
(M, si ) |= Ï†2 and for each j < i, (M, sj ) |= Ï†1 .
118

CTL Model Update for System Modifications

From the above definition, we can see that the intuitive meaning of A, E, X, and G are
quite clear: A means for all paths, E means that there exists a path, X refers to the next
state and G means for all states globally. Then the semantics of a CTL formula is easy to
capture as follows.
In the first six clauses, the truth value of the formula in the state depends on the truth
value of Ï†1 or Ï†2 in the same state. For example, the truth value of Â¬Ï† in a state only
depends on the truth value of Ï† in the same state. This contrasts with clauses 7 and 8 for
AX and EX. For instance, the truth value of AXÏ† in a state s is determined not by Ï†â€™s
truth value in s, but by Ï†â€™s truth values in states s 0 where (s, s0 ) âˆˆ R; if (s, s) âˆˆ R, then
this value also depends on the truth value of Ï† in s.
The next four clauses (9 - 12) also exhibit this phenomenon. For example, the truth value
of AGÏ† involves looking at the truth value of Ï† not only in the immediately related states,
but in indirectly related states as well. In the case of AGÏ†, we must examine the truth value
of Ï† in every state related by any number of forward links (paths) to the current state s. In
clauses 13 and 14, symbol U may be explained as â€œuntilâ€: a path Ï€ = [s 0 , s1 , s2 , Â· Â· Â·] satisfies
Ï†1 UÏ†2 if there is a state si âˆˆ Ï€ such that for all s < si , (M, s) |= Ï†1 until (M, si ) |= Ï†2 .
Clauses 9 - 14 above refer to computation paths in models. It is, therefore, useful to
visualize all possible computation paths from a given state s by unwinding the transition
system to obtain an infinite computation tree. This greatly facilitates deciding whether a
state satisfies a CTL formula. The unwound tree of the graph in Figure 2 is depicted in
Figure 3 (note that we assume s0 is the initial state in this Kripke model).

S0

p, q

S2

S1

q,r

r

S2
p,q

S0

r

S2
r

q,r

S1

r

S2
r

S2

Figure 3: Unwinding the transition state graph as an infinite tree.

In Figure 3, if Ï† = r, then AXr is true; if Ï† = q, then EXq is true. In the same figure,
if Ï† = r, then AFr is true because some states on all paths will satisfy r some time in the
future. If Ï† = q, EFq is true because some states on some paths will satisfy q some time
in the future. The clauses for AG and EG can be explained in Figure 4. In this tree, all
states satisfy r. Thus, AGr is true in this Kripke model. There is one path where all states
satisfy Ï† = q. Thus, EGq is true in this Kripke model.
119

Zhang & Ding

  
  







p,q,r 








AG Ï† When Ï† = r;
EG Ï†

When Ï†= q.



		
	 

		
	 

		
	 

		
	 

		
	 

		
	


			 

			 

			 

			 

			 

			

	

	 
	

	 
	

	 p,q

	
	, r
	


		 

		 

		 

	

		 

	

		 

	

		
    
  q,r  
    
   

    
   
 q,r
    
    


S0

S2

S1

r

S2
S0

r

S2
r

S1

r

S2
r

S2

Figure 4: AGÏ† and EGÏ† in an unwound tree.

The following De Morgan rules and equivalences (Huth & Ryan, 2004) will be useful for
our CTL model update algorithm implementation:
Â¬AFÏ† â‰¡ EGÂ¬Ï†;
Â¬EFÏ† â‰¡ AGÂ¬Ï†;
Â¬AXÏ† â‰¡ EXÂ¬Ï†;
AFÏ† â‰¡ A[>UÏ†];
EFÏ† â‰¡ E[>UÏ†];
A[Ï†1 UÏ†2 ] â‰¡ Â¬(E[Â¬Ï†2 U(Â¬Ï†1 âˆ§ Ï†2 )] âˆ¨ EGÂ¬Ï†2 ).
In the rest of this paper, without explicit declaration, we will assume that all CTL
formulas occurring in our context will be satisfiable. For instance, if we consider updating
a Kripke model to satisfy a CTL formula Ï†, we already assume that Ï† is satisfiable.
From Definition 3, we can see that for a given CTL Kripke model M = (S, R, L), if
(M, s) |= Ï† and Ï† is a propositional formula, then Ï†â€™s truth value solely depends on the
labeling function Lâ€™s assignment on state s. In this case we may simply write L(s) |= Ï† if
there is no confusion from the context.
2.2 Belief Update
Belief change has been a primary research topic in the AI community for almost two decades
e.g., (Gardenfors, 1988; Winslett, 1990). Basically, it studies the problem of how an agent
can change its beliefs when it wants to bring new beliefs into its belief set. There are two
types of belief changes, namely belief revision and belief update. Intuitively, belief revision
is used to modify a belief set in order to accept new information about the static world,
120

CTL Model Update for System Modifications

while belief update is to bring the belief set up to date when the world is described by its
changes.
Katsuno and Mendelzon (1991) have discovered that the original AGM revision postulates cannot precisely characterize the feature of belief update. They proposed the following
alternative update postulates, and argued that any propositional belief update operators
should satisfy these postulates. In the following (U1) - (U8) postulates, all occurrences of
T , Âµ, Î±, etc. are propositional formulas.
T  Âµ |= Âµ.
If T |= Âµ then T  Âµ â‰¡ T .
If both T and Âµ are satisfiable then T  Âµ is also satisfiable.
If T1 â‰¡ T2 and Âµ1 â‰¡ Âµ2 then T  Âµ1 â‰¡ T2  Âµ2 .
(T  Âµ) âˆ§ Î± |= T  (Âµ âˆ§ Î±).
If T  Âµ1 |= Âµ2 and T  Âµ2 |= Âµ1 then T  Âµ1 â‰¡ T  Âµ2 .
If T is complete (i.e., has a unique model) then
(T  Âµ1 ) âˆ§ (T  Âµ2 ) |= T  (Âµ1 âˆ¨ Âµ2 ).
(U8) (T1 âˆ¨ T2 )  Âµ â‰¡ (T1  Âµ) âˆ¨ (T2  Âµ).

(U1)
(U2)
(U3)
(U4)
(U5)
(U6)
(U7)

As shown by Katsuno and Mendelzon (1991), postulates (U1) - (U8) precisely capture
the minimal change criterion for update that is defined based on certain partial ordering
on models. As a typical model based belief update approach, here we briefly introduce
Winslettâ€™s Possible Models Approach (PMA) (Winslett, 1990). We consider a propositional language L. Let I1 and I2 be two Herband interpretations of L. The symmetric
difference between I1 and I2 is defined as dif f (I1 , I2 ) = (I1 âˆ’ I2 ) âˆª (I2 âˆ’ I1 ). Then for a
given interpretation I, we define a partial ordering â‰¤ I as follows: I1 â‰¤I I2 if and only if
dif f (I, I1 ) âŠ† dif f (I, I2 ). Let I be a collection of interpretations, we denote M in(I, â‰¤ M )
to be the set of all minimal models from I with respect to ordering â‰¤ M , where model M
is fixed. Now let Ï† and Âµ be two propositional formulas, the update of Ï† with Âµ using the
PMA, denoted as Ï† pma Âµ, is defined as follows:
M od(Ï† pma Âµ) =

S

M âˆˆM od(Ï†)

M in(M od(Âµ), â‰¤M ),

where M od(Ïˆ) denotes the set of all models of formula Ïˆ. It can be proved that the PMA
update operator pma satisfies all postulates (U1) - (U8).
Our work of CTL model update has a close connection to the idea of belief update. As
will be shown in this paper, in our approach, we view a CTL Kripke model as a description of
the world that we are interested in, i.e., the description of a system of dynamic behaviours,
and the update on this Kripke model occurs when the setting of the system of dynamic
behaviours has to change to accommodate some desired properties. Although there is
a significant difference between classical propositional belief update and our CTL model
update, we will show that Katsuno Mendelzonâ€™s update postulates (U1) - (U8) are also
suitable to characterize the minimal change principle for our CTL model update.

3. Minimal Change for CTL Model Update
We would like to extend the idea of minimal change in belief update to our CTL model
update. In principle, when we need to update a CTL Kripke model to satisfy a CTL formula,
121

Zhang & Ding

we expect the updated model to retain as much information as possible represented in the
original model. In other words, we prefer to change the model in a minimal way to achieve
our goal. In this section, we will propose formal metrics of minimal change for CTL model
update.
3.1 Primitive Update Operations
Given a CTL Kripke model and a (satisfiable) CTL formula, we consider how this model
can be updated in order to satisfy the given formula. From the discussion in the previous
section, we try to incorporate a minimal change principle into our update approach. As the
first step towards this aim, we should have a way to measure the difference between two
CTL Kripke models in relation to a given model. We first illustrate our initial consideration
of this aspect through an example.
Example 1 Consider a simple CTL model M = ({s 0 , s1 , s2 }, {(s0 , s0 ), (s0 , s1 ), (s0 , s2 ),
(s1 , s1 ), (s2 , s2 ), (s2 , s1 )}, L), where L(s0 ) = {p, q}, L(s1 ) = {q, r} and L(s2 ) = {r}. M is
described as in Figure 5.

p,q

s1

s0

r

q,r

s2

Figure 5: Model M .

Now consider formula AGp. Clearly, (M, s 0 ) 6|= AGp. One way to update M to satisfy
AGp is to update states s1 and s2 so that both updated states satisfy p 2 . Therefore,
we obtain a new CTL model M 0 = ({s0 , s1 , s2 }, {(s0 , s0 ), (s0 , s1 ), (s0 , s2 ), (s1 , s1 ), (s2 , s2 ),
(s2 , s1 )}, L0 ), where L0 (s0 ) = L(s0 ) = {p, q}, L0 (s1 ) = {p, q, r} and L0 (s2 ) = {p, r}. In this
update, we can see that the labeling function has been changed to associate different truth
assignments with states s1 and s2 . Another way to update M to satisfy formula AGp is to
simply remove relation elements (s 0 , s1 ) and (s0 , s2 ) from M , this gives (M 00 , s0 ) |= AGp,
where M 00 = ({s0 , s1 , s2 }, {(s0 , s0 ), (s1 , s1 ), (s2 , s2 ), (s2 , s1 )}, L). This more closely resembles
the approach of Buccafurri et al. (Buccafurri et al., 1999), where no state changes occur.
It is interesting to note that the first of the updated models retains the same â€œstructureâ€
as the original, while it is significantly changed in the second. These two possible results
are described in Figure 6. 2
2. Precisely, we update the labeling function L that changes the truth assignments to s1 and s2 .

122

CTL Model Update for System Modifications

p,q

p,q,r
s1

p,q

s0

p,r

q,r

s2

s1

s0

r
s2

Figure 6: Two possible results of updating M with AGp.

The above example shows that in order to update a CTL model to satisfy a formula, we
may apply different kinds of operations to change the model. From all possible operations
applicable to a CTL model, we consider five basic ones where all changes on a CTL model
can be achieved.
PU1: Adding one relation element
Given M = (S, R, L), its updated model M 0 = (S 0 , R0 , L0 ) is obtained from M by adding
only one new relation element. That is, S 0 = S, L0 = L, and R0 = R âˆª {(si , sj )}, where
(si , sj ) 6âˆˆ R for two states si , sj âˆˆ S.
PU2: Removing one relation element
Given M = (S, R, L), its updated model M 0 = (S 0 , R0 , L0 ) is obtained from M by removing
only one existing relation element. That is, S 0 = S, L0 = L, and R0 = R âˆ’ {(si , sj )}, where
(si , sj ) âˆˆ R for two states si , sj âˆˆ S.
PU3: Changing labeling function on one state
Given M = (S, R, L), its updated model M 0 = (S 0 , R0 , L0 ) is obtained from M by changing
labeling function on a particular state. That is, S 0 = S, R0 = R, âˆ€s âˆˆ (S âˆ’ {sâˆ— }), sâˆ— âˆˆ S,
L0 (s) = L(s), and L0 (sâˆ— ) is a set of true variable assigned in state s âˆ— where L0 (sâˆ— ) 6= L(sâˆ— ).
PU4: Adding one state
Given M = (S, R, L), its updated model M 0 = (S 0 , R0 , L0 ) is obtained from M by adding
only one new state. That is, S 0 = S âˆª {sâˆ— }, sâˆ— 6âˆˆ S, R0 = R, and âˆ€s âˆˆ S, L0 (s) = L(s) and
L0 (sâˆ— ) is a set of true variables assigned in s âˆ— .
PU5: Removing one isolated state
Given M = (S, R, L), its updated model M 0 = (S 0 , R0 , L0 ) is obtained from M by removing
only one isolated state: S 0 = S âˆ’ {sâˆ— }, where sâˆ— âˆˆ S and âˆ€s âˆˆ S such that s 6= sâˆ— , neither
(s, sâˆ— ) nor (sâˆ— , s) is not in R, R0 = R, and âˆ€s âˆˆ S 0 , L0 (s) = L(s).
We call the above five operations primitive since they express all kinds of changes to a
CTL model. Figure 7 illustrates examples of applying some of these operations on a model.
In the above five operations, PU1, PU2, PU4 and PU5 represent the most basic operations on a graph. Generally, using these four operations, we can perform any changes to
a CTL model. For instance, if we want to substitute a state in a CTL model, we do the
123

Zhang & Ding

following: (1) remove all relation elements associated to this state, (2) remove this isolated
states, (3) add a state that we want to replace the original one, and (4) add all relevant
relation elements associated to this new state.
Although these four operations are sufficient enough to represent all changes on a CTL
model, they sometimes complicate the measure on the changes of CTL models. Consider
the case of a state substitution. Given a CTL model M , if one CTL model M 0 has exactly
the same graphical structure as M except that M 0 only has one particular state different
from M , then we tend to think that M 0 is obtained from M with a single change of state
replacement, instead of from a sequence of operations PU1, PU2, PU4 and PU5.
This motivates us to have operation PU3. PU3 has an effect of state substitution, but it
is fundamentally different from the combination of PU1, PU2, PU4 and PU5, because PU3
does not change the state name and relation elements in the original model, it only assigns
a different set of propositional atoms to that state in the original model. In this sense,
the combination of PU1, PU2, PU4 and PU5 cannot replace operation PU3. Using PU3
to represent state substitution significantly simplifies our measure on the model difference
as will be illustrated in Definition 4. In the rest of the paper, we assume that all state
substitutions in a CTL model will be achieved through PU3 so that we have a unique way
to measure the differences on CTL model changes in relation to states substitutions.
We should also note that having operation PU3 as a way to substitute a state in a CTL
model, PU5 becomes unnecessary, because we actually do not need to remove an isolated
state from a model. All we need is to remove relevant relation element(s) in the model,
so that this state becomes unreachable from the initial state. Nevertheless, to remain our
discussions to be coherent with all primitive operations described above, in the following
definition on the CTL minimal change, we still consider the measure on changes caused by
applying PU5 in a CTL model update.
S0

S3

S0

S3

S1

M

S1

S2

M1

S2

After PU2 is applied to M.

S0

S3â€™

M2

S1

S2

After PU2, PU2, PU5, PU4,
PU1 and PU1 are applied to M.

Figure 7: Illustration of primitive updates.

3.2 Defining Minimal Change
Following traditional belief update principle, in order to make a CTL model to satisfy some
property, we would expect that the given CTL model is changed as little as possible. By
using primitive update operations, a CTL Kripke model may be updated in different ways:
124

CTL Model Update for System Modifications

adding or removing state transitions, adding new states, and changing the labeling function
for some state(s) in the model. Therefore, we first need to have a method to measure the
changes of CTL models, from which we can develop a minimal change criterion for CTL
model update.
Given two CTL models M = (S, R, L) and M 0 = (S 0 , R0 , L0 ), for each operation P U i
(i = 1, Â· Â· Â· , 5), Diff P U i (M, M 0 ) denotes the differences between the two models where M 0
is an updated model from M , which makes clear that several operations of type P U i have
occurred. Since PU1 and PU2 only change relation elements, we define Diff P U 1 (M, M 0 ) =
R0 âˆ’ R (adding relation elements only) and Diff P U 2 (M, M 0 ) = R âˆ’ R0 (removing relation elements only). For operation PU3, since only labeling function is changed, the difference measure between M and M 0 for PU3 is defined as Diff P U 3 (M, M 0 ) = {s | s âˆˆ
S âˆ© S 0 and L(s) 6= L0 (s)}. For operations PU4 and PU5, on the other hand, we define
Diff P U 4 (M, M 0 ) = S 0 âˆ’ S (adding states) and Diff P U 5 (M, M 0 ) = S âˆ’ S 0 (removing states).
Let M = (M, s) and M0 = (M 0 , s0 ), for convenience, we also denote Diff (M, M 0 ) =
(Diff P U 1 (M, M 0 ), Diff P U 2 (M, M 0 ), Diff P U 3 (M, M 0 ), Diff P U 4 (M, M 0 ), Diff P U 5 (M, M 0 )).
It is worth mentioning that given two CTL Kripke models M and M 0 , there is no
ambiguity to compute Diff P U i (M, M 0 ) (i = 1, Â· Â· Â· , 5), because each primitive operation will
only cause one type of changes (states, relation elements, or labeling function) in the models
no matter how many times it has been applied. Now we can precisely define the ordering
â‰¤M on CTL models.
Definition 4 (Closeness ordering) Let M , M 1 and M2 be three CTL Kripke models.
We say that M1 is at least as close to M as M2 , denoted as M1 â‰¤M M2 , if and only if for
each set of PU1-PU5 operations that transform M to M 2 , there exists a set of PU1-PU5
operations that transform M to M1 such that the following conditions hold:
(1) for each i (i = 1, Â· Â· Â· , 5), Diff P U i (M, M1 ) âŠ† Diff P U i (M, M2 ), and
(2) if Diff P U 3 (M, M1 ) = Diff P U 3 (M, M2 ), then for each s âˆˆ Diff P U 3 (M, M1 ),
dif f (L(s), L1 (s)) âŠ† dif f (L(s), L2 (s)).
We denote M1 <M M2 if M1 â‰¤M M2 and M2 6â‰¤M M1 .
Definition 4 presents a measure on the difference between two models with respect to
a given model. Intuitively, we say that model M 1 is closer to M relative to model M2 , if
(1) M1 is obtained from M by applying all primitive update operations that cause fewer
changes than those applied to obtain model M 2 ; and (2) if the set of states in M1 affected
by applying PU3 is the same as that in M 2 , then we take a closer look at the difference
on the set of propositional atoms associated with the relevant states. Having the ordering
specified in Definition 4, we can define a CTL model update formally.
Definition 5 (Admissible update) Given a CTL Kripke model M = (S, R, L), M =
(M, s0 ) where s0 âˆˆ S, and a CTL formula Ï†, a CTL Kripke model U pdate(M, Ï†) is called
an admissible model (or admissible updated model) if the following conditions hold: (1)
U pdate(M, Ï†) = (M 0 , s00 ), (M 0 , s00 ) |= Ï†, where M 0 = (S 0 , R0 , L0 ) and s00 âˆˆ S 0 ; and, (2) there
does not exist another updated model M 00 = (S 00 , R00 , L00 ) and s000 âˆˆ S 00 such that (M 00 , s000 ) |= Ï†
and M 00 <M M 0 . We use Poss(U pdate(M, Ï†)) to denote the set of all possible admissible
models of updating M to satisfy Ï†.
125

Zhang & Ding

Example 2 In Figure 8, model M is updated in two different ways. Model M 1 is the result
of updating M by applying PU1. Model M 2 is another update of M resulting by applying
PU1, PU2 and PU5. Then we have Diff P U 1 (M, M1 ) = {(s0 , s2 )}, and Diff P U 1 (M, M2 ) =
{(s1 , s0 ), (s0 , s2 )}, which results in Diff P U 1 (M, M1 ) âŠ‚ Diff P U 1 (M, M2 ). Also, it is easy to
see that Diff P U 2 (M, M1 ) = âˆ… and Diff P U 2 (M, M2 ) = {(s3 , s0 ), (s2 , s3 )}, so Diff P U 2 (M, M1 )
âŠ‚ Diff P U 2 (M, M2 ). Similarly, we can see that Diff P U 3 (M, M1 ) = Diff P U 3 (M, M2 ) = âˆ…,
and Diff P U 4 (M, M1 ) = Diff P U 4 (M, M2 ) = âˆ…. Finally, we have Diff P U 5 (M, M1 ) = âˆ… and
Diff P U 5 (M, M2 ) = {s3 }. According to Definition 4, we have M 1 <M M2 . 2

s0

s3

M

s1

s2

s0

s3

s0

s1

M1

s2

s1

s2

M2

Figure 8: Illustration of minimal change rules.
We should note that in a CTL model update, if we can simply replace the initial state
by another existing state in the model to satisfy the formula, then this model actually has
not been changed, and it is the unique admissible model according to Definition 5. In this
case, all other updates will be ruled out by Definition 5. For example, consider the CTL
model M described in Figure 9: If we want to update (M, s 0 ) with AXp, we can see that

S0

S1

p

S2

Figure 9: A special model update scenario.
(M, s1 ) becomes the only admissible updated model according to our definition: we simply
replace the initial state s0 by s1 . Nevertheless, we would expect that some other update
126

CTL Model Update for System Modifications

may also be equally reasonable. For instance, we may change the labeling function of M
to make L0 (s1 ) = {p}. In both updates, we have changed something in M , but the change
caused by the first update is not represented in our minimal change definition.
We can overcome this difficulty by creating a dummy state ] into a CTL Kripke model M ,
and for each initial state s in M , we add relation element (], s) into M . In this way, a change
of initial state from s to s0 will imply a removal of relation element (], s) and an addition
of a new relation element (], s0 ). Such changes will be measured by our minimal change
definition. With this treatment, both updated models described above are admissible. In
the rest of the paper, without explicit declaration, we will assume that each CTL Kripke
model contains a dummy state ] and special state transitions from ] to all initial states.

4. Semantic Properties
In this section, we first explore the relationship between our CTL model update and traditional belief update, and then provide useful semantic characterizations on some typical
CTL model update cases.
4.1 Relationship to Propositional Belief Update
First we show the following result about ordering â‰¤ M defined in Definition 4.
Proposition 1 â‰¤M is a partial ordering.
Proof: From Definition 4, it is easy to see that â‰¤ M is reflexive and antisymmetric. Now
we show that â‰¤M is also transitive. Suppose M1 â‰¤M M2 and M2 â‰¤M M3 . According to Definition 4, we have Dif fP U i (M, M1 ) âŠ† Dif fP U i(M, M2 ), and Dif fP U i(M, M2 ) âŠ†
Dif fP U i(M, M3 ) (i = 1, Â· Â· Â· , 5). Consequently, we have Dif f P U i (M, M1 ) âŠ† Dif fP U i(M, M3 )
(i = 1, Â· Â· Â· , 5). So Condition 1 in Definition 4 holds. Now consider Condition 2 in the definition. The only case we need to consider is that Dif f P U 3 (M, M1 ) = Dif fP U 3(M, M2 )
and Dif fP U 3 (M, M2 ) = Dif fP U 3 (M, M3 ) (note that all other cases will directly imply
Dif fP U 3 (M, M1 ) âŠ† Dif fP U 3 (M, M3 ) and Dif fP U 3 (M, M1 ) 6= Dif fP U 3 (M, M3 )). In this
case, it is obvious that for all s âˆˆ Dif f P U 3 (M, M1 ) = Dif fP U 3(M, M3 ), dif f (L(s), L1 (s)) âŠ†
dif f (L(s), L3 (s)). So we have M1 â‰¤M M3 . 2
It is also interesting to consider a special case of our CTL model update where the update
formula is a classical propositional formula. The following proposition indicates that when
only propositional formula is considered in CTL model update, the admissible model can
be obtained through the traditional model based belief update approach (Winslett, 1988).
Proposition 2 Let M = (S, R, L) be a CTL model and s 0 âˆˆ S. Suppose that Ï† is a
satisfiable propositional formula and (M, s 0 ) 6|= Ï†, then an admissible model of updating
(M, s0 ) to satisfy Ï† is (M 0 , s0 ), where M 0 = (S, R, L0 ), for each s âˆˆ (S âˆ’{s0 }), L0 (s) = L(s),
L0 (s0 ) |= Ï†, and there does not exist another M 00 = (S, R, L00 ) such that L00 (s0 ) |= Ï† and
dif f (L(s0 ), L00 (s0 )) âŠ‚ dif f (L(s0 ), L0 (s0 )).
Proof: Since Ï† is a propositional formula, the update on (M, s 0 ) to satisfy Ï† will not affect
any relation elements and all other states except s 0 . Since L(s0 ) 6|= Ï†, it is obvious that
127

Zhang & Ding

by applying PU3, we can change the labeling function L to L 0 that assigns s0 a new set of
propositional atoms to satisfy Ï†. Then from Definition 5, we can see that the model specified
in the proposition is indeed a minimally changed CTL model with respect to ordering â‰¤ M . 2
We can see that the problem addressed by our CTL model update is essentially different
from the problem concerned in traditional propositional belief update. Nevertheless, the
idea of model based minimal change for CTL model update is closely related to belief update.
Therefore, it is worth investigating the relationship between our CTL model update and
traditional propositional belief update postulates (U1) - (U8). In order to make such a
comparison possible, we should lift the update operator occurring in postulates (U1) - (U8)
beyond the propositional logic case.
For this purpose, we first introduce some notions. Given a CTL formula Ï† and Kripke
model M = (S, R, L), let Init(S) âŠ† S be the set of all initial states in M . (M, s) is called
a model of Ï† iff (M, s) |= Ï†, where s âˆˆ Init(S). We use M od(Ï†) to denote the set of all
models of Ï†. Now we specify an update operator  c to impose on CTL formulas as follows:
given two CTL formulas Ïˆ and Ï†, we define that Ïˆ  c Ï† to be a CTL formula whose models
are defined as:
M od(Ïˆ c Ï†) =

S

(M,s)âˆˆM od(Ïˆ)

Poss(U pdate((M, s), Ï†)).

Theorem 1 Operator c satisfies all Katsuno and Mendelzon update postulates (U1) (U8).
Proof: From Definitions 4 and 5, it is easy to verify that  c satisfies (U1)-(U4). We prove
that c satisfies (U5). To prove (Ïˆc Âµ)âˆ§Î± |= Ïˆc (Âµâˆ§Î±), it is sufficient to prove that for each
model (M, s) âˆˆ M od(Ïˆ), Poss(U pdate((M, s), Âµ))âˆ©M od(Î±) âŠ† Poss(U pdate((M, s), Âµâˆ§Î±)).
In particular, we need to show that for any (M 0 , s0 ) âˆˆ Poss(U pdate((M, s), Âµ)) âˆ© M od(Î±),
(M 0 , s0 ) âˆˆ Poss(U pdate((M, s), Âµ âˆ§ Î±)). Suppose (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ âˆ§ Î±)).
Then we have (1) (M 0 , s0 ) 6|= Âµâˆ§Î±; or (2) there exists a different admissible model (M 00 , s00 ) âˆˆ
M od(Âµâˆ§Î±) such that M 00 <M M 0 . If it is case (1), then (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ))âˆ©
M od(Î±). So the result holds. If it is case (2), it also implies that (M 00 , s00 ) |= Âµ and
M 00 <M M 0 . That means, (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ)). The result still holds.
Now we prove that c satisfies (U6). To prove this result, it is sufficient to prove that for
any (M, s) âˆˆ M od(Ïˆ), if Poss(U pdate((M, s), Âµ 1 )) âŠ† M od(Âµ2 ) and Poss(U pdate((M, s), Âµ2 ))
âŠ† M od(Âµ1 ), then Poss(U pdate((M, s), Âµ1 )) = Poss(U pdate((M, s), Âµ2 )). We first prove
Poss(U pdate((M, s), Âµ1 )) âŠ† Poss(U pdate((M, s), Âµ2 )). Let (M 0 , s0 ) âˆˆ Poss(U pdate((M, s),
Âµ1 )). Then (M 0 , s0 ) |= Âµ2 . Suppose (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ2 )). Then there exists a
different admissible model (M 00 , s00 ) âˆˆ Poss(U pdate((M, s), Âµ2 )) such that M 00 <M M 0 . Also
note that (M 00 , s00 ) |= Âµ1 . This contradicts the fact that (M 0 , s0 ) âˆˆ Poss(U pdate((M, s), Âµ1 )).
So we have Poss(U pdate((M, s), Âµ1 )) âŠ† Poss(U pdate((M, s), Âµ2 )). Similarly, we can prove
that Poss(U pdate((M, s), Âµ2 )) âŠ† Poss(U pdate((M, s), Âµ1 )).
To prove that c satisfies (U7), it is sufficient to prove that Poss(U pdate((M, s), Âµ 1 )) âˆ©
Poss(U pdate((M, s), Âµ1 )) âŠ† Poss(U pdate((M, s), Âµ1 âˆ¨Âµ2 )), where (M, s) is the unique model
of T (note that T is complete). Let (M 0 , s0 ) âˆˆ Poss(U pdate((M, s), Âµ1 ))âˆ©Poss(U pdate((M, s),
Âµ1 )). Suppose (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ1 âˆ¨ Âµ2 )). Then there exists an admissible model (M 00 , s00 ) âˆˆ Poss(U pdate((M, s), Âµ1 âˆ¨ Âµ2 )) such that M 00 <M M 0 . Note that
128

CTL Model Update for System Modifications

(M 00 , s00 ) |= Âµ1 âˆ¨Âµ2 . If (M 00 , s00 ) |= Âµ1 , then it implies that (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ1 )).
If (M 00 , s00 ) |= Âµ2 , then it implies (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ2 )). In both cases, we
have (M 0 , s0 ) 6âˆˆ Poss(U pdate((M, s), Âµ1 )) âˆ© Poss(U pdate((M, s), Âµ1 )). This proves the result.
Finally, we show that c satisfies (U8). From Definition 5, we have that M od((Ïˆ 1 âˆ¨Ïˆ2 )c
S
S
Âµ) = (M,s)âˆˆM od(Ïˆ1 âˆ¨Ïˆ2 ) Poss(U pdate((M, s), Âµ)) = (M,s)âˆˆM od(Ïˆ1 ) Poss(U pdate((M, s), Âµ))
S
âˆª (M,s)âˆˆM od(Ïˆ2 ) Poss(U pdate((M, s), Âµ)) = M od(Ïˆ1 c Âµ) âˆª M od(Ïˆ2 c Âµ). This completes
our proof. 2
From Theorem 1, it is evident that Katsuno and Mendelzonâ€™s update postulates (U1) (U8) characterize a wide range of update formulations beyond the propositional logic case,
where model based minimal change principle is employed. In this sense, we can view that
Katsuno and Mendelzonâ€™s update postulates (U1) - (U8) are essential requirements for any
model based update approaches.
4.2 Characterizing Special CTL Model Updates
From previous description, we observe that, for a given CTL Kripke model M and formula
Ï†, there may be many admissible models satisfying Ï†, where some are simpler than others.
In this section, we provide various results that present possible solutions to achieve admissible updates under certain conditions. In general, in order to achieve admissible update
results, we may have to combine various primitive operations during an update process.
Nevertheless, as will be shown below, a single type primitive operation will be enough to
achieve an admissible updated model in many situations. These characterizations also play
an essential role in simplifying CTL model update implementation.
Firstly, the following proposition simply shows that during a CTL update only reachable
states will be taken into account in the sense that unreachable state will never be removed
or newly introduced.
Proposition 3 Let M = (S, R, L) be a CTL Kripke model, s 0 âˆˆ S an initial state of M , Ï†
a satisfiable CTL formula and (M, s0 ) 6|= Ï†. Suppose (M 0 , s00 ) is an admissible model after
updating (M, s0 ) with Ï†, where M 0 = (S 0 , R0 , L0 ). Then the following properties hold:
1. if s is a state in M (i.e. s âˆˆ S) and is not reachable from s 0 (i.e. there does not exist
a path Ï€ = [s0 , Â· Â· Â·] in M such that s âˆˆ Ï€), then s must also be a state in M 0 (i.e.
s âˆˆ S 0 );
2. if s0 is a state in M 0 and is not reachable from s00 , then s0 must also be a state in M .
Proof: We only give the proof of result 1 since the proof for result 2 is similar. Suppose s
is not in M 0 . That is, s has been removed from M during the generation of (M 0 , s00 ). From
Definitions 4 and 5, we know that the only way to remove s from M is to apply operation
PU5 (and possibly other associated operations such as PU2 - removing transition relations,
if s is connected to other states).
Now we construct a new CTL Kripke model M 00 in such a way that M 00 is exactly the
same as M 0 except that s is also in M 00 . That is, M 00 = (S 00 , R00 , L00 ), where S 00 = S 0 âˆª {s},
R00 = R0 , for all sâˆ— âˆˆ S 0 , L00 (sâˆ— ) = L0 (sâˆ— ), and L00 (s) = L(s). Note that in M 00 , state s is
129

Zhang & Ding

an isolated state, not connecting to any other states. Since s is in M , from Definition 4 we
can see that M 00 <M M 0 . Now we will show that (M 00 , s00 ) |= Ï†. We prove this by showing
a bit more general result:
Result: For any satisfiable CTL formula Ï† and any state s âˆ— âˆˆ S 0 , (M 00 , sâˆ— ) |= Ï†
iff (M 0 , sâˆ— ) |= Ï†.
This can be showed by induction on the structure of Ï†. (a) Suppose Ï† is a propositional
formula. In this case, (M 00 , sâˆ— ) |= Ï† iff L00 (sâˆ— ) |= Ï†. Since L00 (sâˆ— ) = L0 (sâˆ— ), and (M 0 , sâˆ— ) |= Ï†
iff L0 (sâˆ— ) |= Ï†, we have (M 00 , sâˆ— ) |= Ï† iff (M 00 , sâˆ— ) |= Ï†. (b) Assume that the result holds for
formula Ï†. (c) We consider variours cases for formulas constructed from Ï†. (c.1) Suppose
Ï† is of the form AGÏ†. (M 0 , sâˆ— ) |= AGÏ† iff for every path from sâˆ— Ï€ 0 = [sâˆ— , Â· Â· Â· , ], and for
every state s0 âˆˆ Ï€ 0 , (M 0 , s0 ) |= Ï†. From the construction of M 00 , it is obvious that every
path from sâˆ— in M 0 must be also a path in M 00 , and vice versa. Also from the induction
assumption, we have (M 0 , s0 ) |= Ï† iff (M 00 , s0 ) |= Ï†. This follows that (M 0 , sâˆ— ) |= AGÏ† iff
(M 00 , sâˆ— ) |= AGÏ†. Proofs for other cases such as AFÏ†, EGÏ†, etc. are similar.
Thus, we can find another model M 00 such that (M 00 , s00 ) |= Ï† and M 00 <M M 0 . This
contradicts to the fact that (M 0 , s00 ) is an admissible model from the update of (M, s 0 ) by
Ï†. 2

Theorem 2 Let M = (S, R, L) be a Kripke model and M = (M, s 0 ) 6|= EXÏ†, where s0 âˆˆ S
and Ï† is a propositional formula. Let M 0 = Update(M, EXÏ†) be the model obtained from
the update of M with EXÏ† through the following 1 or 2, then M 0 is an admissible model.
1. PU3 is applied to one succ(s0 ) to make L0 (succ(s0 )) |= Ï† and
diff (L(succ(s0 )), L0 (succ(s0 ))) minimal, or, PU4 and PU1 are applied once successively to add a new state sâˆ— such that L0 (sâˆ— ) |= Ï† and a new relation element (s0 , sâˆ— );
2. if there exists some si âˆˆ S such that L(si ) |= Ï† and si 6= succ(s0 ), PU1 is applied
once to add a new relation element (s 0 , si ).
Proof: Consider case 1 first. After PU3 is applied to change the assignment on succ(s 0 ),
or PU4 and PU1 are applied to add a new state s âˆ— and a relation element (s0 , sâˆ— ), the new
model M 0 contains a succ(s0 ) such that L0 (succ(s0 )) |= Ï†. Thus, M0 = (M 0 , s0 ) |= EXÏ†. If
PU3 is applied once, then Diff (M, M0 ) = (âˆ…, âˆ…, {succ(s0 )}, âˆ…, âˆ…); if PU4 and PU1 are applied once successively, Diff (M, M0 ) = ({(s0 , sâˆ— )}, âˆ…, âˆ…, {, sâˆ— }, âˆ…). Thus, updates by a single
application of PU3 or applications of PU4 and PU1 once successively are not compatible
with each other. For PU3, if any other update is applied in combination, Diff (M, M 00 ) will
either be not compatible with Diff (M, M 0 ) or contain Diff (M, M0 ) (e.g., another PU3
together with its predecessor). A similar situation occurs with the applications of PU4
and PU1. Thus, applying either PU3 once or PU4 and PU1 once successively represents
a minimal change. For case 2, after PU1 is applied to connect s 0 and L(si ) |= Ï†, the new
model M 0 has a successor which satisfies Ï†. Thus, M 0 = (M 0 , s0 ) |= EXÏ†. If PU1 is applied,
Diff (M, M0 ) = ({(s0 , si )}, âˆ…, âˆ…, âˆ…, âˆ…). Note that this case remains a minimal change of the
relation element on the original model M and is not compatible with case 1. Hence, case 2
130

CTL Model Update for System Modifications

also represents a minimal change. 2
Theorem 2 provides two cases where admissible CTL model update results can be
achieved for formula EXÏ†. It is important to note that here we restrict Ï† to be a propositional formula. The first case says that we can either select one of the successor states of
s0 and change its assignment minimally to satisfy Ï† (i.e., apply PU3 once), or simply add
a new state and a new relation element that satisfies Ï† as a successor of s 0 (i.e., apply PU4
and PU1 once successively). The second case indicates that if some state s i in S already
satisfies Ï†, then it is enough to simply add a new relation element (s 0 , si ) to make it a
successor of s0 . Clearly, both cases will yield new CTL models that satisfy EXÏ†.
Theorem 3 Let M = (S, R, L) be a Kripke model and M = (M, s 0 ) 6|= AGÏ†, where s0 âˆˆ S,
Ï† is a propositional formula and s0 |= Ï†. Let M0 = Update(M, AGÏ†) be a model obtained
from the update of M with AGÏ† through the following way, then M 0 is an admissible model.
For each path starting from s0 : Ï€ = [s0 , Â· Â· Â· , si , Â· Â· Â·]:
1. if for all s < si in Ï€, L(s) |= Ï† but L(si ) 6|= Ï†, PU2 is applied to remove relation
element (siâˆ’1 , si ); or
2. PU3 is applied to all states s in Ï€ not satisfying Ï† to change their assignments such
that L0 (s) |= Ï† and diff (L(s), L0 (s)) is minimal.
Proof: Case 1 is simply to cut path Ï€ from the first state s i that does not satisfy Ï†. Clearly,
there is only one minimal way to cut Ï€: remove relation element (s iâˆ’1 , s) (i.e., apply PU2
once). Case 2 is to minimally change the assignments for all states belonging to Ï€ that do
not satisfy Ï†. Since the changes imposed by case 1 and case 2 are not compatible with each
other, both will generate admissible update results. 2
In Theorem 3, case 1 considers a special form of the path Ï€ where the first i states
starting from s0 already satisfy formula Ï†. Under this condition, we can simply cut off the
path to disconnect all other states not satisfying Ï†. Case 2 is straightforward: we minimally
modify the assignments of all states belonging to Ï€ that do not satisfy formula Ï†.
Theorem 4 Let M = (S, R, L) be a Kripke model, M = (M, s 0 ) 6|= EGÏ†, where s0 âˆˆ S
and Ï† is a propositional formula. Let M 0 = Update(M, EGÏ†) be a model obtained from the
update of M with EGÏ† through the following way, then M 0 is an admissible model: Select
a path Ï€ = [s0 , s1 , Â· Â· Â· , si , Â· Â· Â· , sj , Â· Â· Â·] from M which contains minimal number of different
states not satisfying Ï†3 , and then
1. if for all s0 âˆˆ Ï€ such that L(s0 ) 6|= Ï†, there exist si , sj âˆˆ Ï€ satisfying si < s0 < sj and
âˆ€s â‰¤ si or âˆ€s â‰¥ sj , L(s) |= Ï†, then PU1 is applied to add a relation element (s i , sj ),
or PU4 and PU1 are applied to add a state s âˆ— such that L0 (sâˆ— ) |= Ï† and new relation
elements (si , sâˆ— ) and (sâˆ— , sj );
2. if âˆƒsi âˆˆ Ï€ such that âˆ€s â‰¤ si , L(s) |= Ï†, and âˆƒsk âˆˆ Ï€ 00 , where Ï€ 00 = [s0 , Â· Â· Â· , sk , Â· Â· Â·] such
that âˆ€s â‰¥ sk and L(s) |= Ï†, then PU1 is applied to connect s i and sk ;
3. Note that although a path may be infinite, it will only contain finite number of different states.

131

Zhang & Ding

3. if âˆƒsi âˆˆ Ï€ (i > 1) such that for all s0 < si , L(s0 ) |= Ï†, L(si ) 6|= Ï†, then,
a. PU1 is applied to connect siâˆ’1 and s0 to form a new transition (siâˆ’1 , s0 );
b. if si is the only successor of siâˆ’1 , then PU2 is applied to remove relation element
(siâˆ’1 , si );
4. if âˆƒ s0 âˆˆ Ï€, such that L(s0 ) 6|= Ï†, then PU3 is applied to change the assignments for
all states s0 such that L0 (s0 ) |= Ï† and diff (L(s), L0 (s0 )) is minimal.
Proof: In case 1, without loss of generality, we assume for the selected path Ï€, there
exist states s0 that do not satisfy Ï†, and all other states in Ï€ satisfy Ï†. We also assume
that such s0 are in the middle of path Ï€. Therefore, there are two other states s i , sj in
Ï€ such that si < s0 < sj . That is, Ï€ = [s0 , Â· Â· Â· , siâˆ’1 , si , Â· Â· Â· , s0 , Â· Â· Â· , sj , sj+1 , Â· Â· Â·]. We first
consider applying PU1. It is clear that by applying PU1 to add a new relation element
(si , sj ), a new path is formed: Ï€ 0 = [s0 , Â· Â· Â· , siâˆ’1 , si , sj , sj+1 , Â· Â· Â·]. Note that each state
in Ï€ 0 is also in path Ï€ and s0 6âˆˆ Ï€ 0 . Accordingly, we know that EGÏ† holds in the new
model M 0 = (S, R âˆª {(si , sj )}, L) at state s0 . Consider M = (M, s0 ) and M0 = (M 0 , s00 ).
Clearly, Diff (M, M0 ) = ({(si , sj )}, âˆ…, âˆ…, âˆ…, âˆ…), which implies that (M 0 , s0 ) must be a minimally changed model with respect to â‰¤ M that satisfies EGÏ†.
Now we consider applying PU4 and PU1. In this case, we will have a new model
M 0 = (S âˆª {sâˆ— }, R âˆª {(si , sâˆ— ), (sâˆ— , sj )}, L0 ) where L0 is an extension of L on new state sâˆ—
that satisfies Ï†. We can see that Ï€ 0 = [s0 , Â· Â· Â· , si , sâˆ— , sj , Â· Â· Â·] is a path in M 0 which shares
all states with path Ï€ except the state s âˆ— in Ï€ 0 and those states between si+1 and sjâˆ’1
including s0 in Ï€. So we also have (M 0 , s0 ) |= EGÏ†. Furthermore, we have Diff (M, M 0 ) =
({(si , sâˆ— ), (sâˆ— , sj )}, âˆ…, âˆ…, {sâˆ— }, âˆ…). Obviously, (M 0 , s0 ) is a minimally changed model with
respect to â‰¤M that satisfies EGÏ†.
It is worth mentioning that in case 1, the model obtained by only applying PU1 is not
comparable to the model obtained by applying PU4 and PU1, because no set inclusion
relation holds for the changes on relation elements caused by these two different ways.
In case 2, consider two different paths Ï€ = [s 0 , Â· Â· Â· , si , Â· Â· Â·] and Ï€ 0 = [s0 , Â· Â· Â· , sk , Â· Â· Â·] such
that all states before state si in path Ï€ satisfy Ï†, and all states after state s k in path Ï€ 0
satisfy Ï†, then PU1 is applied to form a new transition (s i , sk ). This transition therefore
connects all states from s0 to si in path Ï€ and all states after sk in path Ï€ 0 . Hence all states
in the new path [s0 , Â· Â· Â· , si , sk Â· Â· Â·] satisfy Ï†. Thus, M0 |= EGÏ†. Such change is also minimal,
because after PU1 is applied, Diff (M, M 0 ) = ({(si , sk )}, âˆ…, âˆ…, âˆ…, âˆ…) is minimum and (M 0 , s0 )
is a minimally changed model with respect to â‰¤ M that satisfies EGÏ†.
In case 3, there are two situations. (a) If PU1 is applied to form a new transition (siâˆ’1 , s0 ), then a new path containing [s0 , Â· Â· Â· , s0 , Â· Â· Â· , siâˆ’1 , s0 , Â· Â· Â· , siâˆ’1 , s0 , Â· Â· Â·] consists
of Strongly Connected Components where all states satisfy Ï†, and
Diff (M, M0 ) = ({(siâˆ’1 , s0 )}, âˆ…, âˆ…, âˆ…, âˆ…) is minimum. Thus, (M 0 , s0 ) is a minimally changed
model with respect to â‰¤M that satisfies EGÏ†.
(b) If PU2 is applied, then, a new path Ï€ 0 containing [s0 , Â· Â· Â· , s0 , Â· Â· Â· , siâˆ’1 ] is derived
where all states satisfy Ï† and Dif f (M, M 0 ) = (âˆ…, {(siâˆ’1 , si )}, âˆ…, âˆ…, âˆ…) is minimal. Obviously,
(M 0 , s0 ) is a minimally changed model with respect to â‰¤ M that satisfies EGÏ†.
In case 4, suppose that there are n states on the selected path Ï€ that do not satisfy Ï†.
After PU3 is applied to all these states, Diff (M, M 0 ) = (âˆ…, âˆ…, {s01 , s02 , Â· Â· Â· , s0n }, âˆ…, âˆ…), where
for each s0 âˆˆ {s01 , Â· Â· Â· , s0n }, dif f (L(s0 ), L0 (s0 )) is minimal. Diff (M, M0 ) in this case is not
132

CTL Model Update for System Modifications

compatible with those in cases 1, 2 and 3. Thus, (M 0 , s0 ) is a minimally changed model
with respect to â‰¤M that satisfies EGÏ†. 2
Theorem 4 characterizes four typical situations for the update with formula EGÏ† where
Ï† is a propositional formula. Basically, this theorem says that in order to make formula
EGÏ† true, we first select a path, then we can either make a new path based on this path so
that all states in the new path satisfy Ï† (i.e., case 1, case 2 and case 3(a)), or trim the path
from the state where all previous states satisfy Ï† (i.e., case 3(b)), if the previous state has
only this state as its successor; or simply change the assignments for all states not satisfying
Ï† in the path (i.e., case 4). Our proof shows that models obtained from these operations
are admissible.
It is possible to provide further semantic characterizations for updates with other special
CTL formulas such as EFÏ†, AXÏ†, and E[Ï†UÏˆ]. In fact, in our prototype implementation,
such characterizations have been used to simplify the update process whenever certain
conditions hold.
We should also indicate that all characterization theorems presented in this section only
provide sufficient conditions to compute admissible models. There are other admissible
models which will not be captured by these theorems.

5. Computational Properties
In this section, we study computational properties for our CTL model update approach in
some detail. We will first present a general complexity result, and then we identify a useful
subclass of CTL model updates which can always be achieved in polynomial time.
5.1 The General Complexity Result
Theorem 5 Given two CTL Kripke models M = (S, R, L) and M 0 = (S 0 , R0 , L0 ), where
s0 âˆˆ S and s00 âˆˆ S 0 , and a CTL formula Ï†, it is co-NP-complete to decide whether (M 0 , s00 )
is an admissible model of the update of (M, s 0 ) to satisfy Ï†. The hardness holds even if Ï†
is of the form EXÏˆ where Ïˆ is a propositional formula.
Proof: Membership proof: Firstly, we know from Clarke et al. (1999) that checking
whether (M 0 , s00 ) satisfies Ï† or not can be performed in time O(|Ï†| Â· (|S| + |R|)). In order
to check whether (M 0 , s00 ) is an admissible update result, we need to check whether M 0 is
a minimally updated model with respect to ordering â‰¤ M . For this purpose, we consider
the complement of the problem by checking whether M 0 is not a minimally updated model.
Therefore, we do two things: (1) guess another updated model of M : M 00 = (S 00 , R00 , L00 )
satisfying Ï† for some s00 âˆˆ S 00 ; and, (2) test whether M 00 <M M 0 . Step (1) can be done
in polynomial time. To check M 00 <M M 0 , we first compute dif f (S, S 0 ), dif f (S, S 00 ),
dif f (R, R0 ) and dif f (R, R00 ). All these can be computed in polynomial time. Then, according to these sets, we identify Dif f P U i (M, M 0 ) and Dif fP U i(M, M 00 ) (i = 1, Â· Â· Â· , 5) in
terms of PU1 to PU5. Again, these steps can also be completed in polynomial time. Finally,
by checking Dif fP U i(M, M 00 ) âŠ† Dif fP U i(M, M 0 ) (i = 1, Â· Â· Â· , 5), and dif f (L(s), L0 (s)) âŠ†
dif f (L(s), L00 (s)) for all s âˆˆ Dif fP U 3 (M, M 00 ) (if Dif fP U 3 (M, M 00 ) = Dif fP U 3 (M, M 0 )),
133

Zhang & Ding

we can decide whether M 00 <M M 0 . Thus, both steps (1) and (2) can be achieved in
polynomial time with a non-deterministic Turing machine.
Hardness proof: It is well known that the validity problem for a propositional formula
is co-NP-complete. Given a propositional formula Ï†, we construct a transformation from
the problem of deciding Ï†â€™s validity to a CTL model update in polynomial time. Let X be
the set of all variables occurring in Ï†, and a, b two new variables do not occur in X. We
V
denote Â¬X = xi âˆˆX Â¬xi . Then, we specify a CTL Kripke model based on the variable set
X âˆª {a, b}: M = ({s0 , s1 }, {(s0 , s1 ), (s1 , s1 )}, L), where L(s0 ) = âˆ… (i.e., all variables are assigned false), L(s1 ) = X (i.e., variables in X are assigned true, while a, b are assigned false).
Now we define a new formula Âµ = EX(((Ï† âŠƒ a)âˆ§(Â¬X âˆ§b))âˆ¨(Â¬Ï†âˆ§a)). Clearly, formula ((Ï† âŠƒ
a)âˆ§(Â¬X âˆ§b))âˆ¨(Â¬Ï†âˆ§a) is satisfiable and s 1 6|= ((Ï† âŠƒ a)âˆ§(Â¬X âˆ§b))âˆ¨(Â¬Ï†âˆ§a). So (M, s 0 ) 6|= Âµ.
Consider the update U pdate((M, s0 ), Âµ). We define M 0 = ({s0 , s1 }, {(s0 , s1 ), (s1 , s1 )}, L0 ),
where L0 (s0 ) = L(s0 ) and L0 (s1 ) = {a, b}. Next, we will show that Ï† is valid iff (M 0 , s0 ) is
an admissible update result from U pdate((M, s 0 ), Âµ).
Case 1: We show that if Ï† is valid, then (M 0 , s0 ) is an admissible update result from
U pdate((M, s0 ), Âµ). Since Ï† is valid, we have Â¬X |= Ï†. Thus, L 0 (s1 ) |= (Ï† âŠƒ a) âˆ§ (Â¬X âŠƒ b)).
This leads to (M 0 , s0 ) |= Âµ. Also note that M 0 is obtained by applying PU3 to change L(s 1 )
to L0 (s1 ). dif f (L(s1 ), L0 (s1 )) = X âˆª {a, b}, which presents a minimal change from L(s 1 ) in
order to satisfy (Ï† âŠƒ a) âˆ§ (Â¬X âˆ§ b).
Case 2: Suppose that Ï† is not valid. Then, X 1 âŠ† X exists such that X1 |= Â¬Ï†. We construct M 00 = ({s0 , s1 }, {(s0 , s1 ), (s1 , s1 )}, L00 ), where L00 (s0 ) = L(s0 ) and L00 (s1 ) = X1 âˆª {a}.
It can be seen that L00 (s1 ) |= (Â¬Ï† âˆ§ a), hence (M 00 , s0 ) |= Âµ. Now we show that (M 0 , s0 ) |= Âµ
implies M 00 <M M 0 . Suppose (M 0 , s0 ) |= Âµ. Clearly, both M 0 and M 00 are each obtained from M by applying PU3 once to change the assignment on s 1 . However, we have
dif f (L(s1 ), L00 (s1 )) = (X âˆ’ X1 ) âˆª {a} âŠ‚ X âˆª {a, b} = dif f (L(s), L0 (s1 )). Thus, we conclude
that (M 0 , s0 ) is not an admissible updated model. 2
Theorem 5 implies that it is probably not feasible to develop a polynomial time algorithm
to implement our CTL model update. Indeed, our algorithm described in the next section,
generally runs in exponential time.
5.2 A Tractable Subclass of CTL Model Updates
In the light of the complexity result of Theorem 5, we expect to identify some useful cases
of CTL model updates which can be performed efficiently. First, we have the following
observation.
Observation: Let M = (S, R, L) be a CTL Kripke model, Ï† a CTL formula and (M, s 0 ) 6|=
Ï† where s0 âˆˆ S. If an admissible model U pdate((M, s 0 ), Ï†) is obtained by only applying
operations PU1 and PU2 to M , then this result can be computed in polynomial time.
Intuitively, if an admissible updated model can be obtained by only using PU1 and PU2,
then it implies that we only need to at most visit all states and relation elements in M , and
each operation involving PU1 or PU2 can be completed by just adding or removing relation
elements, which obviously can be done in linear time.
134

CTL Model Update for System Modifications

This observation tells us that under certain conditions, operations PU1 and PU2 may be
efficiently applied to compute an admissible model. This is quite obvious because both PU3
and PU4 are involved in finding models for some propositional formulas, while applying
PU3 usually needs to further find the minimal change on the assignment on the state,
both of these operations may cost exponential time in the size of input updating formula
Ï†. However, the above observation does not tell us what kinds of CTL model updates can
really be achieved in polynomial time. In the following, we will provide a sufficient condition
for a class of CTL model updates which can always be solved in polynomial time.
We first specify a subclass of CTL formulas AEClass: (1) formulas AXÏ†, AGÏ†, AFÏ†,
A[Ï†1 UÏ†2 ], EXÏ†, EGÏ†, EFÏ† and E[Ï†1 UÏ†2 ] are in AEClass, where Ï†, Ï†1 and Ï†2 are propositional formulas; (2) if Ïˆ1 and Ïˆ2 are in AEClass, then Ïˆ1 âˆ§ Ïˆ2 and Ïˆ1 âˆ¨ Ïˆ2 are in
AEClass; (3) no formulas other than those specified in (1) and (2) are in AEClass. We
also call formulas of the forms specified in (1) are atomic AEClass formulas.
Note that AEClass is a class of CTL formulas without nested temporal operators.
Although this is somewhat restricted, as we will show next, updates with this kind of CTL
formulas may be much simpler than other cases. Now we define valid states and paths for
AEClass formulas with respect to a given model.
Definition 6 (Valid state and path for AEClass) Let M = (S, R, L) be a CTL Kripke
model, Ïˆ âˆˆ AEClass, and (M, s0 ) 6|= Ïˆ, where s0 âˆˆ S. We define Ïˆâ€™s valid state or valid
path in (M, s0 ) as follows.
1. If Ïˆ is of the form AXÏ†, then state s âˆˆ S is a valid state of Ïˆ in (M, s 0 ) if (s0 , s) âˆˆ R
and L(s) |= Ï†;
2. If Ïˆ is of the form (a) AGÏ†, (b) AFÏ† or (c) A[Ï† 1 UÏ†2 ], then a path Ï€ = [s0 , Â· Â· Â·] is
a valid path of Ïˆ in (M, s0 ) if âˆ€s âˆˆ Ï€, L(s) |= Ï† (case (a)); âˆƒs âˆˆ Ï€ and s > s 0 ,
L(s) |= Ï† (case (b)); or âˆƒs âˆˆ Ï€, s |= Ï†2 and âˆ€s0 < s L(s0 ) |= Ï†1 (case (c)) respectively;
3. If Ïˆ is of the form EXÏ†, then state s âˆˆ S is a valid state of Ïˆ in (M, s 0 ) if L(s) |= Ï†;
4. If Ïˆ is of the form (a) EGÏ†, (b) EFÏ† or (c) E[Ï† 1 UÏ†2 ], then a path Ï€ = [s00 , Â· Â· Â·]
(s00 6= s0 ) is a valid path of Ïˆ in (M, s0 ) if âˆ€s âˆˆ Ï€, L(s) |= Ï† and L(s0 ) |= Ï† (case
(a)); âˆƒs âˆˆ Ï€ and s > s00 , L(s) |= Ï† (case (b)); or L(s0 ) |= Ï†1 and âˆƒs âˆˆ Ï€, L(s) |= Ï†2
and âˆ€s0 < s L(s0 ) |= Ï†1 (case (c)) respectively.
For an arbitrary Ïˆ âˆˆ AEClass, we say that Ïˆ has a valid witness in (M, s 0 ) if every atomic
AEClass formula occurring in Ïˆ has a valid state or path in (M, s 0 ).
Intuitively, for formulas AXÏ†, AGÏ†, AFÏ† and A[Ï† 1 UÏ†2 ], a valid state or path in a
CTL model represents a local structure that partially satisfies the underlying formula. For
formulas EXÏ†, EGÏ†, EFÏ† and E[Ï†1 UÏ†2 ], on the other hand, a valid state or path also
represents a local structure which will satisfy the underlying formula if a relation element
is added to connect this local structure and the initial state.
Example 3 Consider the CTL Kripke model M in Figure 10 and formula EX(p âˆ§ q).
Clearly, (M, s0 ) 6|= EX(p âˆ§ q). Since p, q âˆˆ L(s3 ), s3 is a valid state of EX(p âˆ§ q). Then
135

Zhang & Ding

S0

S1
p

S2

q

r

S3

S4

p,q

r,p

Figure 10: A simple CTL model update.

we can simply add one relation element (s 0 , s3 ) into M to form a new model M 0 so that
(M 0 , s0 ) |= EX(p âˆ§ q). Obviously, (M 0 , s0 ) is an admissible updated model.
2
From the above example, we observe that if we update a CTL model with an AEClass
formula and this formula has a valid witness in the model, then it is possible to compute an
admissible model by only adding or removing relation elements (i.e. operations PU1 and
PU2). The following results confirm that a CTL model update with an AEClass formula
may be achieved in polynomial time if the formula has a valid witness in the model.
Theorem 6 Let M = (S, R, L) be a CTL Kripke model, Ïˆ âˆˆ AEClass, and (M, s 0 ) 6|=
Ïˆ. Deciding whether Ïˆ has a valid witness in (M, s 0 ) can be solved in polynomial time.
Furthermore, if Ïˆ has a valid witness in (M, s 0 ), then all valid states and paths of atomic
AEClass formulas occurring in Ïˆ can be computed from (M, s 0 ) in time O(|Ïˆ|Â·(|S|+|R|)2 ).

Proof: To prove this theorem, we show that by using CTL model checking algorithm SAT
(Huth & Ryan, 2004), which takes a CTL Kripke model and an AEClass formula as inputs,
we can generate all valid states and paths of atomic AEClass formulas occurring in Ïˆ (if
any). We know that the complexity of algorithm SAT is O(|Ïˆ| Â· (|S| + |R|)). We consider
each case of atomic AEClass formulas.
Ïˆ is AXÏ†. We use SAT to check whether (M, s 0 ) |= EXÏ†. If (M, s0 ) 6|= EXÏ†, then
AEÏ† does not have a valid state in (M, s 0 ). Otherwise, SAT will return a state s such that
L(s) |= Ï† and (s0 , s) âˆˆ R. Then remove relation element (s 0 , s) from M , and continue
checking formula EXÏ† in the model. By the end of this process, we obtain all valid states
in (M, s0 ) for formula AXÏ†. Altogether, there are at most |S| SAT calls.
Ïˆ is AGÏ†. We use SAT to check whether (M, s 0 ) |= EGÏ†. If (M, s0 ) |= EGÏ†, then we
can obtain a path in M from SAT Ï€ = [s0 , s1 , Â· Â· Â·] such that âˆ€s âˆˆ Ï€, L(s) |= Ï†. Clearly,
such Ï€ is a valid path of AGÏ†. Now if there does not exist a state s âˆ— such that sâˆ— 6âˆˆ Ï€
and (s, sâˆ—) âˆˆ R for some s âˆˆ Ï€, i.e. state s connects to state s âˆ— leading to a different path,
136

CTL Model Update for System Modifications

then the process stops, and Ï€ is the only valid path for AGÏ†. Otherwise, Then we remove
one relation element (s, s0 ) from Ï€ (i.e. s, s0 âˆˆ Ï€) such that for all states s00 âˆˆ Ï€ where
s0 < s00 , there is no relation element (s00 , sâˆ— ) leading to a different path (i.e. sâˆ— 6âˆˆ Ï€). In
this way, we actually disable path Ï€ to satisfy formula EGÏ† without affecting other paths.
Then we continue checking formula EGÏ† in the newly obtained model. By the end of this
process, we will obtain all paths that make EGÏ† true, and these paths are all valid paths
for AGÏ†. Since for each generated valid path, we need to remove one relation element from
this path before we generate the next valid path, there are at most |R| such valid paths
to be generated. So all together, there are at most |R| SAT calls to find all valid paths of
AGÏ†.
In the cases of AFÏ† and A[Ï†UÏ†2 ], all valid paths for these formulas can be generated
in a similar way as described above for formula AGÏ†. The only different point is that for
the case of A[Ï†UÏ†2 ], once a valid path Ï€ has been generated, we need to find the last state
s âˆˆ Ï€ before Ï†2 becomes true, such that s connects to a state s âˆ— 6âˆˆ Ï€ leading to a different
path, then we disable Ï€ by removing relation element (s, succ(s)) from Ï€. Then we continue
the procedure to generate the next valid path for A[Ï†UÏ† 2 ]. If no such s exists in Ï€, then
the process stops.
Ïˆ is EXÏ†. In this case, each valid state s can be found by checking whether L(s) |= Ï†.
At most we need to visit |S| states for this checking.
Ïˆ is EGÏ†. Similarly, we can find a valid path by selecting a state s âˆˆ S (s 6= s 0 ), such
that (M, s) |= EGÏ†. At most, we need to visit |S| states, and have |S| SAT calls to check
(M, s) |= EGÏ†.
Finally, valid paths for EFÏ† and E[Ï† 1 âˆª Ï†2 ] can be found in a similar way. 2

Theorem 7 Let M = (S, R, L) be a CTL Kripke model, Ïˆ âˆˆ AEClass, and (M, s 0 ) 6|= Ïˆ.
An admissible model U pdate((M, s0 ), Ïˆ) can be computed in polynomial time if Ïˆ has a valid
witness in (M, s0 ).
Proof: From the proof of Theorem 6, we can obtain all valid states and paths for all atomic
AEClass formulas in Ïˆ in time O(|Ïˆ| Â· (|S| + |R|) 2 ). Now we consider each case of atomic
AEClass formulas Ïˆ, while the cases of conjunctive and disjunctive AEClass formulas are
easy to justify.
Ïˆ is AXÏ†. Let S âˆ— = {s1 , Â· Â· Â· , sk } be all valid states for AXÏ†. Then we remove all relation
elements (s0 , s) where s 6âˆˆ S âˆ— . In this way, we obtain a new model M 0 = (S, R0 , L), where
R0 = R âˆ’ {(s0 , s) | s 6âˆˆ S âˆ— }. Obviously, we have (M 0 , s0 ) |= AXÏ†. It is also easy to see that
the change between M and M 0 is minimal in order to satisfy AXÏ†. So (M 0 , s0 ) is also an
admissible model.
Ïˆ is AGÏ†. Let S âˆ— be the set of all states that are in some valid paths of AGÏ†. For each
state s0 âˆˆ S such that L(s0 ) 6|= Ï†, we check whether s0 is reachable from s0 . If it is reachable,
then we remove a relation element (s 1 , s2 ) from M so that s0 becomes unreachable from
s0 and (s1 , s2 ) is not a relation element in a valid path of AGÏ†. Clearly, model (M 0 , s0 )
will then satisfy AGÏ†. Also, checking whether a state is reachable from s 0 can be done in
polynomial time by computing a spanning tree of M rooted at s 0 (Pettie & Ramachandran,
2002).
137

Zhang & Ding

Ïˆ is AFÏ†. In this case, we need to cut all those paths starting from s 0 that are not
valid paths for AFÏ† in (M, s0 ). For doing this, it is sufficient to disconnect all states that
are reachable from s0 but not occur in any of AFÏ†â€™s valid paths in (M, s 0 ). Let S âˆ— be the
set of all these states, and R âˆ— be the set of all relation elements that are directly connected
to these states, i.e. (s1 , s2 ) âˆˆ Râˆ— iff s1 âˆˆ S âˆ— or s2 âˆˆ S âˆ— . Then we remove a minimal subset
of Râˆ— from M such that removing them will disconnect all states in S âˆ— from s0 . The set
S âˆ— can be identified in polynomial time by computing a spanning tree of M rooted at s 0 ,
and the minimal subset of R âˆ— that disconnects all states S âˆ— from s0 can be found in time
O(|Râˆ— |2 ). So the entire process can be completed in polynomial time.
The case of A[Ï†1 UÏ†2 ] can be handled in a similar way as described above for AFÏ†.
Now we consider that Ïˆ is EXÏ†. In this case, we only need to select one valid state s for
EXÏ†, and add relation element (s0 , s) into M . Then the model (M 0 , s0 ) satisfies EXÏ†. For
the case of EGÏ†, we also select a valid path Ï€ = [s, Â· Â· Â·] for EGÏ†, and then add a relation
element (s0 , s), so we have (M 0 , s0 ) |= EGÏ†. The other two cases of EFÏ† and E[Ï† 1 UÏ†2 ] can
be handled in a similar way. 2
We should emphasize that although the above results characterize a useful subclass of
CTL model update scenarios in which some admissible updated models can be computed
through simple operations of adding or removing relation elements, it does not mean that
all such admissible models represent intuitive modifications from a practical viewpoint.
Sometimes, for the same update problem, using other operations such as PU3 and PU4 are
probably more preferred in order to generate a sensible system modification. This will be
illustrated in Section 7.

6. CTL Model Update Algorithm
We have implemented a prototype for the CTL model update. In this implementation, the
CTL model update algorithm is designed in line with the CTL model checking algorithm
used in SAT (Huth & Ryan, 2004), where an updated formula is parsed according to its
structure and recursive calls to appropriate functions are used. This recursive call usage
allows the checked property Ï† to range from nested modalities to atomic propositional
formulas. In this section, we will focus our discussions on the key ideas of handling CTL
model update and provide high level pseudo code for major functions in the algorithm.
6.1 Main Functions
Handling propositional formulas
Since the satisfaction of a propositional formula does not involve any relation elements
in a CTL Kripke model, we implement the update with a propositional formula directly
through operation PU3 with a minimal change on the labeling function of the truth assignment on the relevant state. This procedure is outlined as follows.
âˆ— function Updateprop ((M, s0 ), Ï†) âˆ—
input: (M, s0 ) and Ï†, where M = (S, R, L) and s0 âˆˆ S;
output: (M 0 , s00 ), where M 0 = (S 0 , R0 , L0 ), s00 âˆˆ S 0 and L0 (s00 ) |= Ï†;
138

CTL Model Update for System Modifications

01 begin
02
apply PU3 to change labeling function L on state s 0 to form a new model M 0 =
0
0
(S , R , L0 ):
03
S 0 = S; R0 = R; âˆ€s âˆˆ S that s 6= s0 , L0 (s) = L(s);
04
L0 (s0 ) is defined such that L0 (s0 ) |= Ï†, and dif f (L0 (s0 ), L(s0 )) is minimal;
05
return (M 0 , s0 );
06 end
It is easy to observe that this procedure is implemented as the PMA belief update
(Winslett, 1988). It is used in the lowest level in our CTL model update prototype.
Handling modal formulas AFÏ†, EXÏ† and E[Ï† 1 âˆª Ï†2 ]
From the De Morgan rules and equivalences displayed in Section 2.1, we know that all
CTL formulas with modal operators can be expressed in terms of these three typical CTL
modal formulas. Hence it is sufficient to only give the update functions for these three types
of formulas without considering other types of CTL modal formulas.
âˆ— function UpdateAF ((M, s0 ), AFÏ†) âˆ—
input: (M, s0 ) and AFÏ†, where M = (S, R, L), s0 âˆˆ S, and (M, s0 ) 6|= AFÏ†;
output: (M 0 , s00 ), where M 0 = (S 0 , R0 , L0 ), s00 âˆˆ S 0 and (M 0 , s00 ) |= AFÏ†;
01 begin
02
if for all s âˆˆ S, (M, s) 6|= Ï†,
03
then select a state s âˆˆ S that is reachable from s 0 , (M 0 , sâˆ— ) = CTLUpdate((M, s), Ï†)4 ;
04
else select a path Ï€ starting from s 0 where for all s âˆˆ Ï€, (M, s) 6|= Ï†, do (a) or (b):
05
(a) select a state s âˆˆ Ï€, (M 0 , s0 ) = CTLUpdate((M, s), Ï†);
06
(b) apply PU2 to disable path Ï€ and form a new model:
07
remove a relation element from Ï€ that does not affect other paths;
08
form a new model M 0 = (S 0 , R0 , L0 ):
09
S 0 = S, R0 = R âˆ’ {(si , si+1 )} (note (si , si+1 ) âŠ† Ï€), and
10
âˆ€s âˆˆ S 0 , L0 (s) = L(s);
0
11
if (M , s00 ) |= AFÏ†, then return (M 0 , s00 )5 ;
12
else UpdateAF ((M 0 , s00 ), AFÏ†);
13 end
Function UpdateAF handles the update of formula AFÏ† as follows: if no state in the
model satisfies formula Ï†, UpdateAF will first update the model on one state to satisfy Ï†;
otherwise, for each path in the model that fails to satisfy AFÏ†, Update AF either disables
this path in some minimal way, or updates this path to make it valid for AFÏ†.
âˆ— function UpdateEX ((M, s0 ), EXÏ†) âˆ—
input: (M, s0 ) and EXÏ†, where M = (S, R, L), s0 âˆˆ S, and (M, s0 ) 6|= EXÏ†;
output: (M 0 , s00 ), where M 0 = (S 0 , R0 , L0 ), s00 âˆˆ S 0 and (M 0 , s00 ) |= EXÏ†;
01 begin
02
do one of (a), (b) and (c):
4. Here CTLUpdate((M, s), Ï†) is the main update function that we will describe later.
5. Here s00 is the corresponding state of s0 in the updated model M 0 , and the same for other functions
described next.

139

Zhang & Ding

03
04
05
06
07
08
09
10
11
12
13

(a) apply PU1 to form a new model:
select a state s âˆˆ S such that (M, s) |= Ï†;
add a relation element (s0 , s) to form a new model M 0 = (S 0 , R0 , L0 ):
S 0 = S; R0 = R âˆª {(s0 , s)}; âˆ€s âˆˆ S, L0 (s) = L(s);
(b) select a state s = succ(s0 ), (M 0 , sâˆ— ) = CTLUpdate((M, s), Ï†);
(c) apply PU4 and PU1 to form a new model M 0 = (S 0 , R0 , L0 ):
S 0 = S âˆª {sâˆ— }; R0 = R âˆª {(s0 , sâˆ— }; âˆ€s âˆˆ S, L0 (s) = L(s),
L0 (sâˆ— ) is defined such that (M 0 , sâˆ— ) |= Ï†;
0
if (M , s00 ) |= EXÏ†, then return (M 0 , s00 );
else UpdateEX ((M 0 , s00 ), EXÏ†);
end

Function UpdateEX may be viewed as the implementation algorithm of the characterization for EXÏ† in Theorem 2 in Section 4. However, it is worth to mentioning that this
algorithm illustrates the difference in Ï† in all update functions from those in the update
characterizations and demonstrates the wider application of the algorithm compared with
their corresponding characterizations. The usage of recursive calls in the algorithm allows
Ï† to be an arbitrary CTL formula rather than a propositional formula as demonstrated in
the characterizations. This is the major difference between the characterizations and the
algorithmic implementation.
âˆ— function UpdateEU ((M, s0 ), E[Ï†1 UÏ†2 ]) âˆ—
input: (M, s0 ) and E[Ï†1 UÏ†2 ], where M = (S, R, L), s0 âˆˆ S, and (M, s0 ) 6|= E[Ï†1 UÏ†2 ];
output: (M 0 , s00 ), where M 0 = (S 0 , R0 , L0 ), s00 âˆˆ S 0 and (M 0 , s00 ) |= E[Ï†1 UÏ†2 ];
01 begin
02
if (M, s0 ) 6|= Ï†1 , then (M 0 , s00 ) = CTLUpdate((M, s0 ), Ï†1 );
03
else do (a) or (b):
04
(a) if (M, s0 ) |= Ï†1 , and there is a path Ï€ = [sâˆ— , Â· Â· Â·] (s0 6= sâˆ— )
05
such that (M, sâˆ— ) |= E[Ï†1 UÏ†2 ],
06
then apply PU1 to form a new model M 0 = (S 0 , R0 , L0 ):
07
S 0 = S; R0 = R âˆª {(s0 , sâˆ— }; âˆ€s âˆˆ S L0 (s) = L(s);
08
(b) select a path Ï€ = [s0 , Â· Â· Â· , si , Â· Â· Â· , sj , Â· Â· Â·];
09
if âˆ€s s0 < s < si , (M, s) |= Ï†1 , (M, sj ) |= Ï†2 ,
10
but âˆ€s0 si+1 < s0 < sjâˆ’1 , (M, s0 ) 6|= Ï†1 âˆ¨ Ï†2
11
then apply PU1 to form a new model M 0 = (S 0 , R0 , L0 ):
12
S 0 = S; R0 = R âˆª {(si , sj )}; âˆ€s âˆˆ S, L0 (s) = L(s);
13
if âˆ€s s < si , (M, s) |= Ï†1 , and âˆ€s0 s0 > si+1 , (M, s0 ) 6|= Ï†1 âˆ¨ Ï†2 ,
14
then apply PU4 to form a new model M 0 = (S 0 , R0 , L0 ):
15
S 0 = S âˆª {sâˆ— }; R0 = R âˆª {(siâˆ’1 , sâˆ— ), (sâˆ— , si )};
16
âˆ€s âˆˆ S, L0 (s) = L(s), L(sâˆ— ) is defined such that (M 0 , sâˆ— ) |= Ï†2 ;
0
0
17
if (M , s0 ) |= E[Ï†1 UÏ†2 ], then return (M 0 , s00 );
18
else UpdateEU ((M 0 , s00 ), E[Ï†1 UÏ†2 ]);
19 end
To update (M, s0 ) to satisfy formula E[Ï†1 UÏ†2 ], function UpdateEU first checks whether
M satisfies Ï†1 at the initial state s0 . If it does not, then UpdateEU will update this
140

CTL Model Update for System Modifications

initial state so that the model satisfies Ï† 1 at its initial state. This will make the later
update possible. Then under the condition that (M, s 0 ) satisfies Ï†1 , UpdateEU considers
two cases: if there is a valid path in M for formula E[Ï† 1 UÏ†2 ], then it simply links the
initial state s0 to this path and forms a new path that satisfies E[Ï† 1 UÏ†2 ] (i.e. case (a)); or
UpdateEU directly selects a path to make it satisfy formula E[Ï† 1 UÏ†2 ] (i.e. case (b)).
Handling logical connectives Â¬, âˆ¨ and âˆ§
Having the De Morgan rules and equivalences on CTL modal formulas, an update for
formula Â¬Ï† can be handled quite easily. In fact we only need to consider a few primary forms
of negative formulas in our algorithm implementation. Update on a disjunctive formula
Ï†1 âˆ¨ Ï†2 , on the other hand, is simply implemented by calling CTLUpdate((M, s 0 ), Ï†1 )
or CTLUpdate((M, s0 ), Ï†2 ) in a nondeterministic way. Hence here we only describe the
function of updating for conjunctive formula Ï† 1 âˆ§ Ï†2 .
âˆ— function Updateâˆ§ ((M, s0 ), Ï†1 âˆ§ Ï†2 ) âˆ—
input: (M, s0 ) and Ï†1 âˆ§ Ï†2 , where M = (S, R, L), s0 âˆˆ S, and (M, s0 ) 6|= Ï†1 âˆ§ Ï†2 ;
output: (M 0 , s00 ), where M 0 = (S 0 , R0 , L0 ), s00 âˆˆ S 0 and (M 0 , s00 ) |= Ï†1 âˆ§ Ï†2 ;
01 begin
02
if Ï†1 âˆ§ Ï†2 is a propositional formula, then (M 0 , s00 ) = Updateprop ((M, s0 ), Ï†1 âˆ§ Ï†2 );
03
else (M âˆ— , sâˆ—0 ) = CTLUpdate((M, s0 ), Ï†1 );
04
(M 0 , s00 ) = CTLUpdate((M âˆ— , sâˆ—0 ), Ï†2 ) with constraint Ï†1 ;
05
return (M 0 , s00 );
06 end
Function Updateâˆ§ handles update for a conjunctive formula in an obvious way. Line
04 indicates that when we conduct the update with Ï† 2 , we should view Ï†1 as a constraint
that the update has to obey. Without this condition, the result of updating Ï† 2 may violate
the satisfaction of Ï†1 that is achieved in the previous update. We will address this point in
more details in next subsection.
Finally, we describe the CTL model update algorithm as follows.
âˆ— algorithm CTLUpdate((M, s0 ), Ï†) âˆ—
input: (M, s0 ) and Ï†, where M = (S, R, L), s0 âˆˆ S, and (M, s0 ) 6|= Ï†;
output: (M 0 , s00 ), where M 0 = (S 0 , R0 , L0 ), s00 âˆˆ S 0 and (M 0 , s00 ) |= Ï†;
01 begin
02
case
03
Ï† is a propositional formula: return Update prop ((M, s0 ), Ï†);
04
Ï† is Ï†1 âˆ§ Ï†2 : return Updateâˆ§ ((M, s0 ), Ï†1 âˆ§ Ï†2 );
05
Ï† is Ï†1 âˆ¨ Ï†2 : return Updateâˆ¨ ((M, s0 ), Ï†1 âˆ¨ Ï†2 );
06
Ï† is Â¬Ï†1 : return UpdateÂ¬ ((M, s0 ), Â¬Ï†1 );
07
Ï† is AXÏ†1 : return CTLUpdate((M, s0 ), Â¬EXÂ¬Ï†1 );
08
Ï† is EXÏ†1 : return UpdateEX ((M, s0 ), EXÏ†1 );
09
Ï† is A[Ï†1 UÏ†2 ]: return CTLUpdate((M, s0 ), Â¬(E[Â¬Ï†2 U(Â¬Ï†1 âˆ§ Ï†2 )] âˆ¨ EGÂ¬Ï†2 ));
10
Ï† is E[Ï†1 UÏ†2 ]: return UpdateEU ((M, s0 ), E[Ï†1 UÏ†2 ]);
11
Ï† is EFÏ†1 ; return CTLUpdate((M, s0 ), E[>UÏ†1 ]);
12
Ï† is EGÏ†1 : return CTLUpdate((M, s0 ), Â¬AFÂ¬Ï†1 );
141

Zhang & Ding

13
14
15
16

Ï† is AFÏ†1 : return UpdateAF ((M, s0 ), AFÏ†1 );
Ï† is AGÏ†1 : return CTLUpdate((M, s0 ), Â¬E[>UÂ¬Ï†1 ]);
end case;
end

Theorem 8 Given a CTL Kripke model M = (S, R, L) and a satisfiable CTL formula
Ï†, where (M, s0 ) 6|= Ï† and s0 âˆˆ S. Algorithm CTLUpdate((M, s0 ), Ï†) terminates and
generates an admissible model to satisfy Ï†. In the worst case, CTLUpdate runs in time
O(2|Ï†| Â· |Ï†|2 Â· (|S| + |R|)2 ).
Proof: Since we have assumed that Ï† is satisfiable, from above descriptions, it is not
difficult to see that CTLUpdate will only call these functions finite times, and each call
to these functions will (recursively) generate a result that satisfies the underlying updated
formula, and then return to the main algorithm CTLUpdate. So CTLUpdate((M, s 0 ), Ï†)
will terminate, and the output model (M 0 , s00 ) satisfies Ï†.
We can show that the output model (M 0 , s00 ) is admissible by induction on the structure
of Ï†. The proof is quite tedious - it involves detailed examinations on Ï† running through each
update function. Here it is sufficient to observe that for each update function, each time the
input model is updated in a minimal way, e.g., it adds one state or relation element, removes
a minimal set of relation elements to disconnect a state, or updates a state minimally. With
iterated updates on sub-formulas of Ï†, minimal changes on the original input model will be
retained.
Now we consider the complexity of CTLUpdate. We first analyze these functionsâ€™ complexity without considering their embedded recursions. Function Update prop is to update
a state by a propositional formula, which has the worst time complexity O(2 |Ï†| ). Function UpdateAF contains the following major computations: (1) finding a reachable state
in (M, s0 ); (2) selecting a path in which each state does not satisfy Ï†; and (3) checking
(M 0 , s00 ) |= AFÏ†. Task (1) can be achieved by computing a spanning tree of M rooted
at s0 , which can be done in time O(|R| Â· log|S|) (Pettie & Ramachandran, 2002). Task
(2) can be reduced to find a valid path for formula AGÏ†. From Theorem 6, this can be
done in time O(|Ï†| Â· (|S| + |R|)2 ). Task (3) has the same complexity of task (2). So,
overall, function UpdateAF has the complexity O(|Ï†| Â· (|S| + |R|) 2 ). Similarly, we can
show that functions UpdateEX and UpdateEU have complexity O(|Ï†| Â· (|S| + |R|)2 ) and
O(|Ï†| Â· (|S| + |R|)2 + 2|Ï†| ) respectively. Other functionsâ€™ complexity are obvious either from
their implementations based on the De Morgan rules and equivalences, or from the calls
to other functions (i.e. UpdateÂ¬ ) or the main algorithm (i.e. Update âˆ§ and Updateâˆ¨ ). At
most algorithm CTLUpdate has |Ï†| calls to other functions. Therefore, in the worst time,
CTLUpdate runs in time O(2|Ï†| Â· |Ï†|2 Â· (|S| + |R|)2 ). 2

6.2 Discussions
It is worth mentioning that except functions Update prop , UpdateÂ¬ and Updateâˆ§ , all other
functions used in algorithm CTLUpdate are involved in some nondeterministic choices.
This implies that algorithm CTLUpdate is not syntax independent. In other words, given
142

CTL Model Update for System Modifications

a CTL model and two logical equivalent formulas, updating the model with one formula
may generate different admissible models.
In the description of function Update âˆ§ , we have briefly mentioned the issue of constraints
in a CTL model update. In general, when we perform a CTL model update, we usually have
to protect some properties that should not be violated by this update procedure. These
properties are usually called domain constraints. It is not difficult to modify algorithm
CTLUpdate to cope with this requirement. In particular, suppose C is the set of domain
constraints for a system specification M = (S, R, L), and we need to update (M, s 0 ) with
formula Ï†, where s0 âˆˆ S, and C âˆª{Ï†} is satisfiable. Then in each function of CTLUpdate, we
simply add a model checking condition on the candidate model M 0 = (S 0 , R0 , L0 ): (M 0 , s00 ) |=
C (s00 âˆˆ S 0 ). The result (M 0 , s00 ) is returned from the function if it satisfies C. Otherwise,
the function will look for another candidate model. Since model checking (M 0 , s00 ) |= C can
be done in time O(|C| Â· (|S 0 | + |R0 |)), the modified algorithm does not significantly increase
the overall complexity. In our implemented system prototype, we have integrated a generic
constraint checking component as an option to be added into our update functions so that
domain constraints may be taken into account when necessary.
In addition to the implementation of the algorithm CTLUpdate, we have implemented
separate update functions for typical CTL formulas such as EXÏ†, AGÏ†, EGÏ†, AFÏ†, EFÏ†,
etc., where Ï† is a propositional formula, based on our characterizations provided in Section
4.2. These functions simplify an update procedure when the input formula does not contain
nested CTL temporal operators or can be converted into such simplified formula.

7. Two Case Studies
In this section, we show two case studies of applications of our CTL model update approach
for system modifications. The two cases have been implemented in the CTL model updater
prototype, which is a simplified compiler. In this prototype, the input is a complete CTL
Kripke model and a CTL formula, and the output is an updated CTL Kripke model which
satisfies the input formula.
We should indicate that our prototype contains three major components: parsing, model
checking and model update functions. The prototype first parses the input formula and
breaks it down into its atomic subformulas. Then the model checking function checks
whether the input formula is satisfied in the underlying model. If the formula is not satisfied
in the model, our model checking function will generate all relevant states that violate the
input formula. Consequently, this information will directly be used for the model update
function to update the model.
7.1 The Microwave Oven Example
We consider the well-known microwave oven scenario presented by Clarke et al. (1999),
that has been used to illustrate the CTL model checking algorithm on the model describing
the behaviour of a microwave oven. The Kripke model as shown in Figure 11 can be viewed
as a hardware design of a microwave oven. In this Kripke model, each state is labeled with
both the propositional atoms that are true in the state and the negations of propositional
atoms that are false in the state. The labels on the arcs present the actions that cause
state transitions in the Kripke model. Note that actions are not part of this Kripke model.
143

Zhang & Ding

The initial state is state 1. Then the given Kripke model M describes the behaviour of a
microwave oven.

s1

start oven

s2
Start
~Close
~Heat
Error

open door

s5

close door

Start
Close
~Heat
Error

~Start
~Close
~Heat
~Error

open door

close door

s3

s4

~Start
Close
~Heat
~Error

reset

s6

done

~Start
Close
Heat
~Error

start cooking

start oven

Start
Close
~Heat
~Error

cook

open door

s7
warm up

Start
Close
Heat
~Error

Figure 11: CTL Kripke model M of a microwave oven.

It is observed that this model does not satisfy a desired property Ï† = Â¬EF(Start âˆ§
EGÂ¬Heat): â€œonce the microwave oven is started, the stuff inside will be eventually heatedâ€
(Clarke et al., 1999)6 . That is, (M, s1 ) 6|= Ï†. What we would like to do is to apply our
CTL model update prototype to modify this Kripke model to satisfy property Ï†. As we
mentioned earlier, since our prototype combines formula parsing, model checking and model
update together, the update procedure for this case study does not exactly follow the generic
CTL model update algorithm illustrated in Section 6.

s1

~Start
~Close
~Heat
~Error

open door

s2
Start
~Close
~Heat
Error

open door

s5

close door

Start
Close
~Heat
Error

close door

s3

s4

~Start
Close
~Heat
~Error

reset

s6

done

s7
warm up

~Start
Close
Heat
~Error

start cooking

start oven

Start
Close
~Heat
~Error

cook

open door

Start
Close
Heat
~Error

Figure 12: Updated microwave oven model using PU2.

6. This formula is equivalent to AG(Start â†’ AFheat).

144

CTL Model Update for System Modifications

First, we parse Ï† into AG(Â¬(Startâˆ§EGÂ¬Heat)) to remove the front Â¬. The translation is
performed by function UpdateÂ¬ , which is called in CTLUpdate((M, s 1 ), Ï†). Then we check
whether each state satisfies Â¬(Startâˆ§EGÂ¬Heat). First, we select EGÂ¬Heat to be checked
using the model checking function for EG. In this model checking, each path that has every
state with Â¬Heat is identified. Here we find paths [s 1 , s2 , s5 , s3 , s1 , Â· Â· Â·] and [s1 , s3 , s1 , Â· Â· Â·]
which are strongly connected component loops (Clarke et al., 1999) containing all states
with Â¬Heat. Thus the model satisfies EGÂ¬Heat. Consequently, we identify all states with
Start: they are {s2 , s5 , s6 , s7 }. Now we select those states with both Start and Â¬Heat: they
are {s2 , s5 }. Since the formula AG(Â¬(Startâˆ§EGÂ¬Heat)) requires that the model should
not have any states with both Start and Â¬Heat, we should perform model update related
to states s2 and s5 . Now, using Theorem 3 in Section 4.2, the proper update is performed.
Eventually, we obtain two possible minimal updates: (1) applying PU2 to remove relation
element (s1 , s2 ); or (2) applying PU3 to change the truth assignments on s 2 and s5 . After
the update, the model satisfies formula Ï† and it has a minimal change from the original
model M . For instance, by choosing the update (1) above, we obtain a new Kripke model
(as shown in Figure 12), which simply states that no state transition from s 1 to s2 is allowed,
whereas choosing update (2), we obtain a new Kripke model (as shown in Figure 13), which
says that allowing transition from state s 1 to state s2 will cause an error that the microwave
oven could not start in s2 , and this error message will carry on to its next state s 5 .
s1

start oven
s2

~Start
~Close
~Heat
Error

open door

s5 ~Start

close door

Close
~Heat
Error

~Start
~Close
~Heat
~Error

open door

close door

s3

s4

~Start
Close
~Heat
~Error

reset

s6

open door

done

~Start
Close
Heat
~Error

start cooking

start oven

Start
Close
~Heat
~Error

cook

s7
warmup

Start
Close
Heat
~Error

Figure 13: Updated microwave oven model using PU3.

7.2 Updating the Andrew File System 1 Protocol
The Andrew File System 1 (AFS1) (Wing & Vaziri-Farahani, 1995) is a cache coherence
protocol for a distributed file system. AFS1 applies a validation-based technique to the
client-server protocol, as described by Wing and Vaziri-Farahani (1995). In this protocol,
a client has two initial states: either it has no files or it has one or more files but no beliefs
about their validity. If the protocol starts with the client having suspect files, then the client
may request a file validation from the server. If the file is invalid, then the client requests
a new copy and the run terminates. If the file is valid, the protocol simply terminates.
145

Zhang & Ding

AFS1 is abstracted as a model with one client, one server and one file. The state transition
diagrams with single client and server modules are presented in Figure 14. The nodes and
arcs are labelled with the value for the state variable, belief , and, the name of the received
message that causes the state transition, respectively. A protocol run begins at an initial
state (one of the leftmost nodes) and ends at a final state (one of the rightmost nodes).
Client

val

nofile
valid

val
suspect
inval

val

fetch

Server
none

invalid

valid

validate & valid-file

validate
& !valid-file

invalid

fetch

Figure 14: State transition diagrams for AFS1.
The clientâ€™s belief about a file has 4 possible values {nof ile, valid, invalid, suspect},
where nofile means that the client cache is empty; valid, if the client believes its cached
file is valid; invalid if it believes its caches file is not valid; and suspect, if it has no belief
about the validity of the file (it could be valid or invalid). The serverâ€™s belief about the file
cached by the client ranges over {valid, invalid, none}, where valid, if the server believes
that the file cached at the client is valid; invalid, if the server believes it is not valid; none,
if the server has no belief about the existence of the file in the clientâ€™s cache or its validity.
The set of messages that the client may send to the server is {f etch, validate}. The
message f etch stands for a request for a file, and validate message is used by the client to
determine the validity of the file in its cache. The set of messages that the server may send
to the client is {val, inval}. The server sends the val (inval) message to indicate to the
client that its cached file is valid (invalid). valid-f ile is used when the client has a suspect
file in its cache and requests a validation from the server. If an update by some other client
has occurred then the server reflects this fact by nondeterministically setting the value of
valid-f ile to 0; otherwise, 1 (the file cached at the client is still valid). The specification
property for AFS1 is:
AG((Server.belief = valid) â†’ (Client.belief = valid)).

(1)

In this file system design, the client belief leads the server belief. This specification
property has been deliberately chosen to fail with AFS1 (Wing & Vaziri-Farahani, 1995).
Thus, after model updating, we do not need to pay much attention to the rationality of
the updated models. Our model updater will update the AFS1 model to derive admissible
146

CTL Model Update for System Modifications

models which satisfy the specification property (1). In this case study, we focus on the
update procedure according to the functionality of the prototype.
Extracting the Kripke model of AFS1 from NuSMV
It should be noted that, in our CTL model update algorithm described in Section 6, the
complete Kripke model describing system behaviours is one of two input parameters (i.e.,
(M, s0 ) and Ï†), while the original AFS1 model checking process demonstrated in (Wing &
Vaziri-Farahani, 1995) does not contain such a Kripke model. In fact, it only provides SMV
model definitions (e.g., AFS1.smv) as input to the SMV model checker. This requires initial
extraction of a complete AFS1 Kripke model before performing any update of it. For this
purpose, NuSMV (Cimatti et al., 1999) has been used to derive the Kripke model for the
loaded model (AFS1). The output Kripke model is shown in Figure 15. This method can
also be used for extracting any other Kripke model.

#1: Client.out={0,fetch,validate} ;
#2: Client.belief={valid,invalid,suspect,nofile} ;
#3: Server.out={0,val,inval} ;
#4: Server.belief={none,valid,invalid} ;
#5: Server.validâˆ’file={true,false} ;
11

17

19

0,n,
0,n,
t

0,n,
0,n,
f

f,n,
0,n,
f

f,n,
0,n,
t

f,n,
v,v,
t

f,n,
v,v,
f

25

13

v,s,

12
1

22 f,i,

23

f,i,
v,v,
t

26

v,s,
i, i,
f

4

v,i,
0,i,
t

20

v,s,
0,n,
t

f

v,s,
i, i,
t

0,i,
f

f,v,
0,v,
t

0,s,
0,n,
f
14

6 0,n,

3

18

0,s,
0,n,
t

2

v,i,
0,i,
f

21

f,i,
0,i,
t

24

7

8 v,s,
v,v,

v,s,
v,v,
t

9

f

v,v,
0,v,
t

v,v,

10 0,v,
f

f,i,
v,v,
f

f,v,
0,v,
f

#1,#2,
#3,#4, shows order of variables in a state;
15
#5
Initials of values of variables are shown in states.

5

0,v,
0,v,
t

0,v,
0,v,
f

16

Initial states: {11, 12, 13, 14}
False states: {19, 20, 23, 24, 7, 8}

Figure 15: CTL Kripke model of AFS1.

In the AFS1 Kripke model (see Figure 15), there are 26 reachable states (out of total 216
states) with 52 transitions between them. The model contains 4 initial states {11, 12, 13, 14}
and 5 variables with each individual variable having 2, 3 or 4 possible values. These variables are: â€œClient.outâ€, (range {0, f etch, validate}); â€œClient.beliefâ€ (range {valid, invalid,
147

Zhang & Ding

suspect, nof ile}); â€œServer.outâ€ (range {0, val, inval}); â€œServer.beliefâ€ (range {none, valid,
invalid}); and â€œServer.valid-fileâ€ (range {true, f alse}).
Update procedure
Model checking: In our CTL model update prototype, we first check whether formula (1) is
satisfied by the AFS1 model. That is, we need to check whether each reachable state contains
either Server.belief = Â¬valid or Client.belief = valid. Our model updater identifies that
the set of reachable states that do not satisfy these conditions is {19, 20, 23, 24, 7, 8}. We
call these states false states.
Model update: Figure 15 reveals that each false state in AFS1 is on a different path. From
Theorem 3 in Section 4 and UpdateAG in Section 6, we know that to update the model
to satisfy the property, operations PU2 and PU3 may be applied to these false states in
certain combinations. As a result, one admissible model is depicted in Figure 16. This
model results from the update where each false state on each false path is updated using
PU2. We observe that after the update, states 25, 26, 15 and 16 are no longer reachable
from initial states 11 and 12, and states 9 and 10 become unreachable from initial states 13
and 14.

#1: Client.out={0,fetch,validate} ;
#2: Client.belief={valid,invalid,suspect,nofile} ;
#3: Server.out={0,val,inval} ;
#4: Server.belief={none,valid,invalid} ;
#5: Server.validâˆ’file={true,false} ;
0,n,
0,n,
f

0,n,
0,n,
t

11

f,n,
0,n,
f

f,n,
0,n,
t

17

19

f,n,
v,v,
t

f,n,
v,v,
f

25

f,v,
0,v,
t

13

3
12
1
18

v,s,
i, i,
t

4 v,s,

i, i,
f

22 f,i,

0,i,
f

23

f,i,
v,v,
t

26

0,s,
0,n,
f

v,s,
6 0,n,
f

v,i,
0,i,
t

20

0,s,
0,n,
t

2

v,i,
0,i,
f

21

f,i,
0,i,
t

24

v,s,
0,n,
t

7

9

0,v,
0,v,
t

5

8 v,s,
v,v,

v,s,
v,v,
t

f

v,v,

v,v,
0,v,
t

10 0,v,
f

f,i,
v,v,
f

f,v,
0,v,
f

#1,#2,
#3,#4, shows order of variables in a state;
15
#5
Initials of values of variables are shown in states.

14

0,v,
0,v,
f

16

Figure 16: One of the admissible models from AFS1 model update.

148

CTL Model Update for System Modifications

We should know that Figure 16 only presents one possible updated model after the update on AFS1 model. In fact there are too many possible admissible models. For instance,
instead of only using PU2 operation, we could also use both PU2 and PU3 in different combinations to produce many other admissible models. The total number of such admissible
models is 64.

8. Optimizing Update Results
From Section 7.2, we observe that very often, our CTL model update approach may derive
many more possible admissible models than we really need. In practice, we would expect
that the solution of a CTL model update provides more concrete information to correct
the underlying system specification. This motivates us to improve our CTL model update
approach so that we can eliminate unnecessary admissible models and narrow down the
update results.
Consider AFS1 update case again. While the model described in Figure 16 satisfies the
required property and is admissible, it, however, does not retain a similar structure to the
original AFS1 model. This implies that after the update, there is a significant change to
the system behaviour. So this admissible model may not represent a desirable correction on
the original system. One way to reduce this possibility is to impose the notion of maximal
reachable states into the minimal change principle, so that each possible updated model will
also retain as many reachable states as possible from the original model.
Given a Kripke model M = (S, R, L) and s 0 âˆˆ S, and, let M = (M, s0 ), we say that
s0 is a reachable state of M, if there is a path in M = (S, R, L) of the form Ï€ = [s 0 , s1 , Â· Â· Â·]
where s0 âˆˆ Ï€. RS(M) = RS(M, s0 ) is used to denote the set of all reachable states of
M. Now, we propose a refined CTL model update principle which can significantly reduce
the number of updated models. Let M = (S, R, L) be a CTL Kripke model and s 0 âˆˆ S.
Suppose M 0 = (S 0 , R0 , L0 ) and (M 0 , s00 ) is an updated model obtained from the update of
(M, s0 ) to satisfy some CTL formula. We specify that
RS(M) âˆ©âˆ¼ RS(M0 ) = {s | s âˆˆ RS(M) âˆ© RS(M0 ) and L(s) = L0 (s)}.
States in RS(M) âˆ©âˆ¼ RS(M0 ) are the common reachable states in M and M 0 , called unchanged reachable states. Note that a state having the same name may be reachable in two
different models but with different truth assignments defined by L and L 0 respectively. In
this case, this state is not a common reachable state for M and M 0 .
Definition 7 (Minimal change with maximal reachable states) Given a CTL Kripke
model M = (S, R, L), M = (M, s0 ), where s0 âˆˆ S, and a CTL formula Ï†, a model
U pdate(M, Ï†) is called committed with respect to the update of M to satisfy Ï†, if the
following conditions hold: (1) U pdate(M, Ï†) = M 0 = (M 0 , s00 ) is admissible; and, (2)
there is no other model M00 = (M 00 , s000 ) such that M00 |= Ï† and RS(M) âˆ©âˆ¼ RS(M0 ) âŠ‚
RS(M) âˆ©âˆ¼ RS(M00 ).
Condition (2) in Definition 7 ensures that a maximal set of unchanged reachable states
is retained in the updated model. As we will prove next, the amended CTL model update
approach based on Definition 7 does not significantly increase the overall computational
cost.
149

Zhang & Ding

Lemma 1 Given a CTL Kripke model M = (S, R, L), M = (M, s 0 ), where s0 âˆˆ S, a CTL
formula Ï†, and two models M0 = (M 0 , s00 ) and M00 = (M 00 , s000 ) from the update of (M, s0 )
to satisfy Ï†, checking whether RS(M) âˆ© âˆ¼ RS(M0 ) âŠ‚ RS(M) âˆ©âˆ¼ RS(M00 ) can be achieved
in polynomial time.
Proof: For a given M = (S, R, L), we can view M as a directed graph G(M ) = (S, R),
where S is the set of vertices and R represents all edges in the graph. Obviously, the problem of finding all reachable states from s 0 in M is the same as that of finding all reachable
vertices from vertex s0 in graph G(M ), which can be obtained by computing a spanning tree
with root s0 in G(M ). It is well known that a spanning tree can be computed in polynomial
time (Pettie & Ramachandran, 2002). Therefore, all sets RS(M), RS(M 0 ), and RS(M00 )
can be obtained in polynomial time. Also, RS(M) âˆ© âˆ¼ RS(M0 ) âŠ‚ RS(M) âˆ©âˆ¼ RS(M00 ) can
be checked in polynomial time. 2
Theorem 9 Given two CTL Kripke models M = (S, R, L) and M 0 = (S 0 , R0 , L0 ), where
s0 âˆˆ S and s00 âˆˆ S 0 , and a CTL formula Ï†, it is co-NP-complete to decide whether (M 0 , s00 )
is a committed result of the update of (M, s 0 ) to satisfy Ï†.
Proof: Since every committed result is also an admissible one, from Theorem 5, the hardness holds. For the membership, we need to check (1) whether (M 0 , s00 ) is admissible; and,
(2) an updated model M 00 does not exist such that (M 00 , s000 ) |= Ï† and RS(M) âˆ©âˆ¼ RS(M0 ) âŠ‚
RS(M) âˆ©âˆ¼ RS(M00 ). From Theorem 5, checking whether (M 0 , s00 ) is in co-NP. For (2),
we consider its complement: a updated model M 00 exits such that (M 00 , s000 ) |= Ï† and
RS(M) âˆ©âˆ¼ RS(M0 ) âŠ‚ RS(M) âˆ©âˆ¼ RS(M00 ). From Lemma 1, we can conclude that the
problem is in NP. Consequently, the original problem of checking (2) is in co-NP. 2
As in Section 4, for many commonly used CTL formulas, we can also provide useful
semantic characterizations to simplify the process of computing a committed model in an
update. Here, we present one such result for formula AFÏ†, where Ï† is a propositional
formula. Given a CTL model M = (S, R, L) such that (M, s 0 ) 6|= AFÏ† (s0 âˆˆ S). We recall
that Ï€ = [s0 , Â· Â· Â·] in (M, s0 ) is a valid path of AFÏ† if there exists some state s âˆˆ Ï€ and s > s 0
such that L(s) |= Ï†; otherwise, Ï€ is called a false path of AFÏ†.
Theorem 10 Let M = (S, R, L) be a Kripke model, and M = (M, s 0 ) 6|= AFÏ†, where
s0 âˆˆ S and Ï† is a propositional formula. Let M 0 = U pdate(M, AFÏ†) be a model obtained
by the following 1 or 2, then M0 is a committed model. For each false path Ï€ = [s 0 , s1 , Â· Â· Â·]:
1. if there is no other false path Ï€ 0 sharing any common state with Ï€, then PU3 is applied
to any state s âˆˆ Ï€ (s > s0 ) to change sâ€™s truth assignment such that L 0 (s) |= Ï† and
Dif f (L(s), L0 (s)) is minimal; otherwise, this operation is only applied to a shared
state sj (j > 0) in maximum number of false paths;
2. PU2 is applied to remove relation element (s 0 , s1 ), if s1 also occurs in another valid
path Ï€ 0 , where Ï€ 0 = [s0 , s01 , Â· Â· Â· , s0k , s1 , s0k+1 , . . .] and there exists some s0i (1 â‰¤ i â‰¤ k)
such that L(s0i ) |= Ï†.
150

CTL Model Update for System Modifications

Proof: We first prove Result 1. Consider a false path Ï€ = [s 0 , Â· Â· Â· , si , si+1 , Â· Â· Â·]. Since each
state in Ï€ does not satisfy Ï†, we need to (minimally) change one state sâ€™s truth assignment
along this path so that L0 (s) satisfies Ï† (i.e., apply PU3 once). If there is no other false
path that shares any states with Ï€, then we can apply PU3 on any state in path Ï€. In this
case, only one reachable state in the original model with respect to this path is changed to
satisfy Ï†. Thus, the updated model retains a maximal set of unchanged states.
Suppose that there are other false paths sharing a common state with Ï€. Without loss
of generality, let Ï€ 0 = [s0 , Â· Â· Â· , s0iâˆ’1 , si , s0i+1 , Â· Â· Â·] be a false path sharing a common state s i
with Ï€. Then applying PU3 to any state rather than s i in Ï€ will not necessarily retain a
maximal set of unchanged reachable states, because a further change on any state such as
si could be made in path Ï€ 0 in order to make Ï€ 0 valid. Since si is a sharing state between
two paths Ï€ and Ï€ 0 , it implies that updating two states with PU3 does not retain a maximal
set of unchanged reachable states comparing to the change only on one state s i that makes
both Ï€ and Ï€ 0 valid.
Now we consider the general case. In order to retain a maximal set of unchanged
reachable states in the original model, we should consider all states in Ï€ that are also in
other false paths. In this case, we only need to apply PU3 operation to one state s j in Ï€
that is shared by a maximal number of false paths. In this way, changing s j to satisfy Ï†
will also minimally change other false paths to be valid at the same time. Consequently, we
retain a maximal set of unchanged reachable states in the original model.
Now we prove Result 2. Let Ï€ = [s0 , s1 , s2 , Â· Â· Â·] be a false path. According to the
condition, there is a valid path Ï€ 0 of the form Ï€ 0 = [s0 , s01 , Â· Â· Â· , s0k , s1 , s0k+1 , Â· Â· Â·], where for
some s0i âˆˆ Ï€ 0 (1 â‰¤ i â‰¤ k), s0i |= Ï†. Note that the third path, formed from Ï€ and Ï€ 0 ,
Ï€ 00 = [s0 , s01 , Â· Â· Â· , s0k , s1 , s2 , Â· Â· Â·] is also valid. Applying PU2 on relation element (s 0 , s1 ) will
simply eliminate the false path Ï€ from the model. Under the condition, it is easy to see that
this operation does not actually affect the state reachability in the original model because
the valid path Ï€ 00 will connect s1 and all states in path Ï€ are still reachable from s 0 but
through path Ï€ 00 . This is described in Figure 17 as follows. 2
As an optimization of function UpdateAF described in Section 6.1, Theorem 10 proposes
an efficient way to update a CTL model to satisfy formula AFÏ† to guarantee that the update
model retains a maximal set of reachable states from the original model. Compared with
(a) in function UpdateAF , which updates any state in a path, case 1 in Theorem 10 only
updates a state shared by the maximum number of false paths to minimize changes in an
update to protect unchanged reachable states. Compared with (b) in function UpdateAF,
which could disconnect a false path to make the disconnected part unreachable, case 2 in
Theorem 10 only disconnects the false path accompanied by an alternate path to ensure
the disconnected path still reachable via the alternate path. This theorem illustrates the
principle of optimization for characterizations for other CTL formulas.
In general, committed models can be computed by revising our previous CTL model
update algorithms with particular emphasis to identifying maximal reachable states. As an
example, using the improved approach, we can obtain a committed model of AFS1 model
update (as illustrated in Figure 18), and rules out the model presented in Figure 16. It
can be shown that using the improved approach to the AFS1 model update, the number of
total possible updated models is reduced from 64 to 36.
151

Zhang & Ding

s0

skâ€™

s1
sk+1â€™

Figure 17: s1 occurs in another valid path {s0 , s01 , Â· Â· Â· , s0k , s1 , s0k+1 , Â· Â· Â·].

#1: Client.out={0,fetch,validate} ;
#2: Client.belief={valid,invalid,suspect,nofile} ;
#3: Server.out={0,val,inval} ;
#4: Server.belief={none,valid,invalid} ;
#5: Server.validâˆ’file={true,false} ;
11

17

19

0,n,
0,n,
t

0,n,
0,n,
f

f,n,
0,n,
t

f,n,
0,n,
f

f,n,
v,v,
t

f,v,
v,v,
f

25

f,v,
0,v,
t

13

0,s,
0,n,
f

v,s,

6 0,n,

3
12
1
18

0,s,
0,n,
t

4 v,s,

i, i,
f

v,i,
0,i,
t

22 f,i,

0,i,
f

20

23

f,i,
v,v,
t

26

v,s,
0,n,
t

f

v,s,
i, i,
t

2

v,i,
0,i,
f

21

f,i,
0,i,
t

24

7

9

0,v,
0,v,
t

f

v,v,
0,v,
t

v,v,

10 0,v,
f

f,i,
v,v,
f

0,v,
0,v,
f

Figure 18: One of the committed models of AFS1.

152

5

8 v,s,
v,n,

v,s,
v,v,
t

f,v,
0,v,
f

#1,#2,
#3,#4, shows order of variables in a state;
15
#5
Initials of values of variables are shown in states.

14

16

CTL Model Update for System Modifications

9. Concluding Remarks
In this paper, we present a formal approach to the update of CTL models. By specifying
primitive operations on CTL Kripke models, we have defined the minimal change criteria for
CTL model update. The semantic and computational properties of our approach are also
investigated in some detail. Based on this formalization, we have developed a CTL model
update algorithm and implemented a system prototype to perform CTL model update.
Two case studies are used to demonstrate important applications of this work.
There are a number of issues that merit further investigations. Our current research
focuses on the following two tasks:

- Partial CTL model update: In our current approach, a model update is performed on a
complete Kripke model. In practice, this may not be feasible if the system is complex
with a large number of states and transition relations. One possible method to handle
this problem is to employ the model checker to extract partial useful information and
use it as the model update input. This could be a counterexample or a partial Kripke
model containing components that should be repaired (Buccafurri, Eiter, Gottlob, &
Leone, 2001; Clarke, Jha, Lu, & Veith, 2002; Groce & Visser, 2003; Rustan, Leino,
Millstein, & Saxe, 2005). In this way, the update can be directly performed on this
counterexample or partial model to generate possible corrections. It is possible to
develop a unified prototype integrating model checking (e.g., SMV) and model update.
- Combining maximal structure similarity with minimal change: As demonstrated in
Section 8, the principle of minimal change with maximal reachable states may significantly reduce the number of updated models. However, it is evident that this
maximal reachable states principle is applied after the minimal change (see Definition
7). We may improve this principle by defining a unified analogue that integrates both
minimal change and maximal structural similarity at the same level. This may further
restrict the number of final updated models. This unified principle may be defined
based on the notion of bisimulation of Kripke models (Clarke, Grumberg, Jha, Liu,
& Veith, 2003). For instance, if two states are preserved in an update and there is a
path between these two states in the original model, then the new definition should
preserve this path in the updated model as well, so that the updated model retains
maximal structural similarity with respect to the original. Consider the committed
model described in Figure 18: since there is a path from state 21 to state 26 in the
original model (i.e., Figure 15), we would require retention of the path between 21
and 26 in the updated model. Accordingly, the model displayed in Figure 18 should
be ruled out as a final updated model.

Acknowledgments
This research is supported in part by an Australian Research Council Discovery Grant
(DP0559592). The authors thank three anonymous reviewers for their many valuable comments on the earlier version of this paper.
153

Zhang & Ding

References
Amla, N., Du, X., Kuehlmann, A., Kurshan, R., & McMillan, K. (2005). An analysis of
sat-based model checking techniques in an industrial environment. In Proceedings of
Correct Hardware Design and Verification Methods - 13th IFIP WG 10.5 Advanced
Research Working Conference (CHARME 2005), pp. 254â€“268.
Baral, C., & Zhang, Y. (2005). Knowledge updates: semantics and complexity issues. Artificial Intelligence, 164, 209â€“243.
Berard, B., Bidoit, M., Finkel, A., Laroussinie, F., Petit, A., Petrucci, L., & Schnoebelen,
P. (2001). System and Software Verification: Model-Checking Techniques and Tools.
Springer-Verlag Berlin Heidelberg.
Boyer, M., & Sighireanu, M. (2003). Synthesis and verification of constraints in the pgm
protocol. In Proceedings of the 12th International Symposium of Formal Methods
Europe (FMEâ€™03), pp. 264â€“281. Springer Verlag.
Buccafurri, F., Eiter, T., Gottlob, G., & Leone, N. (1999). Enhancing model checking in
verification by ai techniques. Artificial Intelligence, 112, 57â€“104.
Buccafurri, F., Eiter, T., Gottlob, G., & Leone, N. (2001). On actl formulas having linear
counterexamples. Journal of Computer and System Sciences, 62, 463â€“515.
Chauhan, P., Clarke, E., Kukula, J., Sapra, S., Veith, H., & Wang, D. (2002). Automated
abstraction refinement for model checking large state spaces using sat based conflict
analysis. In Proceedings of Formal Methods in Computer Aided Design (FMCADâ€™02),
pp. 33â€“51.
Cimatti, A., Clarke, E., Giunchiglia, F., & Roveri, M. (1999). Nusmv: A new symbolic
model verifier. In Proceedings of the 11th International Conference on Computer
Aided Verification, pp. 495â€“499.
Clarke, E., Grumberg, O., Jha, S., Liu, Y., & Veith, H. (2003). Counterexample-guided
abstraction refinement for symbolic model checking. Journal of ACM, 50, 752â€“794.
Clarke, E., Grumberg, O., & Peled, D. (1999). Model Checking. MIT Press.
Clarke, E., Jha, S., Lu, Y., & Veith, H. (2002). Tree-like counterexamples in model checking.
In Proceedings of the 17th Annual IEEE Symposium on Logic in Computer Science
(LICSâ€™02), pp. 19â€“29.
Dennis, L., Monroy, R., & Nogueira, P. (2006). Proof-directed debugging and repair. In
Proceedings of the 7th Symposium on Trends in Functional Programming, pp. 131â€“140.
Ding, Y., & Zhang, Y. (2005). A logic approach for ltl system modification. In Proceedings
of the 15th International Symposium on Methodologies for Intelligent Systems (ISMIS
2005), pp. 436â€“444. Springer.
Ding, Y., & Zhang, Y. (2006). Ctl model update: Semantics, computations and implementation. In Proceedings of the 17th European Conference on Artificial Intelligence (ECAI
2006), pp. 362â€“366. IOS Press.
Eiter, T., & Gottlob, G. (1992). On the complexity of propositional knowledge base revision,
updates, and counterfactuals. Artificial Intelligence, 57, 227â€“270.
154

CTL Model Update for System Modifications

Gammie, P., & van der Meyden, R. (2004). Mck-model checking the logic of knowledge.
In Proceedings of the 16th International Conference on Computer Aided Verification
(CAV-2004), pp. 479â€“483.
Gardenfors, P. (1988). Knowledge in Flux: Modeling the Dynamics of Epistemic States. The
MIT Press.
Groce, A., & Visser, W. (2003). What went wrong: Explaining counterexamples. In Proceedings of the SPIN Workshop on Model Checking of Software, pp. 121â€“135.
Harris, H., & Ryan, M. (2002). Feature integration as an operation of theory change. In
Proceedings of the 15th European Conference on Artificial Intelligence (ECAI-2002),
pp. 546â€“550.
Harris, H., & Ryan, M. (2003). Theoretical foundations of updating systems. In Proceedings
of the 18th IEEE International Conference on Automated Software Engineering, pp.
291â€“298.
Herzig, A., & Rifi, O. (1999). Propositional belief base update and minimal change. Artificial
Intelligence, 115, 107â€“138.
Holzmann, C. (2003). The SPIN Model Checker: Primer and Reference Manual. AddisonWesley Professional.
Huth, M., & Ryan, M. (2004). Logic in Computer Science: Modelling and Reasoning about
Systems. 2nd edition, Cambridge University Press.
Katsuno, H., & Mendelzon, A. (1991). On the difference between updating a knowledge
base and revising it. In Proceedings of International Conference on the Principles of
Knowledge Representation and Reasoning (KRâ€™91), pp. 387â€“394.
McMillan, K., & Amla, N. (2002). A logic of implicit and explicit belief. In Automatic Abstraction without Counterexamples. Cadence Berkeley Labs, Cadence Design Systems.
Pettie, S., & Ramachandran, V. (2002). An optimal minimum spanning tree algorithm.
Journal of ACM, 49, 16â€“34.
Rustan, K., Leino, M., Millstein, T., & Saxe, J. (2005). Generating error traces from
verification-condition counterexamples. Science of Computer Programming, 55, 209â€“
226.
Stumptner, M., & Wotawa, F. (1996). A model-based approach to software debugging. In
Proceedings of the 7th International Workshop on Principles of Diagnosis.
Wing, J., & Vaziri-Farahani, M. (1995). A case study in model checking software. In
Proceedings of the 3rd ACM SIGSOFT Symposium on the Foundations of Software
Engineering.
Winslett, M. (1988). Reasoning about action using a possible models approach. In Proceedings of AAAI-88, pp. 89â€“93.
Winslett, M. (1990). Updating Logical Databases. Cambridge University Press.

155

Journal of Artificial Intelligence Research 31 (2008) 33-82

Submitted 02/07; published 01/08

Planning with Durative Actions in Stochastic Domains
Mausam
Daniel S. Weld

MAUSAM @ CS . WASHINGTON . EDU
WELD @ CS . WASHINGTON . EDU

Dept of Computer Science and Engineering
Box 352350, University of Washington
Seattle, WA 98195 USA

Abstract
Probabilistic planning problems are typically modeled as a Markov Decision Process (MDP).
MDPs, while an otherwise expressive model, allow only for sequential, non-durative actions. This
poses severe restrictions in modeling and solving a real world planning problem. We extend the
MDP model to incorporate â€” 1) simultaneous action execution, 2) durative actions, and 3) stochastic durations. We develop several algorithms to combat the computational explosion introduced by
these features. The key theoretical ideas used in building these algorithms are â€” modeling a complex problem as an MDP in extended state/action space, pruning of irrelevant actions, sampling
of relevant actions, using informed heuristics to guide the search, hybridizing different planners
to achieve benefits of both, approximating the problem and replanning. Our empirical evaluation
illuminates the different merits in using various algorithms, viz., optimality, empirical closeness to
optimality, theoretical error bounds, and speed.

1. Introduction
Recent progress achieved by planning researchers has yielded new algorithms which relax, individually, many of the classical assumptions. For example, successful temporal planners like SGPlan,
SAPA, etc. (Chen, Wah, & Hsu, 2006; Do & Kambhampati, 2003) are able to model actions that take
time, and probabilistic planners like GPT, LAO*, SPUDD, etc. (Bonet & Geffner, 2005; Hansen &
Zilberstein, 2001; Hoey, St-Aubin, Hu, & Boutilier, 1999) can deal with actions with probabilistic
outcomes, etc. However, in order to apply automated planning to many real-world domains we must
eliminate larger groups of the assumptions in concert. For example, NASA researchers note that
optimal control for a NASA Mars rover requires reasoning about uncertain, concurrent, durative
actions and a mixture of discrete and metric fluents (Bresina, Dearden, Meuleau, Smith, & Washington, 2002). While todayâ€™s planners can handle large problems with deterministic concurrent
durative actions, and MDPs provide a clear framework for non-concurrent durative actions in the
face of uncertainty, few researchers have considered concurrent, uncertain, durative actions â€” the
focus of this paper.
As an example consider the NASA Mars rovers, Spirit and Oppurtunity. They have the goal of
gathering data from different locations with various instruments (color and infrared cameras, microscopic imager, Mossbauer spectrometers etc.) and transmitting this data back to Earth. Concurrent
actions are essential since instruments can be turned on, warmed up and calibrated, while the rover
is moving, using other instruments or transmitting data. Similarly, uncertainty must be explicitly
confronted as the roverâ€™s movement, arm control and other actions cannot be accurately predicted.
Furthermore, all of their actions, e.g., moving between locations and setting up experiments, take
time. In fact, these temporal durations are themselves uncertain â€” the rover might lose its way and
c
2008
AI Access Foundation. All rights reserved.

M AUSAM & W ELD

take a long time to reach another location, etc. To be able to solve the planning problems encountered by a rover, our planning framework needs to explicitly model all these domain constructs â€”
concurrency, actions with uncertain outcomes and uncertain durations.
In this paper we present a unified formalism that models all these domain features together.
Concurrent Markov Decision Processes (CoMDPs) extend MDPs by allowing multiple actions per
decision epoch. We use CoMDPs as the base to model all planning problems involving concurrency.
Problems with durative actions, concurrent probabilistic temporal planning (CPTP), are formulated
as CoMDPs in an extended state space. The formulation is also able to incorporate the uncertainty
in durations in the form of probabilistic distributions.
Solving these planning problems poses several computational challenges: concurrency, extended durations, and uncertainty in those durations all lead to explosive growth in the state space,
action space and branching factor. We develop two techniques, Pruned RTDP and Sampled RTDP to
address the blowup from concurrency. We also develop the â€œDURâ€ family of algorithms to handle
stochastic durations. These algorithms explore different points in the running time vs. solutionquality tradeoff. The different algorithms propose several speedup mechanisms such as â€” 1) pruning of provably sub-optimal actions in a Bellman backup, 2) intelligent sampling from the action
space, 3) admissible and inadmissible heuristics computed by solving non-concurrent problems, 4)
hybridizing two planners to obtain a hybridized planner that finds good quality solution in intermediate running times, 5) approximating stochastic durations by their mean values and replanning, 6)
exploiting the structure of multi-modal duration distributions to achieve higher quality approximations.
The rest of the paper is organized as follows: In section 2 we discuss the fundamentals of
MDPs and the real-time dynamic programming (RTDP) solution method. In Section 3 we describe
the model of Concurrent MDPs. Section 4 investigates the theoretical properties of the temporal
problems. Section 5 explains our formulation of the CPTP problem for deterministic durations. The
algorithms are extended for the case of stochastic durations in Section 6. Each section is supported
with an empirical evaluation of the techniques presented in that section. In Section 7 we survey the
related work in the area. We conclude with future directions of research in Sections 8 and 9.

2. Background
Planning problems under probabilistic uncertainty are often modeled using Markov Decision Processes (MDPs). Different research communities have looked at slightly different formulations of
MDPs. These versions typically differ in objective functions (maximizing reward vs. minimizing
cost), horizons (finite, infinite, indefinite) and action representations (DBN vs. parametrized action
schemata). All these formulations are very similar in nature, and so are the algorithms to solve
them. Though, the methods proposed in the paper are applicable to all the variants of these models,
for clarity of explanation we assume a particular formulation, known as the stochastic shortest path
problem (Bertsekas, 1995).
We define a Markov decision process (M) as a tuple hS, A, Ap, Pr, C, G, s0 i in which
â€¢ S is a finite set of discrete states. We use factored MDPs, i.e., S is compactly represented in
terms of a set of state variables.
â€¢ A is a finite set of actions.
34

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

State variables : x1 , x2 , x3 , x4 , p12
Action
Precondition
Effect
toggle-x1
Â¬p12
x1 â† Â¬x1
toggle-x2
p12
x2 â† Â¬x2
toggle-x3
true
x3 â† Â¬x3
no change
toggle-x4
true
x4 â† Â¬x4
no change
toggle-p12
true
p12 â† Â¬p12
Goal : x1 = 1, x2 = 1, x3 = 1, x4 = 1

Probability
1
1
0.9
0.1
0.9
0.1
1

Figure 1: Probabilistic STRIPS definition of a simple MDP with potential parallelism
â€¢ Ap defines an applicability function. Ap : S â†’ P(A), denotes the set of actions that can be
applied in a given state (P represents the power set).
â€¢ Pr : S Ã— A Ã— S â†’ [0, 1] is the transition function. We write Pr(s0 |s, a) to denote the
probability of arriving at state s0 after executing action a in state s.
â€¢ C : S Ã— A Ã— S â†’ <+ is the cost model. We write C(s, a, s0 ) to denote the cost incurred when
the state s0 is reached after executing action a in state s.
â€¢ G âŠ† S is a set of absorbing goal states, i.e., the process ends once one of these states is
reached.
â€¢ s0 is a start state.
We assume full observability, i.e., the execution system has complete access to the new state
after an action has been performed. We seek to find an optimal, stationary policy â€” i.e., a function
Ï€: S â†’ A that minimizes the expected cost (over an indefinite horizon) incurred to reach a goal
state. Note that any cost function, J: S â†’ <, mapping states to the expected cost of reaching a goal
state defines a policy as follows:
Ï€J (s) = argmin

X

Pr(s0 |s, a) C(s, a, s0 ) + J(s0 )


	

(1)

aâˆˆAp(s) s0 âˆˆS

The optimal policy derives from the optimal cost function, J âˆ— , which satisfies the following pair
of Bellman equations.
J âˆ— (s) = 0, if s âˆˆ G else
J âˆ— (s) = min

aâˆˆAp(s)

X

Pr(s0 |s, a) C(s, a, s0 ) + J âˆ— (s0 )


	

(2)

s0 âˆˆS

For example, Figure 1 defines a simple MDP where four state variables (x1 , . . . , x4 ) need to be
set using toggle actions. Some of the actions, e.g., toggle-x3 are probabilistic.
Various algorithms have been developed to solve MDPs. Value iteration is a dynamic programming approach in which the optimal cost function (the solution to equations 2) is calculated as the
limit of a series of approximations, each considering increasingly long action sequences. If Jn (s)
35

M AUSAM & W ELD

is the cost of state s in iteration n, then the cost of state s in the next iteration is calculated with a
process called a Bellman backup as follows:
Jn+1 (s) = min

aâˆˆAp(s)

X

Pr(s0 |s, a) C(s, a, s0 ) + Jn (s0 )


	

(3)

s0 âˆˆS

Value iteration terminates when âˆ€s âˆˆ S, |Jn (s) âˆ’ Jnâˆ’1 (s)| â‰¤ , and this termination is guaranteed for  > 0. Furthermore, in the limit, the sequence of {Ji } is guaranteed to converge to the
optimal cost function, J âˆ— , regardless of the initial values as long as a goal can be reached from every reachable state with non-zero probability. Unfortunately, value iteration tends to be quite slow,
since it explicitly updates every state, and |S| is exponential in the number of domain features. One
optimization restricts search to the part of state space reachable from the initial state s0 . Two algorithms exploiting this reachability analysis are LAO* (Hansen & Zilberstein, 2001) and our focus:
RTDP (Barto, Bradtke, & Singh, 1995).
RTDP, conceptually, is a lazy version of value iteration in which the states get updated in proportion to the frequency with which they are visited by the repeated executions of the greedy policy.
An RTDP trial is a path starting from s0 , following the greedy policy and updating the costs of
the states visited using Bellman backups; the trial ends when a goal is reached or the number of
updates exceeds a threshold. RTDP repeats these trials until convergence. Note that common states
are updated frequently, while RTDP wastes no time on states that are unreachable, given the current
policy. RTDPâ€™s strength is its ability to quickly produce a relatively good policy; however, complete
convergence (at every relevant state) is slow because less likely (but potentially important) states get
updated infrequently. Furthermore, RTDP is not guaranteed to terminate. Labeled RTDP (LRTDP)
fixes these problems with a clever labeling scheme that focuses attention on states where the value
function has not yet converged (Bonet & Geffner, 2003). Labeled RTDP is guaranteed to terminate,
and is guaranteed to converge to the -approximation of the optimal cost function (for states reachable using the optimal policy) if the initial cost function is admissible, all costs (C) positive and a
goal reachable from all reachable states with non-zero probability.
MDPs are a powerful framework to model stochastic planning domains. However, MDPs make
two unrealistic assumptions â€” 1) all actions need to be executed sequentially, and 2) all actions
are instantaneous. Unfortunately, there are many real-world domains where these assumptions are
unrealistic. For example, concurrent actions are essential for a Mars rover, since instruments can
be turned on, warmed up and calibrated while the rover is moving, and using other instruments
for transmitting data. Moreover, the action durations are non-zero and stochastic â€” the rover might
lose its way while navigating and may take a long time to reach its destination; it may make multiple
attempts before finding the accurate arm placement. In this paper we successively relax these two
assumptions and build models and algorithms that can scale up in spite of the additional complexities
imposed by the more general models.

3. Concurrent Markov Decision Processes
We define a new model, Concurrent MDP (CoMDP), which allows multiple actions to be executed
in parallel. This model is different from semi-MDPs and generalized state semi-MDPs (Younes
& Simmons, 2004b) in that it does not incorporate action durations explicitly. CoMDPs focus on
adding concurrency in an MDP framework. The input to a CoMDP is slightly different from that of
an MDP â€“ hS, A, Apk , Prk , Ck , G, s0 i. The new applicability function, probability model and cost
36

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

(Apk , Prk and Ck respectively) encode the distinction between allowing sequential executions of
single actions versus the simultaneous executions of sets of actions.
3.1 The Model
The set of states (S), set of actions (A), goals (G) and the start state (s0 ) follow the input of an MDP.
The difference lies in the fact that instead of executing only one action at a time, we may execute
multiple of them. Let us define an action combination, A, as a set of one or more actions to be
executed in parallel. With an action combination as a new unit operator available to the agent, the
CoMDP takes the following new inputs
â€¢ Apk defines the new applicability function. Apk : S â†’ P(P(A)), denotes the set of action
combinations that can be applied in a given state.
â€¢ Prk : S Ã— P(A) Ã— S â†’ [0, 1] is the transition function. We write Prk (s0 |s, A) to denote the
probability of arriving at state s0 after executing action combination A in state s.
â€¢ Ck : S Ã— P(A) Ã— S â†’ <+ is the cost model. We write Ck (s, A, s0 ) to denote the cost incurred
when the state s0 is reached after executing action combination A in state s.
In essence, a CoMDP takes an action combination as a unit operator instead of a single action.
Our approach is to convert a CoMDP into an equivalent MDP (Mk ) that can be specified by the
tuple hS, P(A), Apk , Prk , Ck , G, s0 i and solve it using the known MDP algorithms.
3.2 Case Study: CoMDP over Probabilistic STRIPS
In general a CoMDP could require an exponentially larger input than does an MDP, since the transition model, cost model and the applicability function are all defined in terms of action combinations
as opposed to actions. A compact input representation for a general CoMDP is an interesting, open
research question for the future. In this work, we consider a special class of compact CoMDP
â€“ one that is defined naturally via a domain description very similar to the probabilistic STRIPS
representation for MDPs (Boutilier, Dean, & Hanks, 1999).
Given a domain encoded in probabilistic STRIPS we can compute a safe set of co-executable
actions. Under this safe semantics, the probabilistic dynamics gets defined in a consistent way as
we describe below.
3.2.1 A PPLICABILITY F UNCTION
We first discuss how to compute the sets of actions that can be executed in parallel since some
actions may conflict with each other. We adopt the classical planning notion of mutual exclusion (Blum & Furst, 1997) and apply it to the factored action representation of probabilistic STRIPS.
Two distinct actions are mutex (may not be executed concurrently) if in any state one of the following occurs:
1. they have inconsistent preconditions
2. an outcome of one action conflicts with an outcome of the other
3. the precondition of one action conflicts with the (possibly probabilistic) effect of the other.
37

M AUSAM & W ELD

4. the effect of one action possibly modifies a feature upon which another actionâ€™s transition
function is conditioned upon.
Additionally, an action is never mutex with itself. In essence, the non-mutex actions do not interact â€” the effects of executing the sequence a1 ; a2 equals those for a2 ; a1 â€” and so the semantics
for parallel executions is clear.
Example: Continuing with Figure 1, toggle-x1 , toggle-x3 and toggle-x4 can execute in parallel but
toggle-x1 and toggle-x2 are mutex as they have conflicting preconditions. Similarly, toggle-x1 and
toggle-p12 are mutex as the effect of toggle-p12 interferes with the precondition of toggle-x1 . If
toggle-x4 â€™s outcomes depended on toggle-x1 then they would be mutex too, due to point 4 above.
For example, toggle-x4 toggle-x1 will be mutex if the effect of toggle-x4 was as follows: â€œif togglex1 then the probability of x4 â† Â¬x4 is 0.9 else 0.1â€. 2
The applicability function is defined as the set of action-combinations, A, such that each action
in A is independently applicable in s and all of the actions are pairwise non-mutex with each other.
Note that pairwise concurrency is sufficient to ensure problem-free concurrency of all multiple
actions in A. Formally Apk can be defined in terms of our original definition Ap as follows:
Apk (s) = {A âŠ† A|âˆ€a, a0 âˆˆ A, a, a0 âˆˆ Ap(s) âˆ§ Â¬mutex(a, a0 )}

(4)

3.2.2 T RANSITION F UNCTION
Let A = {a1 , a2 , . . . , ak } be an action combination applicable in s. Since none of the actions are
mutex, the transition function may be calculated by choosing any arbitrary order in which to apply
them as follows:
Prk (s0 |s, A) =

X

...

X

Pr(s1 |s, a1 )Pr(s2 |s1 , a2 ) . . . Pr(s0 |skâˆ’1 , ak )

(5)

s1 ,s2 ,...sk âˆˆS

While we define the applicability function and the transition function by allowing only a consistent set of actions to be executable concurrently, there are alternative definitions possible. For
instance, one might be willing to allow executing two actions together if the probability that they
conflict is very small. A conflict may be defined as two actions asserting contradictory effects or
one negating the precondition of the other. In such a case, a new state called failure could be created such that the system transitions to this state in case of a conflict. And the transition may be
computed to reflect a low probability transition to this failure state.
Although we impose that the model be conflict-free, most of our techniques donâ€™t actually depend on this assumption explicitly and extend to general CoMDPs.
3.2.3 C OST MODEL
We make a small change to the probabilistic STRIPS representation. Instead of defining a single
cost (C) for each action, we define it additively as a sum of resource and time components as follows:
â€¢ Let t be the durative cost, i.e., cost due to time taken to complete the action.
â€¢ Let r be the resource cost, i.e., cost of resources used for the action.
38

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Assuming additivity we can think of cost of an action C(s, a, s0 ) = t(s, a, s0 ) + r(s, a, s0 ), to be
sum of its time and resource usage. Hence, the cost model for a combination of actions in terms of
these components may be defined as:
Ck (s, {a1 , a2 , ..., ak }, s0 ) =

k
X

r(s, ai , s0 ) + max {t(s, ai , s0 )}
i=1..k

i=1

(6)

For example, a Mars rover might incur lower cost when it preheats an instrument while changing
locations than if it executes the actions sequentially, because the total time is reduced while the
energy consumed does not change.
3.3 Solving a CoMDP with MDP Algorithms
We have taken a concurrent MDP that allowed concurrency in actions and formulated it as an equivalent MDP, Mk , in an extended action space. For the rest of the paper we will use the term CoMDP
to also refer to the equivalent MDP Mk .
3.3.1 B ELLMAN EQUATIONS
We extend Equations 2 to a set of equations representing the solution to a CoMDP:
Jkâˆ— (s) = 0, if s âˆˆ G else
Jkâˆ— (s) = min

AâˆˆApk (s)

X

n

o

Prk (s0 |s, A) Ck (s, A, s0 ) + Jkâˆ— (s0 )

(7)

s0 âˆˆS

These equations are the same as in a traditional MDP, except that instead of considering single
actions for backup in a state, we need to consider all applicable action combinations. Thus, only this
small change must be made to traditional algorithms (e.g., value iteration, LAO*, Labeled RTDP).
However, since the number of action combinations is worst-case exponential in |A|, efficiently
solving a CoMDP requires new techniques. Unfortunately, there is no structure to exploit easily,
since an optimal action for a state from a classical MDP solution may not even appear in the optimal
action combination for the associated concurrent MDP.
Theorem 1 All actions in an optimal combination for a CoMDP (Mk ) may be individually suboptimal for the MDP M.
Proof: In the domain of Figure 1 let us have an additional action toggle-x34 that toggles both x3
and x4 with probability 0.5 and toggles exactly one of x3 and x4 with probability 0.25 each. Let
all the actions take one time unit each, and therefore cost of any action combination is one as well.
Let the start state be x1 = 1, x2 = 1, x3 = 0, x4 = 0 and p12 = 1. For the MDP M the only optimal
action for the start state is toggle-x34 . However, for the CoMDP Mk the optimal combination is
{toggle-x3 , toggle-x4 }. 2
3.4 Pruned Bellman Backups
Recall that during a trial, Labeled RTDP performs Bellman backups in order to calculate the costs of
applicable actions (or in our case, action combinations) and then chooses the best action (combination); we now describe two pruning techniques that reduce the number of backups to be computed.
39

M AUSAM & W ELD

Let Qk (s, A) be the expected cost incurred by executing an action combination A in state s and then
following the greedy policy, i.e.
Qkn (s, A) =

X

n

o

Prk (s0 |s, A) Ck (s, A, s0 ) + Jknâˆ’1 (s0 )

(8)

s0 âˆˆS

A Bellman update can thus be rewritten as:
Jkn (s) =

min

AâˆˆApk (s)

Qkn (s, A)

(9)

3.4.1 C OMBO -S KIPPING
Since the number of applicable action combinations can be exponential, we would like to prune
suboptimal combinations. The following theorem imposes a lower bound on Qk (s, A) in terms of
the costs and the Qk -values of single actions. For this theorem the costs of the actions may depend
only on the action and not the starting or ending state, i.e., for all states âˆ€s, s0 C(s, a, s0 ) = C(a).
Theorem 2 Let A = {a1 , a2 , . . . , ak } be an action combination which is applicable in state s. For
a CoMDP over probabilistic STRIPS, if costs are dependent only on actions and Qkn values are
monotonically non-decreasing then
Qk (s, A) â‰¥ max Qk (s, {ai }) + Ck (A) âˆ’
i=1..k

k
X

!

Ck ({ai })

i=1

Proof:
Qkn (s, A) = Ck (A) +

X

Prk (s0 |s, A)Jknâˆ’1 (s0 )

(using Eqn. 8)

s0

â‡’

X

Prk (s0 |s, A)Jknâˆ’1 (s0 ) = Qkn (s, A) âˆ’ Ck (A)

(10)

s0

Qkn (s, {a1 }) = Ck ({a1 }) +

X

Pr(s00 |s, a1 )Jknâˆ’1 (s00 )

s00

"

â‰¤ Ck ({a1 }) +

X

#

00

Pr(s |s, a1 ) Ck ({a2 }) +

s00

X

000

00

000

Pr(s |s , a2 )Jknâˆ’2 (s )

s000

(using Eqns. 8 and 9)
= Ck ({a1 }) + Ck ({a2 }) +

X

000

000

Prk (s |s, {a1 , a2 })Jknâˆ’2 (s )

s000

â‰¤
=

k
X
i=1
k
X

Ck ({ai }) +

X

Prk (s0 |s, A)Jknâˆ’k (s0 )

(repeating for all actions in A)

s0

Ck ({ai }) + [Qknâˆ’k+1 (s, A) âˆ’ Ck (A)]

i=1

Replacing n by n + k âˆ’ 1
40

(using Eqn. 10)

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Qkn (s, A) â‰¥ Qkn+kâˆ’1 (s, {a1 }) + Ck (A) âˆ’

k
X

!

Ck ({ai })

i=1

â‰¥ Qkn (s, {a1 }) + Ck (A) âˆ’

k
X

!

Ck ({ai })

(monotonicity of Qkn )

i=1

â‰¥

max Qkn (s, {ai }) + Ck (A) âˆ’

i=1..k

k
X

!

Ck ({ai })

i=1

2

The proof above assumes equation 5 from probabilistic STRIPS. The following corollary can
be used to prune suboptimal action combinations:
Corollary 3 Let dJkn (s)e be an upper bound of Jkn (s). If
dJkn (s)e < max Qkn (s, {ai }) + Ck (A) âˆ’
i=1..k

k
X

!

Ck ({ai })

i=1

then A cannot be optimal for state s in this iteration.
Proof: Let Aâˆ—n = {a1 , a2 , . . . , ak } be the optimal combination for state s in this iteration n. Then,
dJkn (s)e â‰¥ Jkn (s)
Jkn (s) = Qkn (s, Aâˆ—n )
Combining with Theorem 2
dJkn (s)e â‰¥ maxi=1..k Qkn (s, {ai }) +

Ck (Aâˆ—n )

âˆ’

k
X

!

Ck ({ai }) 2

i=1

Corollary 3 justifies a pruning rule, combo-skipping, that preserves optimality in any iteration
algorithm that maintains cost function monotonicity. This is powerful because all Bellman-backup
based algorithms preserve monotonicity when started with an admissible cost function. To apply
combo-skipping, one must compute all the Qk (s, {a}) values for single actions a that are applicable
in s. To calculate dJkn (s)e one may use the optimal combination for state s in the previous iteration
(Aopt ) and compute Qkn (s, Aopt ). This value gives an upper bound on the value Jkn (s).
Example: Consider Figure 1. Let a single action incur unit cost, and let the cost of an action combination be: Ck (A) = 0.5 + 0.5|A|. Let state s = (1,1,0,0,1) represent the ordered values x1 = 1, x2 =
1, x3 = 0, x4 = 0, and p12 = 1. Suppose, after the nth iteration, the cost function assigns the values:
Jkn (s) = 1, Jkn (s1 =(1,0,0,0,1)) = 2, Jkn (s2 =(1,1,1,0,1)) = 1, Jkn (s3 =(1,1,0,1,1)) = 1. Let Aopt for
state s be {toggle-x3 , toggle-x4 }. Now, Qkn+1 (s, {toggle-x2 }) = Ck ({toggle-x2 }) + Jkn (s1 ) = 3
and Qkn+1 (s, Aopt ) = Ck (Aopt ) + 0.81Ã—0 + 0.09Ã—Jkn (s2 ) + 0.09Ã—Jkn (s3 ) + 0.01Ã—Jkn (s) = 1.69.
So now we can apply Corollary 3 to skip combination {toggle-x2 , toggle-x3 } in this iteration, since
using toggle-x2 as a1 , we have dJkn+1 (s)e = Qkn+1 (s, Aopt ) = 1.69 â‰¤ 3 + 1.5 - 2 = 2.5. 2
Experiments show that combo-skipping yields considerable savings. Unfortunately, comboskipping has a weakness â€” it prunes a combination for only a single iteration. In contrast, our
second rule, combo-elimination, prunes irrelevant combinations altogether.
41

M AUSAM & W ELD

3.4.2 C OMBO -E LIMINATION
We adapt the action elimination theorem from traditional MDPs (Bertsekas, 1995) to prove a similar
theorem for CoMDPs.
Theorem 4 Let A be an action combination which is applicable in state s. Let bQâˆ—k (s, A)c denote
a lower bound of Qâˆ—k (s, A). If bQâˆ—k (s, A)c > dJkâˆ— (s)e then A is never the optimal combination for
state s.
Proof: Because a CoMDP is an MDP in a new action space, the original proof for MDPs (Bertsekas,
1995) holds after replacing an action by an â€˜action combinationâ€™. 2
In order to apply the theorem for pruning, one must be able to evaluate the upper and lower
bounds. By using an admissible cost function when starting RTDP search (or in value iteration,
LAO* etc.), the current cost Jkn (s) is guaranteed to be a lower bound of the optimal cost; thus,
Qkn (s, A) will also be a lower bound of Qâˆ—k (s, A). Thus, it is easy to compute the left hand side
of the inequality. To calculate an upper bound of the optimal Jkâˆ— (s), one may solve the MDP M,
i.e., the traditional MDP that forbids concurrency. This is much faster than solving the CoMDP,
and yields an upper bound on cost, because forbidding concurrency restricts the policy to use a
strict subset of legal action combinations. Notice that combo-elimination can be used for all general
MDPs and is not restricted to only CoMDPs over probabilistic STRIPS.
Example: Continuing with the previous example, let A={toggle-x2 } then Qkn+1 (s, A) = Ck (A) +
Jkn (s1 ) = 3 and dJkâˆ— (s)e = 2.222 (from solving MDP M). As 3 > 2.222, A can be eliminated for
state s in all remaining iterations. 2
Used in this fashion, combo-elimination requires the additional overhead of optimally solving
the single-action MDP M. Since algorithms like RTDP exploit state-space reachability to limit
computation to relevant states, we do this computation incrementally, as new states are visited by
our algorithm.
Combo-elimination also requires computation of the current value of Qk (s, A) (for the lower
bound of Qâˆ—k (s, A)); this differs from combo-skipping which avoids this computation. However,
once combo-elimination prunes a combination, it never needs to be reconsidered. Thus, there is
a tradeoff: should one perform an expensive computation, hoping for long-term pruning, or try a
cheaper pruning rule with fewer benefits? Since Q-value computation is the costly step, we adopt
the following heuristic: â€œFirst, try combo-skipping; if it fails to prune the combination, attempt
combo-elimination; if it succeeds, never consider it againâ€. We also tried implementing some other
heuristics, such as: 1) If some combination is being skipped repeatedly, then try to prune it altogether with combo-elimination. 2) In every state, try combo-elimination with probability p. Neither
alternative performed significantly better, so we kept our original (lower overhead) heuristic.
Since combo-skipping does not change any step of labeled RTDP and combo-elimination removes provably sub-optimal combinations, pruned labeled RTDP maintains convergence, termination, optimality and efficiency, when used with an admissible heuristic.
3.5 Sampled Bellman Backups
Since the fundamental challenge posed by CoMDPs is the explosion of action combinations, sampling is a promising method to reduce the number of Bellman backups required per state. We
describe a variant of RTDP, called sampled RTDP, which performs backups on a random set of
42

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

action combinations1 , choosing from a distribution that favors combinations that are likely to be
optimal. We generate our distribution by:
1. using combinations that were previously discovered to have low Qk -values (recorded by memoizing the best combinations per state, after each iteration)
2. calculating the Qk -values of all applicable single actions (using current cost function) and
then biasing the sampling of combinations to choose the ones that contain actions with low
Qk -values.

Algorithm 1 Sampled Bellman Backup(state, m)
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

Function 2 SampleComb(state, i, l)
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

//returns the best combination found

list l = âˆ… //a list of all applicable actions with their values
for all action âˆˆ A do
compute Qk (state, {action})
insert ha, 1/Qk (state, {action})i in l
for all i âˆˆ [1..m] do
newcomb = SampleComb(state, i, l);
compute Qk (state, newcomb)
clear memoizedlist[state]
compute Qmin as the minimum of all Qk values computed in line 7
store all combinations A with Qk (state, A) = Qmin in memoizedlist[state]
return the first entry in memoizedlist[state]

//returns ith combination for the sampled backup

if i â‰¤ size(memoizedlist[state]) then
return ith entry in memoizedlist[state] //return the combination memoized in previous iteration
newcomb = âˆ…
repeat
randomly sample an action a from l proportional to its value
insert a in newcomb
remove all actions mutex with a from l
if l is empty then
done = true
else if |newcomb| == 1 then
done = false //sample at least 2 actions per combination
else
|newcomb|
done = true with prob. |newcomb|+1
until done
return newcomb

This approach exposes an exploration / exploitation trade-off. Exploration, here, refers to testing a wide range of action combinations to improve understanding of their relative merit. Exploitation, on the other hand, advocates performing backups on the combinations that have previously
been shown to be the best. We manage the tradeoff by carefully maintaining the distribution over
combinations. First, we only memoize best combinations per state; these are always backed-up
1. A similar action sampling approach was also used in the context of space shuttle scheduling to reduce the number of
actions considered during value function computation (Zhang & Dietterich, 1995).

43

M AUSAM & W ELD

in a Bellman update. Other combinations are constructed by an incremental probabilistic process,
which builds a combination by first randomly choosing an initial action (weighted by its individual Qk -value), then deciding whether to add a non-mutex action or stop growing the combination.
There are many implementations possible for this high level idea. We tried several of those and
found the results to be very similar in all of them. Algorithm 1 describes the implementation used
in our experiments. The algorithm takes a state and a total number of combinations m as an input
and returns the best combination obtained so far. It also memoizes all the best combinations for the
state in memoizedlist. Function 2 is a helper function that returns the ith combination that is either
one of the best combinations memoized in the previous iteration or a new sampled combination.
Also notice line 10 in Function 2. It forces the sampled combinations to be at least size 2, since all
individual actions have already been backed up (line 3 of Algo 1).
3.5.1 T ERMINATION AND O PTIMALITY
Since the system does not consider every possible action combination, sampled RTDP is not guaranteed to choose the best combination to execute at each state. As a result, even when started with
an admissible heuristic, the algorithm may assign Jkn (s) a cost that is greater than the optimal Jkâˆ— (s)
â€” i.e., the Jkn (s) values are no longer admissible. If a better combination is chosen in a subsequent
iteration, Jkn+1 (s) might be set a lower value than Jkn (s), thus sampled RTDP is not monotonic.
This is unfortunate, since admissibility and monotonicity are important properties required for termination2 and optimality in labeled RTDP; indeed, sampled RTDP loses these important theoretical
properties. The good news is that it is extremely useful in practice. In our experiments, sampled
RTDP usually terminates quickly, and returns costs that are extremely close to the optimal.
3.5.2 I MPROVING S OLUTION Q UALITY
We have investigated several heuristics in order to improve the quality of the solutions found by
sampled RTDP. Our heuristics compensate for the errors due to partial search and lack of admissibility.
â€¢ Heuristic 1: Whenever sampled RTDP asserts convergence of a state, do not immediately
label it as converged (which would preclude further exploration (Bonet & Geffner, 2003));
instead first run a complete backup phase, using all the admissible combinations, to rule out
any easy-to-detect inconsistencies.
â€¢ Heuristic 2: Run sampled RTDP to completion, and use the cost function it produces, J s (),
as the initial heuristic estimate, J0 (), for a subsequent run of pruned RTDP. Usually, such a
heuristic, though inadmissible, is highly informative. Hence, pruned RTDP terminates quite
quickly.
â€¢ Heuristic 3: Run sampled RTDP before pruned RTDP, as in Heuristic 2, except instead of
using the J s () cost function directly as an initial estimate, scale linearly downward â€” i.e.,
use J0 () := cJ s () for some constant c âˆˆ (0, 1). While there are no guarantees we hope that
this lies on the admissible side of the optimal. In our experience this is often the case for
c = 0.9, and the run of pruned RTDP yields the optimal policy very quickly.
2. To ensure termination we implemented the policy: if number of trials exceeds a threshold, force monotonicity on the
cost function. This will achieve termination but will reduce quality of solution.

44

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Experiments showed that Heuristic 1 returns a cost function that is close to optimal. Adding
Heuristic 2 improves this value moderately, and a combination of Heuristics 1 and 3 returns the
optimal solution in our experiments.
3.6 Experiments: Concurrent MDP
Concurrent MDP is a fundamental formulation, modeling concurrent actions in a general planning
domain. We first compare the various techniques to solve CoMDPs, viz., pruned and sampled RTDP.
In following sections we use these techniques to model problems with durative actions.
We tested our algorithms on problems in three domains. The first domain was a probabilistic
variant of NASA Rover domain from the 2002 AIPS Planning Competition (Long & Fox, 2003), in
which there are multiple objects to be photographed and various rocks to be tested with resulting
data communicated back to the base station. Cameras need to be focused, and arms need to be
positioned before usage. Since the rover has multiple arms and multiple cameras, the domain is
highly parallel. The cost function includes both resource and time components, so executing multiple actions in parallel is cheaper than executing them sequentially. We generated problems with
20-30 state variables having up to 81,000 reachable states and the average number of applicable
combinations per state, Avg(Ap(s)), which measures the amount of concurrency in a problem, is
up to 2735.
We also tested on a probabilistic version of a machineshop domain with multiple subtasks (e.g.,
roll, shape, paint, polish etc.), which need to be performed on different objects using different
machines. Machines can perform in parallel, but not all are capable of every task. We tested
on problems with 26-28 state variables and around 32,000 reachable states. Avg(Ap(s)) ranged
between 170 and 2640 on the various problems.
Finally, we tested on an artificial domain similar to the one shown in Figure 1 but much more
complex. In this domain, some Boolean variables need to be toggled; however, toggling is probabilistic in nature. Moreover, certain pairs of actions have conflicting preconditions and thus, by
varying the number of mutex actions we may control the domainâ€™s degree of parallelism. All the
problems in this domain had 19 state variables and about 32,000 reachable states, with Avg(Ap(s))
between 1024 and 12287.
We used Labeled RTDP, as implemented in GPT (Bonet & Geffner, 2005), as the base MDP
solver. It is implemented in C++. We implemented3 various algorithms, unpruned RTDP (U RTDP), pruned RTDP using only combo skipping (Ps -RTDP), pruned RTDP using both combo
skipping and combo elimination (Pse -RTDP), sampled RTDP using Heuristic 1 (S-RTDP) and sampled RTDP using both Heuristics 1 and 3, with value functions scaled with 0.9 (S3 -RTDP). We tested
all of these algorithms on a number of problem instantiations from our three domains, generated by
varying the number of objects, degrees of parallelism, and distances to goal. The experiments were
performed on a 2.8 GHz Pentium processor with a 2 GB RAM.
We observe (Figure 2(a,b)) that pruning significantly speeds the algorithm. But the comparison of Pse -RTDP with S-RTDP and S3 -RTDP (Figure 3(a,b)) shows that sampling has a dramatic
speedup with respect to the pruned versions. In fact, pure sampling, S-RTDP, converges extremely
quickly, and S3 -RTDP is slightly slower. However, S3 -RTDP is still much faster than Pse -RTDP.
The comparison of qualities of solutions produced by S-RTDP and S3 -RTDP w.r.t. optimal is shown
in Table 1. We observe that solutions produced by S-RTDP are always nearly optimal. Since the
3. The code may be downloaded at http://www.cs.washington.edu/ai/comdp/comdp.tgz

45

M AUSAM & W ELD

Comparison of Pruned and Unpruned RTDP for Rover domain

Comparison of Pruned and Unpruned RTDP for Factory domain
12000

y=x
Ps-RTDP
Pse-RTDP

25000

Times for Pruned RTDP (in sec)

Times for Pruned RTDP (in sec)

30000

20000
15000
10000
5000

y=x
Ps-RTDP
Pse-RTDP

10000
8000
6000
4000
2000

0

0
0

5000
10000 15000 20000 25000
Times for Unpruned RTDP (in sec)

30000

0

2000
4000
6000
8000
10000
Times for Unpruned RTDP (in sec)

12000

Figure 2: (a,b): Pruned vs. Unpruned RTDP for Rover and MachineShop domains respectively. Pruning
non-optimal combinations achieves significant speedups on larger problems.

Comparison of Pruned and Sampled RTDP for Rover domain

Comparison of Pruned and Sampled RTDP for Factory domain
8000

y=x
S-RTDP
S3-RTDP

8000

Times for Sampled RTDP (in sec)

Times for Sampled RTDP (in sec)

10000

6000
4000
2000
0

y=x
S-RTDP
S3-RTDP

7000
6000
5000
4000
3000
2000
1000
0

0

2000 4000 6000 8000 1000012000140001600018000
Times for Pruned RTDP (Pse-RTDP) - (in sec)

0

1000 2000 3000 4000 5000 6000 7000 8000
Times for Pruned RTDP (Pse-RTDP) - (in sec)

Figure 3: (a,b): Sampled vs Pruned RTDP for Rover and MachineShop domains respectively. Random
sampling of action combinations yields dramatic improvements in running times.

46

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Comparison of algorithms with size of problem for Rover domain
30000

S-RTDP
S3-RTDP
Pse-RTDP
U-RTDP

25000

S-RTDP
S3-RTDP
Pse-RTDP
U-RTDP

15000

20000

Times (in sec)

Times (in sec)

Comparison of different algorithms for Artificial domain
20000

15000
10000

10000

5000
5000
0

0
0

5e+07

1e+08
1.5e+08
Reach(|S|)*Avg(Ap(s))

2e+08

2.5e+08

0

2000

4000

6000 8000
Avg(Ap(s))

10000 12000 14000

Figure 4: (a,b): Comparison of different algorithms with size of the problems for Rover and Artificial domains. As the problem size increases, the gap between sampled and pruned approaches widens
considerably.

Results on varying the Number of samples for Rover Problem#4

300
250
200
150
100
50
0

Running times
Values of start state

300

100

200

300 400 500 600 700
Concurrency : Avg(Ap(s))/|A|

800

900

12.8

250

12.79

200

12.78

150

12.77

100

12.76

50

J*(s0)

0
0

12.81

Value of the start state

350

S-RTDP/Pse-RTDP

Times for Sampled RTDP (in sec)

Speedup : Sampled RTDP/Pruned RTDP

Speedup vs. Concurrency for Artificial domain
350

10

20

30

40 50 60 70 80
Number of samples

12.74
90 100

Figure 5: (a): Relative Speed vs. Concurrency for Artificial domain. (b) : Variation of quality of solution
and efficiency of algorithm (with 95% confidence intervals) with the number of samples in Sampled RTDP for one particular problem from the Rover domain. As number of samples increase,
the quality of solution approaches optimal and time still remains better than Pse -RTDP (which
takes 259 sec. for this problem).

47

M AUSAM & W ELD

Problem
Rover1
Rover2
Rover3
Rover4
Rover5
Rover6
Rover7
Artificial1
Artificial2
Artificial3
MachineShop1
MachineShop2
MachineShop3
MachineShop4
MachineShop5

J(s0 ) (S-RTDP)
10.7538
10.7535
11.0016
12.7490
7.3163
10.5063
12.9343
4.5137
6.3847
6.5583
15.0859
14.1414
16.3771
15.8588
9.0314

J âˆ— (s0 ) (Optimal)
10.7535
10.7535
11.0016
12.7461
7.3163
10.5063
12.9246
4.5137
6.3847
6.5583
15.0338
14.0329
16.3412
15.8588
8.9844

Error
<0.01%
0
0
0.02%
0
0
0.08%
0
0
0
0.35%
0.77%
0.22%
0
0.56%

Table 1: Quality of solutions produced by Sampled RTDP
error of S-RTDP is small, scaling it by 0.9 makes it an admissible initial cost function for the pruned
RTDP; indeed, in all experiments, S3 -RTDP produced the optimal solution.
Figure 4(a,b) demonstrates how running times vary with problem size. We use the product of
the number of reachable states and the average number of applicable action combinations per state
as an estimate of the size of the problem (the number of reachable states in all artificial domains is
the same, hence the x-axis for Figure 4(b) is Avg(Ap(s))). From these figures, we verify that the
number of applicable combinations plays a major role in the running times of the concurrent MDP
algorithms. In Figure 5(a), we fix all factors and vary the degree of parallelism. We observe that the
speedups obtained by S-RTDP increase as concurrency increases. This is a very encouraging result,
and we can expect S-RTDP to perform well on large problems inolving high concurrency, even if
the other approaches fail.
In Figure 5(b), we present another experiment in which we vary the number of action combinations sampled in each backup. While solution quality is inferior when sampling only a few
combinations, it quickly approaches the optimal on increasing the number of samples. In all other
experiments we sample 40 combinations per state.

4. Challenges for Temporal Planning
While the CoMDP model is powerful enough to model concurrency in actions, it still assumes each
action to be instantaneous. We now incorporate actual action durations in the modeling the problem.
This is essential to increase the scope of current models to real world domains.
Before we present our model and the algorithms we discuss several new theoretical challenges
imposed by explicit action durations. Note that the results in this section apply to a wide range of
planning problems:
â€¢ regardless of whether durations are uncertain or fixed
â€¢ regardless of whether effects are stochastic or deterministic.
48

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Actions of uncertain duration are modeled by associating a distribution (possibly conditioned
on the outcome of stochastic effects) over execution times. We focus on problems whose objective
is to achieve a goal state while minimizing total expected time (make-span), but our results extend
to cost functions that combine make-span and resource usage. This raises the question of when a
goal counts as achieved. We require that:
Assumption 1 All executing actions terminate before the goal is considered achieved.
Assumption 2 An action, once started, cannot be terminated prematurely.
We start by asking the question â€œIs there a restricted set of time points such that optimality is
preserved even if actions are started only at these points?â€
Definition 1 Any time point when a new action is allowed to start execution is called a decision
epoch. A time point is a pivot if it is either 0 or a time when a new effect might occur (e.g., the
end of an actionâ€™s execution) or a new precondition may be needed or an existing precondition may
no longer be needed. A happening is either 0 or a time when an effect actually occurs or a new
precondition is definitely needed or an existing precondition is no longer needed.
Intuitively, a happening is a point where a change in the world state or action constraints actually
â€œhappensâ€ (e.g., by a new effect or a new precondition). When execution crosses a pivot (a possible
happening), information is gained by the agentâ€™s execution system (e.g., did or didnâ€™t the effect
occur) which may â€œchange the directionâ€ of future action choices. Clearly, if action durations are
deterministic, then the set of pivots is the same as the set of happenings.
Example: Consider an action a whose durations follow a uniform integer duration between 1 and
10. If it is started at time 0 then all timepoints 0, 1, 2,. . ., 10 are pivots. If in a certain execution it
finishes at time 4 then 4 (and 0) is a happening (for this execution). 2
Definition 2 An action is a PDDL2.1 action (Fox & Long, 2003) if the following hold:
â€¢ The effects are realized instantaneously either (at start) or (at end), i.e., at the beginning or
the at the completion of the action (respectively).
â€¢ The preconditions may need to hold instaneously before the start (at start), before the end (at
end) or over the complete execution of the action (over all).

(:durative-action a
:duration (= ?duration 4)
:condition (and (over all P ) (at end Q))
:effect (at end Goal))
(:durative-action b
:duration (= ?duration 2)
:effect (and (at start Q) (at end (not P ))))

Figure 6: A domain to illustrate that an expressive action model may require arbitrary decision epochs for a
solution. In this example, b needs to start at 3 units after aâ€™s execution to reach Goal.

49

M AUSAM & W ELD

Theorem 5 For a PDDL2.1 domain restricting decision epochs to pivots causes incompleteness
(i.e., a problem may be incorrectly deemed unsolvable).
Proof: Consider the deterministic temporal planning domain in Figure 6 that uses PDDL2.1 notation
(Fox & Long, 2003). If the initial state is P =true and Q=false, then the only way to reach Goal is
to start a at time t (e.g., 0), and b at some timepoint in the open interval (t + 2, t + 4). Clearly, no
new information is gained at any of the time points in this interval and none of them is a pivot. Still,
they are required for solving the problem. 2
Intuitively, the instantaneous start and end effects of two PDDL2.1 actions may require a certain
relative alignment within them to achieve the goal. This alignment may force one action to start
somewhere (possibly at a non-pivot point) in the midst of the otherâ€™s execution, thus requiring
intermediate decision epochs to be considered.
Temporal planners may be classified as having one of two architectures: constraint-posting
approaches in which the times of action execution are gradually constrained during planning (e.g.,
Zeno and LPG, see Penberthy and Weld, 1994; Gerevini and Serina, 2002) and extended statespace methods (e.g., TP4 and SAPA, see Haslum and Geffner, 2001; Do and Kambhampati, 2001).
Theorem 5 holds for both architectures but has strong computational implications for state-space
planners because limiting attention to a subset of decision epochs can speed these planners. The
theorem also shows that planners like SAPA and Prottle (Little, Aberdeen, & Thiebaux, 2005) are
incomplete. Fortunately, an assumption restricts the set of decision epochs considerably.
Definition 3 An action is a TGP-style action4 if all of the following hold:
â€¢ The effects are realized at some unknown point during action execution, and thus can be used
only once the action has completed.
â€¢ The preconditions must hold at the beginning of an action.
â€¢ The preconditions (and the features on which its transition function is conditioned) must not
be changed during an actionâ€™s execution, except by an effect of the action itself.
Thus, two TGP-style actions may not execute concurrently if they clobber each otherâ€™s preconditions or effects. For the case of TGP-style actions the set of happenings is nothing but the set of
time points when some action terminates. TGP pivots are the set of points when an action might
terminate. (Of course both these sets additionally include zero).
Theorem 6 If all actions are TGP-style, then the set of decision epochs may be restricted to pivots
without sacrificing completeness or optimality.
Proof Sketch: By contradiction. Suppose that no optimal policy satisfies the theorem; then there
must exist a path through the optimal policy in which one must start an action, a, at time t even
though there is no action which could have terminated at t. Since the planner hasnâ€™t gained any
information at t, a case analysis (which requires actions to be TGP-style) shows that one could
have started a earlier in the execution path without increasing the make-span. The detailed proof is
discussed in the Appendix. 2
In the case of deterministic durations, the set of happenings is same as the set of pivots; hence
the following corollary holds:
4. While the original TGP (Smith & Weld, 1999) considered only deterministic actions of fixed duration, we use the
phrase â€œTGP-styleâ€ in a more general way, without these restrictions.

50

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Probabillity: 0.5
a0

s0

a2

G

a1
Makeâˆ’span: 3
Probability 0.5
a0

s0
a1

G

b0
Makeâˆ’span: 9

0

2

4

6

8

Time

Figure 7: Pivot decision epochs are necessary for optimal planning in face of nonmonotonic continuation. In this domain, Goal can be achieved by h{a0 , a1 }; a2 i or hb0 i; a0 has duration 2
or 9; and b0 is mutex with a1 . The optimal policy starts a0 and then, if a0 does not finish
at time 2, it starts b0 (otherwise it starts a1 ).

Corollary 7 If all actions are TGP-style with deterministic durations, then the set of decision
epochs may be restricted to happenings without sacrificing completeness or optimality.
When planning with uncertain durations there may be a huge number of pivots; it is useful to
further constrain the range of decision epochs.
Definition 4 An action has independent duration if there is no correlation between its probabilistic
effects and its duration.
Definition 5 An action has monotonic continuation if the expected time until action termination is
nonincreasing during execution.
Actions without probabilistic effects, by nature, have independent duration. Actions with monotonic continuations are common, e.g. those with uniform, exponential, Gaussian, and many other duration distributions. However, actions with bimodal or multi-modal distributions donâ€™t have monotonic continuations. For example consider an action with uniform distribution over [1,3]. If the
action doesnâ€™t terminate until 2, then the expected time until completion is calculated as 2, 1.5,
and 1 for times 0, 1, and 2 respectively, which is monotonically decreasing. For an example of
non-monotonic continuation see Figure 18.
Conjecture 8 If all actions are TGP-style, have independent duration and monotonic continuation,
then the set of decision epochs may be restricted to happenings without sacrificing completeness or
optimality.
If an actionâ€™s continuation is nonmonotonic then failure to terminate can increase the expected
time remaining and cause another sub-plan to be preferred (see Figure 7). Similarly, if an actionâ€™s
duration isnâ€™t independent then failure to terminate changes the probability of its eventual effects
and this may prompt new actions to be started.
By exploiting these theorems and conjecture we may significantly speed planning since we are
able to limit the number of decision epochs needed for decision-making. We use this theoretical
understanding in our models. First, for simplicity, we consider only the case of TGP-style actions
with deterministic durations. In Section 6, we relax this restriction by allowing stochastic durations,
both unimodal as well as multimodal.
51

M AUSAM & W ELD

toggleâˆ’p12
p12 (effect)
conflict
Â¬p12 (Precondition)
toggleâˆ’x1
0

2

4

6

8

10

Figure 8: A sample execution demonstrating conflict due to interfering preconditions and effects. (The
actions are shaded to disambiguate them with preconditions and effects)

5. Temporal Planning with Deterministic Durations
We use the abbreviation CPTP (short for Concurrent Probabilistic Temporal Planning) to refer to
the probabilistic planning problem with durative actions. A CPTP problem has an input model
similar to that of CoMDPs except that action costs, C(s, a, s0 ), are replaced by their deterministic
durations, âˆ†(a), i.e., the input is of the form hS, A, Pr, âˆ†, G, s0 i. We study the objective of minimizing the expected time (make-span) of reaching a goal. For the rest of the paper we make the
following assumptions:
Assumption 3 All action durations are integer-valued.
This assumption has a negligible effect on expressiveness because one can convert a problem
with rational durations into one that satisfies Assumption 3 by scaling all durations by the g.c.d. of
the denominators. In case of irrational durations, one can always find an arbitrarily close approximation to the original problem by approximating the irrational durations by rational numbers.
For reasons discussed in the previous section we adopt the TGP temporal action model of Smith
and Weld (1999), rather than the more complex PDDL2.1 (Fox & Long, 2003). Specifically:
Assumption 4 All actions follow the TGP model.
These restrictions are consistent with our previous definition of concurrency. Specifically, the
mutex definitions (of CoMDPs over probabilistic STRIPS) hold and are required under these assumptions. As an illustration, consider Figure 8. It describes a situation in which two actions with
interfering preconditions and effects can not be executed concurrently. To see why not, suppose
initially p12 was false and two actions toggle-x1 and toggle-p12 were started at time 2 and 4, respectively. As Â¬p12 is a precondition of toggle-x1 , whose duration is 5, it needs to remain false
until time 7. But toggle-p12 may produce its effects anytime between 4 and 9, which may conflict
with the preconditions of the other executing action. Hence, we forbid the concurrent execution of
toggle-x1 and toggle-p12 to ensure a completely predictable outcome distribution.
Because of this definition of concurrency, the dynamics of our model remains consistent with
Equation 5. Thus the techniques developed for CoMDPs derived from probabilistic STRIPS actions
may be used.
52

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

An Aligned Epoch policy execution
(takes 9 units)
toggleâˆ’x1
t3

f

f

f

f

t3 t3 t3 t3

0

5

s

10
time

toggleâˆ’x1
f

f

f

f

t3 t3 t3 t3 t3

s

An Interwoven Epoch policy execution
(takes 5 units)

Figure 9: Comparison of times taken in a sample execution of an interwoven-epoch policy and an alignedepoch policy. In both trajectories the toggle-x3 (t3) action fails four times before succeeding.
Because the aligned policy must wait for all actions to complete before starting any more, it takes
more time than the interwoven policy, which can start more actions in the middle.

5.1 Formulation as a CoMDP
We can model a CPTP problem as a CoMDP, and thus as an MDP, in more than one way. We list
the two prominent formulations below. Our first formulation, aligned epoch CoMDP models the
problem approximately but solves it quickly. The second formulation, interleaved epochs models
the problem exactly but results in a larger state space and hence takes longer to solve using existing
techniques. In subsequent subsections we explore ways to speed up policy construction for the
interleaved epoch formulation.
5.1.1 A LIGNED E POCH S EARCH S PACE
A simple way to formulate CPTP is to model it as a standard CoMDP over probabilistic STRIPS,
in which action costs are set to their durations and the cost of a combination is the maximum
duration of the constituent actions (as in Equation 6). This formulation introduces a substantial
approximation to the CPTP problem. While this is true for deterministic domains too, we illustrate
this using our example involving stochastic effects. Figure 9 compares the trajectories in which the
toggle-x3 (t3) actions fails for four consecutive times before succeeding. In the figure, â€œfâ€ and â€œsâ€
denote failure and success of uncertain actions, respectively. The vertical dashed lines represent the
time-points when an action is started.
Consider the actual executions of the resulting policies. In the aligned-epoch case (Figure 9
top), once a combination of actions is started at a state, the next decision can be taken only when
the effects of all actions have been observed (hence the name aligned-epochs). In contrast, Figure 9
bottom shows that at a decision epoch in the optimal execution for a CPTP problem, many actions
may be midway in their execution. We have to explicitly take into account these actions and their
remaining execution times when making a subsequent decision. Thus, the actual state space for
CPTP decision making is substantially different from that of the simple aligned-epoch model.
Note that due to Corollary 7 it is sufficient to consider a new decision epoch only at a happening,
i.e., a time-point when one or more actions complete. Thus, using Assumption 3 we infer that these
decision epochs will be discrete (integer). Of course, not all optimal policies will have this property.
53

M AUSAM & W ELD

State variables : x1 , x2 , x3 , x4 , p12
Action
âˆ†(a) Precondition
toggle-x1
5
Â¬p12
toggle-x2
5
p12
toggle-x3
1
true

Effect
x1 â† Â¬x1
x2 â† Â¬x2
x3 â† Â¬x3
no change
toggle-x4
1
true
x4 â† Â¬x4
no change
toggle-p12
5
true
p12 â† Â¬p12
Goal : x1 = 1, x2 = 1, x3 = 1, x4 = 1

Probability
1
1
0.9
0.1
0.9
0.1
1

Figure 10: The domain of Example 1 extended with action durations.
But it is easy to see that there exists at least one optimal policy in which each action begins at a
happening. Hence our search space reduces considerably.
5.1.2 I NTERWOVEN E POCH S EARCH S PACE
We adapt the search space representation of Haslum and Geffner (2001), which is similar to that
in other research (Bacchus & Ady, 2001; Do & Kambhampati, 2001). Our original state space S
in Section 2 is augmented by including the set of actions currently executing and the times passed
since they were started. Formally, let the new interwoven state5 s âˆˆ S â€“- be an ordered pair hX, Y i
where:
â€¢ XâˆˆS
â€¢ Y = {(a, Î´)|a âˆˆ A, 0 â‰¤ Î´ < âˆ†(a)}
Here X represents the values of the state variables (i.e. X is a state in the original state space)
and Y denotes the set of ongoing actions â€œaâ€ and the times
 passed since their start â€œÎ´â€. Thus the
N
overall interwoven-epoch search space is S â€“- = S Ã— aâˆˆA {a} Ã— Zâˆ†(a) , where Zâˆ†(a) represents
N
the set {0, 1, . . . , âˆ†(a) âˆ’ 1} and
denotes the Cartesian product over multiple sets.
Also define As to be the set of actions already in execution. In other words, As is a projection
of Y ignoring execution times in progress:
As = {a|(a, Î´) âˆˆ Y âˆ§ s = hX, Y i}
Example: Continuing our example with the domain of Figure 10, suppose state s1 has all state
variables false, and suppose the action toggle-x1 was started 3 units ago from the current time. Such
a state would be represented as hX1 , Y1 i with X1 =(F, F, F, F, F ) and Y1 ={(toggle-x1 ,3)} (the five
state variables are listed in the order: x1 , x2 , x3 , x4 and p12 ). The set As1 would be {toggle-x1 }.
To allow the possibility of simply waiting for some action to complete execution, that is, deciding at a decision epoch not to start any additional action, we augment the set A with a no-op action,
which is applicable in all states s = hX, Y i where Y 6= âˆ… (i.e. states in which some action is still
being executed). For a state s, the no-op action is mutex with all non-executing actions, i.e., those in
A \ As . In other words, at any decision epoch either a no-op will be started or any combination not
5. We use the subscript â€“- to denote the interwoven state space (S â€“- ), value function (J â€“- ), etc..

54

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

involving no-op. We define no-op to have a variable duration6 equal to the time after which another
already executing action completes (Î´next (s, A) as defined below).
The interwoven applicability set can be defined as:
(

Ap â€“- (s) =

Apk (X) if Y = âˆ… else
{noop}âˆª{A|AâˆªAs âˆˆ Apk (X) and Aâˆ©As = âˆ…}

Transition Function: We also need to define the probability transition function, Pr â€“- , for the
interwoven state space. At some decision epoch let the agent be in state s = (X, Y ). Suppose
that the agent decides to execute an action combination A. Define Ynew as the set similar to Y
but consisting of the actions just starting; formally Ynew = {(a, âˆ†(a))|a âˆˆ A}. In this system, the
next decision epoch will be the next time that an executing action terminates. Let us call this time
Î´next (s, A). Notice that Î´next (s, A) depends on both executing and newly started actions. Formally,
Î´next (s, A) =

min

(a,Î´)âˆˆY âˆªYnew

âˆ†(a) âˆ’ Î´

Moreover, multiple actions may complete simultaneously. Define Anext (s, A) âŠ† A âˆª As to be
the set of actions that will complete exactly in Î´next (s, A) timesteps. The Y -component of the state
at the decision epoch after Î´next (s, A) time will be
Ynext (s, A) = {(a, Î´ + Î´next (s, A))|(a, Î´) âˆˆ Y âˆª Ynew , âˆ†(a) âˆ’ Î´ > Î´next (s, A)}
Let s=hX, Y i and let s0 =hX 0 , Y 0 i. The transition function for CPTP can now be defined as:
Prk (X 0 |X, Anext (s, A)) if Y 0= Ynext (s, A)
0
otherwise

(
0

Pr â€“- (s |s, A)=

In other words, executing an action combination A in state s = hX, Y i takes the agent to a
decision epoch Î´next (s, A) ahead in time, specifically to the first time when some combination
Anext (s, A) completes. This lets us calculate Ynext (s, A): the new set of actions still executing
with their times elapsed. Also, because of TGP-style actions, the probability distribution of different
state variables is modified independently. Thus the probability transition function due to CoMDP
over probabilistic STRIPS can be used to decide the new distribution of state variables, as if the
combination Anext (s, A) were taken in state X.
Example: Continuing with the previous example, let the agent in state s1 execute the action combination A = {toggle-x4 }. Then Î´next (s1 , A) = 1, since toggle-x4 will finish the first. Thus,
Anext (s1 , A)= {toggle-x4 }. Ynext (s1 , A) = {(toggle-x1 ,4)}. Hence, the probability distribution of
states after executing the combination A in state s1 will be
â€¢ ((F, F, F, T, F ), Ynext (s1 , A)) probability = 0.9
â€¢ ((F, F, F, F, F ), Ynext (s1 , A)) probability = 0.1
6. A precise definition of the model will create multiple no-opt actions with different constant durations t and the no-opt
applicable in an interwoven state will be the one with t = Î´next (s, A).

55

M AUSAM & W ELD

Start and Goal States: In the interwoven space, the start state is hs0 , âˆ…i and the new set of goal
states is G â€“- = {hX, âˆ…i|X âˆˆ G}.
By redefining the start and goal states, the applicability function, and the probability transition
function, we have finished modeling a CPTP problem as a CoMDP in the interwoven state space.
Now we can use the techniques of CoMDPs (and MDPs as well) to solve our problem. In particular,
we can use our Bellman equations as described below.
Bellman Equations: The set of equations for the solution of a CPTP problem can be written as:
J âˆ—- (s) = 0, if s âˆˆ G â€“- else
â€“
ï£±

(11)

ï£´
ï£²

ï£¼
ï£´
ï£½

Î´next (s, A) + Pr â€“- (s0 |s, A)J âˆ—- (s0 )
J - (s) = min
â€“
â€“
ï£´
AâˆˆAp - (s) ï£´
ï£¾
ï£³
s0 âˆˆS â€“
â€“
âˆ—

X

We will use DURsamp to refer to the sampled RTDP algorithm over this search space. The main
bottleneck in naively inheriting algorithms like DURsamp is the huge size of the interwoven state
space. In the worst case (when all actions can be executed concurrently) the size of the state space is
Q
|S| Ã— ( aâˆˆA âˆ†(a)). We get this bound by observing that for each action a, there are âˆ†(a) number
of possibilities: either a is not executing or it is and has remaining times 1, 2, . . . , âˆ†(a) âˆ’ 1.
Thus we need to reduce or abstract/aggregate our state space in order to make the problem
tractable. We now present several heuristics which can be used to speed the search.
5.2 Heuristics
We present both an admissible and an inadmissible heuristics that can be used as the initial cost
function for DURsamp algorithm. The first heuristic (maximum concurrency) solves the underlying MDP and is thus quite efficient to compute. The second heuristic (average concurrency) is
inadmissible, but tends to be more informed than the maximum concurrency heuristic.
5.2.1 M AXIMUM C ONCURRENCY H EURISTIC
We prove that the optimal expected cost in a traditional (serial) MDP divided by the maximum
number of actions that can be executed in parallel is a lower bound for the expected make-span of
reaching a goal in a CPTP problem. Let J(X) denote the value of a state X âˆˆ S in a traditional
MDP with costs of an action equal to its duration. Let Q(X, A) denote the expected cost to reach the
goal if initially all actions in the combination A are executed and the greedy serial policy is followed
P
thereafter. Formally, Q(X, A) = X 0 âˆˆS Prk (X 0 |X, A)J(X 0 ). Let J â€“- (s) be the value for equivalent
CPTP problem with s as in our interwoven-epoch state space. Let concurrency of a state be the
maximum number of actions that could be executed in the state concurrently. We define maximum
concurrency of a domain (c) as the maximum number of actions that can be concurrently executed
in any world state in the domain. The following theorem can be used to provide an admissible
heuristic for CPTP problems.
Theorem 9 Let s = hX, Y i,
J âˆ—- (s) â‰¥
â€“
J âˆ—- (s) â‰¥
â€“

J âˆ— (X)
for Y = âˆ…
c
Qâˆ— (X, As )
for Y 6= âˆ…
c
56

(12)

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Proof Sketch: Consider any trajectory of make-span L (from a state s = hX, âˆ…i to a goal state) in a
CPTP problem using its optimal policy. We can make all concurrent actions sequential by executing
them in the chronological order of being started. As all concurrent actions are non-interacting, the
outcomes at each stage will have similar probabilities. The maximum make-span of this sequential
trajectory will be cL (assuming c actions executing at all points in the semi-MDP trajectory). Hence
J(X) using this (possibly non-stationary) policy would be at most cJ âˆ—- (s). Thus J âˆ— (X) â‰¤ cJ âˆ—- (s).
â€“
â€“
The second inequality can be proven in a similar way. 2
There are cases where these bounds are tight. For example, consider a deterministic planning
problem in which the optimal plan is concurrently executing c actions each of unit duration (makespan = 1). In the sequential version, the same actions would be taken sequentially (make-span =
c).
Following this theorem, the maximum concurrency (MC) heuristic for a state s = hX, Y i is
defined as follows:
Qâˆ— (X, As )
J âˆ— (X)
else HM C (s) =
if Y = âˆ… HM C (s) =
c
c
The maximum concurrency c can be calculated by a static analysis of the domain and is a onetime expense. The complete heuristic function can be evaluated by solving the MDP for all states.
However, many of these states may never be visited. In our implementation, we do this calculation
on demand, as more states are visited, by starting the MDP from the current state. Each RTDP run
can be seeded by the previous value function, thus no computation is thrown away and only the
relevant part of the state space is explored. We refer to DURsamp initiated with the MC heuristic by
DURMC
samp .
5.2.2 AVERAGE C ONCURRENCY H EURISTIC
Instead of using maximum concurrency c in the above heuristic we use the average concurrency
in the domain (ca ) to get the average concurrency (AC) heuristic. We call the resulting algorithm
DURAC
samp . The AC heuristic is not admissible, but in our experiments it is typically a more informed
heuristic. Moreover, in the case where all the actions have the same duration, the AC heuristic equals
the MC heuristic.
5.3 Hybridized Algorithm
We present an approximate method to solve CPTP problems. While there can be many kinds of
possible approximation methods, our technique exploits the intuition that it is best to focus computation on the most probable branches in the current policyâ€™s reachable space. The danger of this
approach is the chance that, during execution, the agent might end up in an unlikely branch, which
has been poorly explored; indeed it might blunder into a dead-end in such a case. This is undesirable, because such an apparently attractive policy might have a true expected make-span of infinity.
Since, we wish to avoid dead-ends, we explore the desirable notion of propriety.
Definition 6 Propriety: A policy is proper at a state if it is guaranteed to lead, eventually, to the goal
state (i.e., it avoids all dead-ends and cycles) (Barto et al., 1995). We define a planning algorithm
proper if it always produces a proper policy (when one exists) for the initial state.
We now describe an anytime approximation algorithm, which quickly generates a proper policy
and uses any additional available computation time to improve the policy, focusing on the most
likely trajectories.
57

M AUSAM & W ELD

5.3.1 H YBRIDIZED P LANNER
Our algorithm, DURhyb , is created by hybridizing two other policy creation algorithms. Indeed,
our novel notion of hybridization is both general and powerful, applying to many MDP-like problems; however, in this paper we focus on the use of hybridization for CPTP. Hybridization uses an
anytime algorithm like RTDP to create a policy for frequently visited states, and uses a faster (and
presumably suboptimal) algorithm for the infrequent states.
For the case of CPTP, our algorithm hybridizes the RTDP algorithms for interwoven-epoch and
aligned-epoch models. With aligned-epochs, RTDP converges relatively quickly, because the state
space is smaller, but the resulting policy is suboptimal for the CPTP problem, because the policy
waits for all currently executing actions to terminate before starting any new actions. In contrast,
RTDP for interwoven-epochs generates the optimal policy, but it takes much longer to converge.
Our insight is to run RTDP on the interwoven space long enough to generate a policy which is
good on the common states, but stop well before it converges in every state. Then, to ensure that the
rarely explored states have a proper policy, we substitute the aligned policy, returning this hybridized
policy.
Algorithm 3 Hybridized Algorithm DURhyb (r, k, m)
1: for all s âˆˆ S - do
â€“
2:
initialize J â€“- (s) with an admissible heuristic
3: repeat
4:
perform m RTDP trials
5:
compute hybridized policy (Ï€hyb ) using interwoven-epoch policy for k-familiar states and aligned-

epoch policy otherwise
clean Ï€hyb by removing all dead-ends and cycles
J Ï€- hs0 , âˆ…i â† evaluation of Ï€hyb from the start state
â€“ Ï€

J - (hs0 ,âˆ…i)âˆ’J - (hs0 ,âˆ…i)
â€“
â€“
8: until
<r
J - (hs0 ,âˆ…i)
â€“
9: return hybridized policy Ï€hyb

6:
7:

Thus the key question is how to decide which states are well explored and which are not. We
define the familiarity of a state s to be the number of times it has been visited in previous RTDP
trials. Any reachable state whose familiarity is less than a constant, k, has an aligned policy created
for it. Furthermore, if a dead-end state is reached using the greedy interwoven policy, then we create
an aligned policy for the immediate precursors of that state. If a cycle is detected7 , then we compute
an aligned policy for all the states which are part of the cycle.
We have not yet said how the hybridized algorithm terminates. Use of RTDP helps us in defining
a very simple termination condition with a parameter that can be varied to achieve the desired
closeness to optimality as well. The intuition is very simple. Consider first, optimal labeled RTDP.
This starts with an admissible heuristic and guarantees that the value of the start state, J â€“- (hs0 , âˆ…i),
remains admissible (thus less than or equal to optimal). In contrast, the hybridized policyâ€™s makespan is always longer than or equal to optimal. Thus as time progresses, these values approach the
optimal make-span from opposite sides. Whenever the two values are within an optimality ratio (r),
we know that the algorithm has found a solution, which is close to the optimal.
7. In our implementation cycles are detected using simulation.

58

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Finally, evaluation of the hybridized policy is done using simulation, which we perform after a
fixed number of m RTDP trials. Algorithm 3 summarizes the details of the algorithm. One can see
that this combined policy is proper for two reasons: 1) if the policy at a state is from the aligned
policy, then it is proper because the RTDP for the aligned-epoch model was run to convergence, and
2) for the rest of the states it has explicitly ensured that there are no cycles or dead-ends.
5.4 Experiments: Planning with Deterministic Durations
Continuing from Section 3.6, in this set of experiments we evaluate the various techniques for
solving problems involving explicit deterministic durations. We compare the computation time and
solution quality of five methods: interwoven Sampled RTDP with no heuristic (DURsamp ), with the
AC
maximum concurrency (DURMC
samp ), and average concurrency (DURsamp ) heuristics, the hybridized
algorithm (DURhyb ) and Sampled RTDP on the aligned-epoch model (DURAE ). We test on our
Rover, MachineShop and Aritificial domains. We also use our Artificial domain to see if the relative
performance of the techniques varies with the amount of concurrency in the domain.
5.4.1 E XPERIMENTAL S ETUP
We modify the domains used in Section 3.6 by additionally including action durations. For NASA
Rover and MachineShop domains, we generate problems with 17-26 state variables and 12-18 actions, whose duration range between 1 and 20. The problems have between 15,000-700,000 reachable states in the interwoven-epoch state space, S â€“- .
We use Artificial domain for control experiments to study the effect of degree of parallelism.
All the problems in this domain have 14 state variables and 17,000-40,000 reachable states and
durations of actions between 1 and 3.
We use our implementation of Sampled RTDP8 and implement all heuristics: maximum concurrency (HM C ), average concurrency (HAC ), for the initialization of the value function. We calculate
these heuristics on demand for the states visited, instead of computing the complete heuristic for the
whole state space at once. We also implement the hybridized algorithm in which the initial value
function was set to the HM C heuristic. The parameters r, k, and m are kept at 0.05, 100 and 500,
respectively. We test each of these algorithms on a number of problem instances from the three
domains, which we generate by varying the number of objects, degrees of parallelism, durations of
the actions and distances to the goal.
5.4.2 C OMPARISON OF RUNNING T IMES
Figures 11(a, b) and 12(a) show the variations in the running times for the algorithms on different
problems in Rover, Machineshop and Artificial domains, respectively. The first three bars represent
the base Sampled RTDP without any heuristic, with HM C , and with HAC , respectively. The fourth
bar represents the hybridized algorithm (using the HM C heuristic) and the fifth bar is computation
of the aligned-epoch Sampled RTDP with costs set to the maximum action duration. The white
region in the fourth bar represents the time taken for the aligned-epoch RTDP computations in the
hybridized algorithm. The error bars represent 95% confidence intervals on the running times. Note
that the plots are on a log scale.
8. Note that policies returned by DURsamp are not guaranteed to be optimal. Thus all the implemented algorithms are
approximate. We can replace DURsamp by pruned RTDP (DURprun ) if optimality is desired.

59

M AUSAM & W ELD

Rover16

Mach11

10^3

10^2

10^1

Mach12

Mach13

Mach14

Mach15

Mach16

0
M
AC
H
AE

Rover15

0
M
AC
H
AE

Rover14

Time in sec (on log scale)

10^3

10^2

10^1

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

10^0

10^0

0
M
AC
H
AE

Time in sec (on log scale)

Rover13

0
M
AC
H
AE

Rover12

Rover11

0
M
AC
H
AE

10^4

10^4

Figure 11: (a,b): Running times (on a log scale) for the Rover and Machineshop domain, respectively. For
each problem the five bars represent the times taken by the algorithms: DURsamp (0), DURMC
samp
(AE), DURAC
(AC),
DUR
(H),
and
DUR
(AE),
respectively.
The
white
bar
on
DUR
hyb
AE
hyb
samp
denotes the portion of time taken by aligned-epoch RTDP.

Algos
DURMC
samp
DURAC
samp
DURhyb
DURAE

Speedup compared with DURsamp
Rover
Machineshop Artificial Average
3.016764
1.545418
1.071645 1.877942
3.585993
2.173809
1.950643 2.570148
10.53418
2.154863
16.53159 9.74021
135.2841
16.42708
241.8623 131.1911

Table 2: The ratio of the time taken by S â€“- S-RTDP with no heuristics to that of each algorithm. Our
heuristics produce 2-3 times speedups. The hybridized algo produces about a 10x speedup. Aligned
epoch search produces 100x speedup, but sacrifices solution quality.

We notice that DURAE solves the problems extremely quickly; this is natural since the alignedepoch space is much smaller. Use of both HM C and HAC always speeds search in the S â€“- model.
Comparing the heuristics amongst themselves, we find that average concurrency heuristic mostly
performs faster than maximum concurrency â€” presumably because HAC is a more informed heuristic in practice, although at the cost of being inadmissible. We find a couple of cases in which HAC
doesnâ€™t perform better; this could be because it is focusing the search in the incorrect region, given
its inadmissible nature.
For the Rover domain, the hybridized algorithm performs fastest. In fact, the speedups are
dramatic compared to other methods. In other domains, the results are more comparable for small
problems. However, for large problems in these two domains, hybridized outperforms the others by
a huge margin. In fact for the largest problem in Artificial domain, none of the heuristics are able to
converge (within a day) and only DURhyb and DURAE converge to a solution.
60

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

10^4

Art12

Art13

Art14

Art15

0
M
AC
H
AE

Art11

0
M
AC
H
AE

1.6
Art11(68) Art12(77) Art13(81) Art14(107) Art15(224) Art16(383) Art17(1023)

Art16

Art17

Ratio of make-span to optimal

Time in sec (on log scale)

1.5
10^3

10^2

10^1

1.4
1.3
1.2
1.1
1
0.9

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0
M
AC
H
AE

0.8

10^0

Figure 12: (a,b): Comparison of the different algorithms (running times and solution quality respectively)
for the Artificial domain. As degree of parallelism increases the problems become harder; the
largest problem is solved only by DURhyb and DURAE .

Table 2 shows the speedups obtained by various algorithms compared to the basic DURsamp .
In the Rover and Artificial domains the speedups obtained by DURhyb and DURAE are much more
prominent than in the Machineshop domain. Averaging over all domains, H produces a 10x speedup
and AE produces more than a 100x speedup.
5.4.3 C OMPARISON OF S OLUTION Q UALITY
Figures 13(a, b) and 12(b) show the quality of the policies obtained by the same five methods on the
same domains. We measure quality by simulating the generated policy across multiple trials, and
reporting the average time taken to reach the goal. We plot the ratio of the so-measured expected
make-span to the optimal expected make-span9 . Table 3 presents solution qualities for each method,
averaged over all problems in a domain. We note that the aligned-epoch policies usually yield
significantly longer make-spans (e.g., 25% longer); thus one must make a quality sacrifice for their
speedy policy construction. In contrast, the hybridized algorithm extorts only a small sacrifice in
quality in exchange for its speed.
5.4.4 VARIATION WITH C ONCURRENCY
Figure 12(a) represents our attempt to see if the relative performance of the algorithms changed with
increasing concurrency. Along the top of the figure, by the problem names, are numbers in brackets;
these list the average number of applicable combinations in each MDP state, AvgsâˆˆS - |Ap(s)|, and
â€“
range from 68 to 1023 concurrent actions. Note that for the difficult problems with a lot of parallelism, DURsamp slows dramatically, regardless of heuristic. In contrast, the DURhyb is still able to
quickly produce a policy, and at almost no loss in quality (Figure 12(b)).
9. In some large problems the optimal algorithm did not converge. For those, we take as optimal, the best policy found
in our runs.

61

M AUSAM & W ELD

Rover16

1.7 Mach11
Ratio of make-span to optimal

1.4
1.3
1.2
1.1
1

Mach16

1.2
1.1
1

0
M
AC
H
AE

0
M
AC
H
AE

Mach15

1.3

0.8
0
M
AC
H
AE

Mach14

1.4

0.8
0
M
AC
H
AE

Mach13

1.5

0.9

0
M
AC
H
AE

Mach12

1.6

0.9

0
M
AC
H
AE

Ratio of make-span to optimal

1.5

0
M
AC
H
AE

Rover15

0
M
AC
H
AE

Rover14

0
M
AC
H
AE

Rover13

0
M
AC
H
AE

Rover12

0
M
AC
H
AE

Rover11

0
M
AC
H
AE

1.8

1.6

Figure 13: (a,b): Comparison of make-spans of the solution found with the optimal(plotted as 1 on the yaxes) for Rover and Machineshop domains, respectively. All algorithms except DURAE produce
solutions quite close to the optimal.

Algos
DURsamp
DURMC
samp
DURAC
samp
DURhyb
DURAE

Rover
1.059625
1.018405
1.017141
1.059349
1.257205

Average Quality
Machineshop Artificial
1.065078
1.042561
1.062564
1.013465
1.046391
1.020523
1.075534
1.059201
1.244862
1.254407

Average
1.055704
1.031478
1.028019
1.064691
1.252158

Table 3: Overall solution quality produced by all algorithms. Note that all algorithms except DURAE produce policies whose quality is quite close to optimal. On average DURAE produces make-spans
that are about 125% of the optimal.

6. Optimal Planning with Uncertain Durations
We now extend the techniques of previous section for the case when action durations are not deterministic. As before, we consider TGP-style actions and a discrete temporal model. We assume
independent durations, and monotonic continuations, but Section 6.3 relaxes the latter, extending
our algorithms to handle multimodal duration distributions. As before we aim to minimize the
expected time required to reach a goal.
6.1 Formulating as a CoMDP
We now formulate our planning problem as a CoMDP similar to Section 5.1. While some of the
parameters of the CoMDP can be used directly from our work on deterministic durations, we need
to recompute the transition function.
62

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

State Space: Both the aligned epoch state space as well as the interwoven epoch space, as defined
in Section 5.1 are adequate to model this planning problem. To determine the size of the interwoven
space, we replace the duration of an action by its max duration. Let âˆ†M (a) denote the maximum
time within which action a will complete. The overall interwoven-epoch search space is S â€“- = S Ã—




{a} Ã— Zâˆ†M (a) , where Zâˆ†M (a) represents the set {0, 1, . . . , âˆ†M (a) âˆ’ 1} and
denotes
the Cartesian product over multiple sets.
Action Space: At any state we may apply a combination of actions with the applicability function
reflecting the fact that the combination of actions is safe w.r.t itself (and w.r.t. already executing
actions in case of interwoven space) as in the previous sections. While the previous state space and
action space work well for our problem, the transition function definition needs to change, since we
now need to take into account the uncertainty in durations.
Transition Function: Uncertain durations require significant changes to the probability transition
function (Pr â€“- ) for the interwoven space from the definitions of Section 5.1.2. Since our assumptions justify Conjecture 8, we need only consider happenings when choosing decision epochs.
N

N

aâˆˆA

Algorithm 4 ComputeTransitionFunc(s=hX, Y i,A)
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

Y â† Y âˆª {(a, 0)} âˆ€a âˆˆ A
mintime â† min(a,Î´)âˆˆY minimum remaining time for a
maxtime â† min(a,Î´)âˆˆY maximum remaining time for a
for all integer t âˆˆ [mintime, maxtime] do
At â† set of actions that could possibly terminate after t
for all non-empty subsets Asubt âŠ† At do
pc â† (prob. that exactly Asubt terminates after t (see Equation 13).
W â† {(Xt , pw ) | Xt is a world state; pw is the probability that Asubt terminates yielding Xt }.
for all (Xt , pw ) âˆˆ W do
Yt â† {(a, Î´ + t) | (a, Î´) âˆˆ Y, a âˆˆ
/ Asubt }
insert (hXt , Yt i, pw Ã— pc ) in output
return output

The computation of transition function is described in Algorithm 4. Although the next decision
epoch is determined by a happening, we still need to consider all pivots for the next state calculations
as all these are potential happenings. mintime is the minimum time when an executing action could
terminate, maxtime is the minimum time by which it is guaranteed that at least one action will
terminate. For all times between mintime and maxtime we compute the possible combinations that
could terminate then and the resulting next interwoven state. The probability, pc , (line 7) may be
computed using the following formula:
pc =

Y

(prob. a terminates at Î´a + t|a hasn0 t terminated till Î´a ) Ã—

(a,Î´a )âˆˆY,aâˆˆAsubt

Y

(prob. b doesn0 t terminate at Î´b + t|b hasn0 t terminated till Î´b )

(13)

(b,Î´b )âˆˆY,bâˆˆAsub
/
t

Considering all pivots makes the algorithm computationally intensive because there may be
many pivots and many action combinations could end at each one, and with many outcomes each.
In our implementation, we cache the transition function so that we do not have to recompute the
information for any state.
63

M AUSAM & W ELD

Start and Goal States: The start state and goal set that we developed for the deterministic durations
work unchanged when the durations are stochastic. So, the start state is hs0 , âˆ…i and the goal set is
G â€“- = {hX, âˆ…i|X âˆˆ G}.
Thus we have modeled our problem as a CoMDP in the interwoven state space. We have redefined the start and goal states, and the probability transition function. Now we can use the techniques
of CoMDPs to solve our problem. In particular, we can use our Bellman equations as below.
Bellman Equations for Interwoven-Epoch Space: Define Î´el (s, A, s0 ) as the time elapsed between two interwoven states s and s0 when combination A is executed in s. The set of equations for
the solution of our problem can be written as:

J âˆ—- (s) = 0, if s âˆˆ G â€“- else
â€“
n
o
X
Pr â€“- (s0 |s, A) Î´el (s, A, s0 ) + J âˆ—- (s0 )
J âˆ—- (s) = min
â€“
â€“
AâˆˆAp - (s) 0
â€“ s âˆˆS â€“-

(14)

Compare these equations with Equation 11. There is one difference besides the new transition
function â€” the time elapsed is within the summation sign. This is because time elapsed depends
also on the next interwoven state.
Having modeled this problem as a CoMDP we again use our algorithms of Section 5. We use
âˆ†DUR to denote the family of algorithms for the CPTP problems involving stochastic durations.
The main bottleneck in solving these problem, besides the size of the interwoven state space, is the
high branching factor.
6.1.1 P OLICY C ONSTRUCTION : RTDP & H YBRIDIZED P LANNING
Since we have modeled our problem as a CoMDP in the new interwoven space, we may use pruned
RTDP (âˆ†DURprun ) and sampled RTDP (âˆ†DURsamp ) for policy construction. Since the cost function in our problem (Î´el ) depends also on the current and the next state, combo-skipping does not
apply for this problem. Thus âˆ†DURprun refers to RTDP with only combo-elimination.
Furthermore, only small adaptations are necessary to incrementally compute the (admissible)
maximum concurrency (M C) and (more informed, but inadmissible) average concurrency (AC)
heuristics. For example, for the serial MDP (in the RHS of Equation 12) we now need to compute
the average duration of an action and use that as the actionâ€™s cost.
Likewise, we can further speed planning by hybridizing (âˆ†DURhyb ) RTDP algorithms for interwoven and aligned-epoch CoMDPs to produce a near-optimal policy in significantly less time.
The dynamics of aligned epoch space is same as that in Section 5 with one exception. The cost of a
combination, in the case of deterministic durations, was simply the max duration of the constituent
actions. The novel twist stems from the fact that uncertain durations require computation of the cost
of an action combination as the expected time that the last action in the combination will terminate.
For example, suppose two actions, both with uniform duration distributions over [1,3], are started
concurrently. The probabilities that both actions will have finished by times 1, 2 and 3 (and no earlier) are 1/9, 3/9, and 5/9 respectively. Thus the expected duration of completion of the combination
(let us call it âˆ†AE ) is 1Ã—1/9 + 2Ã—3/9 + 3Ã—5/9 = 2.44.
64

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

6.2 Expected-Duration Planner
When modeled as a CoMDP in the full-blown interwoven space, stochastic durations cause an
exlposive growth in the branching factor. In general, if n actions are started each with m possible
durations and each having r probabilistic effects, then there are (m âˆ’ 1)[(r + 1)n âˆ’ rn âˆ’ 1] + rn
potential successors. This number may be computed as follows: for each duration between 1 and
m âˆ’ 1 any subset of actions could complete and each action could result in r outcomes. Hence, total
P
number of successors per duration is iâˆˆ[1..n] n Ci ri = (r + 1)n âˆ’ rn âˆ’ 1. Moreover, if none of the
actions finish until time m âˆ’ 1 then at the last step all actions terminate leading into rn outcomes.
So, total number of successors is (m âˆ’ 1)[(r + 1)n âˆ’ rn âˆ’ 1] + rn . Thus, the branching factor is
multiplicative in the duration uncertainty and exponential in the concurrency.
To manage this extravagant computation we must curb the branching factor. One method is
to ignore duration distributions. We can assign each action a constant duration equal to the mean
of its distribution, then apply a deterministic-duration planner such as DURsamp . However, when
executing the deterministic-duration policy in a setting where durations are actually stochastic, an
action will likely terminate at a time different than its mean, expected duration. The âˆ†DURexp
planner addresses this problem by augmenting the deterministic-duration policy created to account
for these unexpected outcomes.
6.2.1 O NLINE V ERSION
The procedure is easiest to understand in its online version (Algorithm 5): wait until the unexpected
happens, pause execution, and re-plan. If the original estimate of an actionâ€™s duration is implausible,
we compute a revised deterministic estimate in terms of Ea (min) â€” the expected value of aâ€™s
duration given that it has not terminated by time min. Thus, Ea (0) will compute the expected
duration of a.
Algorithm 5 Online âˆ†DURexp
1: build a deterministic-duration policy from the start state s0
2: repeat
3:
execute action combination specified by policy
4:
wait for interrupt
5:
case: action a terminated as expected {//do nothing}
6:
case: action a terminates early
7:
extend policy from current state
8:
case: action a didnâ€™t terminate as expected
9:
extend policy from current state revising

aâ€™s duration as follows:
10:
Î´ â† time elapsed since a started executing
11:
nextexp â† dEa (0)e
12:
while nextexp < Î´ do
13:
nextexp â† dEa (nextexp)e
14:
endwhile
15:
aâ€™s revised duration â† nextexp âˆ’ Î´
16:
endwait
17: until goal is reached

65

M AUSAM & W ELD

Example: Let the duration of an action a follow a uniform distribution between 1 and 15. The
expected value that gets assigned in the first run of the algorithm (dEa (0)e) is 8. While running the
algorithm, suppose the action didnâ€™t terminate by 8 and we reach a state where a has been running
for, say, 9 time units. In that case, a revised expected duration for a would be (dEa (8)e) = 12.
Similarly, if it doesnâ€™t terminate by 12 either then the next expected duration would be 14, and
finally 15. In other words for all states where a has been executing for times 0 to 8, it is expected to
terminate at 8. For all times between 8 and 12 the expected completion is at 12, for 12 to 14 it is 14
and if it doesnâ€™t terminate at 14 then it is 15. 2
6.2.2 O FFLINE V ERSION
This algorithm also has an offline version in which re-planning for all contingencies is done ahead of
time and for fairness we used this version in the experiments. Although the offline algorithm plans
for all possible action durations, it is still much faster than the other algorithms. The reason is that
each of the planning problems solved is now significantly smaller (less branching factor, smaller
reachable state space), and all the previous computation can be succinctly stored in the form of the
hinterwoven state, valuei pairs and thus reused. Algorithm 6 describes this offline planner and the
subsequent example illustrates the savings.
Algorithm 6 Offline âˆ†DURexp
1: build a deterministic-duration policy from the start state s0 ; get current J - and Ï€ - values
â€“
â€“
2: insert s0 in the queue open
3: repeat
4:
state = open.pop()
5:
for all currstate s.t. Pr - (currstate|state, Ï€ âˆ—- (state)) > 0 do

â€“
â€“
if currstate is not goal and currstate is not in the set visited then
visited.insert(currstate)
if J â€“- (currstate) has not converged then
if required, change the expected durations of the actions that are currently executing in
currstate.
10:
solve a deterministic-duration planning problem with the start state currstate
11:
insert currstate in the queue open
12: until open is empty
6:
7:
8:
9:

Line 9 of Algorithm 6 assigns a new expected duration for all actions that are currently running
in the current state and have not completd by the time of their previous termination point. This
reassignment follows the similar case in the online version (line 13).
Example: Consider a domain with two state-variables, x1 and x2 , with two actions set-x1 and
set-x2 . The task is to set both variables (initially they are both false). Assume that set-x2 always
succeeds whereas set-x1 succeeds with only 0.5 probability. Moreover, let both actions have a
uniform duration distribution of 1, 2, or 3. In such a case a complete interwoven epoch search
could touch 36 interwoven states (each state variable could be true or false, each action could be
â€œnot runningâ€, â€œrunning for 1 unitâ€, and â€œrunning for 2 unitsâ€). Instead, if we build a deterministic
duration policy then each actionâ€™s deterministic duration will be 2, and so the total number of states
touched will be from the 16 interwoven states (each action could now only be â€œnot runningâ€ or
â€œrunning for 1 unitâ€).
66

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Problem
A2

B2

G

C2

D

G

Optimal Solution (Trajectory 1, pr =0.5, makeâˆ’span 9)
A2

B2

G

C2

Optimal Solution (Trajectory 2, pr =0.5, makeâˆ’span 5)
A2
C2

D

G

DUR exp Solution (makeâˆ’span 8)
A2

Time

0

B2
4

G
8

12

Figure 14: An example of a domain where the âˆ†DURexp algorithm does not compute an optimal solution.
Now, suppose that the deterministic planner decides to execute both actions in the start state.
Having committed to this combination, it is easy to see that certain states will never be reached. For
example, the state h(Â¬x1 , Â¬x2 ), {(setâˆ’x1 , 2)}i can never be visited, since once set-x2 completes
it is guaranteed that x2 will be set. In fact, in our example, only 3 new states will initiate offline
replanning (line 10 in Algo 6), viz., h(x1 , Â¬x2 ), {(setâˆ’x2 , 2)}i, h(Â¬x1 , Â¬x2 ), {(setâˆ’x2 , 2)}i, and
h(Â¬x1 , x2 ), {(setâˆ’x1 , 2)}i 2
6.2.3 P ROPERTIES
Unfortunately, our âˆ†DURexp algorithm is not guaranteed to produce an optimal policy. How bad
are the policies generated by the expected-duration planner? The experiments show that âˆ†DURexp
typically generates policies which are extremely close to optimal. Even the worst-case pathological
domain we are able to construct leads to an expected make-span which is only 50% longer than
optimal (in the limit). This example is illustrated below.
Example: We consider a domain which has actions A2:n , B2:n , C2:n and D. Each Ai and Bi
takes time 2i . Each Ci has a probabilistic duration: with probability 0.5, Ci takes 1 unit of time,
and with the remaining probability, it takes 2i+1 + 1 time. Thus, the expected duration of Ci is
2i + 1. D takes 4 units. In sub-problem SPi , the goal may be reached by executing Ai followed
by Bi . Alternatively, the goal may be reached by first executing Ci and then recursively solving
the sub-problem SPiâˆ’1 . In this domain, the âˆ†DURexp algorithm will always compute hAi ; Bi i
as the best solution. However, the optimal policy starts both {Ai , Ci }. If Ci terminates at 1, the
policy executes the solution for SPiâˆ’1 ; otherwise, it waits until Ai terminates and then executes Bi .
Figure 14 illustrates the sub-problem SP2 in which the optimal policy has an expected make-span
of 7 (vs. âˆ†DURexp â€™s make-span of 8). In general, the expected make-span of the optimal policy on
3
SPn is 13 [2n+2 + 24âˆ’n ] + 22âˆ’n + 2. Thus, limnâ†’âˆž exp
opt = 2 .2
6.3 Multi-Modal Duration Distributions
The planners of the previous two sections benefited by considering the small set of happenings
instead of pivots, an approach licensed by Conjecture 8. Unfortunately, this simplification is not
67

M AUSAM & W ELD

warranted in the case of actions with multi-modal duration distributions, which can be common
in complex domains where all factors canâ€™t be modeled explicitly. For example, the amount of
time for a Mars rover to transmit data might have a bimodal distribution â€” normally it would
take little time, but if a dust storm were in progress (unmodeled) it could take much longer. To
handle these cases we model durations with a mixture of Gaussians parameterized by the triple
hamplitude, mean, variancei.
6.3.1 C O MDP F ORMULATION
Although we cannot restrict decision epochs to happenings, we need not consider all pivots; they
are required only for actions with multi-modal distributions. In fact, it suffices to consider pivots in
regions of the distribution where the expected-time-to-completion increases. In all other cases we
need consider only happenings.
Two changes are required to the transition function of Algorithm 4. In line 3, the maxtime
computation now involves time until the next pivot in the increasing remaining time region for
all actions with multi-modal distributions (thus forcing us to take a decision at those points, even
when no action terminates). Another change (in line 6) allows a non-empty subset Asub t for t =
maxtime. That is, next state is computed even without any action termination. By making these
changes in the transition function we reformulate our problem as a CoMDP in the interwoven space
and thus solve, using our previous methods of pruned/sampled RTDP, hybrid algorithm or expectedduration algorithm.
6.3.2 A RCHETYPAL -D URATION P LANNER
We also develop a multi-modal variation of the expected-duration planner, called âˆ†DURarch . Instead of assigning an action a single deterministic duration equal to the expected value, this planner
assigns it a probabilistic duration with various outcomes being the means of the different modes in
the distribution and the probabilities being the probability mass in each mode. This enhancement
reflects our intuitive understanding for multi-modal distributions and the experiments confirm that
âˆ†DURarch produces solutions having shorter make-spans than those of âˆ†DURexp .
6.4 Experiments: Planning with Stochastic Durations
We now evaluate our techniques for solving planning problems involving stochastic durations. We
compare the computation time and solution quality (make-span) of our five planners for domains
with and without multi-modal duration distributions. We also re-evaluate the effectiveness of the
maximum- (MC) and average-concurrency (AC) heuristics for these domains.
6.4.1 E XPERIMENTAL S ETUP
We modify our Rover, MachineShop, and Artificial domains by additionally including uncertainty
in action durations. For this set of experiments, our largest problem had 4 million world states
of which 65536 were reachable. Our algorithms explored up to 1,000,000 distinct states in the
interwoven state space during planning. The domains contained as many as 18 actions, and some
actions had as many as 13 possible durations. For more details on the domains please refer to the
longer version (Mausam, 2007).
68

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Planning Time (in sec)

6000
5000
4000

Rover

Machine-Shop

3000
âˆ†Pruned
DURprun
DURsamp
âˆ†Sampled
âˆ†DURhyb
Hybrid

2000
1000

âˆ†DURexp
Exp-Dur

0
21

22

23

24

25

26

27

28

29

30 Problems

Figure 15: Planning time comparisons for Rover and MachineShop domains: Variation along algorithms
when all initialized by the average concurrency (AC) heuristic; âˆ†DURexp performs the best.

Algos
âˆ†DURsamp
âˆ†DURhyb
âˆ†DURexp

Average Quality of Make-Span
Rover MachineShop Artificial
1.001
1.000
1.001
1.022
1.011
1.019
1.008
1.015
1.046

Table 4: All three planners produce near-optimal policies as shown by this table of ratios to the
optimal make-span.11

6.4.2 C OMPARING RUNNING T IMES
We compare all algorithms with and without heuristics and reaffirm that the heuristics significantly
speed up the computation on all problems; indeed, some problems are too large to be solved without
heuristics. Comparing them amongst themselves we find that AC beats M C â€” regardless of the
planning algorithm; this isnâ€™t surprising since AC sacrifices admissibility.
Figure 15 reports the running times of various algorithms (initialized with the AC heuristic) on
the Rover and Machine-Shop domains when all durations are unimodal. âˆ†DURexp out-performs
the other planners by substantial margins. As this algorithm is solving a comparatively simpler
problem, fewer states are expanded and thus the approximation scales better than others â€” solving,
for example, two Machine-Shop problems, which were too large for most other planners. In most
cases hybridization speeds planning by significant amounts, but it performs better than âˆ†DURexp
only for the artificial domain.
6.4.3 C OMPARING S OLUTION Q UALITY
We measure quality by simulating the generated policy across multiple trials. We report the ratio
of average expected make-span and the optimal expected make-span for domains with all unimodal
distributions in Table 4. We find that the make-spans of the inadmissible heuristic AC are at par
11. If the optimal algorithm doesnâ€™t converge, we use the best solution found across all runs as â€œoptimalâ€.

69

M AUSAM & W ELD

28
26
24

1000
âˆ†DURprun
Pruned
âˆ†DURsamp
Sampled

100

J*(s0)

Planning time (log scale)

10000

âˆ†DURhyb
Hybrid
âˆ†DURarch
Arch-Dur
âˆ†DURexp
Exp-Dur

10

22
âˆ†DURprun
DUR-prun
âˆ†DURsamp
DUR-samp

20
18

âˆ†DURhyb
DUR-hyb
âˆ†DURarch
DUR-arch

16

âˆ†DURexp
DUR-exp

14

31

32

33

34

35

36 Problems

31

32

33

34

35

36 Problems

Figure 16: Comparisons in the Machine-Shop domain with multi-modal distributions. (a) Computation
Time comparisons: âˆ†DURexp and âˆ†DURarch perform much better than other algos. (b) Makespans returned by different algos: Solutions returned by âˆ†DURsamp are almost optimal. Overall
âˆ†DURarch finds a good balance between running time and solution quality.

with those of the admissible heuristic M C. The hybridized planner is approximate with a userdefined bound. In our experiments, we set the bound to 5% and find that the make-spans returned
by the algorithm are quite close to the optimal and do not always differ by 5%. âˆ†DURexp has no
quality guarantees, still the solutions returned on the problems we tested upon are nearly as good as
other algorithms. Thus, we believe that this approximation will be quite useful in scaling to larger
problems without losing solution quality.
6.4.4 M ULTIMODAL D OMAINS
We develop multi-modal variants of our domains; e.g., in the Machine-Shop domain, time for fetching paint was bimodal (if in stock, paint can be fetched fast, else it needs to be ordered). There
was an alternative but costly paint action that doesnâ€™t require fetching of paint. Solutions produced
by âˆ†DURsamp made use of pivots as decision epochs by starting the costly paint action in case the
fetch action didnâ€™t terminate within the first mode of the bimodal distribution (i.e. paint was out of
stock).
The running time comparisons are shown in Figure 16(a) on a log-scale. We find that âˆ†DURexp
terminates extremely quickly and âˆ†DURarch is not far behind. However, the make-span comparisons in Figure 16(b) clearly illustrate the approximations made by these methods in order to achieve
planning time. âˆ†DURarch exhibits a good balance of planning time and solution quality.

7. Related Work
This paper extends our prior work, originally reported in several conference publications (Mausam
& Weld, 2004, 2005, 2006a, 2006b).
Temporal planners may be classified as using constraint-posting or extended state-space methods (discussed earlier in Section 4). While the constraint approach is promising, few (if any) probabilistic planners have been implemented using this architecture; one exception is Buridan (Kush70

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

stochastic

deterministic

concurrent
durative
non-durative
âˆ†DUR, Tempastic,
Concurrent MDP,
GSMDP, Prottle,
Factorial MDP,
FPG, Aberdeen et al.
Paragraph
Temporal Planning
Step-optimal planning
(TP4, Sapa, MIPS
(GraphPlan, SATPlan)
TLPlan, etc.)

non-concurrent
durative
non-durative
Time Dependent MDP,
MDP
IxTeT, CIRCA,
(RTDP, LAO*, etc.)
Foss & Onder
Planning with
Classical Planning
Numerical Resources
(HSP, FF, etc.)
(Sapa, Metric-FF, CPT)

Figure 17: A table listing various planners that implement different subsets of concurrent, stochastic, durative actions.

merick, Hanks, & Weld, 1995), which performed poorly. In contrast, the MDP community has
proven the state-space approach successful. Since the powerful deterministic temporal planners,
which have won the various planning competitions, also use the state-space approach, we adopt it
for our algorithms that combine temporal planning with MDPs. It may be interesting to incorporate
constraint-based approaches in a probabilistic paradigm and compare against the techniques of this
paper.
7.1 Comparison with Semi-MDPs
A Semi-Markov Decision Process is an extension of MDPs that allows durative actions to take variable time. A discrete time semi-MDP can be solved by solving a set of equations that is a direct
extension of Equations 2. The techniques for solving discrete time semi-MDPs are natural generalizations of those for MDPs. The main distinction between a semi-MDP and our formulation of
concurrent probabilistic temporal planning with stochastic durations concerns the presence of concurrently executing actions in our model. A semi-MDP does not allow for concurrent actions and
assumes one executing action at a time. By allowing concurrency in actions and intermediate decision epochs, our algorithms need to deal with large state and action spaces, which is not encountered
by semi-MDPs.
Furthermore, Younes and Simmons have shown that in the general case, semi-MDPs are incapable of modeling concurrency. A problem with concurrent actions and stochastic continuous
durations needs another model known as Generalized Semi-Markov Decision Process (GSMDP)
for a precise mathematical formulation (Younes & Simmons, 2004b).
7.2 Concurrency and Stochastic, Durative Actions
Tempastic (Younes & Simmons, 2004a) uses a rich formalism (e.g. continuous time, exogenous
events, and expressive goal language) to generate concurrent plans with stochastic durative actions. Tempastic uses a completely non-probabilistic planner to generate a plan which is treated
as a candidate policy and repaired as failure points are identified. This method does not guarantee
completeness or proximity to the optimal. Moreover, no attention was paid towards heuristics or
search control making the implementation impractical.
GSMDPs (Younes & Simmons, 2004b) extend continuous-time MDPs and semi-Markov MDPs,
modeling asynchronous events and processes. Both of Younes and Simmonsâ€™s approaches handle
71

M AUSAM & W ELD

a strictly more expressive model than ours due to their modeling of continuous time. They solve
GSMDPs by approximation with a standard MDP using phase-type distributions. The approach
is elegant, but its scalability to realistic problems is yet to be demonstrated. In particular, the approximate, discrete MDP model can require many states yet still behave very differently than the
continuous original.
Prottle (Little et al., 2005) also solves problems with an action language more expressive than
ours: effects can occur in the middle of action execution and dependent durations are supported.
Prottle uses an RTDP-type search guided by heuristics computed from a probabilistic planning
graph; however, it plans for a finite horizon â€” and thus for an acyclic state space. It is difficult to
compare Prottle with our approach because Prottle optimizes a different objective function (probability of reaching a goal), outputs a finite-length conditional plan as opposed to a cyclic plan or
policy, and is not guaranteed to reach the goal.
FPG (Aberdeen & Buffet, 2007) learns a separate neural network for each action individually
based on the current state. In the execution phase the decision, i.e., whether an action needs to be
executed or not, is taken independently of decisions regarding other actions. In this way FPG is able
to effectively sidestep the blowup caused by exponential combinations of actions. In practice it is
able to very quickly compute high quality solutions.
Rohanimanesh and Mahadevan (2001) investigate concurrency in a hierarchical reinforcement
learning framework, where abstract actions are represented by Markov options. They propose an
algorithm based on value-iteration, but their focus is calculating joint termination conditions and rewards received, rather than speeding policy construction. Hence, they consider all possible Markov
option combinations in a backup.
Aberdeen et al. (2004) plan with concurrent, durative actions with deterministic durations in a
specific military operations domain. They apply various domain-dependent heuristics to speed the
search in an extended state space.
7.3 Concurrency and Stochastic, Non-durative Actions
Meuleau et al. and Singh & Cohn deal with a special type of MDP (called a factorial MDP) that
can be represented as a set of smaller weakly coupled MDPs â€” the separate MDPs are completely
independent except for some common resource constraints, and the reward and cost models are
purely additive (Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean, & Boutilier, 1998; Singh
& Cohn, 1998). They describe solutions in which these sub-MDPs are independently solved and
the sub-policies are merged to create a global policy. Thus, concurrency of actions of different
sub-MDPs is a by-product of their work. Singh & Cohn present an optimal algorithm (similar to
combo-elimination used in DURprun ), whereas domain specific heuristics in Meuleau et al. have no
such guarantees. All of the work in Factorial MDPs assumes that a weak coupling exists and has
been identified, but factoring an MDP is a hard problem in itself.
Paragraph (Little & Thiebaux, 2006) formulates the planning with concurrency as a regression
search over the probabilistic planning graph. It uses techniques like nogood learning and mutex
reasoning to speed policy construction.
Guestrin et al. solve the multi-agent MDP problem by using a linear programming (LP) formulation and expressing the value function as a linear combination of basis functions. By assuming
that these basis functions depend only on a few agents, they are able to reduce the size of the LP
(Guestrin, Koller, & Parr, 2001).
72

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

7.4 Stochastic, Non-concurrent, Durative Actions
Many researchers have studied planning with stochastic, durative actions in absence of concurrency.
For example, Foss and Onder (2005) use simple temporal networks to generate plans in which the
objective function has no time component. Simple Temporal Networks allow effective temporal
constraint reasoning and their methods can generate temporally contingent plans.
Boyan and Littman (2000) propose Time-dependent MDPs to model problems with actions that
are not concurrent and have time-dependent, stochastic durations; their solution generates piecewise linear value functions.
NASA researchers have developed techniques for generating non-concurrent plans with uncertain continuous durations using a greedy algorithm which incrementally adds branches to a straightline plan (Bresina et al., 2002; Dearden, Meuleau, Ramakrishnan, Smith, & Washington, 2003).
While they handle continuous variables and uncertain continuous effects, their solution is heuristic
and the quality of their policies is unknown. Also, since they consider only limited contingencies,
their solutions are not guaranteed to reach the goal.
IxTeT is a temporal planner that uses constraint based reasoning within partial order planning
(Laborie & Ghallab, 1995). It embeds temporal properties of actions as constraints and does not
optimize make-span. CIRCA is an example of a system that plans with uncertain durations where
each action is associated with an unweighted set of durations (Musliner, Murphy, & Shin, 1991).
7.5 Deterministic, Concurrent, Durative Actions
Planning with deterministic actions is a comparitively simpler problem and much of the work in
planning under uncertainty is based on the previous, deterministic planning research. For instance,
our interwoven state representation and transition function are extensions of the extended state representations in TP4, SAPA, and TLPlan (Haslum & Geffner, 2001; Do & Kambhampati, 2003;
Bacchus & Ady, 2001).
Other planners, like MIPS and AltAltp , have also investigated fast generation of parallel plans
in deterministic settings (Edelkamp, 2003; Nigenda & Kambhampati, 2003) and Jensen and Veloso
(2000) extend it to problems with disjunctive uncertainty.

8. Future Work
Having presented a comprehensive set of techniques to handle probabilistic outcomes, concurrent
and durative actions in a single formalism, we now direct our attention towards different relaxations
and extensions to the proposed model. In particular, we explore other objective functions, infinite
horizon problems, continuous-valued duration distributions, temporally expressive action models,
degrees of goal satisfaction and interruptibility of actions.
8.1 Extension to Other Cost Functions
For the planning problems with durative actions (sections 4 and beyond) we focused on make-span
minimization problems. However, our techniques are quite general and are applicable (directly
or with minor variations) to a variety of cost metrics. As an illustration, consider the mixed cost
optimization problem in which in addition to the duration of each action, we are also given the
amount of resource consumed per action, and we wish to minimize the the sum of make-span
and total resource usage. Assuming that the resource consumption is unaffected by concurrent
73

M AUSAM & W ELD

execution, we can easily compute a new max-concurrency heuristic. The mixed-cost counterpart
for Equations 12 is:
Jtâˆ— (X)
+ Jrâˆ— (X)
for Y = âˆ…
c
Qâˆ—t (X, As )
+ Qâˆ—r (X, As ) for Y 6= âˆ…
c

J âˆ—- (s) â‰¥
â€“
J âˆ—- (s) â‰¥
â€“

(15)

Here, Jt is for the single-action MDP assignng costs to be durations and Jr is for the single
action MDP assigning costs to be resource consumptions. A more informed average concurrency
heuristic can be similarly computed by replacing maximum concurrency by average concurrency.
The hybridized algorithm follows in the same fashion, with the fast algorithm being a CoMDP
solved using techniques of Section 3.
On the same lines, if the objective function is to minimize make-span given a certain maximum
resource usage, then the total amount of resource remaining can be included in the state-space for
all the CoMDPs and underlying single-action MDPs etc. and the same techniques may be used.
8.2 Infinite Horizon Problems
Until now this paper has defined the techniques for the case of indefinite horizon problems, in
which an absorbing state is defined as is reachable. For other problems an alternative formulation is
preferred that allows for infinite execution but discounts the future costs by multiplying them by a
discount factor in each step. Again, our techniques can be suitably extended for such scenario. For
example, Theorem 2 gets modified to the following:
Qk (s, A) â‰¥ Î³

1âˆ’k

Qk (s, {a1 }) + Ck (A) âˆ’

k
X

!

Î³

iâˆ’k

Ck ({ai })

i=1

Recall that this theorem provides us with the pruning rule, combo-skipping. Thus, we can use
Pruned RTDP with the new pruning rule.
8.3 Extensions to Continuous Duration Distributions
Until now we have confined ourselves to actions with discrete durations (refer to Assumption 3).
We now investigate the effects of dealing directly with continuous uncertainty in the duration distributions. Let fiT (t)dt be the probability of action ai completing between times t + T and t + T + dt,
conditioned on action ai not finishing until time T . Similarly, define FiT (t) to be the probability of
the action finishing after time t + T .
Let us consider the extended state hX, {(a1 , T )}i, which denotes that action a1 started T units
ago in the world state X. Let a2 be an applicable action that is started in this extended state. Define
M = min(âˆ†M (a1 )âˆ’T, âˆ†M (a2 )), where âˆ†M denotes the maximum possible duration of execution
for each action. Intuitively, M is the time by which at least one action will complete. Then

Q â€“- n+1 (hX, {(a1 , T )}i, a2 ) =

Z M
0

Z M
0

h

i

f1T (t)F20 (t) t + J â€“- n (hX1 , {a2 , t}i) dt +
h

i

F1T (t)f20 (t) t + J â€“- n (hX2 , {a1 , t + T }i) dt
74

(16)

0

2

4

Time

6

8

10

10

10

Expected time to reach the goal

Expected Remaining Time for action a0

Duration Distribution of a0

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

8
6
4
2

0

2

4

Time

6

8

10

8
6
4
2

0

2

4

6

8

10

Time

Figure 18: If durations are continuous (real-valued) rather than discrete, there may be an infinite number of
potentially important decision epochs. In this domain, a crucial decision epoch could be required
at any time in (0, 1] â€” depending on the length of possible alternate plans.

Here X1 and X2 are world states obtained by applying the deterministic actions a1 and a2
respectively on X. Recall that J â€“- n+1 (s) = mina Q â€“- n+1 (s, a). For a fixed point computation of

this form, we desire that Jn+1 and Jn have the same functional form12 . Going by the equation
above this seems very difficult to achieve, except perhaps for very specific action distributions in
some special planning problems. For example, if all distributions are constant or if there is no
concurrency in the domain, then these equations are easily solvable. But for more interesting cases,
solving these equations is a challenging open question.
Furthermore, dealing with continuous multi-modal distributions worsens the decision epochs
explosion. We illustrate this with the help of an example.
Example: Consider the domain of Figure 7 except that let action a0 have a bimodal distribution,
the two modes being uniform between 0-1 and 9-10 respectively as shown in Figure 18(a). Also
let a1 have a very small duration. Figure 18(b) shows the expected remaining termination times
if a0 terminates at time 10. Notice that due to bimodality, this expected remaining execution time
increases between 0 and 1. The expected time to reach the goal using plan h{a0 , a1 }; a2 i is shown
in the third graph. Now suppose, we have started {a0 , a1 }, and we need to choose the next decision
epoch. It is easy to see that the optimal decision epoch could be any point between 0 and 1 and
would depend on the alternative routes to the goal. For example, if duration of b0 is 7.75, then the
optimal time-point to start the alternative route is 0.5 (right after the expected time to reach the goal
using first plan exceeds 7.75).
Thus, the choice of decision epochs depends on the expected durations of the alternative routes.
But these values are not known in advance, in fact these are the ones being calculated in the planning
phase. Therefore, choosing decision epochs ahead of time does not seem possible. This makes the
optimal continuous multi-modal distribution planning problem mostly intractable for any reasonable
sized problem.
8.4 Generalizing the TGP Action Model
The assumption of TGP style actions enables us to compute optimal policies, since we can prune the
number of decision epochs. In the case of complex action models like PDDL2.1 (Fox & Long, 2003),
all old, deterministic state-space planners are incomplete. For the same reasons, our algorithms are
12. This idea has been exploited in order to plan with continuous resources (Feng, Dearden, Meuleau, & Washington,
2004).

75

M AUSAM & W ELD

incomplete for problems in PPDDL2.1 . Recently, Cushing et al. have introduced Tempo, a statespace planner, which uses lifting over time in to achieve completeness (Cushing, Kambhampati,
Mausam, & Weld, 2007). In pursuit of finding a complete, state-space, probabilistic planner for
complex action models, a natural step is to consider a Tempo-like representation in a probabilistic
setting. While working out the details seems relatively straightforward, the important research
challenge will be to find the right heuristics to streamline the search so that the algorithm can scale.
8.5 Other Extensions
There are several other extensions to the basic framework that we have suggested. Each different
construct introduces additional structure and we need to exploit the knowledge in order to design
fast algorithms. Many times, the basic algorithms proposed in this paper may be easily adapted to
such situations, sometimes they may be not. We list two of the important extensions below.
â€¢ Notion of Goal Satisfaction: Different problems may require slightly different notions of
when a goal is reached. For example, we have assumed thus far that a goal is not â€œofficially
achievedâ€ until all executed actions have terminated. Alternatively, one might consider a goal
to be achieved if a satisfactory world state is reached, even though some actions may be in the
midst of execution. There are intermediate possibilities in which a goal requires some specific
actions to necessarily end. Just by changing the definition of the goal set, these problems can
be modeled as a CoMDP. The hybridized algorithm and the heuristics can be easily adapted
for this case.
â€¢ Interruptible Actions: We have assumed that, once started, an action cannot be terminated.
However, a richer model may allow preemptions, as well as the continuation of an interrupted
action. The problems, in which all actions could be interrupted at will, have a significantly
different flavor. Interrupting an action is a new kind of decision and requires a full study of
when might an action termination be useful. To a large extent, planning with these is similar
to finding different concurrent paths to the goal and starting all of them together, since one can
always interrupt all the executing paths as soon as the goal is reached. For instance, example
in Figure 7 no longer holds since b0 can be started at time 1, and later terminated as needed
to shorten the make-span.
8.6 Effect of Large Durations
A weakness of all extended-state space approaches, both in deterministic as well as probabilistic
settings, is the dependence on absolute durations (or to be more accurate, the greatest common
divisor of action durations). For instance, if the domain has an action a with a large duration,
say 100 and another concurrently executable action with duration 1, then all world states will be
explored with the tuples (a, 1), (a, 2), . . ., (a, 98), (a, 99). In general, many of these states will
behave similarly and there will be certain decision boundaries that will be important. â€œStart b if
a has been executing for 50 units and c otherwiseâ€ is one example of such a decision boundary.
Instead of representing all these flat discrete states individually, planning in an aggregate space in
which each state represents several extended states will help alleviate this inefficiency.
However, it is not obvious how to achieve such an aggregation automatically, since adapting
the well-known methods for aggregation do not hold in our case. For instance, SPUDD (Hoey
76

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

et al., 1999) uses algebraic decision diagrams to represent abstract states that have the same Jvalue. Aggregating the same valued states may not be enough for us, since the expected time of
completion depends linearly on the amount of time left for the longest executing action. So, all
the states which differ only by the amount of time an action has been executing will not be able
to aggregate together. In a similar way, Feng et al. (2004) use piecewise constant and piecewise
linear representations to adaptively discretize continuous variables. In our case, we have |A| of
such variables. While only a few of them that are executing are active at a given time, modeling a
sparse high-dimensional value function is not easy either. Being able to exploit this structure due
to action durations is an essential future direction in order to scale the algorithms to complex real
world domains.

9. Conclusions
Although concurrent and durative actions with stochastic effects characterize many real-world domains, few planners can handle all these challenges in concert. This paper proposes a unified statespace based framework to model and solve such problems. State space formulations are popular
both in deterministic temporal planning as well as in probabilistic planning. However, each of these
features bring in additional complexities to the formulation and afford new solution techniques. We
develop the â€œDURâ€ family of algorithms to alleviates these complexities. We evaluate the techniques on the running times and qualities of solutions produced. Moreover, we study the theoretical
properties of these domains and also identify key conditions under which fast, optimal algorithms
are possible. We make the following contributions:
1. We define Concurrent MDPs (CoMDP) â€” an extension of the MDP model to formulate a
stochastic planning problem with concurrent actions. A CoMDP can be cast back into a new
MDP with an extended action space. Because this action space is possibly exponential in
the number of actions, solving the new MDP naively may take a huge performance hit. We
develop the general notions of pruning and sampling to speed up the algorithms. Pruning
refers to pruning of the provably sub-optimal action-combinations for each state, thus performing less computation but still guaranteeing optimal solutions. Sampling-based solutions
rely on an intelligent sampling of action-combinations to avoid dealing with their exponential
number. This method converges orders of magnitude faster than other methods and produces
near-optimal solutions.
2. We formulate the planning with concurrent, durative actions as a CoMDP in two modified
state spaces â€” aligned epoch, and interwoven epoch. While aligned epoch based solutions
run very fast, interwoven epoch algorithms yield a much higher quality solutions. We also define two heuristic functions â€” maximum concurrency (MC), and average concurrency (AC)
to guide the search. MC is an admissible heuristic, whereas AC, while inadmissible, is typically more-informed leading to better computational gains. We call our algorithms the â€œDURâ€
family of algorithms. The subscripts samp or prun refer to sampling and pruning respectively,
optional superscripts AC or MC refer to the heuristic employed, if any and an optional "âˆ†"
before DUR notifies a problem with stochastic durations. For example, Labeled RTDP for
a deterministic duration problem employing sampling and started with AC heuristic will be
abbreviated as DURAC
samp .
77

M AUSAM & W ELD

3. We also develop the general technique of hybridizing two planners. Hybridizing interwovenepoch and aligned-epoch CoMDPs yields a much more efficient algorithm, DURhyb . The
algorithm has a parameter, which can be varied to trade-off speed against optimality. In
our experiments, DURhyb quickly produces near-optimal solutions. For larger problems, the
speedups over other algorithms are quite significant. The hybridized algorithm can also be
used in an anytime fashion thus producing good-quality proper policies (policies that are
guaranteed to reach the goal) within a desired time. Moreover, the idea of hybridizing two
planners is a general notion; recently it has been applied to solving general stochastic planning
problems (Mausam, Bertoli, & Weld, 2007).
4. Uncertainty in durations leads to more complexities because in addition to state and action
spaces, there is also a blowup in the branching factor and in the number of decision epochs.
We bound the space of decision epochs in terms of pivots (times when actions may potentially terminate) and conjecture further restrictions, thus making the problem tractable. We
also propose two algorithms, the expected duration planner (âˆ†DURexp ) and the archetypal
duration planner (âˆ†DURarch ), which successively solve small planning problems each with
no or limited duration uncertainty, respectively. âˆ†DURarch is also able to make use of the
additional structure offered by multi-modal duration distributions. These algorithms perform
much faster than other techniques. Moreover, âˆ†DURarch offers a good balance between
planning time vs. solution quality tradeoff.
5. Besides our focus on stochastic actions, we expose important theoretical issues related with
durative actions which have repercussions to deterministic temporal planners as well. In
particular, we prove that all common state-space temporal planners are incomplete in the face
of expressive action models, e.g., PDDL2.1 , a result that may have a strong impact on the
future temporal planning research (Cushing et al., 2007).
Overall, this paper proposes a large set of techniques that are useful in modeling and solving
planning problems employing stochastic effects, concurrent executions and durative actions with
duration uncertainties. The algorithms range from fast but suboptimal solutions, to relatively slow
but optimal. Various algorithms that explore different intermediate points in this spectrum are also
presented. We hope that our techniques will be useful in scaling the planning techniques to real
world problems in the future.

Acknowledgments
We thank Blai Bonet for providing the source code of GPT as well as for comments in the course
of this work. We are thankful to Sumit Sanghai for his theorem proving skills and advice at various
stages of this research. We are grateful to Derek Long and the anonymous reviewers of this paper
who gave several thoughtful suggestions for generalizing the theory and improving the clarity of the
text. We also thank Subbarao Kambhampati, Daniel Lowd, Parag, David Smith and all others who
provided useful comments on drafts on parts of this research. This work was performed at University of Washington between 2003 and 2007 and was supported by generous grants from National
Aeronautics and Space Administration (Award NAG 2-1538), National Science Foundation (Award
IIS-0307906), and Office of Naval Research (Awards N00014-02-1-0932, N00014-06-1-0147) and
the WRF / TJ Cable Professorship.
78

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

References
Aberdeen, D., Thiebaux, S., & Zhang, L. (2004). Decision-theoretic military operations planning.
In ICAPSâ€™04.
Aberdeen, D., & Buffet, O. (2007).
gradients. In ICAPSâ€™07.

Concurrent probabilistic temporal planning with policy-

Bacchus, F., & Ady, M. (2001). Planning with resources and concurrency: A forward chaining
approach. In IJCAIâ€™01, pp. 417â€“424.
Barto, A., Bradtke, S., & Singh, S. (1995). Learning to act using real-time dynamic programming.
Artificial Intelligence, 72, 81â€“138.
Bertsekas, D. (1995). Dynamic Programming and Optimal Control. Athena Scientific.
Blum, A., & Furst, M. (1997). Fast planning through planning graph analysis. Artificial Intelligence,
90(1â€“2), 281â€“300.
Bonet, B., & Geffner, H. (2003). Labeled RTDP: Improving the convergence of real-time dynamic
programming. In ICAPSâ€™03, pp. 12â€“21.
Bonet, B., & Geffner, H. (2005). mGPT: A probabilistic planner based on heuristic search. JAIR,
24, 933.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision theoretic planning: Structural assumptions
and computational leverage. J. Artificial Intelligence Research, 11, 1â€“94.
Boyan, J. A., & Littman, M. L. (2000). Exact solutions to time-dependent MDPs. In NIPSâ€™00, p.
1026.
Bresina, J., Dearden, R., Meuleau, N., Smith, D., & Washington, R. (2002). Planning under continuous time and resource uncertainty : A challenge for AI. In UAIâ€™02.
Chen, Y., Wah, B. W., & Hsu, C. (2006). Temporal planning using subgoal partitioning and resolution in sgplan. JAIR, 26, 323.
Cushing, W., Kambhampati, S., Mausam, & Weld, D. S. (2007). When is temporal planning really
temporal?. In IJCAIâ€™07.
Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D. E., & Washington, R. (2003). Incremental
Contingency Planning. In ICAPSâ€™03 Workshop on Planning under Uncertainty and Incomplete Information.
Do, M. B., & Kambhampati, S. (2001). Sapa: A domain-independent heuristic metric temporal
planner. In ECPâ€™01.
Do, M. B., & Kambhampati, S. (2003). Sapa: A scalable multi-objective metric temporal planner.
JAIR, 20, 155â€“194.
Edelkamp, S. (2003). Taming numbers and duration in the model checking integrated planning
system. Journal of Artificial Intelligence Research, 20, 195â€“238.
79

M AUSAM & W ELD

Feng, Z., Dearden, R., Meuleau, N., & Washington, R. (2004). Dynamic programming for structured continuous Markov decision processes. In UAIâ€™04, p. 154.
Foss, J., & Onder, N. (2005). Generating temporally contingent plans. In IJCAIâ€™05 Workshop on
Planning and Learning in Apriori Unknown or Dynamic Domains.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal planning
domains.. JAIR Special Issue on 3rd International Planning Competition, 20, 61â€“124.
Gerevini, A., & Serina, I. (2002). LPG: A planner based on local search for planning graphs with
action graphs. In AIPSâ€™02, p. 281.
Guestrin, C., Koller, D., & Parr, R. (2001). Max-norm projections for factored MDPs. In IJCAIâ€™01,
pp. 673â€“682.
Hansen, E., & Zilberstein, S. (2001). LAO*: A heuristic search algorithm that finds solutions with
loops. Artificial Intelligence, 129, 35â€“62.
Haslum, P., & Geffner, H. (2001). Heuristic planning with time and resources. In ECPâ€™01.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using decision
diagrams. In UAIâ€™99, pp. 279â€“288.
Jensen, R. M., & Veloso, M. (2000). OBDD=based universal planning for synchronized agents in
non-deterministic domains. Journal of Artificial Intelligence Research, 13, 189.
Kushmerick, N., Hanks, S., & Weld, D. (1995). An algorithm for probabilistic planning. Artificial
Intelligence, 76(1-2), 239â€“286.
Laborie, P., & Ghallab, M. (1995). Planning with sharable resource constraints. In IJCAIâ€™95, p.
1643.
Little, I., Aberdeen, D., & Thiebaux, S. (2005). Prottle: A probabilistic temporal planner. In
AAAIâ€™05.
Little, I., & Thiebaux, S. (2006). Concurrent probabilistic planning in the graphplan framework. In
ICAPSâ€™06.
Long, D., & Fox, M. (2003). The 3rd international planning competition: Results and analysis.
JAIR, 20, 1â€“59.
Mausam (2007). Stochastic planning with concurrent, durative actions. Ph.d. dissertation, University of Washington.
Mausam, Bertoli, P., & Weld, D. (2007). A hybridized planner for stochastic domains. In IJCAIâ€™07.
Mausam, & Weld, D. (2004). Solving concurrent Markov decision processes. In AAAIâ€™04.
Mausam, & Weld, D. (2005). Concurrent probabilistic temporal planning. In ICAPSâ€™05, pp. 120â€“
129.
80

P LANNING WITH D URATIVE ACTIONS IN S TOCHASTIC D OMAINS

Mausam, & Weld, D. (2006a). Challenges for temporal planning with uncertain durations. In
ICAPSâ€™06.
Mausam, & Weld, D. (2006b). Probabilistic temporal planning with uncertain durations. In
AAAIâ€™06.
Meuleau, N., Hauskrecht, M., Kim, K.-E., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier, C.
(1998). Solving very large weakly coupled Markov Decision Processes. In AAAIâ€™98, pp.
165â€“172.
Musliner, D., Murphy, D., & Shin, K. (1991). World modeling for the dynamic construction of
real-time control plans. Artificial Intelligence, 74, 83â€“127.
Nigenda, R. S., & Kambhampati, S. (2003). Altalt-p: Online parallelization of plans with heuristic
state search. Journal of Artificial Intelligence Research, 19, 631â€“657.
Penberthy, J., & Weld, D. (1994). Temporal planning with continuous change. In AAAIâ€™94, p. 1010.
Rohanimanesh, K., & Mahadevan, S. (2001). Decision-Theoretic planning with concurrent temporally extended actions. In UAIâ€™01, pp. 472â€“479.
Singh, S., & Cohn, D. (1998). How to dynamically merge markov decision processes. In NIPSâ€™98.
The MIT Press.
Smith, D., & Weld, D. (1999). Temporal graphplan with mutual exclusion reasoning. In IJCAIâ€™99,
pp. 326â€“333 Stockholm, Sweden. San Francisco, CA: Morgan Kaufmann.
Vidal, V., & Geffner, H. (2006). Branching and pruning: An optimal temporal pocl planner based
on constraint programming. AIJ, 170(3), 298â€“335.
Younes, H. L. S., & Simmons, R. G. (2004a). Policy generation for continuous-time stochastic
domains with concurrency. In ICAPSâ€™04, p. 325.
Younes, H. L. S., & Simmons, R. G. (2004b). Solving generalized semi-markov decision processes
using continuous phase-type distributions. In AAAIâ€™04, p. 742.
Zhang, W., & Dietterich, T. G. (1995). A reinforcement learning approach to job-shop scheduling.
In IJCAIâ€™95, pp. 1114â€“1120.

Appendix A
Proof of Theorem 6
We now prove the statement of Theorem 6, i.e., if all actions are TGP-style then the set of pivots
suffices for optimal planning. In the proof make use of the fact that if all actions are TGP-style then
a consistent execution of any concurrent plan requires that any two executing actions be non-mutex
(refer to Section 5 for an explanation on that). In particular, none of their effects conflict and a
precondition of one does not conflict with the effects of the another.
We prove our theorem by contradition. Let us assume that for a problem each optimal solution
requires at least one action to start at a non-pivot. Let us consider one of those optimal plans, in
81

M AUSAM & W ELD

which the first non-pivot point at which an action needs to start at a non-pivot is minimized. Let
us name this time point t and let the action that starts at that point be a. We now prove by a case
analysis that we may, as well, start a at time t âˆ’ 1 without changing the nature of the plan. If t âˆ’ 1
is also a non-pivot then we contradict the hypothesis that t is the minimum first non-pivot point. If
t âˆ’ 1 is pivot then our hypothesis is contradicted because a does not "need to" start at a non-pivot.
To prove that a can be left-shifted by 1 unit, we take up one trajectory at a time (recall that
actions could have several durations) and consider all actions playing a role at t âˆ’ 1, t, t + âˆ†(a) âˆ’ 1,
and t + âˆ†(a), where âˆ†(a) refers to the duration of a in this trajectory. Considering these points
suffice, since the system state does not change at any other points on the trajectory. We prove that
the execution of none of these actions is affected by this left shift. There are the following twelve
cases:
1. âˆ€actions b that start at t âˆ’ 1: b canâ€™t end at t (t is a non-pivot). Thus a and b execute
concurrently after t, implies a and b are non-mutex. Thus a and b may as well start together.
2. âˆ€actions b that continue execution at t âˆ’ 1: Use the argument similar to case 1 above.
3. âˆ€actions b that end at t âˆ’ 1: Because b is TGP-style, its effects are realized in the open interval
ending at t âˆ’ 1. Therefore, start of a does not conflict with the end of b.
4. âˆ€actions b that start at t: a and b start together and hence are not dependent on each other
for preconditions. Also, they are non-mutex, so their starting times can be shifted in any
direction.
5. âˆ€actions b that continue execution at t: If b was started at t âˆ’ 1 refer to case 1 above. If not, t
and t âˆ’ 1 are both similar points for b.
6. âˆ€actions b that end at t: Case not possible due to the assumption that t is a non-pivot.
7. âˆ€actions b that start at t + âˆ†(a) âˆ’ 1: Since a continued execution at this point, a and b are
non-mutex. Thus aâ€™s effects do not clobber bâ€™s preconditions. Hence, b can still be executed
after realizing aâ€™s effects.
8. âˆ€actions b that continue execution at t + âˆ†(a) âˆ’ 1: a and b are non-mutex, so a may end
earlier without any effect of b.
9. âˆ€actions b that end at t + âˆ†(a) âˆ’ 1: a and b were executing concurrently. Thus they are
non-mutex. So they may end together.
10. âˆ€actions b that start at t + âˆ†(a): b may still start at t + âˆ†(a), since the state of t + âˆ†(a)
doesnâ€™t change.
11. âˆ€actions b that continue execution at t + âˆ†(a): If b was started at t + âˆ†(a) âˆ’ 1 refer to case
7 above, else there is no state change at t + âˆ†(a) to cause any effect on b.
12. âˆ€actions b that end at t + âˆ†(a): a and b are non-mutex because they were executing concurrently. Thus, aâ€™s effects donâ€™t clobber bâ€™s preconditions. Hence, a may end earlier.
Since a can be left shifted in all the trajectories, therefore the left-shift is legal. Also, if there
are multiple actions a that start at t they may each be shifted one by one using the same argument.
Hence Proved. 2
82

